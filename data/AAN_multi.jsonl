{"sub": "RWTH", "rel": "participated in", "objs": [{"obj": "System Combination task of the Fourth Workshop on Statistical Machine Translation (WMT 2009)", "doc-id": 26}, {"obj": "System Combination task of the Fifth Workshop on Statistical Machine Translation (WMT 2010)", "doc-id": 241}, {"obj": "Fourth Workshop of Statistical Machine Translation (WMT 2009)", "doc-id": 4194}], "score": 3, "question": "What events or projects did RWTH participate in?"}
{"sub": "word classes", "rel": "improves over", "objs": [{"obj": "translation quality", "doc-id": 29}, {"obj": "accuracy of syntactic disambiguation", "doc-id": 4568}], "score": 2, "question": "What are the various aspects or areas that word classes improve over?"}
{"sub": "BBN", "rel": "submitted", "objs": [{"obj": "system combination outputs", "doc-id": 75}, {"obj": "system combination outputs", "doc-id": 400}], "score": 2, "question": "What documents or proposals did BBN submit?"}
{"sub": "quality control", "rel": "is necessary for", "objs": [{"obj": "high-quality results", "doc-id": 95}, {"obj": "crowdsourcing to work well", "doc-id": 207}], "score": 2, "question": "What are the various processes or outcomes for which quality control is necessary?"}
{"sub": "n-code", "rel": "is based on", "objs": [{"obj": "bilingual n-grams", "doc-id": 154}, {"obj": "bilingual n-grams", "doc-id": 299}, {"obj": "bilingual n-grams", "doc-id": 628}, {"obj": "continuous space models", "doc-id": 628}], "score": 4, "question": "What are all the elements or concepts that n-code is based on?"}
{"sub": "online learning algorithm", "rel": "is based on", "objs": [{"obj": "stochastic gradient descent", "doc-id": 182}, {"obj": "tensor-space models", "doc-id": 1234}], "score": 2, "question": "What are the key principles or concepts that the online learning algorithm is based on?"}
{"sub": "WMT 2010", "rel": "include", "objs": [{"obj": "four language pairs", "doc-id": 287}, {"obj": "English to German, French, Spanish and Czech tracks", "doc-id": 2843}], "score": 2, "question": "What are all the entities included in WMT 2010?"}
{"sub": "Haitian Creole", "rel": "is on", "objs": [{"obj": "low-density language", "doc-id": 350}, {"obj": "source language", "doc-id": 4274}], "score": 2, "question": "What are all the topics or subjects that Haitian Creole is on?"}
{"sub": "University of Edinburgh", "rel": "participated in", "objs": [{"obj": "WMT 2013 Quality Estimation shared-task", "doc-id": 375}, {"obj": "2014 Workshop on Statistical Machine Translation", "doc-id": 2661}], "score": 2, "question": "What events or initiatives did the University of Edinburgh participate in?"}
{"sub": "Uppsala University", "rel": "describes", "objs": [{"obj": "WMT13 system", "doc-id": 379}, {"obj": "WMT14 systems", "doc-id": 1817}], "score": 2, "question": "What are the key aspects or features that Uppsala University describes?"}
{"sub": "dependency length minimization", "rel": "influences", "objs": [{"obj": "constituent ordering choices", "doc-id": 395}, {"obj": "evolution of English", "doc-id": 730}], "score": 2, "question": "What are the various factors that influence dependency length minimization?"}
{"sub": "discriminative word lexicon", "rel": "uses", "objs": [{"obj": "source context information", "doc-id": 424}, {"obj": "sentence-level source information", "doc-id": 1386}], "score": 2, "question": "What are the various applications that the discriminative word lexicon uses?"}
{"sub": "discriminative reranking", "rel": "improves over", "objs": [{"obj": "realization quality", "doc-id": 510}, {"obj": "performance of grounded language acquisition", "doc-id": 4692}], "score": 2, "question": "What are the various methods or techniques that discriminative reranking improves over?"}
{"sub": "pivot language", "rel": "is used for", "objs": [{"obj": "translation", "doc-id": 517}, {"obj": "translation to typologically similar languages", "doc-id": 2380}], "score": 2, "question": "What are the various applications of pivot language?"}
{"sub": "QUAERO", "rel": "submitted", "objs": [{"obj": "WMT 2011 machine translation evaluation", "doc-id": 538}, {"obj": "WMT 2012 machine translation evaluation", "doc-id": 1963}], "score": 2, "question": "What submissions has QUAERO made?"}
{"sub": "HPSG", "rel": "is a type of", "objs": [{"obj": "natural language processing", "doc-id": 789}, {"obj": "constituency-based grammar", "doc-id": 1457}], "score": 2, "question": "What are the different types of HPSG?"}
{"sub": "Named Entities Workshop", "rel": "is associated with", "objs": [{"obj": "ACL 2012 workshop", "doc-id": 874}, {"obj": "ACL 2010 workshop", "doc-id": 4212}], "score": 2, "question": "What are all the entities associated with the Named Entities Workshop?"}
{"sub": "CRFs", "rel": "can be applied to", "objs": [{"obj": "situations where word boundary ambiguity exists", "doc-id": 915}, {"obj": "chunking in Korean texts", "doc-id": 4699}], "score": 2, "question": "What are the various applications of CRFs?"}
{"sub": "Natural Language Toolkit", "rel": "is on", "objs": [{"obj": "suite of program modules, data sets and tutorials", "doc-id": 1000}, {"obj": "suite of program modules", "doc-id": 1432}], "score": 2, "question": "What are all the topics or resources that the Natural Language Toolkit is on?"}
{"sub": "NLTK", "rel": "is written in", "objs": [{"obj": "Python", "doc-id": 1000}, {"obj": "Python", "doc-id": 1432}], "score": 2, "question": "What programming languages is NLTK written in?"}
{"sub": "Nitrogen", "rel": "is on", "objs": [{"obj": "natural language generator", "doc-id": 1058}, {"obj": "generator", "doc-id": 3890}], "score": 2, "question": "What are all the substances or compounds that nitrogen is found on?"}
{"sub": "Integer Linear Programming", "rel": "uses", "objs": [{"obj": "inference framework", "doc-id": 1359}, {"obj": "decoding", "doc-id": 1982}], "score": 2, "question": "What methods or techniques does Integer Linear Programming use?"}
{"sub": "CCG", "rel": "is a type of", "objs": [{"obj": "constituency-based grammar", "doc-id": 1457}, {"obj": "grammar formalism", "doc-id": 3982}], "score": 2, "question": "What are the different types of CCG?"}
{"sub": "decipherment", "rel": "improves over", "objs": [{"obj": "phrase-based machine translation system", "doc-id": 1606}, {"obj": "machine translation", "doc-id": 2456}], "score": 2, "question": "What are the various methods or techniques that the decipherment improves over?"}
{"sub": "NLP tools", "rel": "apply to", "objs": [{"obj": "data that is linguistically different", "doc-id": 1841}, {"obj": "text", "doc-id": 2133}], "score": 2, "question": "What are the various applications of NLP tools?"}
{"sub": "syntactic constructions", "rel": "makes", "objs": [{"obj": "contextually appropriate syntactic choices", "doc-id": 1987}, {"obj": "contextually appropriate choices", "doc-id": 3506}], "score": 2, "question": "What syntactic constructions make up the various objects?"}
{"sub": "Coecke et al", "rel": "developed", "objs": [{"obj": "abstract categorical model", "doc-id": 2001}, {"obj": "DisCoCat", "doc-id": 4893}], "score": 2, "question": "What are the various concepts or theories that Coecke et al developed?"}
{"sub": "Conference on Computational Natural Language Learning", "rel": "features", "objs": [{"obj": "shared task", "doc-id": 2142}, {"obj": "shared task", "doc-id": 2153}], "score": 2, "question": "What are the key features of the Conference on Computational Natural Language Learning?"}
{"sub": "hand-aligned data", "rel": "comes from", "objs": [{"obj": "various language pairs", "doc-id": 2189}, {"obj": "various language pairs", "doc-id": 4252}], "score": 2, "question": "What are all the sources that hand-aligned data comes from?"}
{"sub": "microplanner", "rel": "performs", "objs": [{"obj": "lexical and syntactic choice", "doc-id": 2403}, {"obj": "lexical and syntactic choice", "doc-id": 4073}], "score": 2, "question": "What tasks does the microplanner perform?"}
{"sub": "state transitions", "rel": "correspond to", "objs": [{"obj": "edit operations", "doc-id": 2411}, {"obj": "edit operations", "doc-id": 2566}], "score": 2, "question": "What are the different objects that state transitions correspond to?"}
{"sub": "Coreference resolution", "rel": "is on", "objs": [{"obj": "clustering task", "doc-id": 2996}, {"obj": "NLP problem", "doc-id": 3987}], "score": 2, "question": "What are the various aspects or topics that coreference resolution is on?"}
{"sub": "Transliteration", "rel": "is defined as", "objs": [{"obj": "phonetic translation of names across languages", "doc-id": 3032}, {"obj": "phonetic translation of names across languages", "doc-id": 3751}], "score": 2, "question": "What are the various methods or systems that define transliteration?"}
{"sub": "large-scale computational lexicons", "rel": "include", "objs": [{"obj": "valuable frequency information", "doc-id": 3185}, {"obj": "valuable frequency information", "doc-id": 4287}], "score": 2, "question": "What are the various components that large-scale computational lexicons include?"}
{"sub": "memory-based classifiers", "rel": "predicts", "objs": [{"obj": "next action of the parser", "doc-id": 3204}, {"obj": "membership in 4 countability classes", "doc-id": 4959}], "score": 2, "question": "What do memory-based classifiers predict?"}
{"sub": "many languages", "rel": "lack", "objs": [{"obj": "resources", "doc-id": 3468}, {"obj": "supervised data resources", "doc-id": 4124}], "score": 2, "question": "What are the various aspects or features that many languages lack?"}
{"sub": "prototype-driven learning", "rel": "is used for", "objs": [{"obj": "unsupervised grammar induction", "doc-id": 3725}, {"obj": "unsupervised sequence modeling", "doc-id": 4773}], "score": 2, "question": "What are the various applications of prototype-driven learning?"}
{"sub": "target side texts", "rel": "uses", "objs": [{"obj": "language model", "doc-id": 3826}, {"obj": "language model of SMT system", "doc-id": 4967}], "score": 2, "question": "What are the various objects that target side texts use?"}
{"sub": "information retrieval techniques", "rel": "create", "objs": [{"obj": "French/English parallel data", "doc-id": 3826}, {"obj": "parallel data", "doc-id": 4967}], "score": 2, "question": "What are the various objects that information retrieval techniques create?"}
{"sub": "TextRank", "rel": "is on", "objs": [{"obj": "graph-based ranking model", "doc-id": 4049}, {"obj": "system for unsupervised extractive summarization", "doc-id": 4125}], "score": 2, "question": "What are the various topics or subjects that TextRank is on?"}
{"sub": "LR decoding", "rel": "is on", "objs": [{"obj": "decoding algorithm", "doc-id": 4269}, {"obj": "decoding algorithm", "doc-id": 4280}], "score": 2, "question": "What are all the applications or contexts where LR decoding is used?"}
{"sub": "Hinoki treebank", "rel": "is on", "objs": [{"obj": "Japanese lexical resource", "doc-id": 4312}, {"obj": "Redwoods-style treebank", "doc-id": 4439}], "score": 2, "question": "What are all the locations or platforms where the Hinoki treebank is available?"}
{"sub": "definiteness", "rel": "is helpful for", "objs": [{"obj": "parsing", "doc-id": 4320}, {"obj": "Arabic parsing on predicted input", "doc-id": 4980}], "score": 2, "question": "What are the various contexts or situations in which definiteness is helpful?"}
{"sub": "undiacritzed lemma", "rel": "is helpful for", "objs": [{"obj": "parsing", "doc-id": 4320}, {"obj": "Arabic parsing on predicted input", "doc-id": 4980}], "score": 2, "question": "What are the various applications or contexts in which the undiacritzed lemma is helpful?"}
{"sub": "Statistical Machine Translation", "rel": "uses", "objs": [{"obj": "reordering rules", "doc-id": 47}, {"obj": "parallel training data", "doc-id": 60}], "score": 2, "question": "What are the various techniques or methods that Statistical Machine Translation uses?"}
{"sub": "Amazon Mechanical Turk", "rel": "uses", "objs": [{"obj": "rating computer-generated reading comprehension questions", "doc-id": 66}, {"obj": "annotating translation lexicons", "doc-id": 2338}, {"obj": "generate (counter-)facts", "doc-id": 3867}], "score": 3, "question": "What are the various tasks that Amazon Mechanical Turk uses for its platform?"}
{"sub": "Moses", "rel": "is on", "objs": [{"obj": "machine translation reference", "doc-id": 120}, {"obj": "phrase-based Statistical Machine Translation system", "doc-id": 427}, {"obj": "Statistical Machine Translation system", "doc-id": 1631}], "score": 3, "question": "What are all the places or things that Moses is on?"}
{"sub": "RWTH Aachen University", "rel": "developed", "objs": [{"obj": "statistical machine translation systems", "doc-id": 192}, {"obj": "statistical machine translation (SMT) systems", "doc-id": 621}, {"obj": "statistical machine translation systems", "doc-id": 634}, {"obj": "statistical machine translation systems", "doc-id": 3767}, {"obj": "statistical machine translation system", "doc-id": 4565}], "score": 5, "question": "What technologies or innovations has RWTH Aachen University developed?"}
{"sub": "MEANT", "rel": "produces", "objs": [{"obj": "more robustly adequate translations", "doc-id": 203}, {"obj": "scores", "doc-id": 296}], "score": 2, "question": "What are all the objects that MEANT produces?"}
{"sub": "Bloom filter", "rel": "is on", "objs": [{"obj": "randomised data structure", "doc-id": 250}, {"obj": "randomised data structure", "doc-id": 3154}], "score": 2, "question": "What are all the applications or contexts where a Bloom filter is used?"}
{"sub": "Bloom filter", "rel": "is used for", "objs": [{"obj": "set membership queries", "doc-id": 250}, {"obj": "set membership queries", "doc-id": 3154}], "score": 2, "question": "What are the various applications of a Bloom filter?"}
{"sub": "Bloom filter", "rel": "produces", "objs": [{"obj": "false positives", "doc-id": 250}, {"obj": "false positives", "doc-id": 3154}], "score": 2, "question": "What are the different outputs produced by a Bloom filter?"}
{"sub": "joint decoder", "rel": "produces", "objs": [{"obj": "tokenization and translation", "doc-id": 380}, {"obj": "parse tree on the source side", "doc-id": 1094}, {"obj": "translation on the target side", "doc-id": 1094}], "score": 3, "question": "What are all the outputs produced by the joint decoder?"}
{"sub": "joint decoder", "rel": "achieves", "objs": [{"obj": "significant improvements", "doc-id": 380}, {"obj": "F1 score of 80.6% on the Penn Chinese Treebank", "doc-id": 1094}], "score": 2, "question": "What are the various outcomes that the joint decoder achieves?"}
{"sub": "decoding algorithm", "rel": "describes", "objs": [{"obj": "syntax-based translation model", "doc-id": 461}, {"obj": "syntax-based statistical translation", "doc-id": 2161}], "score": 2, "question": "What are the different aspects or components that the decoding algorithm describes?"}
{"sub": "semantic parser", "rel": "maps", "objs": [{"obj": "sentences into logical form", "doc-id": 505}, {"obj": "natural language sentences", "doc-id": 3371}], "score": 2, "question": "What are the various objects that the semantic parser maps to?"}
{"sub": "factors", "rel": "affects", "objs": [{"obj": "performance of semantic-based methods", "doc-id": 608}, {"obj": "parameter estimation", "doc-id": 1153}, {"obj": "system performance", "doc-id": 1751}], "score": 3, "question": "What are the factors that affect the various outcomes?"}
{"sub": "FBK", "rel": "uses", "objs": [{"obj": "phrase-based Statistical Machine Translation systems", "doc-id": 616}, {"obj": "word lattices", "doc-id": 616}, {"obj": "cross-lingual matching features", "doc-id": 664}], "score": 3, "question": "What are the various resources or tools that FBK uses?"}
{"sub": "RWTH Aachen University", "rel": "participated in", "objs": [{"obj": "evaluation campaign", "doc-id": 621}, {"obj": "evaluation campaign", "doc-id": 634}, {"obj": "QUAERO project", "doc-id": 1963}], "score": 3, "question": "What events or projects did RWTH Aachen University participate in?"}
{"sub": "feature functions", "rel": "depend on", "objs": [{"obj": "source language sentence", "doc-id": 842}, {"obj": "target language sentence", "doc-id": 842}, {"obj": "possible hidden variables", "doc-id": 842}, {"obj": "source language sentence", "doc-id": 1677}, {"obj": "target language sentence", "doc-id": 1677}, {"obj": "additional variables", "doc-id": 1677}], "score": 6, "question": "What do feature functions depend on?"}
{"sub": "FrameNet", "rel": "is on", "objs": [{"obj": "large database of semantically annotated sentences", "doc-id": 910}, {"obj": "bilingual lexicon", "doc-id": 1056}], "score": 2, "question": "What are all the topics or areas that FrameNet is on?"}
{"sub": "FrameNet", "rel": "provides", "objs": [{"obj": "semantic roles", "doc-id": 1607}, {"obj": "semantically annotated corpus", "doc-id": 1707}], "score": 2, "question": "What resources does FrameNet provide?"}
{"sub": "BabelNet", "rel": "is on", "objs": [{"obj": "multilingual semantic network", "doc-id": 1798}, {"obj": "larger sense inventory", "doc-id": 2588}], "score": 2, "question": "What are all the resources or platforms that BabelNet is on?"}
{"sub": "linguistic features", "rel": "provides", "objs": [{"obj": "complementary information", "doc-id": 1842}, {"obj": "less improvement", "doc-id": 3344}], "score": 2, "question": "What objects do linguistic features provide?"}
{"sub": "grammar formalism", "rel": "designed for", "objs": [{"obj": "syntax-based statistical machine translation", "doc-id": 1970}, {"obj": "data-oriented approaches", "doc-id": 4192}], "score": 2, "question": "What are the various applications or purposes for which grammar formalism is designed?"}
{"sub": "Espresso", "rel": "is on", "objs": [{"obj": "weakly-supervised algorithm", "doc-id": 2019}, {"obj": "general-purpose algorithm", "doc-id": 2019}, {"obj": "accurate algorithm", "doc-id": 2019}, {"obj": "weakly-supervised iterative algorithm", "doc-id": 2820}], "score": 4, "question": "What are all the items that espresso is on?"}
{"sub": "Espresso", "rel": "is compared with", "objs": [{"obj": "various state of the art systems", "doc-id": 2019}, {"obj": "two state of the art systems", "doc-id": 2820}], "score": 2, "question": "What are the different types of coffee that espresso is compared with?"}
{"sub": "NLP applications", "rel": "benefit from", "objs": [{"obj": "splitting noun compounds", "doc-id": 2406}, {"obj": "high coverage knowledge bases of paraphrases", "doc-id": 3163}], "score": 2, "question": "What are the various ways in which NLP applications benefit from different technologies or methodologies?"}
{"sub": "similarity measures", "rel": "include", "objs": [{"obj": "WordNet based similarity", "doc-id": 2723}, {"obj": "statistical word similarity measure", "doc-id": 2723}, {"obj": "Vector Space Model", "doc-id": 4255}, {"obj": "Latent Semantic Analysis", "doc-id": 4255}, {"obj": "Pointwise Mutual Information", "doc-id": 4255}, {"obj": "cosine", "doc-id": 4983}, {"obj": "Hellinger", "doc-id": 4983}, {"obj": "Tanimoto", "doc-id": 4983}, {"obj": "clarity", "doc-id": 4983}], "score": 9, "question": "What are the different types of similarity measures that are included in this category?"}
{"sub": "Conditional Random Fields", "rel": "uses", "objs": [{"obj": "chemical entity recognition", "doc-id": 3217}, {"obj": "token-level sequence labeling", "doc-id": 4016}], "score": 2, "question": "What are the various techniques or methods that Conditional Random Fields use?"}
{"sub": "reranking", "rel": "increases", "objs": [{"obj": "parsing accuracy", "doc-id": 3952}, {"obj": "system performance", "doc-id": 4088}], "score": 2, "question": "What are the various factors that reranking increases?"}
{"sub": "phrase-based unigram model", "rel": "describes", "objs": [{"obj": "statistical machine translation", "doc-id": 2}, {"obj": "statistical machine translation", "doc-id": 117}], "score": 2, "question": "What are the key characteristics and components that the phrase-based unigram model describes?"}
{"sub": "syntactic SMT approaches", "rel": "involve", "objs": [{"obj": "word alignment", "doc-id": 9}, {"obj": "monolingual parser", "doc-id": 9}], "score": 2, "question": "What are the various techniques or methods that syntactic SMT approaches involve?"}
{"sub": "DSP model", "rel": "involve", "objs": [{"obj": "phrase-pair vector representation", "doc-id": 110}, {"obj": "derivation structure prediction", "doc-id": 110}], "score": 2, "question": "What are all the components involved in the DSP model?"}
{"sub": "automatic text simplification system", "rel": "combine", "objs": [{"obj": "rule based core module", "doc-id": 113}, {"obj": "statistical support module", "doc-id": 113}], "score": 2, "question": "What are the different components or systems that the automatic text simplification system can combine?"}
{"sub": "N-gram model", "rel": "include", "objs": [{"obj": "translation", "doc-id": 116}, {"obj": "reordering operations", "doc-id": 116}], "score": 2, "question": "What are the different components included in an N-gram model?"}
{"sub": "phrase-based translation system", "rel": "generates", "objs": [{"obj": "translations for English-German", "doc-id": 223}, {"obj": "translations for English-French", "doc-id": 223}, {"obj": "translations for English-German", "doc-id": 4032}, {"obj": "translations for English-French", "doc-id": 4032}], "score": 4, "question": "What are the outputs generated by a phrase-based translation system?"}
{"sub": "phrase-based translation system", "rel": "is extended by", "objs": [{"obj": "bilingual models", "doc-id": 223}, {"obj": "fine-grained part-of-speech models", "doc-id": 223}, {"obj": "automatic cluster language models", "doc-id": 223}, {"obj": "discriminative word lexica", "doc-id": 223}, {"obj": "bilingual models", "doc-id": 4032}, {"obj": "fine-grained POS language models", "doc-id": 4032}, {"obj": "POS-based reordering", "doc-id": 4032}, {"obj": "lattice phrase extraction", "doc-id": 4032}, {"obj": "discriminative word alignment", "doc-id": 4032}], "score": 9, "question": "What are the extensions of the phrase-based translation system?"}
{"sub": "phrase-based translation systems", "rel": "uses", "objs": [{"obj": "word-alignment based heuristic estimates", "doc-id": 240}, {"obj": "word-based language models", "doc-id": 424}, {"obj": "part-of-speech-based language models", "doc-id": 424}, {"obj": "cluster-based language models", "doc-id": 424}], "score": 4, "question": "What are the various techniques or methods that phrase-based translation systems use?"}
{"sub": "discriminative tree-to-tree transduction model", "rel": "accounts for", "objs": [{"obj": "structural mismatches", "doc-id": 248}, {"obj": "lexical mismatches", "doc-id": 248}], "score": 2, "question": "What does the discriminative tree-to-tree transduction model account for?"}
{"sub": "human-robot dialogue system", "rel": "enables", "objs": [{"obj": "robot", "doc-id": 268}, {"obj": "human user", "doc-id": 268}], "score": 2, "question": "What are the various applications that the human-robot dialogue system enables?"}
{"sub": "minimum Bayes-risk system combination", "rel": "integrates", "objs": [{"obj": "consensus decoding", "doc-id": 285}, {"obj": "system combination", "doc-id": 285}], "score": 2, "question": "What are the different systems that the minimum Bayes-risk system combination integrates?"}
{"sub": "MBR system combination", "rel": "uses", "objs": [{"obj": "MBR decision rule", "doc-id": 285}, {"obj": "linear combination of component systems' probability distributions", "doc-id": 285}], "score": 2, "question": "What are all the components that the MBR system combination uses?"}
{"sub": "phrase-based statistical machine translation system", "rel": "trains", "objs": [{"obj": "WMT 2012 French-English data", "doc-id": 354}, {"obj": "WMT 2012 French-English data", "doc-id": 904}], "score": 2, "question": "What are the various components or models that the phrase-based statistical machine translation system trains?"}
{"sub": "method for regularizing the MERT objective", "rel": "is combined with", "objs": [{"obj": "Powell's method", "doc-id": 381}, {"obj": "coordinate descent", "doc-id": 381}], "score": 2, "question": "What are the different methods that are combined with the method for regularizing the MERT objective?"}
{"sub": "word alignment based on this method", "rel": "compared to", "objs": [{"obj": "conventional HMM", "doc-id": 388}, {"obj": "IBM model 4 based word alignment", "doc-id": 388}], "score": 2, "question": "What are the objects that word alignment based on this method is compared to?"}
{"sub": "augmented dependency-to-string model", "rel": "propose", "objs": [{"obj": "merits of head-dependents relations", "doc-id": 422}, {"obj": "fixed and floating structures", "doc-id": 422}], "score": 2, "question": "What are the various applications or benefits proposed by the augmented dependency-to-string model?"}
{"sub": "unsupervised word alignment models", "rel": "include", "objs": [{"obj": "GIZA++", "doc-id": 437}, {"obj": "Berkeley aligner", "doc-id": 437}], "score": 2, "question": "What are the different models that are included in unsupervised word alignment?"}
{"sub": "phrase-based translation models", "rel": "rely on", "objs": [{"obj": "large phrase pairs", "doc-id": 488}, {"obj": "target language models", "doc-id": 488}], "score": 2, "question": "What do phrase-based translation models rely on?"}
{"sub": "noun phrase translation subsystem", "rel": "incorporate", "objs": [{"obj": "special modeling", "doc-id": 507}, {"obj": "special features", "doc-id": 507}], "score": 2, "question": "What are all the components that the noun phrase translation subsystem incorporates?"}
{"sub": "lexicalized reordering model", "rel": "scores", "objs": [{"obj": "monotone phrase orientations", "doc-id": 539}, {"obj": "swap phrase orientations", "doc-id": 539}, {"obj": "discontinuous phrase orientations", "doc-id": 539}], "score": 3, "question": "What are the scores associated with the lexicalized reordering model?"}
{"sub": "large-margin based discriminative methods", "rel": "allows", "objs": [{"obj": "exploration into many new types of features", "doc-id": 540}, {"obj": "integrating millions of sparse features", "doc-id": 540}], "score": 2, "question": "What are the various applications that large-margin based discriminative methods allow?"}
{"sub": "Named Entity Recognition systems", "rel": "suffer from", "objs": [{"obj": "lack of hand-tagged data", "doc-id": 551}, {"obj": "degradation when moving to other domain", "doc-id": 551}], "score": 2, "question": "What challenges do Named Entity Recognition systems suffer from?"}
{"sub": "standard annotation methodology", "rel": "involve", "objs": [{"obj": "lexical units", "doc-id": 750}, {"obj": "frame elements", "doc-id": 750}], "score": 2, "question": "What are the various elements involved in the standard annotation methodology?"}
{"sub": "word sense disambiguation (WSD) based system", "rel": "depend on", "objs": [{"obj": "WSD system for English", "doc-id": 760}, {"obj": "automatic word alignment method", "doc-id": 760}], "score": 2, "question": "What are the various factors that a word sense disambiguation (WSD) based system depends on?"}
{"sub": "maximum entropy bitext parsing model", "rel": "define", "objs": [{"obj": "distribution over source trees", "doc-id": 768}, {"obj": "distribution over target trees", "doc-id": 768}, {"obj": "node-to-node alignments", "doc-id": 768}], "score": 3, "question": "What are the definitions and key characteristics of the maximum entropy bitext parsing model?"}
{"sub": "hidden semiMarkov model", "rel": "models", "objs": [{"obj": "word-to-phrase translations", "doc-id": 908}, {"obj": "phraseto-word translations", "doc-id": 908}], "score": 2, "question": "What are the different types of processes or phenomena that the hidden semiMarkov model can model?"}
{"sub": "KYOTO system", "rel": "uses", "objs": [{"obj": "open text representation format", "doc-id": 979}, {"obj": "central ontology", "doc-id": 979}], "score": 2, "question": "What are the various resources or components that the KYOTO system uses?"}
{"sub": "SPMT models", "rel": "improves over", "objs": [{"obj": "2.64 Bleu points", "doc-id": 992}, {"obj": "0.28 points on a humanbased quality metric", "doc-id": 992}], "score": 2, "question": "What are the various aspects or features that SPMT models improve over?"}
{"sub": "stemming model", "rel": "uses", "objs": [{"obj": "English stemmer", "doc-id": 994}, {"obj": "small (10K sentences) parallel corpus", "doc-id": 994}], "score": 2, "question": "What are the various techniques or methods that the stemming model uses?"}
{"sub": "syntax-based statistical translation model", "rel": "transforms", "objs": [{"obj": "source-language parse tree", "doc-id": 1003}, {"obj": "target-language string", "doc-id": 1003}], "score": 2, "question": "What are the various outputs that the syntax-based statistical translation model transforms?"}
{"sub": "log-linear model", "rel": "selects", "objs": [{"obj": "highest scoring candidate translation", "doc-id": 1030}, {"obj": "lists of entities", "doc-id": 2505}], "score": 2, "question": "What are the different objects that the log-linear model selects?"}
{"sub": "DTSC model", "rel": "is capable of", "objs": [{"obj": "lexicalization", "doc-id": 1078}, {"obj": "generalization", "doc-id": 1078}, {"obj": "handling discontinuous phrases", "doc-id": 1078}], "score": 3, "question": "What are all the capabilities of the DTSC model?"}
{"sub": "dependency grammar induction models", "rel": "uses", "objs": [{"obj": "word-level alignments", "doc-id": 1085}, {"obj": "source language parser", "doc-id": 1085}], "score": 2, "question": "What are the various techniques or methods that dependency grammar induction models use?"}
{"sub": "LABTG approach", "rel": "outperforms", "objs": [{"obj": "baseline BTG-based system", "doc-id": 1090}, {"obj": "state-of-the-art phrase-based system", "doc-id": 1090}], "score": 2, "question": "What are the approaches that the LABTG approach outperforms?"}
{"sub": "n-gram counting method", "rel": "reduces", "objs": [{"obj": "size of data sets", "doc-id": 1098}, {"obj": "model sizes", "doc-id": 1098}], "score": 2, "question": "What does the n-gram counting method reduce in terms of complexity or data processing?"}
{"sub": "WordNet-based models", "rel": "achieves", "objs": [{"obj": "good level of accuracy", "doc-id": 1099}, {"obj": "good level of coverage", "doc-id": 1099}], "score": 2, "question": "What are the various outcomes that WordNet-based models achieve?"}
{"sub": "Heidelberg University system", "rel": "combine", "objs": [{"obj": "monolingual and cross-lingual word alignments", "doc-id": 1191}, {"obj": "standard textual entailment distance", "doc-id": 1191}, {"obj": "bag-of-words features", "doc-id": 1191}], "score": 3, "question": "What are the different systems that combine with the Heidelberg University system?"}
{"sub": "fixed order Markov models", "rel": "uses", "objs": [{"obj": "(Church, 1989)", "doc-id": 1205}, {"obj": "(Charniak et al, 1993)", "doc-id": 1205}], "score": 2, "question": "What are the various applications that fixed order Markov models use?"}
{"sub": "hybrid approach to coreference resolution", "rel": "combine", "objs": [{"obj": "strengths of rule-based methods", "doc-id": 1222}, {"obj": "strengths of learning-based methods", "doc-id": 1222}], "score": 2, "question": "What are the different methods or techniques that the hybrid approach to coreference resolution combines?"}
{"sub": "hybridizing an existing RTE system", "rel": "yields", "objs": [{"obj": "significant performance gains", "doc-id": 1272}, {"obj": "significant gains", "doc-id": 1283}], "score": 2, "question": "What are the outcomes yielded by hybridizing an existing RTE system?"}
{"sub": "latent-variable model", "rel": "captures", "objs": [{"obj": "situational roles of dialogue participants", "doc-id": 1294}, {"obj": "structure of the dialogue", "doc-id": 1294}, {"obj": "relevance of each utterance", "doc-id": 1294}], "score": 3, "question": "What are the various aspects or phenomena that the latent-variable model captures?"}
{"sub": "phrase-based machine translation system", "rel": "combine", "objs": [{"obj": "lexicalized reordering", "doc-id": 1313}, {"obj": "POS-based reordering", "doc-id": 1313}, {"obj": "syntactic tree-based reordering", "doc-id": 1313}], "score": 3, "question": "What are the different components or systems that the phrase-based machine translation system combines?"}
{"sub": "text simplification systems", "rel": "performs", "objs": [{"obj": "lexical and syntactic simplification", "doc-id": 1357}, {"obj": "sentence compression", "doc-id": 1357}], "score": 2, "question": "What tasks do text simplification systems perform?"}
{"sub": "hybrid reasoning model", "rel": "employ", "objs": [{"obj": "plan inference", "doc-id": 1363}, {"obj": "logical inference", "doc-id": 1363}], "score": 2, "question": "What are the various applications that the hybrid reasoning model employs?"}
{"sub": "information extraction system", "rel": "classifies", "objs": [{"obj": "organisation", "doc-id": 1615}, {"obj": "person", "doc-id": 1615}, {"obj": "location", "doc-id": 1615}, {"obj": "tinm names", "doc-id": 1615}], "score": 4, "question": "What types of data does the information extraction system classify?"}
{"sub": "corpus-based supervised word sense disambiguation system", "rel": "uses", "objs": [{"obj": "statistical classification", "doc-id": 1704}, {"obj": "linguistic information", "doc-id": 1704}], "score": 2, "question": "What are the various resources or methods that the corpus-based supervised word sense disambiguation system uses?"}
{"sub": "phrase-based translation system", "rel": "extends", "objs": [{"obj": "bilingual models", "doc-id": 1843}, {"obj": "fine-grained part-of-speech (POS) models", "doc-id": 1843}, {"obj": "automatic cluster language models", "doc-id": 1843}, {"obj": "discriminative word lexica (DWL)", "doc-id": 1843}], "score": 4, "question": "What are the various systems or methods that the phrase-based translation system extends?"}
{"sub": "probabilistic model", "rel": "is based on", "objs": [{"obj": "Incremental Sigmoid Belief Networks", "doc-id": 1916}, {"obj": "lexical PCFG model", "doc-id": 4998}], "score": 2, "question": "What are the different concepts or theories that the probabilistic model is based on?"}
{"sub": "character-level translation models", "rel": "supports", "objs": [{"obj": "translation from and to underresourced languages", "doc-id": 1928}, {"obj": "translation from and to textual domains", "doc-id": 1928}], "score": 2, "question": "What are the different applications or tasks that character-level translation models support?"}
{"sub": "semantic parsing approach", "rel": "evaluates", "objs": [{"obj": "Textual Entitlement", "doc-id": 1962}, {"obj": "Textual Similarity", "doc-id": 1962}], "score": 2, "question": "What are the various methods or criteria that the semantic parsing approach evaluates?"}
{"sub": "WIDL-based NLG system", "rel": "is effective in", "objs": [{"obj": "automatic translation", "doc-id": 2006}, {"obj": "headline generation", "doc-id": 2006}], "score": 2, "question": "What are the various applications or areas where the WIDL-based NLG system is effective?"}
{"sub": "features in e-rater's models", "rel": "include", "objs": [{"obj": "discourse features", "doc-id": 2017}, {"obj": "topical features", "doc-id": 2017}, {"obj": "syntactic features", "doc-id": 2017}], "score": 3, "question": "What are all the features included in e-rater's models?"}
{"sub": "NER approaches", "rel": "include", "objs": [{"obj": "dictionary-based", "doc-id": 2054}, {"obj": "rule-based", "doc-id": 2054}, {"obj": "machine learning", "doc-id": 2054}], "score": 3, "question": "What are the different objects that NER approaches include?"}
{"sub": "ILP model", "rel": "considers", "objs": [{"obj": "content selection", "doc-id": 2111}, {"obj": "lexicalization", "doc-id": 2111}, {"obj": "aggregation", "doc-id": 2111}], "score": 3, "question": "What are the various factors that the ILP model considers?"}
{"sub": "automatic interpretation system", "rel": "integrates", "objs": [{"obj": "freestyle sentence translation", "doc-id": 2171}, {"obj": "parallel text based translation", "doc-id": 2171}], "score": 2, "question": "What are the various components that the automatic interpretation system integrates?"}
{"sub": "statistical language modeling", "rel": "has", "objs": [{"obj": "speech recognition", "doc-id": 2278}, {"obj": "statistical machine translation", "doc-id": 2278}], "score": 2, "question": "What are the various techniques or methods that statistical language modeling has?"}
{"sub": "unsupervised semantic role labelling system", "rel": "relies on", "objs": [{"obj": "predicate lexicon", "doc-id": 2290}, {"obj": "probability model", "doc-id": 2290}], "score": 2, "question": "What are the components or techniques that the unsupervised semantic role labeling system relies on?"}
{"sub": "model that combines LDA and AT", "rel": "outperforms", "objs": [{"obj": "LDA", "doc-id": 2318}, {"obj": "AT", "doc-id": 2318}, {"obj": "support vector machines", "doc-id": 2318}], "score": 3, "question": "What are the models that the model combining LDA and AT outperforms?"}
{"sub": "Conditional Random Field model", "rel": "uses", "objs": [{"obj": "local context", "doc-id": 2496}, {"obj": "phonemic information", "doc-id": 2496}], "score": 2, "question": "What are the different techniques or methods that the Conditional Random Field model uses?"}
{"sub": "active learning method", "rel": "outperforms", "objs": [{"obj": "passive learning", "doc-id": 2522}, {"obj": "traditional active learning", "doc-id": 2522}], "score": 2, "question": "What are the different methods that the active learning method outperforms?"}
{"sub": "incremental dialogue system", "rel": "has", "objs": [{"obj": "split utterances", "doc-id": 2560}, {"obj": "adjuncts", "doc-id": 2560}, {"obj": "mid-sentence clarification requests", "doc-id": 2560}, {"obj": "backchannels", "doc-id": 2560}], "score": 4, "question": "What are the components that the incremental dialogue system has?"}
{"sub": "modeling morphological and phonological variation", "rel": "lead to", "objs": [{"obj": "substantial average gain of F=0.206", "doc-id": 2570}, {"obj": "error reduction of up to 63.8%", "doc-id": 2570}], "score": 2, "question": "What are the various outcomes that modeling morphological and phonological variation can lead to?"}
{"sub": "probabilistic approach to frame induction", "rel": "incorporate", "objs": [{"obj": "frames", "doc-id": 2589}, {"obj": "events", "doc-id": 2589}, {"obj": "participants", "doc-id": 2589}], "score": 3, "question": "What are the various elements that the probabilistic approach to frame induction incorporates?"}
{"sub": "domain-independent generation systems", "rel": "require", "objs": [{"obj": "large grammars", "doc-id": 2616}, {"obj": "full lexicons", "doc-id": 2616}, {"obj": "complex collocational information", "doc-id": 2616}], "score": 3, "question": "What do domain-independent generation systems require?"}
{"sub": "hybrid disambiguation methods", "rel": "combine", "objs": [{"obj": "hand-written disambiguation rules", "doc-id": 2697}, {"obj": "statistical taggers", "doc-id": 2697}], "score": 2, "question": "What are the different methods that hybrid disambiguation methods combine?"}
{"sub": "Statistical machine translation systems", "rel": "uses", "objs": [{"obj": "translation models", "doc-id": 2720}, {"obj": "language model", "doc-id": 2720}], "score": 2, "question": "What are the various techniques or methods that statistical machine translation systems use?"}
{"sub": "dependency parsing method", "rel": "applied to", "objs": [{"obj": "cross-lingual transfer learning", "doc-id": 2740}, {"obj": "domain adaptation techniques", "doc-id": 2740}], "score": 2, "question": "What are the various applications of the dependency parsing method?"}
{"sub": "transfer learning methods", "rel": "rely on", "objs": [{"obj": "aligned corpora", "doc-id": 2740}, {"obj": "bilingual lexicons", "doc-id": 2740}], "score": 2, "question": "What do transfer learning methods rely on?"}
{"sub": "in-vehicle dialogue systems", "rel": "contain", "objs": [{"obj": "navigation application", "doc-id": 2803}, {"obj": "telephone application", "doc-id": 2803}], "score": 2, "question": "What are the various components that in-vehicle dialogue systems contain?"}
{"sub": "English-Manipuri statistical machine translation system", "rel": "identifies", "objs": [{"obj": "suffixes and dependency relations", "doc-id": 2864}, {"obj": "case markers", "doc-id": 2864}], "score": 2, "question": "What are the various languages or systems that the English-Manipuri statistical machine translation system identifies?"}
{"sub": "Manipuri English system", "rel": "identifies", "objs": [{"obj": "case markers", "doc-id": 2864}, {"obj": "POS tags information", "doc-id": 2864}, {"obj": "suffixes and dependency relations", "doc-id": 2864}], "score": 3, "question": "What are all the elements that the Manipuri English system identifies?"}
{"sub": "Cross-lingual topic modelling", "rel": "has", "objs": [{"obj": "machine translation", "doc-id": 2908}, {"obj": "word sense disambiguation", "doc-id": 2908}, {"obj": "terminology alignment", "doc-id": 2908}], "score": 3, "question": "What are the various techniques or methods that cross-lingual topic modelling has?"}
{"sub": "HL-SOT approach", "rel": "is based on", "objs": [{"obj": "Hierarchical Learning process", "doc-id": 2953}, {"obj": "Sentiment Ontology Tree", "doc-id": 2953}], "score": 2, "question": "What are the key concepts or methods that the HL-SOT approach is based on?"}
{"sub": "nonparametric Bayesian models", "rel": "considers", "objs": [{"obj": "potentially infinite number of features", "doc-id": 3040}, {"obj": "categorical outcomes", "doc-id": 3040}], "score": 2, "question": "What are the various aspects or components that nonparametric Bayesian models consider?"}
{"sub": "PB-SMT model", "rel": "is independent of", "objs": [{"obj": "travel translation domain", "doc-id": 3052}, {"obj": "news translation domain", "doc-id": 3052}], "score": 2, "question": "What are all the factors or elements that the PB-SMT model is independent of?"}
{"sub": "word-sense disambiguation systems", "rel": "trains", "objs": [{"obj": "bilingual material", "doc-id": 3180}, {"obj": "monolingual material", "doc-id": 3180}], "score": 2, "question": "What are the various systems that word-sense disambiguation systems train?"}
{"sub": "class-based language model", "rel": "improves over", "objs": [{"obj": "performance", "doc-id": 3182}, {"obj": "perplexity", "doc-id": 3182}, {"obj": "speech recognition word-error rate", "doc-id": 3182}], "score": 3, "question": "What are the various models or techniques that the class-based language model improves over?"}
{"sub": "HMM part-of-speech tagging method", "rel": "is based on", "objs": [{"obj": "splitting of the POS tags into attribute vectors", "doc-id": 3192}, {"obj": "decomposition of the contextual POS probabilities", "doc-id": 3192}, {"obj": "estimation of the contextual probabilities with decision trees", "doc-id": 3192}, {"obj": "use of high-order HMMs", "doc-id": 3192}], "score": 4, "question": "What are the key principles or techniques that the HMM part-of-speech tagging method is based on?"}
{"sub": "chemical entity recognition approach", "rel": "consist of", "objs": [{"obj": "Conditional Random Fields", "doc-id": 3217}, {"obj": "lexical similarity", "doc-id": 3217}], "score": 2, "question": "What are the components that the chemical entity recognition approach consists of?"}
{"sub": "standard MT evaluation methods", "rel": "include", "objs": [{"obj": "BLEU", "doc-id": 3239}, {"obj": "NIST", "doc-id": 3239}, {"obj": "WER", "doc-id": 3239}, {"obj": "PER", "doc-id": 3239}], "score": 4, "question": "What are the various objects included in the standard MT evaluation methods?"}
{"sub": "NRC system", "rel": "uses", "objs": [{"obj": "Weka machine learning software", "doc-id": 3282}, {"obj": "Brill's rule-based part-of-speech tagger", "doc-id": 3282}], "score": 2, "question": "What are all the resources or technologies that the NRC system uses?"}
{"sub": "English-Czech machine translation system", "rel": "combine", "objs": [{"obj": "linguistically motivated layers of language description", "doc-id": 3283}, {"obj": "statistical NLP approaches", "doc-id": 3283}], "score": 2, "question": "What are the components that the English-Czech machine translation system combines?"}
{"sub": "SCR model", "rel": "achieves", "objs": [{"obj": "62% acquisition accuracy", "doc-id": 3374}, {"obj": "50% precision", "doc-id": 3374}], "score": 2, "question": "What are all the outcomes that the SCR model achieves?"}
{"sub": "CoNLL 2009 Shared Task system", "rel": "include", "objs": [{"obj": "syntactic parsing", "doc-id": 3452}, {"obj": "predicate classification", "doc-id": 3452}, {"obj": "semantic role labeling", "doc-id": 3452}], "score": 3, "question": "What are all the components included in the CoNLL 2009 Shared Task system?"}
{"sub": "2007 Ngram-based statistical machine translation system", "rel": "include", "objs": [{"obj": "novel word ordering strategy", "doc-id": 3477}, {"obj": "feature for out-of-domain units", "doc-id": 3477}, {"obj": "improved optimization procedure", "doc-id": 3477}], "score": 3, "question": "What are the components included in the 2007 Ngram-based statistical machine translation system?"}
{"sub": "agreement and disagreement tagging model", "rel": "is evaluated on", "objs": [{"obj": "Wikipedia Talk pages", "doc-id": 3663}, {"obj": "online debates", "doc-id": 3663}], "score": 2, "question": "What are the criteria or metrics on which the agreement and disagreement tagging model is evaluated?"}
{"sub": "constituency-to-dependency translation model", "rel": "uses", "objs": [{"obj": "constituency forests", "doc-id": 3745}, {"obj": "dependency trees", "doc-id": 3745}], "score": 2, "question": "What are the components or techniques that the constituency-to-dependency translation model uses?"}
{"sub": "Baby Semantic Role Labeling system", "rel": "combine", "objs": [{"obj": "world knowledge", "doc-id": 3797}, {"obj": "simple grammatical constraints", "doc-id": 3797}], "score": 2, "question": "What are the different components or systems that the Baby Semantic Role Labeling system combines?"}
{"sub": "NetEase WS system", "rel": "supports", "objs": [{"obj": "Chinese and English word segmentation", "doc-id": 3808}, {"obj": "Chinese named entity recognition", "doc-id": 3808}, {"obj": "Chinese part of speech tagging", "doc-id": 3808}, {"obj": "phrase conglutination", "doc-id": 3808}], "score": 4, "question": "What are all the services or features that the NetEase WS system supports?"}
{"sub": "methods of text summarization", "rel": "combine", "objs": [{"obj": "sentence selection", "doc-id": 3919}, {"obj": "sentence compression", "doc-id": 3919}], "score": 2, "question": "What are the different methods of text summarization that can be combined?"}
{"sub": "RenTAL system", "rel": "enables", "objs": [{"obj": "sharing resources", "doc-id": 3953}, {"obj": "sharing grammars and lexicons", "doc-id": 3953}, {"obj": "sharing parsing techniques", "doc-id": 3953}], "score": 3, "question": "What are all the functionalities that the RenTAL system enables?"}
{"sub": "evaluations of PPI-extraction systems", "rel": "can be used in", "objs": [{"obj": "incomparable", "doc-id": 3958}, {"obj": "invalid", "doc-id": 3958}], "score": 2, "question": "What are the various applications where evaluations of PPI-extraction systems can be used?"}
{"sub": "RF language models", "rel": "reduces", "objs": [{"obj": "perplexity", "doc-id": 4151}, {"obj": "word error rate", "doc-id": 4151}], "score": 2, "question": "What does RF language models reduce in terms of their impact or effectiveness?"}
{"sub": "CoNLL 2008 Shared Task system", "rel": "include", "objs": [{"obj": "syntactic dependency parser", "doc-id": 4343}, {"obj": "semantic dependency parser", "doc-id": 4343}], "score": 2, "question": "What are all the components included in the CoNLL 2008 Shared Task system?"}
{"sub": "CIAOSENSO WSD system", "rel": "is based on", "objs": [{"obj": "Conceptual Density", "doc-id": 4348}, {"obj": "WordNet Domains", "doc-id": 4348}, {"obj": "frequencies of WordNet senses", "doc-id": 4348}], "score": 3, "question": "What are the components or technologies that the CIAOSENSO WSD system is based on?"}
{"sub": "upvunige-CIAOSENSO WSD system", "rel": "uses", "objs": [{"obj": "english lexical sample", "doc-id": 4348}, {"obj": "WordNet gloss disambiguation tasks", "doc-id": 4348}], "score": 2, "question": "What are all the components or technologies that the upvunige-CIAOSENSO WSD system uses?"}
{"sub": "stochastic parsing system", "rel": "consist of", "objs": [{"obj": "Lexical-Functional Grammar (LFG)", "doc-id": 4587}, {"obj": "constraint-based parser", "doc-id": 4587}, {"obj": "stochastic disambiguation model", "doc-id": 4587}], "score": 3, "question": "What are the components that a stochastic parsing system consists of?"}
{"sub": "geographic term disambiguation system", "rel": "relies on", "objs": [{"obj": "positive context", "doc-id": 4619}, {"obj": "negative context", "doc-id": 4619}], "score": 2, "question": "What are the various resources or methods that the geographic term disambiguation system relies on?"}
{"sub": "topic segmentation approach", "rel": "combine", "objs": [{"obj": "lexical cohesion", "doc-id": 4705}, {"obj": "linguistic evidence", "doc-id": 4705}], "score": 2, "question": "What are the different methods or techniques that can be combined in a topic segmentation approach?"}
{"sub": "low-rank coregionalisation approach", "rel": "combine", "objs": [{"obj": "vector-valued Gaussian Process", "doc-id": 4767}, {"obj": "rich parameterisation scheme", "doc-id": 4767}], "score": 2, "question": "What are the different methods or techniques that the low-rank coregionalisation approach combines?"}
{"sub": "vector space model", "rel": "addresses", "objs": [{"obj": "polysemy issue", "doc-id": 4933}, {"obj": "one representation per word type", "doc-id": 4933}], "score": 2, "question": "What are the various aspects or components that the vector space model addresses?"}
