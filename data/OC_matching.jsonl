{"doc-1": "Normal somatic cells invariably enter a state of irreversibly arrested growth and altered function after a finite number of divisions. This process, termed replicative senescence, is thought to be a tumor-suppressive mechanism and an underlying cause of aging. There is ample evidence that escape from senescence, or immortality, is important for malignant transformation. By contrast, the role of replicative senescence in organismic aging is controversial. Studies on cells cultured from donors of different ages, genetic backgrounds, or species suggest that senescence occurs in vivo and that organismic lifespan and cell replicative lifespan are under common genetic control. However, senescent cells cannot be distinguished from quiescent or terminally differentiated cells in tissues. Thus, evidence that senescent cells exist and accumulate with age in vivo is lacking. We show that several human cells express a beta-galactosidase, histochemically detectable at pH 6, upon senescence in culture. This marker was expressed by senescent, but not presenescent, fibroblasts and keratinocytes but was absent from quiescent fibroblasts and terminally differentiated keratinocytes. It was also absent from immortal cells but was induced by genetic manipulations that reversed immortality. In skin samples from human donors of different age, there was an age-dependent increase in this marker in dermal fibroblasts and epidermal keratinocytes. This marker provides in situ evidence that senescent cells may exist and accumulate with age in vivo.", "doc-2": "OBJECTIVEEndothelial dysfunction is a key event in the onset and progression of atherosclerosis associated with diabetes. Increasing cell senescence may lead to endothelial dysfunction and contribute to vascular complications. Therefore, we aimed to elucidate the possible role and mechanism of L-arginine in preventing cell senescence induced by high glucose.METHODSHUVECs were respectively cultured under normal control glucose (5.5mM), high glucose (33mM), co-incubation with L-arginine (800microM)and high glucose, and senescence was identified by beta-galactosidase staining, change of cell cycle and telomerase activity. Akt and eNOS activity was analyzed by western blot.RESULTSHigh glucose significantly increased number of beta-galactosidase-positive stained cells, inhibited telomerase activity, increased proportion of cells in the G(0)/G(1) phase and reduced proportion in the S phase, and decreased NO synthesis. L-arginine significantly attenuated these senescent alterations. Furthermore, high glucose induced a decrease in Akt and eNOS activity, and L-arginine prevented the decrease in activity. The PI3K inhibitor LY294002 or eNOS inhibitor L-NAME attenuated anti-senescence effect of L-arginine.CONCLUSIONL-arginine may have an anti-senescence effect via the PI3K/Akt pathway in HUVECs exposed to high glucose and it might be a therapeutic agent for diabetic vascular complications.", "label": 1}
{"doc-1": "The P300 ERP was measured in 10 subjects each for 9 days. The selection of instructions for subjects, the recording technique, the elimination of a few single trials significantly contaminated by eye movements, and the use of a correction procedure for ocular artifacts with calculable reliability and validity resulted in a set of data, in which 94% of the single trials were suitable for further analysis. The correction procedure relies on regression analysis. To reduce coherence between eyeblink activity and ongoing EEG, VEOG and EEG are averaged on eyeblinks. This yields a high reliability and validity of regression factors, determined per day, subject, and lead. In addition, this correction procedure allows for an estimation of the maximal error that must be taken into account. The efficiency of the procedure is demonstrated for single trials and averaged potentials.", "doc-2": "The aim of this study is to investigate the neural mechanism of extending a brand in a specific product category to other product categories. Facing two sequential stimuli in pairs consisting of beverage brand names (stimulus 1) and product names (stimulus 2) in other categories, 16 participants were asked to indicate the suitability of extending the brand in stimulus 1 to the product category in stimulus 2. These stimulus pairs were divided into four conditions depending on the product category in stimulus 2: beverage, snack, clothing, and household appliance. A negative component, N270, was recorded for each condition on the participants' scalps,whereas the maximum amplitude was observed at the frontal area. Greater N270 amplitude was observed when participants were presented with stronger conflict between the brand product category (stimulus 1) and the extension category (stimulus 2). It suggests that N270 can be evoked not only by a conflict of physical attributes (different shapes of words of brand and product names) but also by that of lexical content. From the marketing perspective, N270 can be potentially used as a reference measure in brand-extension attempts.", "label": 1}
{"doc-1": "From the Publisher: The updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Like the first edition,this text can also be used for self-study by technical professionals since it discusses engineering issues in algorithm design as well as the mathematical aspects. In its new edition,Introduction to Algorithms continues to provide a comprehensive introduction to the modern study of algorithms. The revision has been updated to reflect changes in the years since the book's original publication. New chapters on the role of algorithms in computing and on probabilistic analysis and randomized algorithms have been included. Sections throughout the book have been rewritten for increased clarity,and material has been added wherever a fuller explanation has seemed useful or new information warrants expanded coverage. As in the classic first edition,this new edition of Introduction to Algorithms presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers. Further,the algorithms are presented in pseudocode to make the book easily accessible to students from all programming language backgrounds. Each chapter presents an algorithm,a design technique,an application area,or a related topic. The chapters are not dependent on one another,so the instructor can organize his or her use of the book in the way that best suits the course's needs. Additionally,the new edition offers a 25% increase over the first edition in the number of problems,giving the book 155 problems and over 900 exercises thatreinforcethe concepts the students are learning.", "doc-2": "In a WSN, it is desirable to keep many sensors active to collect data as much as possible which causes network failure, on the other hand, if most of the sensors are asleep, enough data can not be collected. Therefore, the trade-off between data collection and energy saving has made data gathering an interesting research field. To handle these challenges, we present an energy efficient data gathering method which increases the network lifetime and a good throughput. In our research, the tasks of data collection are distributed among the nodes of the different zones which resist the sensor nodes from going to the bottleneck state by minimizing latency. We design a load balanced data collection scheme by dividing the network zone into on-demand data collection clusters and routes which ultimately provides higher packet delivery. We find that our method provides longer network lifetime and higher throughput compared to some commonly used methods.", "label": 1}
{"doc-1": "Newborn mice homozygous for a targeted disruption of insulin-like growth factor gene (Igf-1) exhibit a growth deficiency similar in severity to that previously observed in viable Igf-2 null mutants (60% of normal birthweight). Depending on genetic background, some of the Igf-1(-/-) dwarfs die shortly after birth, while others survive and reach adulthood. In contrast, null mutants for the Igf1r gene die invariably at birth of respiratory failure and exhibit a more severe growth deficiency (45% normal size). In addition to generalized organ hypoplasia in Igf1r(-/-) embryos, including the muscles, and developmental delays in ossification, deviations from normalcy were observed in the central nervous system and epidermis. Igf-1(-/-)/Igf1r(-/-) double mutants did not differ in phenotype from Igf1r(-/-) single mutants, while in Igf-2(-)/Igf1r(-/-) and Igf-1(-/-)/Igf-2(-) double mutants, which are phenotypically identical, the dwarfism was further exacerbated (30% normal size). The roles of the IGFs in mouse embryonic development, as revealed from the phenotypic differences between these mutants, are discussed.", "doc-2": "Growth is a polygenic trait that is under the influence of multiple physiological pathways regulating energy metabolism and muscle growth. Among the possible growth-regulating pathways in vertebrates, components of the somatotropic axis are thought to have the greatest influence. There is growing body of literature focusing on the somatotropic axis and its role regulating growth in fish. This includes research into growth hormone, upstream hypothalamic hormones, insulin-like growth factors, and downstream signaling molecules. Many of these signals have both somatic effects stimulating the growth of tissues and metabolic effects that play a role in nutrient metabolism. Signals of other endocrine axes exhibit profound effects on the function of the somatotropic axis in vivo. In this review we highlight recent advances in our understanding of the teleost fish endocrine somatotropic axis, including emerging research using genetic modified models. These studies have revealed new aspects and challenges associated with regulation of the important steps of somatic growth.", "label": 1}
{"doc-1": "DOCUMENT RESUME", "doc-2": "Background: Higher education researchers have much to say about the transition to college. This field focuses primarily on inequities in college participation and completion, the relative importance of high school preparation, and the utility of financial aid in promoting enrollment. This literatures strongest conceptual emphasis is on theoretical models of student retention. Less is known about other facets of the transition to college, including different postsecondary pathways and college outcomes. Purpose: This paper describes the major findings of research on the transition to college contributed by higher education, and how further research might be improved. The specific areas covered are college preparation, college access, persistence, and college outcomes. The reviewed literature covered extant research on the transition to college as conducted by higher education researchers. Research Design: This essay is an analysis of extant research on the college transition in the field of higher education Conclusions/Recommendations: This review highlights the fields major shortcoming as undertaking insufficiently rigorous, empirical testing of theories on the transition to college. Existing research on postsecondary pathways is often compromised by data or methodological limitations, failure to be critical in attributing causality, and not differentiating effects occurring at different measurement levels (i.e., individual vs. institution).", "label": 1}
{"doc-1": "The Hardy-Weinberg law plays an important role in the field of population genetics and often serves as a basis for genetic inference. Because of its importance, much attention has been devoted to tests of Hardy-Weinberg proportions (HWP) over the decades. It has long been recognized that large-sample goodness-of-fit tests can sometimes lead to spurious results when the sample size and/or some genotypic frequencies are small. Although a complete enumeration algorithm for the exact test has been proposed, it is not of practical use for loci with more than a few alleles due to the amount of computation required. We propose two algorithms to estimate the significance level for a test of HWP. The algorithms are easily applicable to loci with multiple alleles. Both are remarkably simple and computationally fast. Relative efficiency and merits of the two algorithms are compared. Guidelines regarding their usage are given. Numerical examples are given to illustrate the practicality of the algorithms.", "doc-2": "AbstractThe San Joaquin kit fox (Vulpes macrotis mutica) was once ubiquitous throughout Californias San Joaquin Valley and its surrounds. However, most of its habitat has been lost to irrigated agriculture, urban development, and oil fields. The remaining foxes are concentrated in six areas, although there are several small pockets of foxes throughout the Valley. To help conserve kit foxes, we sought an ecological understanding of the level of genetic variation remaining in these locations and the extent of gene flow among them. We collected tissue from 317 kit foxes from 8 sites and estimated genetic variability in and gene flow among sites using data from 8 polymorphic, microsatellite markers. We found no differences in both observed and expected heterozygosity between locations using Bonferonni corrected paired t-tests. We found differences in mean number of alleles per locus, even after we used Monte Carlo simulations to adjust for sample size differences. Population subdivision was low among sites (Fst=0.043), yet a matrix of pairwise Fst values was correlated with a matrix of pairwise geographic distances. An assignment test classified only 45% of the individuals to the site where they were captured. Overall, these data suggest that kit fox dispersal between locations may still maintain genetic variation throughout most of the areas we sampled.", "label": 1}
{"doc-1": "The Digital Signal Processing Group develops signal processing algorithms that span a wide variety of application areas including speech and image processing, sensor networks, communications, radar and sonar. Our primary focus is on algorithm development in general, with the applications serving as motivating contexts. Our approach to new algorithms includes some unconventional directions, such as algorithms based on fractal signals, chaotic behavior in nonlinear dynamical systems, quantum mechanics and biology in addition to the more conventional areas of signal modeling, quantization, parameter estimation, sampling and signal representation.", "doc-2": "Time-domain autocovariance processing is widely accepted as a computationally efficient method to estimate the first three spectral moments of Doppler weather radar signals (i.e., mean signal power, mean Doppler velocity, and spectrum width). However, when signals with different frequency content (e.g., ground clutter) contaminate the weather signal, spectral processing using the periodogram estimator of the power spectral density (PSD) is the preferred tool of analysis. After spectral processing (i.e., filtering), a PSD-based autocorrelation estimator is typically employed to produce unbiased estimates of the weather-signal spectral moments. However, the PSD does not convey explicit phase information, which has the potential to aid in the spectral analysis of radar signals. In this paper, the autocorrelation spectral density (ASD) is introduced for spectral analysis of weather-radar signals as a generalization of the classical PSD, and an ASD-based autocorrelation estimator is proposed to produce unbiased estimates of the weather-signal spectral moments. A significant advantage of the ASD over the PSD is that it provides explicit phase information that can be exploited to identify and remove certain types of contaminant signals. Thus, the ASD provides an alternative means for spectral analysis, which can lead to improved quality of meteorological data from weather radars.", "label": 1}
{"doc-1": "In clinical measurement comparison of a new measurement technique with an established one is often needed to see whether they agree sufficiently for the new to replace the old. Such investigations are often analysed inappropriately, notably by using correlation coefficients. The use of correlation is misleading. An alternative approach, based on graphical techniques and simple calculations, is described, together with the relation between this analysis and the assessment of repeatability.", "doc-2": "BACKGROUNDApplication of a multisample method using inulin to estimate glomerular filtration rate (GFR) in cats is cumbersome.OBJECTIVESTo establish a simplified procedure to estimate GFR in cats, a single-blood-sample method using inulin was compared with a conventional 3-sample method.ANIMALSNine cats including 6 clinically healthy cats and 3 cats with spontaneous chronic kidney disease.METHODSRetrospective study. Inulin was administered as an intravenous bolus at 50 mg/kg to cats, and blood was collected at 60, 90, and 120 minutes later for the 3-sample method. Serum inulin concentrations were colorimetrically determined by an autoanalyzer method. The GFR in the single-blood-sample method was calculated from the dose injected, serum concentration, sampling time, and estimated volume of distribution on the basis of the data of the 3-sample method.RESULTSAn excellent correlation was observed (r = 0.99, P = .0001) between GFR values estimated by the single-blood-sample and 3-sample methods.CONCLUSIONS AND CLINICAL IMPORTANCEThe single-blood-sample method using inulin provides a practicable and ethical alternative for estimating glomerular filtration rate in cats.", "label": 1}
{"doc-1": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning.", "doc-2": "In this paper, we consider the problem of sentiment classification of English Twitter messages using machine learning techniques. We systematically evaluate the use of different feature types on the performance of two text classification methods: Naive Bayes (NB) and Support Vector Machines (SVM). Our goal is threefold: (1) to investigate whether or not partof-speech (POS) features are useful for this task, (2) to study the effectiveness of sparse phrasal features (bigrams and skipgrams) to capture sentiment information, and (3) to investigate the impact of combining unigrams with phrasal features on the classifications performance. For this purpose we conducted a series of classification experiments. Our results show that POS features are useful for this task while phrasal features could improve the performance of the classification only when combined with unigrams.", "label": 1}
{"doc-1": "Introduction to Optimization The Binary Genetic Algorithm The Continuous Parameter Genetic Algorithm Applications An Added Level of Sophistication Advanced Applications Evolutionary Trends Appendix Glossary Index.", "doc-2": "This paper describes the results of a series of cyclic triaxial tests on sand waste tire mixtures, and applications of genetic programming (GP) and stepwise regression (SR) for the prediction of damping ratio and shear modulus of the mixtures tested. In the tests, shear modulus, and damping ratio of the geomaterials were measured for a strain range of 0.0001% up to 0.04%. The input variables in the developed GP and SR models are the waste tire content (0%, 10%, 20%, and 30%), waste tire type (tire crumbs or tire buffings), strain, and confining pressures (40 kPa, 100 kPa, and 200 kPa), and outputs are shear modulus and damping ratio. Test results show that the shear modulus and the damping ratio of the mixtures are strongly influenced by the waste tire inclusions. The performance of the proposed GP models (R2 = 0.95 for shear modulus, and R2 = 0.94 for damping ratio) are observed to be more accurate than that of the SR models (R2 = 0.87 for shear modulus, and R2 = 0.91 for damping ratio).", "label": 1}
{"doc-1": "Abstract : A foundational model of concurrency is developed in this thesis. It examines issues in the design of parallel systems and show why the actor model is suitable for exploiting large-scale parallelism. Concurrency in actors is constrained only by the availability of hardware resources and by the logical dependence inherent in the computation. Unlike dataflow and functional programming, however, actors are dynamically reconfigurable and can model shared resources with changing local state. Concurrency is spawned in actors using asynchronous message-passing, pipelining, and the dynamic creation of actors. The author defines an abstract actor machine and provide a minimal programming language for it. A more expressive language, which includes higher level constructs such as delayed and eager evaluation, can be defined in terms of the primitives. Examples are given to illustrate the ease with which concurrent data and control structures can be programmed. This thesis deals with some central issues in distributed computing. Specifically, problems of divergence and deadlock are addressed. Additional keywords: Object oriented programming; Semantics.", "doc-2": "Statics. Mechanics of Materials. Dynamics and Vibration. Kinematics and Mechanisms. Structures. Fluid Mechanics. Thermodynamics and Heat Transfer. Separation Processes. Fuels and Energy Conversion. Kinetics and Reaction Engineering. Geotechnical. Transportation. Coastal and Ocean Engineering. Environmental Systems and Management. Water Resources Engineering. Linear Systems and Models. Circuits. Electronics. Digital Systems. Communications and Signal Processing. Computers. Measurement and Instrumentation. Surveying. Control Systems. Manufacturing. Aeronautics and Aerospace. Safety. Engineering Economics and Management. Materials Engineering. Mathematics.", "label": 1}
{"doc-1": "The need to make default assumptions is frequently encountered in reasoning about incompletely specified worlds. Inferences sanctioned by default are best viewed as beliefs which may well be modified or rejected by subsequent observations. It is this property which leads to the non-monotonicity of any logic of defaults.  In this paper we propose a logic for default reasoning. We then specialize our treatment to a very large class of commonly occuring defaults. For this class we develop a complete proof theory and show how to interface it with a top down resolution theorem prover. Finally, we provide criteria under which the revision of derived beliefs must be effected.", "doc-2": "Ever since Wood's \"What's in a Link\" paper, there has been a growing concern for formalization in the study of knowledge representation. Several arguments have been made that frame representation languages and semantic-network languages are syntactic variants of the first-order predicate calculus (FOPC). The typical argument proceeds by showing how any given frame or network representation can be mapped to a logically isomorphic FOPC representation. For the past two years we have been studying the formalization of knowledge retrievers as well as the representation languages that they operate on. This paper presents a representation language in the notation of FOPC whose form facilitates the design of a semantic-network-like retriever.", "label": 1}
{"doc-1": "Preface 1. Introduction and preliminaries 2. Linear internal waves 3. Finite amplitude motions in stably stratified fluids 4. Instability and the production of turbulence 5. Turbulent shear flows in a stratified fluid 6. Buoyant convection from isolated sources 7. Convection from heated surfaces 8. Double-diffusive convection 9. Mixing across density interfaces 10. Internal mixing processes Bibliography and author index Recent publications Subject index.", "doc-2": "Abstract The coexistence in the deep ocean of a finite, stable stratification, a strong meridional overturning circulation, and mesoscale eddies raises complex questions concerning the circulation energetics. In particular, small-scale mixing processes are necessary to resupply the potential energy removed in the interior by the overturning and eddy-generating process. A number of lines of evidence, none complete, suggest that the oceanic general circulation, far from being a heat engine, is almost wholly governed by the forcing of the wind field and secondarily by deep water tides. In detail however, the budget of mechanical energy input into the ocean is poorly constrained. The now inescapable conclusion that over most of the ocean significant vertical mixing is confined to topographically complex boundary areas implies a potentially radically different interior circulation than is possible with uniform mixing. Whether ocean circulation models, either simple box or full numerical ones, neither explicitly accounting for the energy input into the system nor providing for spatial variability in the mixing, have any physical relevance under changed climate conditions is at issue.", "label": 1}
{"doc-1": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.", "doc-2": "We present a method for computing ambient occlusion (AO) for a stack of images of a scene from a fixed viewpoint. Ambient occlusion, a concept common in computer graphics, characterizes the local visibility at a point: it approximates how much light can reach that point from different directions without getting blocked by other geometry. While AO has received surprisingly little attention in vision, we show that it can be approximated using simple, per-pixel statistics over image stacks, based on a simplified image formation model. We use our derived AO measure to compute reflectance and illumination for objects without relying on additional smoothness priors, and demonstrate state-of-the art performance on the MIT Intrinsic Images benchmark. We also demonstrate our method on several synthetic and real scenes, including 3D printed objects with known ground truth geometry.", "label": 1}
{"doc-1": "Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.", "doc-2": "Finding the k-nearest neighbours of every node in a dataset is one of the most important data operations with wide application in various areas such as recommendation and information retrieval. However, a major challenge is that the execution time of existing approaches grows rapidly as the number of nodes or dimensions increases. In this paper, we present greedy filtering, an efficient and scalable algorithm for finding an approximate k-nearest neighbour graph. It selects a fixed number of nodes as candidates for every node by filtering out node pairs that do not have any matching dimensions with large values. Greedy filtering achieves consistent approximation accuracy across nodes in linear execution time. We also present a faster version of greedy filtering that uses inverted indices on the node prefixes. Through theoretical analysis, we show that greedy filtering is effective for datasets whose features have Zipfian distribution, a characteristic observed in majority of large datasets. We also conduct extensive comparative experiments against a three state-of-the-art algorithms, and b three algorithms in related research domains. Our experimental results show that greedy filtering consistently outperforms other algorithms in various types of high-dimensional datasets.", "label": 1}
{"doc-1": "When small RNA is sequenced on current sequencing machines, the resulting reads are usually longer than the RNA and therefore contain parts of the 3' adapter. That adapter must be found and removed error-tolerantly from each read before read mapping. Previous solutions are either hard to use or do not offer required features, in particular support for color space data. As an easy to use alternative, we developed the command-line tool cutadapt, which supports 454, Illumina and SOLiD (color space) data, offers two adapter trimming algorithms, and has other useful features. Cutadapt, including its MIT-licensed source code, is available for download at http://code.google.com/p/cutadapt/", "doc-2": "The aim of this research was the identification of novel pharmacogenomic biomarkers for better understanding the complex gene regulation mechanisms underpinning glucocorticoid (GC) action in paediatric inflammatory bowel disease (IBD). This goal was achieved by evaluating high-throughput microRNA (miRNA) profiles during GC treatment, integrated with the assessment of expression changes in GC receptor (GR) heterocomplex genes. Furthermore, we tested the hypothesis that differentially expressed miRNAs could be directly regulated by GCs through investigating the presence of GC responsive elements (GREs) in their gene promoters. Ten IBD paediatric patients responding to GCs were enrolled. Peripheral blood was obtained at diagnosis (T0) and after four weeks of steroid treatment (T4). MicroRNA profiles were analyzed using next generation sequencing, and selected significantly differentially expressed miRNAs were validated by quantitative reverse transcription-polymerase chain reaction. In detail, 18 miRNAs were differentially expressed from T0 to T4, 16 of which were upregulated and 2 of which were downregulated. Out of these, three miRNAs (miR-144, miR-142, and miR-96) could putatively recognize the 3UTR of the GR gene and three miRNAs (miR-363, miR-96, miR-142) contained GREs sequences, thereby potentially enabling direct regulation by the GR. In conclusion, we identified miRNAs differently expressed during GC treatment and miRNAs which could be directly regulated by GCs in blood cells of young IBD patients. These results could represent a first step towards their translation as pharmacogenomic biomarkers.", "label": 1}
{"doc-1": "Linear algebra and matrix theory are fundamental tools in mathematical and physical science, as well as fertile fields for research. This new edition of the acclaimed text presents results of both classic and recent matrix analyses using canonical forms as a unifying theme, and demonstrates their importance in a variety of applications. The authors have thoroughly revised, updated, and expanded on the first edition. The book opens with an extended summary of useful concepts and facts and includes numerous new topics and features, such as: - New sections on the singular value and CS decompositions - New applications of the Jordan canonical form - A new section on the Weyr canonical form - Expanded treatments of inverse problems and of block matrices - A central role for the Von Neumann trace theorem - A new appendix with a modern list of canonical forms for a pair of Hermitian matrices and for a symmetric-skew symmetric pair - Expanded index with more than 3,500 entries for easy reference - More than 1,100 problems and exercises, many with hints, to reinforce understanding and develop auxiliary themes such as finite-dimensional quantum systems, the compound and adjugate matrices, and the Loewner ellipsoid - A new appendix provides a collection of problem-solving hints.", "doc-2": "We study different notions of quantum correlations in multipartite systems of distinguishable and indistinguishable particles. Based on the definition of quantum coherence for a single particle, we consider two possible extensions of this concept to the many-particle scenario and determine the influence of the exchange symmetry. Moreover, we characterize the relation of multiparticle coherence to the entanglement of the compound quantum system. To support our general treatment with examples, we consider the quantum correlations of a collection of qudits. The impact of local and global quantum superpositions on the different forms of quantum correlations is discussed. For differently correlated states in the bipartite and multipartite scenarios, we provide a comprehensive characterization of the various forms and origins of quantum correlations.", "label": 1}
{"doc-1": "Pathological angiogenesis is a hallmark of cancer and various ischaemic and inflammatory diseases. Concentrated efforts in this area of research are leading to the discovery of a growing number of pro- and anti-angiogenic molecules, some of which are already in clinical trials. The complex interactions among these molecules and how they affect vascular structure and function in different environments are now beginning to be elucidated. This integrated understanding is leading to the development of a number of exciting and bold approaches to treat cancer and other diseases. But owing to several unanswered questions, caution is needed.", "doc-2": "MOTIVATIONEvent extraction using expressive structured representations has been a significant focus of recent efforts in biomedical information extraction. However, event extraction resources and methods have so far focused almost exclusively on molecular-level entities and processes, limiting their applicability.RESULTSWe extend the event extraction approach to biomedical information extraction to encompass all levels of biological organization from the molecular to the whole organism. We present the ontological foundations, target types and guidelines for entity and event annotation and introduce the new multi-level event extraction (MLEE) corpus, manually annotated using a structured representation for event extraction. We further adapt and evaluate named entity and event extraction methods for the new task, demonstrating that both can be achieved with performance broadly comparable with that for established molecular entity and event extraction tasks.AVAILABILITYThe resources and methods introduced in this study are available from http:/ actem.ac.uk/MLEE/.CONTACTpyysalos@cs.man.ac.ukSUPPLEMENTARY INFORMATIONSupplementary data are available at Bioinformatics online.", "label": 1}
{"doc-1": "The present article presents an integrative theoretical framework to explain and to predict psychological changes achieved by different modes of treatment. This theory states that psychological procedures, whatever their form, alter the level and strength of self-efficacy. It is hypothesized that expectations of personal efficacy determine whether coping behavior will be initiated, how much effort will be expended, and how long it will be sustained in the face of obstacles and aversive experiences. Persistence in activities that are subjectively threatening but in fact relatively safe produces, through experiences of mastery, further enhancement of self-efficacy and corresponding reductions in defensive behavior. In the proposed model, expectations of personal efficacy are derived from four principal sources of information: performance accomplishments, vicarious experience, verbal persuasion, and physiological states. The more dependable the experiential sources, the greater are the changes in perceived selfefficacy. A number of factors are identified as influencing the cognitive processing of efficacy information arising from enactive, vicarious, exhortative, and emotive sources. The differential power of diverse therapeutic procedures is analyzed in terms of the postulated cognitive mechanism of operation. Findings are reported from microanalyses of enactive, vicarious, and emotive modes of treatment that support the hypothesized relationship between perceived self-efficacy and behavioral changes. Possible directions for further research are discussed.", "doc-2": "Background: The Expert Patients Program (EPP) has high non-participation and dropout rates and some uncertainty on its effectiveness. Aim: To identify, in patients with a cardiovascular event (CVE), the usefulness of participating in the EPP in relation to the quality of life, morbi-mortality and use of specialized healthcare resources during two years. Methods: The research design is A quasi-experimental study with non-random assignment of EPP with two years of monitoring and the subjects are patients at the first acute myocardial infarction (AMI) or ischemic stroke. The measures taken are Clinical and socio-demographic variables and a quality of life questionnaire were registered at starting. During the monitoring, the new CVE, the number of specialized out-patient or emergency consultations and hospital admittances, life questionnaire and death, were reported. Descriptive and comparative bivariate and multivariate analysis was conducted as statistical analysis. Results: 100 patients with AMI and 69 with stroke were included, 51% refused and 10% dropped out. During monitoring, 21% presented a CVE, 59% went to the emergency, 34% required admittance, and 4% died without any relationship with the participation. There was a significantly higher frequency of scheduled visits in patients who received the intervention. The general health, vitality and mental health worsened significantly regardless of the participation. The physical functioning, social functioning and bodily pain did not undergo significant differences; while the physical and emotional roles changed significantly and in a different way according to the degree of participation. Conclusions: Despite the low participation in the PPE, we find a significant improvement in the quality of life in the intervention group.", "label": 1}
{"doc-1": "OBJECTIVESTo develop a 10-minute cognitive screening tool (Montreal Cognitive Assessment, MoCA) to assist first-line physicians in detection of mild cognitive impairment (MCI), a clinical state that often progresses to dementia.DESIGNValidation study.SETTINGA community clinic and an academic center.PARTICIPANTSNinety-four patients meeting MCI clinical criteria supported by psychometric measures, 93 patients with mild Alzheimer's disease (AD) (Mini-Mental State Examination (MMSE) score > or =17), and 90 healthy elderly controls (NC).MEASUREMENTSThe MoCA and MMSE were administered to all participants, and sensitivity and specificity of both measures were assessed for detection of MCI and mild AD.RESULTSUsing a cutoff score 26, the MMSE had a sensitivity of 18% to detect MCI, whereas the MoCA detected 90% of MCI subjects. In the mild AD group, the MMSE had a sensitivity of 78%, whereas the MoCA detected 100%. Specificity was excellent for both MMSE and MoCA (100% and 87%, respectively).CONCLUSIONMCI as an entity is evolving and somewhat controversial. The MoCA is a brief cognitive screening tool with high sensitivity and specificity for detecting MCI as currently conceptualized in patients performing in the normal range on the MMSE.", "doc-2": "Abstract Huntingtons disease (HD) is associated with impairments in dual-task performance. Despite that, only a few studies have investigated dual-tasking in HD. We examined dual-task performance in 15 participants in the early stages of HD and 15 healthy controls. Participants performed direct circle tracing (able to view arm) and indirect circle tracing (arm obscured) either on their own (single tasks) or paired with serial subtraction by twos or threes (dual tasks). Overall, our results suggested that HD participants were significantly slower and less accurate than controls. Both groups were slower and less accurate when performing indirect circle tracing compared with direct circle tracing. HD participants experienced greater dual-task interference in terms of accuracy when performing direct circle tracing compared with indirect circle tracing. Despite that, controls were more inclined to speedaccuracy trade-offs compared with HD participants. Importantly, unlike controls, HD participants were not disproportionately faster when performing direct circle tracing as a single task compared with the dual-task conditions. Our results suggest that simple tasks place greater attentional demands on HD participants compared with controls. These findings support that impaired automaticity may be responsible for some of the attentional deficits manifested in HD.", "label": 1}
{"doc-1": "Fluorescence methods are being used increasingly in biochemical, medical, and chemical research. This is because of the inherent sensitivity of this technique. and the favorable time scale of the phenomenon of fluorescence. 8 Fluorescence emission occurs about 10- sec (10 nsec) after light absorp tion. During this period of time a wide range of molecular processes can occur, and these can effect the spectral characteristics of the fluorescent compound. This combination of sensitivity and a favorable time scale allows fluorescence methods to be generally useful for studies of proteins and membranes and their interactions with other macromolecules. This book describes the fundamental aspects of fluorescence. and the biochemical applications of this methodology. Each chapter starts with the -theoreticalbasis of each phenomenon of fluorescence, followed by examples which illustrate the use of the phenomenon in the study of biochemical problems. The book contains numerous figures. It is felt that such graphical presentations contribute to pleasurable reading and increased understand ing. Separate chapters are devoted to fluorescence polarization, lifetimes, quenching, energy transfer, solvent effects, and excited state reactions. To enhance the usefulness of this work as a textbook, problems are included which illustrate the concepts described in each chapter. Furthermore, a separate chapter is devoted to the instrumentation used in fluorescence spectroscopy. This chapter will be especially valuable for those perform ing or contemplating fluorescence measurements. Such measurements are easily compromised by failure to consider a number of simple principles.\"", "doc-2": "The distribution of the transcription machinery among different sub-nuclear domains raises the question on how the architecture of the nucleus modulates the transcriptional response. Here, we used fluorescence fluctuation analyses to quantitatively explore the organization of the glucocorticoid receptor (GR) in the interphase nucleus of living cells. We found that this ligand-activated transcription factor diffuses within the nucleus and dynamically interacts with bodies enriched in the coregulator NCoA-2, DNA-dependent foci and chromatin targets. The distribution of the receptor among the nuclear compartments depends on NCoA-2 and the conformation of the receptor as assessed with synthetic ligands and GR mutants with impaired transcriptional abilities. Our results suggest that the partition of the receptor in different nuclear reservoirs ultimately regulates the concentration of receptor available for the interaction with specific targets, and thus has an impact on transcription regulation.", "label": 1}
{"doc-1": "Part 1 Newtonian mechanics: experimental facts investigation of the equations of motion. Part 2 Lagrangian mechanics: variational principles Lagrangian mechanics on manifolds oscillations rigid bodies. Part 3 Hamiltonian mechanics: differential forms symplectic manifolds canonical formalism introduction to pertubation theory.", "doc-2": "Abstract A simpleyet plausiblemodel for B-type vortex breakdown flows is postulated; one that is based on the immersion of a pair of slender coaxial vortex rings in a swirling flow of an ideal fluid rotating around the axis of symmetry of the rings. It is shown that this model exhibits in the advection of passive fluid particles (kinematics) just about all of the characteristics that have been observed in what is now a substantial body of published research on the phenomenon of vortex breakdown. Moreover, it is demonstrated how the very nature of the fluid dynamics in axisymmetric breakdown flows can be predicted and controlled by the choice of the initial ring configurations and their vortex strengths. The dynamic intricacies produced by the two ring + swirl model are illustrated with several numerical experiments.", "label": 1}
{"doc-1": "The purpose of this handout is to briefly show that several seemingly unrelated models are actually all special cases of the generalized linear model. (Indeed, I think most of these techniques were initially developed without people realizing they were interconnected.) We will also briefly introduce the use of factor variables and the margins command, both of which will be used heavily during the course.", "doc-2": "We examined how freshwater flow and phytoplankton biomass affected abundance and population dynamics of the introduced subtropical copepod Pseudodiaptomus forbesi in brackish and freshwater regions of the San Francisco Estuary, California, USA. This copepod is key prey for the endangered and food-limited delta smelt, Hypomesus transpacificus, in low-salinity water during summerautumn. Long-term monitoring data showed that P. forbesi was most abundant in fresh water, where summerautumn abundance was invariant with freshwater flow. Abundance was positively related to freshwater flow in low-salinity water. Reproductive rates in both regions during 20102012 were low and unresponsive to chlorophyll or freshwater flow. Development indices, calculated as ratios of laboratory-derived to field-derived stage durations, were lowest for nauplii and highest for late copepodites, but averaged below 0.5 for all stages combined. Development indices were weakly related to chlorophyll for late copepodites only, unrelated to freshwater flow, and slightly higher in low-salinity than fresh water. Thus, the principal mechanism by which flow affects the P. forbesi population is apparently transport of copepods from fresh water to low-salinity water, where copepods are available to delta smelt. This work demonstrates how freshwater flow affects estuarine foodwebs through spatial subsidies of food supply.", "label": 1}
{"doc-1": "MicroRNAs (miRNAs) are small RNAs that regulate the expression of complementary messenger RNAs. Hundreds of miRNA genes have been found in diverse animals, and many of these are phylogenetically conserved. With miRNA roles identified in developmental timing, cell death, cell proliferation, haematopoiesis and patterning of the nervous system, evidence is mounting that animal miRNAs are more numerous, and their regulatory impact more pervasive, than was previously suspected.", "doc-2": "BackgroundThe power of genome-wide association studies (GWAS) is often limited by the sample size available for the analysis. Milk fatty acid (FA) traits are scarcely recorded due to expensive and time-consuming analytical techniques. Combining multi-population datasets can enhance the power of GWAS enabling detection of genomic region explaining medium to low proportions of the genetic variation. GWAS often detect broader genomic regions containing several positional candidate genes making it difficult to untangle the causative candidates. Post-GWAS analyses with data on pathways, ontology and tissue-specific gene expression status might allow prioritization among positional candidate genes.ResultsMulti-population GWAS for 16 FA traits quantified using gas chromatography (GC) in sample populations of the Chinese, Danish and Dutch Holstein with high-density (HD) genotypes detects 56 genomic regions significantly associated to at least one of the studied FAs; some of which have not been previously reported. Pathways and gene ontology (GO) analyses suggest promising candidate genes on the novel regions including OSBPL6 and AGPS on Bos taurus autosome (BTA) 2, PRLH on BTA 3, SLC51B on BTA 10, ABCG5/8 on BTA 11 and ALG5 on BTA 12. Novel genes in previously known regions, such as FABP4 on BTA 14, APOA1/5/7 on BTA 15 and MGST2 on BTA 17, are also linked to important FA metabolic processes.ConclusionIntegration of multi-population GWAS and enrichment analyses enabled detection of several novel genomic regions, explaining relatively smaller fractions of the genetic variation, and revealed highly likely candidate genes underlying the effects. Detection of such regions and candidate genes will be crucial in understanding the complex genetic control of FA metabolism. The findings can also be used to augment genomic prediction models with regions collectively capturing most of the genetic variation in the milk FA traits.", "label": 1}
{"doc-1": "This paper summarizes the current state of the art and recent trends in software engineering economics. It provides an overview of economic analysis techniques and their applicability to software engineering and management. It surveys the field of software cost estimation, including the major estimation techniques available, the state of the art in algorithmic cost models, and the outstanding research issues in software cost estimation.", "doc-2": "This paper explores some of the practical issues associated with the use of case-based reasoning (CBR) or estimation by analogy for software project effort prediction. We note that different research teams have reported widely differing results with this technology. Whilst we accept that underlying characteristics of the datasets being used play a major role we also argue that configuring a CBR system can also have an impact. We examine the impact of the choice of number of analogies when making predictions. Our analysis is based on project effort data derived from two sources. The first data has been collected by a Canadian software house. The other data was obtained by means of simulation. The results show that using a larger number of analogies generated better predictions. On the other hand, the nearest neighbour is observed to be the better predictor for smaller training sets. We also found that the underlying distribution of the dataset does have a significant impact on the choice of the number of analogies. It was difficult to identify patterns for datasets with complex distribution properties. We believe that a considerable amount of work is required to understand the relationship between the properties of the dataset and configuring a CBR system.", "label": 1}
{"doc-1": "The main purpose of this article is to present several new statistical tests of neutrality of mutations against a class of alternative models, under which DNA polymorphisms tend to exhibit excesses of rare alleles or young mutations. Another purpose is to study the powers of existing and newly developed tests and to examine the detailed pattern of polymorphisms under population growth, genetic hitchhiking and background selection. It is found that the polymorphic patterns in a DNA sample under logistic population growth and genetic hitchhiking are very similar and that one of the newly developed tests, Fs, is considerably more powerful than existing tests for rejecting the hypothesis of neutrality of mutations. Background selection gives rise to quite different polymorphic patterns than does logistic population growth or genetic hitchhiking, although all of them show excesses of rare alleles or young mutations. We show that Fu and Li's tests are among the most powerful tests against background selection. Implications of these results are discussed.", "doc-2": "Anastrepha striata is widely distributed across the Americas and is a pest of economically important crops, especially crops of the Myrtaceae family. Insect population structures can be influenced by the presence of physical barriers or characteristics associated with habitat differences. This study evaluated the effect of the Western Andes on the population structure of A. striata. Individuals were collected from Psidium guajava fruits from three natural regions of southwestern Colombia (Pacific Coast, mountainous region and the inter-Andean valley of the Cauca River). Based on a 1318bp concatenated of the genes Cytochrome Oxidase subunit I (COI) and NADH dehydrogenase subunit 6 (ND6), 14 haplotypes with few changes among them (between 1 and 3) were found. There was only one dominant haplotype in all three regions. No genetic structure associated with the three eco-geographical regions of the study was found. Moreover, the Western Andes are not an effective barrier for the genetic isolation of the populations from the Pacific Coast compared with the inter-Andean valley populations. This genetic homogeneity could be partially due to anthropogenic intervention, which acts as a dispersal agent of infested fruits. Another hypothesis to explain the lack of structure would be the relatively recent arrival of A. striata to the region, as indicated by an analysis of the demographic history, which reveals a process of population expansion. This study represents the first attempt to understand the population genetics of A. striata in Colombia and could contribute to the integral management of this pest.", "label": 1}
{"doc-1": "Learning methods based on dynamic programming (DP) are receiving increasing attention in artificial intelligence. Researchers have argued that DP provides the appropriate basis for compiling planning results into reactive strategies for real-time control, as well as for learning such strategies when the system being controlled is incompletely known. We introduce an algorithm based on DP, which we call Real-Time DP (RTDP), by which an embedded system can improve its performance with experience. RTDP generalizes Korf''s Learning-Real-Time-A algorithm to problems involving uncertainty. We invoke results from the theory of asynchronous DP to prove that RTDP achieves optimal behavior in several different classes of problems. We also use the theory of asynchronous DP to illuminate aspects of other DP-based reinforcement learning methods such as Watkins'' Q-Learning algorithm. A secondary aim of this article is to provide a bridge between AI research on real-time planning and learning and relevant concepts and algorithms from control theory. This research was supported by grants to A.G. Barto from the National Science Foundation (ECS-8912623 and ECS-9214866) and the Air Force Office of Scientific Research, Bolling AFB (AFOSR-89-0526).", "doc-2": "We present a heuristic-based algorithm for solving restricted Markov decision processes (MDPs). Our approach, which combines ideas from deterministic search and recent dynamic programming methods, focusses computation towards promising areas of the state space. It is thus able to significantly reduce the amount of processing required to produce a solution. We demonstrate this improvement by comparing the performance of our approach to the performance of several existing algorithms on a robotic path planning domain.", "label": 1}
{"doc-1": "This paper summarizes the current state of the art and recent trends in software engineering economics. It provides an overview of economic analysis techniques and their applicability to software engineering and management. It surveys the field of software cost estimation, including the major estimation techniques available, the state of the art in algorithmic cost models, and the outstanding research issues in software cost estimation.", "doc-2": "In this experiment, seven software teams developed versions of the same small-size (2000-4000 source instruction) application software product. Four teams used the Specifying approach. Three teams used the Prototyping approach. The main results of the experiment were: Prototyping yielded products with roughly equivalent performance, but with about 40% less code and 45% less effort. The prototyped products rated somewhat lower on functionality and robustness, but higher on ease of use and ease of learning. Specifying produced more coherent designs and software that was easier to integrate. The paper presents the experimental data supporting these and a number of additional conclusions.", "label": 1}
{"doc-1": "Molecular Cloning has served as the foundation of technical expertise in labs worldwide for 30 years. No other manual has been so popular, or so influential. Molecular Cloning, Fourth Edition, by the celebrated founding author Joe Sambrook and new co-author, the distinguished HHMI investigator Michael Green, preserves the highly praised detail and clarity of previous editions and includes specific chapters and protocols commissioned for the book from expert practitioners at Yale, U Mass, Rockefeller University, Texas Tech, Cold Spring Harbor Laboratory, Washington University, and other leading institutions. The theoretical and historical underpinnings of techniques are prominent features of the presentation throughout, information that does much to help trouble-shoot experimental problems. For the fourth edition of this classic work, the content has been entirely recast to include nucleic-acid based methods selected as the most widely used and valuable in molecular and cellular biology laboratories. Core chapters from the third edition have been revised to feature current strategies and approaches to the preparation and cloning of nucleic acids, gene transfer, and expression analysis. They are augmented by 12 new chapters which show how DNA, RNA, and proteins should be prepared, evaluated, and manipulated, and how data generation and analysis can be handled. The new content includes methods for studying interactions between cellular components, such as microarrays, next-generation sequencing technologies, RNA interference, and epigenetic analysis using DNA methylation techniques and chromatin immunoprecipitation. To make sense of the wealth of data produced by these techniques, a bioinformatics chapter describes the use of analytical tools for comparing sequences of genes and proteins and identifying common expression patterns among sets of genes. Building on thirty years of trust, reliability, and authority, the fourth edition of Mol", "doc-2": "Rhizobium leguminosarum bv. trifolii rosR gene encodes a transcriptional regulator involved in the positive regulation of exopolysaccharide synthesis. Transcription of rosR is directed by two promoters, distal P1 and proximal P2, of different strengths. We demonstrated that rosR P1 functions as the main promoter and, besides the -35 and -10 sequences, it contains two other important regulatory elements, an extended -10 motif and an upstream promoter element, that play a significant role in the initiation of transcription. Two cAMP-CRP binding sites (I and II) have been identified upstream of P1, both necessary for optimal rosR expression. cAMP-CRP binding site III is located within the P2 promoter and also influences rosR transcription. rosR transcription levels are dependent both on the presence of the cAMP-CRP complex and on the carbon source, indicating regulation of transcription and exopolysaccharide production by catabolite repression.", "label": 1}
{"doc-1": "One possible reason for the continued neglect of statistical power analysis in research in the behavioral sciences is the inaccessibility of or difficulty with the standard material. A convenient, although not comprehensive, presentation of required sample sizes is provided here. Effect-size indexes and conventional values for these are given for operationally defined small, medium, and large effects. The sample sizes necessary for .80 power to detect effects at these levels are tabled for eight standard statistical tests: (a) the difference between independent means, (b) the significance of a product-moment correlation, (c) the difference between independent rs, (d) the sign test, (e) the difference between independent proportions, (f) chi-square tests for goodness of fit and contingency tables, (g) one-way analysis of variance, and (h) the significance of a multiple or multiple partial correlation.", "doc-2": "In this research, for an effective learning of concepts in the scope of functional groups in organic chemistry, it has been developed as Organic Chemistry Taboo (OrCheTaboo) which is an educational activity by the researchers. The aim of this study is to analyze the effect of the game OrCheTaboo on learning of concepts related to functional groups. The study group of the research consists of 62 students who took the Organic Chemistry Laboratory Course in the spring term and they enrolled in the Department of Secondary Science and Mathematics Education of a Faculty of Education at a state university in Turkey. Quasi-experimental design with pretest-posttest control group has been used. As a result, the game OrCheTaboo gives the opportunity to be in conceptual development processes like describing the terms to the students, identifying from the other terms or establishing its similar characteristics with the other terms, put their relation forward. Because of these characteristics, while turning the complicated and difficult terms, the game has a positive and active role.", "label": 1}
{"doc-1": "Using an improved method of gel electrophoresis, many hitherto unknown proteins have been found in bacteriophage T4 and some of these have been identified with specific gene products. Four major components of the head are cleaved during the process of assembly, apparently after the precursor proteins have assembled into some large intermediate structure.", "doc-2": "Xanthohumol (XH), the principal prenylflavonoid of the hop plant (Humulus lupulus L.), dose-dependently inhibited isobutylmethylxanthine (IBMX)-induced melanogenesis in B16 melanoma cells, with little cytotoxicity at the effective concentrations. Decreased melanin content was accompanied by reduced tyrosinase enzyme activity, protein and mRNA expression. The levels of tyrosinase-related protein 1 and 2 mRNAs were decreased by XH. XH also inhibited -melanocyte stimulating hormone- or forskolin-induced increases in melanogenesis, suggesting an action on the cAMP-dependent melanogenic pathway. XH downregulated the protein and mRNA expression of microphthalmia-associated transcription factor (MITF), a master transcriptional regulator of key melanogenic enzymes. These results suggest that XH might act as a hypo-pigmenting agent through the downregulation of MITF in the cAMP-dependent melanogenic pathway.", "label": 1}
{"doc-1": "Preeclampsia, a syndrome affecting 5% of pregnancies, causes substantial maternal and fetal morbidity and mortality. The pathophysiology of preeclampsia remains largely unknown. It has been hypothesized that placental ischemia is an early event, leading to placental production of a soluble factor or factors that cause maternal endothelial dysfunction, resulting in the clinical findings of hypertension, proteinuria, and edema. Here, we confirm that placental soluble fms-like tyrosine kinase 1 (sFlt1), an antagonist of VEGF and placental growth factor (PlGF), is upregulated in preeclampsia, leading to increased systemic levels of sFlt1 that fall after delivery. We demonstrate that increased circulating sFlt1 in patients with preeclampsia is associated with decreased circulating levels of free VEGF and PlGF, resulting in endothelial dysfunction in vitro that can be rescued by exogenous VEGF and PlGF. Additionally, VEGF and PlGF cause microvascular relaxation of rat renal arterioles in vitro that is blocked by sFlt1. Finally, administration of sFlt1 to pregnant rats induces hypertension, proteinuria, and glomerular endotheliosis, the classic lesion of preeclampsia. These observations suggest that excess circulating sFlt1 contributes to the pathogenesis of preeclampsia.", "doc-2": "Despite substantial research, the early diagnosis of preeclampsia remains elusive. Lipids are now recognized to be involved in regulation and pathophysiology of some disease. Shotgun lipidomic studies were undertaken to determine whether serum lipid biomarkers exist that predict preeclampsia later in the same in pregnancy. A discovery study was performed using sera collected at 12-14 weeks pregnancy from 27 controls with uncomplicated pregnancies and 29 cases that later developed preeclampsia. Lipids were extracted and analyzed by direct infusion into a TOF mass spectrometer. MS signals, demonstrating apparent differences were selected, their abundances determined, and statistical differences tested. Statistically significant lipid markers were reevaluated in a second confirmatory study having 43 controls and 37 preeclampsia cases. Multi-marker combinations were developed using those lipid biomarkers confirmed in the second study. The initial study detected 45 potential preeclampsia markers. Of these, 23 markers continued to be statistically significant in the second confirmatory set. Most of these markers, representing several lipid classes, were chemically characterized, typically providing lipid class and potential molecular components using MS(2) Several multi-marker panels with areas under the curve >0.85 and high predictive values were developed. Developed panels of serum lipidomic biomarkers appear to be able to identify most women at risk for preeclampsia in a given pregnancy at 12-14 weeks gestation.", "label": 1}
{"doc-1": "EXAMINATION of the mental state is essential in evaluating psychiatric patients.1 Many investigators have added quantitative assessment of cognitive performance to the standard examination, and have documented reliability and validity of the several clinical tests of the sensorium.2*3 The available batteries are lengthy. For example, WITHERS and HINTONS test includes 33 questions and requires about 30 min to administer and score. The standard WAIS requires even more time. However, elderly patients, particularly those with delirium or dementia syndromes, cooperate well only for short periods.4 Therefore, we devised a simplified, scored form of the cognitive mental status examination, the Mini-Mental State (MMS) which includes eleven questions, requires only 5-10 min to administer, and is therefore practical to use serially and routinely. It is mini because it concentrates only on the cognitive aspects of mental functions, and excludes questions concerning mood, abnormal mental experiences and the form of thinking. But within the cognitive realm it is thorough. We have documented the validity and reliability of the MMS when given to 206 patients with dementia syndromes, affective disorder, affective disorder with cognitive impairment pseudodementia5T6), mania, schizophrenia, personality disorders, and in 63 normal subjects.", "doc-2": "OBJECTIVEFreezing of gait (FOG) in Parkinson's disease (PD) may involve specific impairments in acquiring automaticity under working memory load. This study examined whether implicit sequence learning, with or without a secondary task, is impaired in patients with FOG.METHODFourteen freezers (FRs), 14 nonfreezers (nFRs), and 14 matched healthy controls (HCs) performed a serial reaction time (SRT) task with a deterministic stimulus sequence under single-task (ST) and dual-task (DT) conditions. The increase in reaction times (RTs) for random compared with sequenced blocks was used as a measure of implicit sequence learning. Neuropsychological tests assessing global cognitive functioning and executive dysfunction were administered in order to investigate their relation to sequence learning.RESULTSnFRs and HCs showed significant implicit sequence learning effects (p < 0.001). FRs demonstrated a tendency to learn sequence-specific information in the SRT-ST task (p = 0.07) but not in the SRT-DT task (p = 0.69). Severity of FOG, however, correlated positively with SRT-DT task performance (r = -0.56; p < 0.05).CONCLUSIONSThe present results suggest that PD patients suffering from FOG pathology exhibit a specific impairment in the acquisition of automaticity. When working memory capacity is supplementarily loaded by adding a DT, sequence learning in FRs becomes increasingly impaired. These findings indicate that therapies should focus on extensive training in acquiring novel motor activities and reducing working memory load to improve learning in FOG.", "label": 1}
{"doc-1": "In this article, the optical properties of the In x Ga 1x N/GaN quantum well(QW) are investigated. The refractive index spectrum of a QW is essential to the design and implementation of optoelectronic devices. Yet, the refractive index of the InGaN/GaN QW system over a wide spectral range has been unavailable so far. This article presents a comprehensive model, which includes the excitoneffect and most of the major critical points, to calculate the complex index of refraction of the InGaN/GaN QW at room temperature. The calculations have been performed for QWs with various alloy compositions and well widths in the spectral range from 1 to 9 eV. The model presented here fully considers transitions near the band edge and above barrier gap contributions.", "doc-2": "We experimentally and theoretically investigate the relationship between the electroreflectance (ER) and photocurrent (PC) spectra, and how they can be utilized to estimate the flat-band voltage and the bandgap energy of the InGaN/GaN-based quantum-well (QW) structure in blue light-emitting diodes. With theoretical modeling of ER and PC spectra, we calculate the changes in both the refractive index (<inline-formula> <tex-math notation=\"LaTeX\">$\\Delta \\text{n}$ </tex-math></inline-formula>) and optical absorption (<inline-formula> <tex-math notation=\"LaTeX\">$\\Delta \\alpha )$ </tex-math></inline-formula> spectra from experimental ER and PC data by using the KramersKronig relation. Then, we compare <inline-formula> <tex-math notation=\"LaTeX\">$\\Delta \\text{n}$ </tex-math></inline-formula> (or <inline-formula> <tex-math notation=\"LaTeX\">$\\Delta \\alpha )$ </tex-math></inline-formula> spectra obtained differently from the ER and PC data and try to comprehend their physical meanings interactively. From these combined studies, we propose an exact method of determining the flat-band voltage, the piezoelectric field, the emission energy, the effective bandgap energy, and the Stokes shift of a QW structure under the quantum-confined Stark effect (QCSE).", "label": 1}
{"doc-1": "The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSI-BLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.", "doc-2": "GT factors constitute a plant-specific transcription factor family with a conserved trihelix DNA-binding domain. In this study, comprehensive sequence analysis suggested that 26 putative GT factors exist in rice. Phylogenetic analysis revealed three distinctive subfamilies (GT, GT, and GT) of plant GT factors and each subfamily has a unique composition of predicted motifs. We characterized the OsGT-1 gene, a typical member of the GT subfamily in rice. This gene encodes a protein containing a conserved trihelix domain, and the OsGT-1:GFP fusion protein was targeted to nuclei of rice cells. The transcript level of OsGT-1 was strongly induced by salt stress and slightly induced by drought and cold stresses and abscisic acid treatment. Two other members of the GT subfamily, OsGT-2 and OsGT-3, were also induced by most of the abiotic stresses. These results suggested that the genes of the GT subfamily in rice may be involved in stress responses. A homozygous mutant osgt-1 (with T-DNA inserted in the promoter region of OsGT-1) showed more sensitive to salt stress than wild-type rice. Overexpression of OsGT-1 in rice enhanced salt tolerance at the seedling stage. This evidence suggests that the OsGT subfamily may participate in the regulation of stress tolerance in rice.", "label": 1}
{"doc-1": "We present a new polynomial-time algorithm for linear programming. The running-time of this algorithm is <italic>O</italic>(<italic>n</italic><supscrpt>3-5</supscrpt><italic>L</italic><supscrpt>2</supscrpt>), as compared to <italic>O</italic>(<italic>n</italic><supscrpt>6</supscrpt><italic>L</italic><supscrpt>2</supscrpt>) for the ellipsoid algorithm. We prove that given a polytope <italic>P</italic> and a strictly interior point <italic>a</italic>  <italic>P</italic>, there is a projective transformation of the space that maps <italic>P</italic>, <italic>a</italic> to <italic>P'</italic>, <italic>a'</italic> having the following property. The ratio of the radius of the smallest sphere with center <italic>a'</italic>, containing <italic>P'</italic> to the radius of the largest sphere with center <italic>a'</italic> contained in <italic>P'</italic> is <italic>O</italic> (<italic>n</italic>). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial-time.", "doc-2": "Task scheduling has been one of the hot and difficult problems in grid computing, it is a big challenge to design an efficient scheduling algorithm. This paper discusses the problem of independent tasks scheduling on tree-based grid computing platforms, a small heap tree (virtual resource tree) model was proposed and on the model we propose a tasks scheduling heuristic algorithm based-on linear programming. In this algorithm, we consider the computing power and bandwidth for each node in the model and assign task for each node in an integrated manner. The algorithm analysis shows the proposed algorithm is rational and effective.", "label": 1}
{"doc-1": "A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), ()} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17  -(+) * (+)  (-) * (+)  (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17  -(+) + (+)  (-) + (+)  ()). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, ).", "doc-2": "Convex polyhedra capture linear relations between variables. They are used in static analysis and optimizing compilation. Their high expressiveness is however barely used in verification because of their cost, often prohibitive as the number of variables involved increases. Our goal in this article is to lower this cost.", "label": 1}
{"doc-1": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films.", "doc-2": "When codeword frequency meets geographical location in landmark search applications, is it still discriminative for the search procedure. In this paper, we give a systematic investigation about how geographical location affects the effectiveness of codeword frequency. We explain why the standard IDF in the BoW models is less effective in location related search applications [11][12]. Consequently, we propose a location discriminative codeword frequency strategy to introduce the location context into the codeword discriminability measurement. This new codeword frequency is calculated in each geographical region, for which a spectral clustering scheme is proposed to partition the geographical map of each city into distinct regions. Extensive comparisons over the standard codeword frequency in state-of-the-art landmark search systems [1][1] demonstrates our approach's effectiveness.", "label": 1}
{"doc-1": "Table of", "doc-2": "OBJECTIVETo evaluate the impact of the position of noise source(s) and reverberation on the directional benefit and performance of three commercially available directional hearing aids.DESIGNDirectional benefit and performance were measured for four different configurations of competing noise source(s) in two different reverberant rooms. Three pairs of hearing aids representing three commercial models were selected based on electroacoustic evaluation of directivity. Directional benefit and performance of 25 subjects with symmetrical, sloping, sensorineural hearing loss were measured in all test environments using a modified version of the Hearing in Noise Test.RESULTSBoth reverberation and configuration of the competing noise source(s) significantly affected directional benefit and performance. There was no significant correlation between directional benefit and directional performance. The order of benefit and performance across hearing aid brands (from best to worst) varied depending on the noise source configuration.CONCLUSIONSData revealed increasing reverberation significantly decreased directional benefit and performance. The absolute and relative (rank ordering) directional benefit and performance varied across hearing aid brand, with noise source configuration. These results suggest that data collected in traditional test environments (e.g., a single competing noise placed at 180 degrees azimuth) cannot be used to accurately predict directional benefit or performance in the majority of other test and real-world environments. The impact of reverberation and noise source configuration on directional benefit/performance can be explained fairly well by the interaction between the spatial properties of the noise source(s) and the polar directivity patterns of the hearing aids.", "label": 1}
{"doc-1": "A comprehensive, self-contained treatment presenting general results of the theory. Establishes a geometric intuition and a working facility with specific geometric practices. Emphasizes applications through the study of interesting examples and the development of computational tools. Coverage ranges from analytic to geometric. Treats basic techniques and results of complex manifold theory, focusing on results applicable to projective varieties, and includes discussion of the theory of Riemann surfaces and algebraic curves, algebraic surfaces and the quadric line complex as well as special topics in complex manifolds.", "doc-2": "An algebraic variety is an object which can be defined in a purely algebraic way, starting from polynomials or more generally from finitely generated algebras over fields. When the base field is the field of complex numbers, it can also", "label": 1}
{"doc-1": "The Gene Ontology (GO) project (http://www. geneontology.org/) provides structured, controlled vocabularies and classications that cover several domains of molecular and cellular biology and are freely available for community use in the annotation of genes, gene products and sequences. Many model organism databases and genome annotation groups use the GO and contribute their annotation sets to the GO resource. The GO database integrates the vocabularies and contributed annotations and provides full access to this information in several formats. Members of the GO Consortium continually work collectively, involving outside experts as needed, to expand and update the GO vocabularies. The GO Web resource also provides access to extensive documentation about the GO project and links to applications that use GO data for functional", "doc-2": "Bladder cancer (BC) is one of the most common urogenital malignancies. However, present studies of its multiple gene interaction and cellular pathways remain unable to accurately verify the genesis and the development of BC. The aim of the present study was to investigate the genetic signatures of BC and identify its potential molecular mechanisms. The gene expression profiles of GSE31189 were downloaded from the Gene Expression Omnibus database. The GSE31189 dataset contained 92 samples, including 52 BC and 40 non-cancerous urothelial cells. To further examine the biological functions of the identified differentially expressed genes (DEGs), Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes pathway (KEGG) enrichment analyses were performed, and a protein-protein interaction (PPI) network was mapped using Cytoscape software. In total, 976 DEGs were identified in BC, including 457 upregulated genes and 519 downregulated genes. GO and KEGG pathway enrichment analyses indicated that upregulated genes were significantly enriched in the cell cycle and the negative regulation of the apoptotic process, while the downregulated genes were mainly involved in cell proliferation, cell adhesion molecules and oxidative phosphorylation pathways (P<0.05). From the PPI network, the 12 nodes with the highest degrees were screened as hub genes; these genes were involved in certain pathways, including the chemokine-mediated signaling pathway, fever generation, inflammatory response and the immune response nucleotide oligomerization domain-like receptor signaling pathway. The present study used bioinformatics analysis of gene profile datasets and identified potential therapeutic targets for BC.", "label": 1}
{"doc-1": "Modern survival analysis and more general event history analysis may be effectively handled in the mathematical framework of counting processes, stochastic integration, martingale central limit theory and product integration. This book presents this theory, which has been the subject of an intense research activity during the past one-and-a-half decades. The exposition of the theory is integrated with the careful presentation of many practical examples, based almost exlusively on the authors' experience, with detailed numerical and graphical illustrations. \"Statistical Models Based on Counting Processes\" may be viewed as a research monograph for mathematical statisticians and biostatisticians, although almost all methods are given in sufficient detail to be used in practice by other mathematically oriented researchers studying event histories (demographers, econometricians, epidemiologists, actuariala mathematicians, reliability engineers, biologists). Much of the material has so far only been available in the journal literature (if at all), and a wide variety of researchers will find this an invlauable survey of the subject.", "doc-2": "In many credit risk and pricing applications, credit transition matrix is modeled by a constant transition probability or generator matrix for Markov processes. Based on empirical evidence, we model rating transition processes as piecewise homogeneous Markov chains with unobserved structural breaks. The proposed model provides explicit formulas for the posterior distribution of the time-varying rating transition generator matrices, the probability of structural break at each period and prediction of transition matrices in the presence of possible structural breaks. Estimating the model by credit rating history, we show that the structural break in rating transitions can be captured by the proposed model. We also show that structural breaks in rating dynamics are different for different industries. We then compare the prediction performance of the proposed and time-homogeneous Markov chain models.", "label": 1}
{"doc-1": "Summary. We consider the problem of selecting grouped variables (factors) for accurate prediction in regression. Such a problem arises naturally in many practical situations with the multifactor analysis-of-variance problem as the most important and well-known example. Instead of selecting factors by stepwise backward elimination, we focus on the accuracy of estimation and consider extensions of the lasso, the LARS algorithm and the non-negative garrotte for factor selection. The lasso, the LARS algorithm and the non-negative garrotte are recently proposed regression methods that can be used to select individual variables. We study and propose efficient algorithms for the extensions of these methods for factor selection and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences between these methods. Simulations and real examples are used to illustrate the methods.", "doc-2": "In this work, we are interested in predicting the diagnostic statuses of potentially neurodegenerated patients using feature values derived from multi-modality neuroimaging data and biological data, which might be incomplete. Collecting the feature values into a matrix, with each row containing a feature vector of a sample, we propose a framework to predict the corresponding associated multiple target outputs (e.g., diagnosis label and clinical scores) from this feature matrix by performing matrix shrinkage following matrix completion. Specifically, we first combine the feature and target output matrices into a large matrix and then partition this large incomplete matrix into smaller submatrices, each consisting of samples with complete feature values (corresponding to a certain combination of modalities) and target outputs. Treating each target output as the outcome of a prediction task, we apply a 2-step multi-task learning algorithm to select the most discriminative features and samples in each submatrix. Features and samples that are not selected in any of the submatrices are discarded, resulting in a shrunk version of the original large matrix. The missing feature values and unknown target outputs of the shrunk matrix is then completed simultaneously. Experimental results using the ADNI dataset indicate that our proposed framework achieves higher classification accuracy at a greater speed when compared with conventional imputation-based classification methods and also yields competitive performance when compared with the state-of-the-art methods.", "label": 1}
{"doc-1": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting.", "doc-2": "In recent years, the widespread adoption of GPS enabled vehicles brings the Location Based Services new opportunities. It benefits many related fields such as urban planning, city traffic modeling, personalized recommendations and driving suggestions. The service providers can understand their users better by modeling the mobility pattern and provide more personalized services by predicting the destination of users' travels. In this paper, we propose to model both the temporal and spatial mobility patterns of human movements and predict the user's travel destination from certain origin place at certain time with specific IOHMM. In order to account for data missing, we introduce a dummy state in the process of constructing the IOHMM data sequence. We also demonstrate the possibility to represent individual mobility preference by building the user mobility profiles with the learnt IOHMM. We evaluate the prediction accuracy of our method with two datasets, and the experimental results show that our method outperforms several state-of-the-art works on both datasets.", "label": 1}
{"doc-1": "We have developed an online catalog of SNP-trait associations from published genome-wide association studies for use in investigating genomic characteristics of trait/disease-associated SNPs (TASs). Reported TASs were common [median risk allele frequency 36%, interquartile range (IQR) 21%-53%] and were associated with modest effect sizes [median odds ratio (OR) 1.33, IQR 1.20-1.61]. Among 20 genomic annotation sets, reported TASs were significantly overrepresented only in nonsynonymous sites [OR = 3.9 (2.2-7.0), p = 3.5 x 10(-7)] and 5kb-promoter regions [OR = 2.3 (1.5-3.6), p = 3 x 10(-4)] compared to SNPs randomly selected from genotyping arrays. Although 88% of TASs were intronic (45%) or intergenic (43%), TASs were not overrepresented in introns and were significantly depleted in intergenic regions [OR = 0.44 (0.34-0.58), p = 2.0 x 10(-9)]. Only slightly more TASs than expected by chance were predicted to be in regions under positive selection [OR = 1.3 (0.8-2.1), p = 0.2]. This new online resource, together with bioinformatic predictions of the underlying functionality at trait/disease-associated loci, is well-suited to guide future investigations of the role of common variants in complex disease etiology.", "doc-2": "BackgroundCurrent studies of environmental health suggest a link between air pollution components, such as particulate matter (PM), and various diseases. However, the specific genes and regulatory mechanisms implicated in PM-induced diseases remain largely unknown. Epigenetic systems such as covalent modification of histones in chromatin may mediate environmental factors in gene regulation. Investigating the relationships between PM exposure and histone modification status may help understand the mechanisms underlying environment-associated health conditions.MethodsIn this study, we obtained genome-wide profiles of H3K27ac (histone 3 lysine 27 acetylation), known to be an active gene regulatory histone modification marker, in blood samples collected from four Chinese individuals exposed to high or low PM2.5 (particles with diameters up to 2.5m).ResultsThe genome-wide chromatin immunoprecipitation sequencing (ChIP-Seq) data indicated a comprehensive differential H3K27ac landscape across the individual genomes, which was associated with high PM2.5. Moreover, a substantial number of these PM2.5-associated differential H3K27ac markers were in genes involved in immune cell activation, potentially linking these epigenetic changes with air pollution-induced immune and inflammatory responses.ConclusionsOur study provides the first genome-wide characterization of H3K27ac profiles in individuals subjected to different exposure levels of PM2.5. Future systematic investigations of the relationships between air pollutants and histone modifications in large population samples are warranted to elucidate the contributions of histone modifications to environment-associated diseases.", "label": 1}
{"doc-1": "The psychometric function relates an observers performance to an independent variable, usually some physical quantity of a stimulus in a psychophysical task. This paper, together with its companion paper (Wichmann & Hill, 2001), describes an integrated approach to (1) fitting psychometric functions, (2) assessing the goodness of fit, and (3) providing confidence intervals for the functions parameters and other estimates derived from them, for the purposes of hypothesis testing. The present paper deals with the first two topics, describing a constrained maximum-likelihood method of parameter estimation and developing several goodness-of-fit tests. Using Monte Carlo simulations, we deal with two specific difficulties that arise when fitting functions to psychophysical data. First, we note that human observers are prone to stimulus-independent errors (orlapses). We show that failure to account for this can lead to serious biases in estimates of the psychometric functions parameters and illustrate how the problem may be overcome. Second, we note that psychophysical data sets are usually rather small by the standards required by most of the commonly applied statistical tests. We demonstrate the potential errors of applying traditionalX2 methods to psychophysical data and advocate use of Monte Carlo resampling techniques that do not rely on asymptotic theory. We have made available the software to implement our methods.", "doc-2": "Barn owls are effective nocturnal predators. We tested their visual performance at low light levels and determined visual acuity and contrast sensitivity of three barn owls by their behavior at stimulus luminances ranging from photopic to fully scotopic levels (23.5 to 1.5  10). Contrast sensitivity and visual acuity decreased only slightly from photopic to scotopic conditions. Peak grating acuity was at mesopic (4  10 cd/m) conditions. Barn owls retained a quarter of their maximal acuity when luminance decreased by 5.5 log units. We argue that the visual system of barn owls is designed to yield as much visual acuity under low light conditions as possible, thereby sacrificing resolution at photopic conditions.", "label": 1}
{"doc-1": "UNLABELLEDRAxML-VI-HPC (randomized axelerated maximum likelihood for high performance computing) is a sequential and parallel program for inference of large phylogenies with maximum likelihood (ML). Low-level technical optimizations, a modification of the search algorithm, and the use of the GTR+CAT approximation as replacement for GTR+Gamma yield a program that is between 2.7 and 52 times faster than the previous version of RAxML. A large-scale performance comparison with GARLI, PHYML, IQPNNI and MrBayes on real data containing 1000 up to 6722 taxa shows that RAxML requires at least 5.6 times less main memory and yields better trees in similar times than the best competing program (GARLI) on datasets up to 2500 taxa. On datasets > or =4000 taxa it also runs 2-3 times faster than GARLI. RAxML has been parallelized with MPI to conduct parallel multiple bootstraps and inferences on distinct starting trees. The program has been used to compute ML trees on two of the largest alignments to date containing 25,057 (1463 bp) and 2182 (51,089 bp) taxa, respectively.AVAILABILITYicwww.epfl.ch/~stamatak", "doc-2": "Geographically isolated populations of Barbus present remarkable variation with regard to morphometric and meristic characters within Iranian drainage systems; while they are relatively similar in external morphology such as coloration. Present study is the first report on geographical differentiation of Barbus populations in Iran from both morphological and molecular point of views. The morphometric and meristic characters as well as phylogenetic relationships (using sequence data of mtDNA cytochrome b gene) of twelve populations from three drainages (i.e. South Caspian Sea, Orumyieh and TigrisKaroun) were analyzed. The univariate analysis reveals significant morphological differentiation among the populations from the three drainages. The phylogenetic analyses indicate relatively high genetic differentiation among the populations from the mentioned drainages, which are consistent with the observed morphological variation, and correspond well with their biogeographic distribution. However, the result of Automatic Barcode Gap Discovery (ABGD) analysis shows intra-specific differentiation for the sequences from South Caspian Sea drainage, while support the distinction of the specimens from TigrisKaroun drainage as B. lacerta. Since the sequence data of Barbus cyri from Armenia is clustered with individuals from the South Caspian Sea and the morphological comparison, the specimens from that basin are considered as B. cyri and the Orumyieh basin as Barbus sp.", "label": 1}
{"doc-1": "A method for the screening of antioxidant activity is reported as a decolorization assay applicable to both lipophilic and hydrophilic antioxidants, including flavonoids, hydroxycinnamates, carotenoids, and plasma antioxidants. The pre-formed radical monocation of 2,2'-azinobis-(3-ethylbenzothiazoline-6-sulfonic acid) (ABTS*+) is generated by oxidation of ABTS with potassium persulfate and is reduced in the presence of such hydrogen-donating antioxidants. The influences of both the concentration of antioxidant and duration of reaction on the inhibition of the radical cation absorption are taken into account when determining the antioxidant activity. This assay clearly improves the original TEAC assay (the ferryl myoglobin/ABTS assay) for the determination of antioxidant activity in a number of ways. First, the chemistry involves the direct generation of the ABTS radical monocation with no involvement of an intermediary radical. Second, it is a decolorization assay; thus the radical cation is pre-formed prior to addition of antioxidant test systems, rather than the generation of the radical taking place continually in the presence of the antioxidant. Hence the results obtained with the improved system may not always be directly comparable with those obtained using the original TEAC assay. Third, it is applicable to both aqueous and lipophilic systems.", "doc-2": "Objective: Characterization of polyphenolic contents and the inhibitory effects of aqueous extracts of ripe tomato (Lycopersicon esculentum) and red pepper (Capsicum annuum) fruits on the sodium nitroprusside (SNP) and iron(II) (Fe2+)-induced lipid peroxidation in rat liver were examined in this study. Materials and Methods: Various experimental models such as the ABTS (2,2-azino-bis(3-ethylbenzothiazoline-6-sulphonic acid)) scavenging ability and ferric reducing power were used to characterize the antioxidant activity of the extracts. High-performance liquid chromatography (HPLC) was used to determine the phenolic content of the extracts. Malondialdehyde (MDA) was used as a measure of oxidative stress in the rats liver tissue. Results: The ABTS scavenging ability and ferric reducing power of the aqueous extract of ripe red pepper were significantly higher than that of ripe tomato. Ripe red pepper and tomato fruits extracts inhibited NO in a concentration dependent manner. Furthermore, the introduction of extracts of ripe red pepper and tomato caused a significant concentration-dependent decrease in the MDA content of the SNP and Fe2+-stressed liver homogenates. In addition, HPLC analyses of the extracts revealed the presence of different phenolic compounds. Conclusion: With respect to the results of the current study, ripe tomato, and red pepper could be considered to be potential sources of natural antioxidants.", "label": 1}
{"doc-1": "We have used the Escherichia coli beta-glucuronidase gene (GUS) as a gene fusion marker for analysis of gene expression in transformed plants. Higher plants tested lack intrinsic beta-glucuronidase activity, thus enhancing the sensitivity with which measurements can be made. We have constructed gene fusions using the cauliflower mosaic virus (CaMV) 35S promoter or the promoter from a gene encoding the small subunit of ribulose bisphosphate carboxylase (rbcS) to direct the expression of beta-glucuronidase in transformed plants. Expression of GUS can be measured accurately using fluorometric assays of very small amounts of transformed plant tissue. Plants expressing GUS are normal, healthy and fertile. GUS is very stable, and tissue extracts continue to show high levels of GUS activity after prolonged storage. Histochemical analysis has been used to demonstrate the localization of gene activity in cells and tissues of transformed plants.", "doc-2": "Proper preservation of transgenes and transgenic materials is important for wider use of transgenic technology in plants. Here, we report stable preservation and faithful expression of a transgene via artificial seed technology in alfalfa. DNA constructs containing the uid reporter gene coding for -glucuronidase (GUS) driven by a 35S promoter or a tCUP promoter were introduced into alfalfa via Agrobacterium-mediated genetic transformation. Somatic embryos were subsequently induced from transgenic alfalfa plants via in vitro technology. These embryos were treated with abscisic acid to induce desiccation tolerance and were subjected to a water loss process. After the desiccation procedure, the water content in dried embryos, or called artificial seeds, was about 12-15% which was equivalent to that in true seeds. Upon water rehydration, the dried somatic embryos showed high degrees of viability and exhibited normal germination. Full plants were subsequently developed and recovered in a greenhouse. The progeny plants developed from artificial seeds showed GUS enzyme activity and the GUS expression level was comparable to that of plants developed from somatic embryos without the desiccation process. Polymerase chain reaction analysis indicated that the transgene was well retained in the plants and Southern blot analysis showed that the transgene was stably integrated in plant genome. The research showed that the transgene and the new trait can be well preserved in artificial seeds and the progeny developed. The research provides a new method for transgenic germplasm preservation in different plant species.", "label": 1}
{"doc-1": "A submitted manuscript is the author's version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "We report on the effect of antimony surfactant on the growth of strained InGaAs multiple-quantum-well (MQW) structure by metalorganic vapor phase epitaxy and the application of the structure to buried-heterostructure (BH) lasers. For a 1.85%-strained MQW, supplying a small amount of antimony during well growth is effective in suppressing the three-dimensional growth and increasing the photoluminescence peak intensity at a wavelength of 2.09  m . The secondary ion mass spectroscopy measurement reveals that hardly any antimony is incorporated into the wells. The fabricated BH laser has an emission wavelength of 2.103  m under continuous-wave operation at 25C.", "label": 1}
{"doc-1": "mothur aims to be a comprehensive software package that allows users to use a single piece of software to analyze community sequence data. It builds upon previous tools to provide a flexible and powerful software package for analyzing sequencing data. As a case study, we used mothur to trim, screen, and align sequences; calculate distances; assign sequences to operational taxonomic units; and describe the alpha and beta diversity of eight marine samples previously characterized by pyrosequencing of 16S rRNA gene fragments. This analysis of more than 222,000 sequences was completed in less than 2 h with a laptop computer.", "doc-2": "Microbial communities associated with marine sponges carry out nutrient transformations essential for benthic-pelagic coupling; however, knowledge about their composition and function is still sparse. We evaluated the richness and diversity of prokaryotic assemblages associated with three high-microbial-abundance (HMA) and three low-microbial-abundance (LMA) sympatric Mediterranean sponges to address their stability and uniqueness. Moreover, to examine functionality and because an imbalance between nitrogen ingestion and excretion has been observed for some of these species, we sequenced nitrogenase genes (nifH) and measured N2 fixation. The prokaryotic communities in the two sponge types did not differ in terms of richness, but the highest diversity was found in HMA sponges. Moreover, the discrete composition of the communities in the two sponge types relative to that in the surrounding seawater indicated that horizontal transmission and vertical transmission affect the microbiomes associated with the two sponge categories. nifH genes were found in all LMA species and sporadically in one HMA species, and about half of the nifH gene sequences were common between the different sponge species and were also found in the surrounding water, suggesting horizontal transmission. (15)N2-enriched incubations showed that N2 fixation was measurable in the water but was not associated with the sponges. Also, the analysis of the isotopic ratio of (15)N to (14)N in sponge tissue indicated that N2 fixation is not an important source of nitrogen in these Mediterranean sponges. Overall, our results suggest that compositional and functional features differ between the prokaryotic communities associated with HMA and LMA sponges, which may affect sponge ecology.", "label": 1}
{"doc-1": "Social Network Analysis helps to visualize and understand the roles and relationships that ease or impede the collaboration and sharing of the information and knowledge in an organization. In this research work, we will focus on the Team Formation Problem (TFP) which is an open problem where we need to identify an ideal team, with members of complementary talent or skills, to solve any given task. Current research suggests that TFP solutions have been attempted with evolutionary computation approach using Cultural Algorithms (CA) and Genetic Algorithms (GA). However, SCAN (Structural Clustering Algorithm for Networks) variants such as WSCAN (Weighted Structural Clustering Algorithm for Networks) demonstrate a high capability to find solutions for another type of network problems. In this thesis, we first propose to use WSCAN-TFP algorithm to deal with the problem of team formation in social networks, and we our findings indicate that WSCAN-TFP algorithm worked faster than the evolutionary algorithms counterparts but was of lower performance compared to CAs and GAs. Next, we propose two hybrid solutions by combining GA and CA with a modified WSCAN-TFP algorithm. To test the performance of our proposed approaches, we define multiple quality criteria based on communication cost (CC), average fitness score (AFS) and average processing time. We used big datasets from DBLP nodes network with sizes 50K and 100K. The results show that our proposed methods HGA and HCA can find the near-optimal solutions faster with minimum communication cost with the improvement of  66% and  57% in average fitness in comparison to existing GA and CA methods respectively.", "doc-2": "Part I. Introduction: Networks, Relations, and Structure: 1. Relations and networks in the social and behavioral sciences 2. Social network data: collection and application Part II. Mathematical Representations of Social Networks: 3. Notation 4. Graphs and matrixes Part III. Structural and Locational Properties: 5. Centrality, prestige, and related actor and group measures 6. Structural balance, clusterability, and transitivity 7. Cohesive subgroups 8. Affiliations, co-memberships, and overlapping subgroups Part IV. Roles and Positions: 9. Structural equivalence 10. Blockmodels 11. Relational algebras 12. Network positions and roles Part V. Dyadic and Triadic Methods: 13. Dyads 14. Triads Part VI. Statistical Dyadic Interaction Models: 15. Statistical analysis of single relational networks 16. Stochastic blockmodels and goodness-of-fit indices Part VII. Epilogue: 17. Future directions.", "label": 1}
{"doc-1": "The variable results of positive-negative research with schizophrenics underscore the importance of well-characterized, standardized measurement techniques. We report on the development and initial standardization of the Positive and Negative Syndrome Scale (PANSS) for typological and dimensional assessment. Based on two established psychiatric rating systems, the 30-item PANSS was conceived as an operationalized, drug-sensitive instrument that provides balanced representation of positive and negative symptoms and gauges their relationship to one another and to global psychopathology. It thus constitutes four scales measuring positive and negative syndromes, their differential, and general severity of illness. Study of 101 schizophrenics found the four scales to be normally distributed and supported their reliability and stability. Positive and negative scores were inversely correlated once their common association with general psychopathology was extracted, suggesting that they represent mutually exclusive constructs. Review of five studies involving the PANSS provided evidence of its criterion-related validity with antecedent, genealogical, and concurrent measures, its predictive validity, its drug sensitivity, and its utility for both typological and dimensional assessment.", "doc-2": "OBJECTIVEWe aimed to investigate possible associations between three norepinephrine transporter gene (SLC6A2) single nucleotide polymorphisms (T182C, A3081T, and G1287A) and schizophrenia. Also, we investigated the relationships of those polymorphisms with clinical severity and characteristics of schizophrenia.METHODSParticipants were 220 schizophrenia patients in the acute phase and 167 healthy controls. The genotype, allele frequency, and haplotype of each group were analyzed for T182C, A3081T, and G1287A polymorphisms. Of the 220 schizophrenia patients, 163 patients were evaluated with the Positive and Negative Syndrome Scale (PANSS) and the Korean version of the Calgary depression scale for schizophrenia (K-CDSS) at baseline.RESULTSWe found no significant differences between the schizophrenia patient group and the control group in genotype distribution or allele frequency of the three tested polymorphisms. Likewise, we could not find any significant differences in genotype or allele frequency by analyzing according to gender. In the haplotype study, no significant association emerged between specific haplotype combinations and schizophrenia. We also found no association between clinical scales (PANSS and K-CDSS) and the studied polymorphisms.CONCLUSIONOur results suggest that the investigated polymorphisms of the NET gene are not associated with susceptibility to schizophrenia or its clinical features in a Korean population. However, this study remains significant because it is the first haplotype study to investigate associations between NET gene (SLC6A2) single nucleotide polymorphisms and schizophrenia in a Korean population. Future research with a larger sample size and more genetic markers is needed to replicate our results.", "label": 1}
{"doc-1": "With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.", "doc-2": "In this study, a new marine urostylid ciliate, Metaurostylopsis antarctica nov. spec. collected from the Antarctic Ocean was investigated using morphological, morphometrical, and molecular methods. Metaurostylopsis antarctica nov. spec. is characterized as follows: slender to ellipsoid form in body shape; two types of cortical granules, ellipsoid large one (type I, yellow-green, 1.5  1 m) in rows along dorsal kineties and cirri, circular small one (type II, colourless, 0.3 m in diameter) scattered throughout whole body; 19-24 adoral membranelles, 4 frontal cirri, 2-5 frontoterminal cirri, 1 buccal and 2 transverse cirri; 3-5 midventral pairs, 10-15 cirri of midventral row; 1 right and 2 left marginal rows; 3 dorsal kineties; about 43 macronuclear nodules. This new species mainly differs from the congeners by the number of marginal rows (1 vs. 3 or more on right side; 2 vs. 3 or more on left side). In addition, proter's oral primordium developed on the right side of the oral cavity (vs. in center of oral cavity), and the rightmost anlage splits into two parts, namely, the frontoterminal cirri and a transverse cirrus (vs. only frontoterminal cirri). Inter-specific dissimilarities of the SSU rRNA gene between the congeners range from 3.3 to 4.4%.", "label": 1}
{"doc-1": "We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, at multiple locations and scales. This can be slow and can require a lot of training data since each classifier requires the computation of many different image features. In particular, for independently trained detectors, the (runtime) computational complexity and the (training-time) sample complexity scale linearly with the number of classes to be detected. We present a multitask learning procedure, based on boosted decision stumps, that reduces the computational and sample complexity by finding common features that can be shared across the classes (and/or views). The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required and, therefore, the runtime cost of the classifier, is observed to scale approximately logarithmically with the number of classes. The features selected by joint training are generic edge-like features, whereas the features chosen by training each class separately tend to be more object-specific. The generic features generalize better and considerably reduce the computational cost of multiclass object detection", "doc-2": "The co-occurrence pattern, a combination of binary or local features, is more discriminative than individual features and has shown its advantages in object, scene, and action recognition. We discuss two types of co-occurrence patterns that are complementary to each other, the conjunction (AND) and disjunction (OR) of binary features. The necessary condition of identifying discriminative co-occurrence patterns is firstly provided. Then we propose a novel data mining method to efficiently discover the optimal co-occurrence pattern with minimum empirical error, despite the noisy training dataset. This mining procedure of AND and OR patterns is readily integrated to boosting, which improves the generalization ability over the conventional boosting decision trees and boosting decision stumps. Our versatile experiments on object, scene, and action categorization validate the advantages of the discovered discriminative co-occurrence patterns.", "label": 1}
{"doc-1": "The transtheoretical model posits that health behavior change involves progress through six stages of change: precontemplation, contemplation, preparation, action, maintenance, and termination. Ten processes of change have been identified for producing progress along with decisional balance, self-efficacy, and temptations. Basic research has generated a rule of thumb for at-risk populations: 40% in precontemplation, 40% in contemplation, and 20% in preparation. Across 12 health behaviors, consistent patterns have been found between the pros and cons of changing and the stages of change. Applied research has demonstrated dramatic improvements in recruitment, retention, and progress using stage-matched interventions and proactive recruitment procedures. The most promising outcomes to data have been found with computer-based individualized and interactive interventions. The most promising enhancement to the computer-based programs are personalized counselors. One of the most striking results to date for stage-matched programs is the similarity between participants reactively recruited who reached us for help and those proactively recruited who we reached out to help. If results with stage-matched interventions continue to be replicated, health promotion programs will be able to produce unprecedented impacts on entire at-risk populations.", "doc-2": "This paper discusses how persuasive technologies can be made adaptive to users. We present persuasion profiling as a method to personalize the persuasive messages used by a system to influence its users. This type of personalization can be based on explicit measures of users? tendencies to comply to distinct persuasive strategies: measures based on standardized questionnaire scores of users. However, persuasion profiling can also be implemented using implicit, behavioral measures of user traits. We present three case studies involving the design, implementation, and field deployment of personalized persuasive technologies, and we detail four design requirements. In each case study we show how these design requirements are implemented. In the discussion we highlight avenues for future research in the field of adaptive persuasive technologies. Author-HighlightsPersuasive technologies can be more effective if they are personalized.We introduce persuasion profiles to personalize persuasive messages.Persuasion profiles can be effective using implicit or explicit measures.In three case studies we show the effects of personalized persuasion.", "label": 1}
{"doc-1": "Cognitive radio is viewed as a novel approach for improving the utilization of a precious natural resource: the radio electromagnetic spectrum. The cognitive radio, built on a software-defined radio, is defined as an intelligent wireless communication system that is aware of its environment and uses the methodology of understanding-by-building to learn from the environment and adapt to statistical variations in the input stimuli, with two primary objectives in mind: /spl middot/ highly reliable communication whenever and wherever needed; /spl middot/ efficient utilization of the radio spectrum. Following the discussion of interference temperature as a new metric for the quantification and management of interference, the paper addresses three fundamental cognitive tasks. 1) Radio-scene analysis. 2) Channel-state estimation and predictive modeling. 3) Transmit-power control and dynamic spectrum management. This work also discusses the emergent behavior of cognitive radio.", "doc-2": "Physical-layer network coding (PNC) is an attractive technique because it can significantly enhance the throughput of a wireless network with a relatively simple implementation, as compared with conventional network coding (NC) schemes. In this paper, we first investigate PNC with frequency shift keying (FSK) through the derivation of its bit-error rate (BER) and capacity, as well as the impact of imperfect synchronization to the overall performance. Based on the discussions on PNC with 2FSK, we then further expand the analysis to PNC with M-ary FSK (MFSK). Theoretical results indicate that the BER performance of PNC with 2FSK is a bit worse than that of PNC with 2PSK. As the constellation dimension M increases, the BER performance of PNC with M-ary FSK improves at the expense of bandwidth efficiency degradation.", "label": 1}
{"doc-1": "The Gene Ontology (GO) project (http://www. geneontology.org/) provides structured, controlled vocabularies and classications that cover several domains of molecular and cellular biology and are freely available for community use in the annotation of genes, gene products and sequences. Many model organism databases and genome annotation groups use the GO and contribute their annotation sets to the GO resource. The GO database integrates the vocabularies and contributed annotations and provides full access to this information in several formats. Members of the GO Consortium continually work collectively, involving outside experts as needed, to expand and update the GO vocabularies. The GO Web resource also provides access to extensive documentation about the GO project and links to applications that use GO data for functional", "doc-2": "Ontologies, which are structured, hierarchical vocabularies, are widely used in molecular biology to annotate sequence and structure data. One such ontology, the GeneOntology, contains some 18000 terms on biological processes, molecular function, and cellular components. GeneOntology is available as flat file, in web formats such as XML and RDF, and as database. Using these formats we compare three different reasoners to query the GeneOntology. Prolog is the classical logic programming approach to reason over the ontology, Prova is a rule-based Java scripting language, and Xcerpt a query language for XML and RDF. We conclude by discussing the strengths and weaknesses of the three approaches.", "label": 1}
{"doc-1": "The most highly conserved noncoding elements (HCNEs) in mammalian genomes cluster within regions enriched for genes encoding developmentally important transcription factors (TFs). This suggests that HCNE-rich regions may contain key regulatory controls involved in development. We explored this by examining histone methylation in mouse embryonic stem (ES) cells across 56 large HCNE-rich loci. We identified a specific modification pattern, termed \"bivalent domains,\" consisting of large regions of H3 lysine 27 methylation harboring smaller regions of H3 lysine 4 methylation. Bivalent domains tend to coincide with TF genes expressed at low levels. We propose that bivalent domains silence developmental genes in ES cells while keeping them poised for activation. We also found striking correspondences between genome sequence and histone methylation in ES cells, which become notably weaker in differentiated cells. These results highlight the importance of DNA sequence in defining the initial epigenetic landscape and suggest a novel chromatin-based mechanism for maintaining pluripotency.", "doc-2": "The molecular bases of myelodysplastic syndromes (MDS) are not fully understood. Trimethylated histone 3 lysine 4 (H3K4me3) is present in promoters of actively transcribed genes and has been shown to be involved in hematopoietic differentiation. We performed a genome-wide H3K4me3 CHIP-Seq (chromatin immunoprecipitation coupled with whole genome sequencing) analysis of primary MDS bone marrow (BM) CD34+ cells. This resulted in the identification of 36 genes marked by distinct higher levels of promoter H3K4me3 in MDS. A majority of these genes are involved in nuclear factor (NF)-B activation and innate immunity signaling. We then analyzed expression of histone demethylases and observed significant overexpression of the JmjC-domain histone demethylase JMJD3 (KDM6b) in MDS CD34+ cells. Furthermore, we demonstrate that JMJD3 has a positive effect on transcription of multiple CHIP-Seq identified genes involved in NF-B activation. Inhibition of JMJD3 using shRNA in primary BM MDS CD34+ cells resulted in an increased number of erythroid colonies in samples isolated from patients with lower-risk MDS. Taken together, these data indicate the deregulation of H3K4me3 and associated abnormal activation of innate immunity signals have a role in the pathogenesis of MDS and that targeting these signals may have potential therapeutic value in MDS.", "label": 1}
{"doc-1": "The development of stimulus selectivity in the primary sensory cortex of higher vertebrates is considered in a general mathematical framework. A synaptic evolution scheme of a new kind is proposed in which incoming patterns rather than converging afferents compete. The change in the efficacy of a given synapse depends not only on instantaneous pre- and postsynaptic activities but also on a slowly varying time-averaged value of the postsynaptic activity. Assuming an appropriate nonlinear form for this dependence, development of selectivity is obtained under quite general conditions on the sensory environment. One does not require nonlinearity of the neuron's integrative power nor does one need to assume any particular form for intracortical circuitry. This is first illustrated in simple cases, e.g., when the environment consists of only two different stimuli presented alternately in a random manner. The following formal statement then holds: the state of the system converges with probability 1 to points of maximum selectivity in the state space. We next consider the problem of early development of orientation selectivity and binocular interaction in primary visual cortex. Giving the environment an appropriate form, we obtain orientation tuning curves and ocular dominance comparable to what is observed in normally reared adult cats or monkeys. Simulations with binocular input and various types of normal or altered environments show good agreement with the relevant experimental data. Experiments are suggested that could test our theory further.", "doc-2": "Competition between synapses arises in some forms of correlation-based plasticity. Here we propose a game theory-inspired model of synaptic interactions whose dynamics is driven by competition between synapses in their weak and strong states, which are characterized by different timescales. The learning of inputs and memory are meaningfully definable in an effective description of networked synaptic populations. We study, numerically and analytically, the dynamic responses of the effective system to various signal types, particularly with reference to an existing empirical motor adaptation model. The dependence of the system-level behavior on the synaptic parameters, and the signal strength, is brought out in a clear manner, thus illuminating issues such as those of optimal performance, and the functional role of multiple timescales.", "label": 1}
{"doc-1": "We describe Hi-C, a method that probes the three-dimensional architecture of whole genomes by coupling proximity-based ligation with massively parallel sequencing. We constructed spatial proximity maps of the human genome with Hi-C at a resolution of 1 megabase. These maps confirm the presence of chromosome territories and the spatial proximity of small, gene-rich chromosomes. We identified an additional level of genome organization that is characterized by the spatial segregation of open and closed chromatin to form two genome-wide compartments. At the megabase scale, the chromatin conformation is consistent with a fractal globule, a knot-free, polymer conformation that enables maximally dense packing while preserving the ability to easily fold and unfold any genomic locus. The fractal globule is distinct from the more commonly used globular equilibrium model. Our results demonstrate the power of Hi-C to map the dynamic conformations of whole genomes.", "doc-2": "The immense increase in the generation of genomic scale data poses an unmet analytical challenge, due to a lack of established methodology with the required flexibility and power. We propose a first principled approach to statistical analysis of sequence-level genomic information. We provide a growing collection of generic biological investigations that query pairwise relations between tracks, represented as mathematical objects, along the genome. The Genomic HyperBrowser implements the approach and is available at http://hyperbrowser.uio.no.", "label": 1}
{"doc-1": "Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, DouglasRachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for l1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.", "doc-2": "We consider estimating simultaneously sparse and low-rank matrices from their noisy observations.We use non-convex penalty functions that are parameterized to ensure strict convexity of the overall objective function.An ADMM based algorithm is derived with guaranteed global convergence.Several examples are shown to emphasize the benefit of using the proposed method over convex regularized sparse low-rank matrix estimation method. We address the problem of estimating a sparse low-rank matrix from its noisy observation. We propose an objective function consisting of a data-fidelity term and two parameterized non-convex penalty functions. Further, we show how to set the parameters of the non-convex penalty functions, in order to ensure that the objective function is strictly convex. The proposed objective function better estimates sparse low-rank matrices than a convex method which utilizes the sum of the nuclear norm and the 1 norm. We derive an algorithm (as an instance of ADMM) to solve the proposed problem, and guarantee its convergence provided the scalar augmented Lagrangian parameter is set appropriately. We demonstrate the proposed method for denoising an audio signal and an adjacency matrix representing protein interactions in the Escherichia coli bacteria.", "label": 1}
{"doc-1": "The physiological and molecular mechanisms of tolerance to osmotic and ionic components of salinity stress are reviewed at the cellular, organ, and whole-plant level. Plant growth responds to salinity in two phases: a rapid, osmotic phase that inhibits growth of young leaves, and a slower, ionic phase that accelerates senescence of mature leaves. Plant adaptations to salinity are of three distinct types: osmotic stress tolerance, Na(+) or Cl() exclusion, and the tolerance of tissue to accumulated Na(+) or Cl(). Our understanding of the role of the HKT gene family in Na(+) exclusion from leaves is increasing, as is the understanding of the molecular bases for many other transport processes at the cellular level. However, we have a limited molecular understanding of the overall control of Na(+) accumulation and of osmotic stress tolerance at the whole-plant level. Molecular genetics and functional genomics provide a new opportunity to synthesize molecular and physiological knowledge to improve the salinity tolerance of plants relevant to food production and environmental sustainability.", "doc-2": "AbstractThis study was conducted using in vitro rice shoot apices cultures of two Malaysian rice cultivarsMR 220 and MR 253 to investigate the effect of NaCl and the exogenous application of proline and glutathione in mitigating the salt-induced damages. The results showed that high NaCl concentrations (150, 200, 250 and 300) mM significantly impeded plant growth resulted in reduction in plant height, root length, biomass and chlorophyll content. Results showed that the supplementation of proline and glutathione effectively ameliorates salt stress induced damages. The plant height recorded at 150mM NaCl (control) were 9.8 and 10.3cm for MR 220 and MR 253. With the supplementation of 5mM proline, the plant height of MR 220 and MR 253 increased to 14.8 and 15.0cm respectively. Similarly, the plant height of MR 220 and MR 253 was further increased to 20.3 and 21.3cm when 10mM glutathione was added exogenously. Fresh weight was recorded as 0.06g in 150mM NaCl media for both cultivars and increased to 0.13, 0.26, 0.16, 0.23g (MR 220) and 0.11, 0.14, 0.27, 0.32 (MR 253) with the supplementation of 5, 10, 15 and 20mM proline respectively. It was noted that supplementation of 5mM proline successfully increase the endogenous proline content from 9.05 to 58.4 and 15.8 to 70.5mol/g for both MR 220 and MR 253 respectively. In addition, supplementation of 5 and 10mM glutathione increased chlorophyll content from 7.0mg/g (NaCl) for both cultivars to 13.09, 17.06mg/g for MR 220 and 14.7, 12.6mg/g for MR 253 respectively. These results highlighted the potential role of exogenously applied proline and glutathione in mitigating the detrimental effect of salt stress.", "label": 1}
{"doc-1": "Use of the real-time polymerase chain reaction (PCR) to amplify cDNA products reverse transcribed from mRNA is on the way to becoming a routine tool in molecular biology to study low abundance gene expression. Real-time PCR is easy to perform, provides the necessary accuracy and produces reliable as well as rapid quantification results. But accurate quantification of nucleic acids requires a reproducible methodology and an adequate mathematical model for data analysis. This study enters into the particular topics of the relative quantification in real-time RT-PCR of a target gene transcript in comparison to a reference gene transcript. Therefore, a new mathematical model is presented. The relative expression ratio is calculated only from the real-time PCR efficiencies and the crossing point deviation of an unknown sample versus a control. This model needs no calibration curve. Control levels were included in the model to standardise each reaction run with respect to RNA integrity, sample loading and inter-PCR variations. High accuracy and reproducibility (<2.5% variation) were reached in LightCycler PCR using the established mathematical model.", "doc-2": "Asporin has been reported as a tumor suppressor in breast cancer, while asporin-activated invasion has been described in gastric cancer. According to our in silico search, high asporin expresion associates with significantly better relapse free survival (RFS) in patients with low-grade tumors but RFS is significantly worse in patients with grade 3 tumors. In line with other studies, we have confirmed asporin expression by RNA scope in situ hybridization in cancer associated fibroblasts. We have also found asporin expression in the Hs578T breast cancer cell line which we confirmed by quantitative RT-PCR and western blotting. From multiple testing, we found that asporin can be downregulated by bone morphogenetic protein 4 while upregulation may be facilited by serum-free cultivation or by three dimensional growth in stiff Alvetex scaffold. Downregulation by shRNA inhibited invasion of Hs578T as well as of CAFs and T47D cells. Invasion of asporin-negative MDA-MB-231 and BT549 breast cancer cells through collagen type I was enhanced by recombinant asporin. Besides other investigations, large scale analysis of aspartic acid repeat polymorphism will be needed for clarification of the asporin dual role in progression of breast cancer.", "label": 1}
{"doc-1": "The construction of a depression rating scale designed to be particularly sensitive to treatment effects is described. Ratings of 54 English and 52 Swedish patients on a 65 item comprehensive psychopathology scale were used to identify the 17 most commonly occurring symptoms in primary depressive illness in the combined sample. Ratings on these 17 items for 64 patients participating in studies of four different antidepressant drugs were used to create a depression scale consisting of the 10 items which showed the largest changes with treatment and the highest correlation to overall change. The inner-rater reliability of the new depression scale was high. Scores on the scale correlated significantly with scores on a standard rating scale for depression, the Hamilton Rating Scale (HRS), indicating its validity as a general severity estimate. Its capacity to differentiate between responders and non-responders to antidepressant treatment was better than the HRS, indicating greater sensitivity to change. The practical and ethical implications in terms of smaller sample sizes in clinical trials are discussed.", "doc-2": "The efficacy and safety of fluoxetine (20-80 mg) was compared with placebo in 144 veterans [36.2 years], diagnosed with combat-related post-traumatic stress disorder (PTSD) selected from a 12-week acute and 24-week relapse prevention PTSD trial. In the acute phase, improvements were greater with fluoxetine than placebo in the disease-specific outcome measures: Treatment Outcome PTSD (TOP-8) total scores (SE):-9.05 (0.90) and -5.20 (1.23), p = 0.001; Clinician Administered PTSD Scale (CAPS) total scores:-31.12 (2.72) and -16.07 (4.24), p < 0.001; all CAPS subscores; Davidson Trauma Scale (DTS) total scores; and other general outcome measures. In the maintenance phase, fluoxetine was superior to placebo in sustaining improvement in TOP-8 [-1.01 (0.91) and 1.56 (0.95)] and CAPS [-4.93 (3.54) and 5.48 (3.66)]. The risk of relapse in the placebo arm was significantly greater than in the fluoxetine arm (log-rank test chi 2 = 4.090, df = 1, p = 0.048). Fluoxetine was well tolerated at a mean daily dose of 65 mg.", "label": 1}
{"doc-1": "We present a new polynomial-time algorithm for linear programming. The running-time of this algorithm is <italic>O</italic>(<italic>n</italic><supscrpt>3-5</supscrpt><italic>L</italic><supscrpt>2</supscrpt>), as compared to <italic>O</italic>(<italic>n</italic><supscrpt>6</supscrpt><italic>L</italic><supscrpt>2</supscrpt>) for the ellipsoid algorithm. We prove that given a polytope <italic>P</italic> and a strictly interior point <italic>a</italic>  <italic>P</italic>, there is a projective transformation of the space that maps <italic>P</italic>, <italic>a</italic> to <italic>P'</italic>, <italic>a'</italic> having the following property. The ratio of the radius of the smallest sphere with center <italic>a'</italic>, containing <italic>P'</italic> to the radius of the largest sphere with center <italic>a'</italic> contained in <italic>P'</italic> is <italic>O</italic> (<italic>n</italic>). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial-time.", "doc-2": "This paper considers signomial geometric programming (GP) dual problems, a class of nonconvex nonlinear programming problems possessing multiple locally optimal solutions. The primary purpose of this paper is to investigate the quality of solutions found by use of a path-following algorithm. The path-following method may be applied to either the original nonconvex problem, or to each of a sequence of convex posynomial GP problems approximating the original problem. For each test problem, the algorithms were initiated with thousands of different starting points. It was determined that, when the stopping criterion was relaxed for early posynomial GP problems in the sequence, the ultimate solution tended to be of better quality, and more frequently globally optimal.", "label": 1}
{"doc-1": "Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.", "doc-2": "Social Network Analysis helps to visualize and understand the roles and relationships that ease or impede the collaboration and sharing of the information and knowledge in an organization. In this research work, we will focus on the Team Formation Problem (TFP) which is an open problem where we need to identify an ideal team, with members of complementary talent or skills, to solve any given task. Current research suggests that TFP solutions have been attempted with evolutionary computation approach using Cultural Algorithms (CA) and Genetic Algorithms (GA). However, SCAN (Structural Clustering Algorithm for Networks) variants such as WSCAN (Weighted Structural Clustering Algorithm for Networks) demonstrate a high capability to find solutions for another type of network problems. In this thesis, we first propose to use WSCAN-TFP algorithm to deal with the problem of team formation in social networks, and we our findings indicate that WSCAN-TFP algorithm worked faster than the evolutionary algorithms counterparts but was of lower performance compared to CAs and GAs. Next, we propose two hybrid solutions by combining GA and CA with a modified WSCAN-TFP algorithm. To test the performance of our proposed approaches, we define multiple quality criteria based on communication cost (CC), average fitness score (AFS) and average processing time. We used big datasets from DBLP nodes network with sizes 50K and 100K. The results show that our proposed methods HGA and HCA can find the near-optimal solutions faster with minimum communication cost with the improvement of  66% and  57% in average fitness in comparison to existing GA and CA methods respectively.", "label": 1}
{"doc-1": "BACKGROUNDThe 7-item Generalized Anxiety Disorder Scale (GAD-7) is a practical self-report anxiety questionnaire that proved valid in primary care. However, the GAD-7 was not yet validated in the general population and thus far, normative data are not available.OBJECTIVESTo investigate reliability, construct validity, and factorial validity of the GAD-7 in the general population and to generate normative data.RESEARCH DESIGNNationally representative face-to-face household survey conducted in Germany between May 5 and June 8, 2006.SUBJECTSFive thousand thirty subjects (53.6% female) with a mean age (SD) of 48.4 (18.0) years.MEASURESThe survey questionnaire included the GAD-7, the 2-item depression module from the Patient Health Questionnaire (PHQ-2), the Rosenberg Self-Esteem Scale, and demographic characteristics.RESULTSConfirmatory factor analyses substantiated the 1-dimensional structure of the GAD-7 and its factorial invariance for gender and age. Internal consistency was identical across all subgroups (alpha = 0.89). Intercorrelations with the PHQ-2 and the Rosenberg Self-Esteem Scale were r = 0.64 (P < 0.001) and r = -0.43 (P < 0.001), respectively. As expected, women had significantly higher mean (SD) GAD-7 anxiety scores compared with men [3.2 (3.5) vs. 2.7 (3.2); P < 0.001]. Normative data for the GAD-7 were generated for both genders and different age levels. Approximately 5% of subjects had GAD-7 scores of 10 or greater, and 1% had GAD-7 scores of 15 or greater.CONCLUSIONSEvidence supports reliability and validity of the GAD-7 as a measure of anxiety in the general population. The normative data provided in this study can be used to compare a subject's GAD-7 score with those determined from a general population reference group.", "doc-2": "Older adults with multiple chronic conditions (MCCs) require considerable health services and complex care. Because the persistence and progression of diseases and courses of treatments affect health status in multiple dimensions, well-validated universal outcome measures across diseases are needed for research, clinical care, and administrative purposes. An expert panel meeting held by the National Institute on Aging in September 2011 recommends that older persons with MCCs complete a brief initial composite measure that includes general health; pain; fatigue; and physical health, mental health, and social role function, along with gait speed measurement. Suitable composite measures include the Medical Outcomes Study 8 (SF-8) and 36 (SF-36) -item Short-Form Survey and the Patient Reported Outcomes Measurement Information System 29-item Health Profile. Based on responses to items in the initial measure, short follow-on measures should be selectively targeted to symptom burden, depression, anxiety, and daily activities. Persons unable to walk a short distance to assess gait speed should be assessed using a physical function scale. Remaining gaps to be considered for measure development include disease burden, cognitive function, and caregiver burden. Routine outcome assessment of individuals with MCCs could facilitate system-based care improvement and clinical effectiveness research.", "label": 1}
{"doc-1": "AbstractPurpose. The contribution of the efflux transporter P-glycoprotein (P-gp) as a barrier to drug absorption may depend on its level of expression at the site of absorption. Accordingly, the distribution of P-gp was examined along the entire length of the human small intestine.Methods. Homogenates prepared from mucosal scrapings from every other 30-cm segment of four unrelated human donor small intestines were analyzed for P-gp and the control protein villin by Western blot.Results. In each donor intestine, relative P-gp expression (P-gp/villin integrated optical density ratio) progressively increased from proximal to distal regions. Among individuals, relative P-gp levels varied 2.1-fold in the duodenal/proximal jejunal region, 1.5- to 2.0-fold in the middle/distal jejunal region, and 1.2- to 1.9-fold in the ileal region. Within-donor variation was somewhat greater, from 1.5- to 3.0-fold.Conclusions. These results provide further evidence that the site of absorption can represent another source for the interindividual variation in the oral bioavailability of drugs.", "doc-2": "The aim of this study in pigs was to investigate the local pharmacokinetics of fexofenadine in the intestine and liver by using the pig as a model for drug transport in the entero-hepatobiliary system. A parallel group design included seven pigs (10-12 weeks, 22.2-29.5 kg) in three groups (G1, G2, G3), and a jejunal single-pass perfusion combined with sampling from the bile duct and the portal, hepatic, and superior caval veins was performed. Fexofenadine was perfused through the jejunal segment alone (G1: 120 mg/l, total dose 24 mg) or with two different verapamil doses (G2: 175 mg/l, total dose 35 mg; and G3: 1000 mg/l, total dose 200 mg). The animals were fully anesthetized and monitored throughout the experiment. Fexofenadine had a low liver extraction (E(H); mean +/- S.E.M.), and the given doses of verapamil did not affect the E(H) (0.13 +/- 0.04, 0.16 +/- 0.03, and 0.12 +/- 0.02 for G1, G2, and G3, respectively) or biliary clearance. The E(H) for verapamil and antipyrine agreed well with human in vivo data. Verapamil did not increase the intestinal absorption of fexofenadine, even though the jejunal permeability of fexofenadine, verapamil, and antipyrine showed a tendency to increase in G2. This combined perfusion and hepatobiliary sampling method showed that verapamil did not affect the transport of fexofenadine in the intestine or liver. In this model the E(H) values for both verapamil and antipyrine were similar to the corresponding values in vivo in humans.", "label": 1}
{"doc-1": "Normal somatic cells invariably enter a state of irreversibly arrested growth and altered function after a finite number of divisions. This process, termed replicative senescence, is thought to be a tumor-suppressive mechanism and an underlying cause of aging. There is ample evidence that escape from senescence, or immortality, is important for malignant transformation. By contrast, the role of replicative senescence in organismic aging is controversial. Studies on cells cultured from donors of different ages, genetic backgrounds, or species suggest that senescence occurs in vivo and that organismic lifespan and cell replicative lifespan are under common genetic control. However, senescent cells cannot be distinguished from quiescent or terminally differentiated cells in tissues. Thus, evidence that senescent cells exist and accumulate with age in vivo is lacking. We show that several human cells express a beta-galactosidase, histochemically detectable at pH 6, upon senescence in culture. This marker was expressed by senescent, but not presenescent, fibroblasts and keratinocytes but was absent from quiescent fibroblasts and terminally differentiated keratinocytes. It was also absent from immortal cells but was induced by genetic manipulations that reversed immortality. In skin samples from human donors of different age, there was an age-dependent increase in this marker in dermal fibroblasts and epidermal keratinocytes. This marker provides in situ evidence that senescent cells may exist and accumulate with age in vivo.", "doc-2": "Temozolomide (TMZ) producesO-methylguanine in DNA, which in turn mispairs with thymine, triggering futile DNA mismatch repair (MMR) and ultimately cell death. We found previously that in p53proficient human glioma cells, TMZ-induced futile DNA MMR resulted not in apoptosis but rather in prolonged, p53and p21-associated G 2-M arrest and senescence. Additionally, p53-deficient cells were relatively more TMZ resistant than p53-deficient glioma cells, which underwent only transient G2-M arrest before death by mitotic catastrophe. These results suggested that prolonged G2-M arrest might protect cells from TMZ-induced cytotoxicity. In the present study, we therefore focused on the mechanism by which TMZ induces G2-M arrest and on whether inhibition of such G2-M arrest might sensitize glioma cells to TMZinduced toxicity. U87MG glioma cells treated with TMZ underwent G2-M arrest associated with Chk1 activation and phosphorylation of both cdc25C and cdc2. These TMZ-induced effects were inhibited by the Chk1 kinase inhibitor UCN-01. Although not in itself toxic, UCN-01 increased the cytotoxicity of TMZ 5-fold, primarily by inhibiting cellular senescence and increasing the percentage of cells bypassing G 2-M arrest and undergoing mitotic catastrophe. In addition to enhancing TMZ-induced cytotoxicity in p53-proficient cells, UCN-01 also blocked TMZ-induced Chk1 activation and transient G2-M arrest in p53-deficient U87MG-E6 cells and similarly enhanced TMZ-induced mitotic catastrophe and cell death. Taken together, these results indicate that Chk1 links TMZ-induced MMR to G 2-M arrest. Furthermore, inhibition of the cytoprotective G 2 arrest pathway sensitizes cells to TMZ-induced cytotoxicity and may represent a novel, mechanism-based means of increasing TMZ efficacy in both p53 wild-type and p53 mutant glioma cells.", "label": 1}
{"doc-1": "A lubricator valve apparatus adapted for use when running wireline tools into an offshore well during a production test of the well. The valve includes a valve body having a central flow passage and a ball valve element for opening and closing the passage, hydraulically operable means responsive to surface-controlled pressure for opening and closing the ball valve, latch means for releasably holding the ball valve in both the open and the closed positions, and bypass valve means for equalizing pressures across the ball valve prior to opening thereof and arranged in the event hydraulic control of the ball valve is lost to be opened in response to pressure applied at the surface to the production pipe to provide a flow path for well control fluids.", "doc-2": "Capital and Financing structure are considered of a crucial importance for the operational and financial sustainability of microfinance institutions (MFIs). Therefore, each decision making process is of the same importance for these institutions. The purpose of this study is to draw attentions toward the microfinance sector and to take into consideration the human factor and the role that managers play in funding and financing modalities and decision making process in microfinance institutions. In this context, this paper explores the differences between conventional and Islamic MFIs capital structure choices on one hand. And, reviews the insights provided by the literature examining capital structure decisions and managerial behavioral biases on the other hand. The theoretical and comparative analysis revealed the substantial differences between capital structure of both Conventional and Islamic MFIs. Furthermore, the empirical literature points that managers behavioral biases play an important role in explaining the capital structure choices. Microfinance institutions still has not been subject of behavioral finance studies. Thus, the discussion emphasizes the theoretical and empirical limitations on this field. In addition, the discussion stresses the importance of studying the behavioral traits of MFIs managers and their role in explaining capital structure choices.", "label": 1}
{"doc-1": "The lateral prefrontal cortex (PFC), a hub of higher-level cognitive processing, is strongly modulated by midbrain dopamine (DA) neurons. The cellular mechanisms have been comprehensively studied in the context of short-term memory, but little is known about how DA regulates sensory inputs to PFC that precede and give rise to such memory activity. By preparing recipient cortical circuits for incoming signals, DA could be a powerful determinant of downstream cognitive processing. Here, we tested the hypothesis that prefrontal DA regulates the representation of sensory signals that are required for perceptual decisions. In rhesus monkeys trained to report the presence or absence of visual stimuli at varying levels of contrast, we simultaneously recorded extracellular single-unit activity and applied DA to the immediate vicinity of the neurons by micro-iontophoresis. We found that DA modulation of prefrontal neurons is not uniform but tailored to specialized neuronal classes. In one population of neurons, DA suppressed activity with high temporal precision but preserved signal oise ratio. Neurons in this group had short visual response latencies and comprised all recorded narrow-spiking, putative interneurons. In a distinct population, DA increased excitability and enhanced signal oise ratio by reducing response variability. These neurons had longer visual response latencies and were composed exclusively of broad-spiking, putative pyramidal neurons. By gating sensory inputs to PFC and subsequently strengthening the representation of sensory signals, DA might play an important role in shaping how the PFC initiates appropriate behavior in response to changes in the sensory environment.", "doc-2": "Humans are adept at switching between goal-directed behaviors quickly and effectively. The prefrontal cortex (PFC) is thought to play a critical role by encoding, updating, and maintaining internal representations of task context in working memory. It has also been hypothesized that the encoding of context representations in PFC is regulated by phasic dopamine gating signals. Here we use multimodal methods to test these hypotheses. First we used functional MRI (fMRI) to identify regions of PFC associated with the representation of context in a working memory task. Next we used single-pulse transcranial magnetic stimulation (TMS), guided spatially by our fMRI findings and temporally by previous event-related EEG recordings, to disrupt context encoding while participants performed the same working memory task. We found that TMS pulses to the right dorsolateral PFC (DLPFC) immediately after context presentation, and well in advance of the response, adversely impacted context-dependent relative to context-independent responses. This finding causally implicates right DLPFC function in context encoding. Finally, using the same paradigm, we conducted high-resolution fMRI measurements in brainstem dopaminergic nuclei (ventral tegmental area and substantia nigra) and found phasic responses after presentation of context stimuli relative to other stimuli, consistent with the timing of a gating signal that regulates the encoding of representations in PFC. Furthermore, these responses were positively correlated with behavior, as well as with responses in the same region of right DLPFC targeted in the TMS experiment, lending support to the hypothesis that dopamine phasic signals regulate encoding, and thereby the updating, of context representations in PFC.", "label": 1}
{"doc-1": "In Risk, Uncertainty and Profit, Frank Knight explored the riddle of profitability in a competitive market profit should not be possible under competitive conditions, as the entry of new entrepreneurs would drive prices down and nullify margins, however evidence abounds of competitive yet profitable markets. To explain this seeming paradox, Knight uncovers the distinction between calculable risk and essentially unknowable uncertainty. Knight argued that risk stems from repeated events, which therefore allow probabilities to be calculated and factored into decisions, as for instance insurers do. Uncertainty however, stems from events that are unpredictable and as such cannot be prepared against. According to Knight, it is the interplay between risk and uncertainty on the one hand and competition between incumbent and new entrepreneurs that accounts for the enormous variation in profitability across firms and, for the same firms, over time. His insights on the sources of profit have been instrumental in shaping modern economic theory and to the development of a useful understanding of probability. This New Edition has been typeset with modern techniques and contains a newly compiled Index of important topics. It has been painstakingly proofread to ensure that it is free from errors and that the content is faithful to the original.", "doc-2": "Over the past century, the institution of capital and the process of its accumulation have been fundamentally transformed. By contrast, the theories that explain this institution and process have remained largely unchanged. The purpose of this paper is to address this mismatch. Using a broad brush, we outline a new, power theory of capital and accumulation. We use this theory to assess the changing meaning of the corporation and the capitalist state, the new ways in which capital gets accumulated and the specific historical trajectory of twentieth-century capitalism up to the present.", "label": 1}
{"doc-1": "The VideoToolbox is a free collection of two hundred C subroutines for Macintosh computers that calibrates and controls the computer-display interface to create accurately specified visual stimuli. High-level platform-independent languages like MATLAB are best for creating the numbers that describe the desired images. Low-level, computer-specific VideoToolbox routines control the hardware that transforms those numbers into a movie. Transcending the particular computer and language, we discuss the nature of the computer-display interface, and how to calibrate and control it.", "doc-2": "A prolonged exposure to foveal defocus is well known to affect the visual functions in the fovea. However, the effects of peripheral blur adaptation on foveal vision, or vice versa, are still unclear. In this study, we therefore examined the changes in contrast sensitivity function from baseline, following blur adaptation to small as well as laterally extended stimuli in four subjects. The small field stimulus (7.5 visual field) was a 30min video of forest scenery projected on a screen and the large field stimulus consisted of 7-tiles of the 7.5 stimulus stacked horizontally. Both stimuli were used for adaptation with optical blur (+2.00D trial lens) as well as for clear control conditions. After small field blur adaptation foveal contrast sensitivity improved in the mid spatial frequency region. However, these changes neither spread to the periphery nor occurred for the large field blur adaptation. To conclude, visual performance after adaptation is dependent on the lateral extent of the adaptation stimulus.", "label": 1}
{"doc-1": "A hypothesized need to form and maintain strong, stable interpersonal relationships is evaluated in light of the empirical literature. The need is for frequent, nonaversive interactions within an ongoing relational bond. Consistent with the belongingness hypothesis, people form social attachments readily under most conditions and resist the dissolution of existing bonds. Belongingness appears to have multiple and strong effects on emotional patterns and on cognitive processes. Lack of attachments is linked to a variety of ill effects on health, adjustment, and well-being. Other evidence, such as that concerning satiation, substitution, and behavioral consequences, is likewise consistent with the hypothesized motivation. Several seeming counterexamples turned out not to disconfirm the hypothesis. Existing evidence supports the hypothesis that the need to belong is a powerful, fundamental, and extremely pervasive motivation.", "doc-2": "Abstract. Research shows that I-sharing, or sharing subjective experiences with an outgroup member, positively shapes attitudes toward that outgroup member. We investigated whether this type of social experience would also promote a positive interracial interaction with a novel outgroup member. Results showed that White and Black participants who I-shared with a racial outgroup member (vs. I-sharing with a racial ingroup member) expressed more liking toward that outgroup member. However, I-sharing with an outgroup member did not reduce anxious behavior in a future social interaction with a novel racial outgroup member. Therefore, although sharing subjective experiences may increase liking toward one individual from a racial outgroup, it remains to be seen whether this positive experience can influence behaviors in future interactions with other racial outgroup members. Future directions are discussed.", "label": 1}
{"doc-1": "1", "doc-2": "We fabricate pentacene field-effect transistors (FETs) showing a very small degradation in performance under a continuous DC bias stress. Pentacene FETs are manufactured on polyimide films with polyimide gate dielectric layers, and then encapsulated by poly-chloro-para-xylylene passivation layers, resulting in very flexible and heat-resistant devices. When such devices are annealed at 140C for 12h in a nitrogen environment, the change in their source-drain current is 31% even after the application of continuous DC voltage biases of VDS=VGS=40V for 11h. Furthermore, their mobility is increased by postannealing effects from 0.27cm2Vsto0.36cm2Vs and their on/off ratio is also increased from 103 to 106.", "label": 1}
{"doc-1": "Preface 1. Introduction and preliminaries 2. Linear internal waves 3. Finite amplitude motions in stably stratified fluids 4. Instability and the production of turbulence 5. Turbulent shear flows in a stratified fluid 6. Buoyant convection from isolated sources 7. Convection from heated surfaces 8. Double-diffusive convection 9. Mixing across density interfaces 10. Internal mixing processes Bibliography and author index Recent publications Subject index.", "doc-2": "Ventilation stacks are becoming increasingly common in the design of naturally ventilated buildings. Maintaining a certain airflow direction is crucial for a successful natural ventilation design. This article presents the experimental and theoretical investigation of unsteady wind effects on natural ventilation of a single envelope with multiple openings for wind and buoyancy combined cases. Wind tunnel tests have been carried out to investigate the hysteresis effects, the effects of turbulent wind pressure fluctuations on stack flow rates, and the initial condition effects on the final flow pattern through multiple stacks. It has been confirmed experimentally that when the wind and buoyancy forces are in opposition and nominally equal, the turbulent wind fluctuation could cause effective ventilation rates. When there are only stacks open with a fixed buoyancy force, the flow directions through the stacks depend on the initial conditions; which indicates the uncertainty in CFD simulation due the input of initial conditions.", "label": 1}
{"doc-1": "The ability to identify active compounds (hits) from large chemical libraries accurately and rapidly has been the ultimate goal in developing high-throughput screening (HTS) assays. The ability to identify hits from a particular HTS assay depends largely on the suitability or quality of the assay used in the screening. The criteria or parameters for evaluating the suitability of an HTS assay for hit identification are not well defined and hence it still remains difficult to compare the quality of assays directly. In this report, a screening window coefficient, called Z-factor, is defined. This coefficient is reflective of both the assay signal dynamic range and the data variation associated with the signal measurements, and therefore is suitable for assay quality assessment. The Z-factor is a dimensionless, simple statistical characteristic for each HTS assay. The Z-factor provides a useful tool for comparison and evaluation of the quality of assays, and can be utilized in assay optimization and validation.", "doc-2": "Asialoglycoprotein receptor (ASGP-R) has been actively investigated for targeted delivery of therapeutic agents into hepatocytes because this receptor is selectively and highly expressed in liver and has a high internalization rate. Synthetic cluster glycopeptides (e.g., triGalNAc) bind with high affinity to ASGP-R and, when conjugated to a therapeutic agent, can drive receptor-mediated uptake in liver. We developed a novel fluorescent polarization (FP) ASGP-R binding assay to determine the binding affinities of ASGP-R-targeted molecules. The assay was performed in 96-well microplates using membrane preparations from rat liver as a source of ASGP-R and Cy5 fluorophore-labeled triGalNAc synthetic ligand as a tracer. This high-throughput homogeneous assay demonstrates advantages over existing multistep methods in that it minimizes both time and resources spent in determining binding affinities to ASGP-R. At the optimized conditions, a Z' factor of 0.73 was achieved in a 96-well format.", "label": 1}
{"doc-1": "A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.", "doc-2": "Considerable research has been devoted to investigating variations in disease susceptibility using SNPs associated with the individual cooccurrence of single nucleotide polymorphisms (SNPs) in genetic and phenotypic variability. Without the raw genotype data, these association studies are difficult to conduct and often omit SNP interactions, thus limiting their reliability and potential applicability. In this study, we apply a particle swarm optimization (PSO) algorithm to detect and identify the best protective SNP barcodes (i.e., SNP combinations and genotypes with a maximum difference between cases and controls) associated with chronic dialysis patients. SNP barcodes containing different numbers of SNPs were computed. We evaluated the combined effects of 27 SNPs related to nine published epigenetic modifier-related genes on breast cancer. Eleven different SNP combinations were found to be protective associated with the risk of breast cancer (odds ratio, OR p-value in silico analysis.", "label": 1}
{"doc-1": "NAMD is a parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems. NAMD scales to hundreds of processors on high-end parallel platforms, as well as tens of processors on low-cost commodity clusters, and also runs on individual desktop and laptop computers. NAMD works with AMBER and CHARMM potential functions, parameters, and file formats. This article, directed to novices as well as experts, first introduces concepts and methods used in the NAMD program, describing the classical molecular dynamics force field, equations of motion, and integration methods along with the efficient electrostatics evaluation algorithms employed and temperature and pressure controls used. Features for steering the simulation across barriers and for calculating both alchemical and conformational free energy differences are presented. The motivations for and a roadmap to the internal design of NAMD, implemented in C++ and based on Charm++ parallel objects, are outlined. The factors affecting the serial and parallel performance of a simulation are discussed. Finally, typical NAMD use is illustrated with representative applications to a small, a medium, and a large biomolecular system, highlighting particular features of NAMD, for example, the Tcl scripting language. The article also provides a list of the key features of NAMD and discusses the benefits of combining NAMD with the molecular graphics/sequence analysis software VMD and the grid computing/collaboratory software BioCoRE. NAMD is distributed free of charge with source code at www.ks.uiuc.edu.", "doc-2": "The 2009 H1N1 pandemic highlights the need to better understand influenza A infectivity and antigenicity. Relative to other recent seasonal H1N1 influenza strains, the 2009 H1N1 virus grew less efficiently in eggs, which hindered efforts to rapidly supply vaccine. Using lentiviral pseudotypes bearing influenza hemagglutinin (HA-pseudotypes) we evaluated a glutamine to arginine mutation at position 223 (Q223R) and glycosylation at residue 276 in HA for their effects on infectivity and neutralization. Q223R emerged during propagation in eggs and lies in the receptor binding site. We found that the Q223R mutation greatly enhanced infectivity of HA-pseudotypes in human cells, which was further augmented by inclusion of the viral neuraminidase (NA) and M2 proteins. Loss of glycosylation at residue 276 did not alter infectivity. None of these modifications affected neutralization. These findings provide information for increasing 2009 H1N1HA-pseudotype titers without altering antigenicity and offer insights into receptor use.", "label": 1}
{"doc-1": "BACKGROUNDAn improvement in overall survival among patients with metastatic melanoma has been an elusive goal. In this phase 3 study, ipilimumab--which blocks cytotoxic T-lymphocyte-associated antigen 4 to potentiate an antitumor T-cell response--administered with or without a glycoprotein 100 (gp100) peptide vaccine was compared with gp100 alone in patients with previously treated metastatic melanoma.METHODSA total of 676 HLA-A*0201-positive patients with unresectable stage III or IV melanoma, whose disease had progressed while they were receiving therapy for metastatic disease, were randomly assigned, in a 3:1:1 ratio, to receive ipilimumab plus gp100 (403 patients), ipilimumab alone (137), or gp100 alone (136). Ipilimumab, at a dose of 3 mg per kilogram of body weight, was administered with or without gp100 every 3 weeks for up to four treatments (induction). Eligible patients could receive reinduction therapy. The primary end point was overall survival.RESULTSThe median overall survival was 10.0 months among patients receiving ipilimumab plus gp100, as compared with 6.4 months among patients receiving gp100 alone (hazard ratio for death, 0.68; P<0.001). The median overall survival with ipilimumab alone was 10.1 months (hazard ratio for death in the comparison with gp100 alone, 0.66; P=0.003). No difference in overall survival was detected between the ipilimumab groups (hazard ratio with ipilimumab plus gp100, 1.04; P=0.76). Grade 3 or 4 immune-related adverse events occurred in 10 to 15% of patients treated with ipilimumab and in 3% treated with gp100 alone. There were 14 deaths related to the study drugs (2.1%), and 7 were associated with immune-related adverse events.CONCLUSIONSIpilimumab, with or without a gp100 peptide vaccine, as compared with gp100 alone, improved overall survival in patients with previously treated metastatic melanoma. Adverse events can be severe, long-lasting, or both, but most are reversible with appropriate treatment. (Funded by Medarex and Bristol-Myers Squibb; ClinicalTrials.gov number, NCT00094653.)", "doc-2": "Guidelines, not backed by evidence from randomized trials, strongly recommend urgent surgery for patients with infective endocarditis and congestive heart failure due to valvular regurgitation.1,2 Management algorithms for infective endocarditis have been developed, and a recent study showed that surgery is still required in 50% of patients who receive antibiotics.3 Experience shows that surgery in patients with active infective endocarditis is associated with low mortality.4 Debate continues, however, about the timing of surgery to prevent embolic events when there are large or mobile vegetations or vegetations in particular locations and when patients have severe valve dysfunction but do not ...", "label": 1}
{"doc-1": "We show that high doses of salicylates reverse hyperglycemia, hyperinsulinemia, and dyslipidemia in obese rodents by sensitizing insulin signaling. Activation or overexpression of the IkappaB kinase beta (IKKbeta) attenuated insulin signaling in cultured cells, whereas IKKbeta inhibition reversed insulin resistance. Thus, IKKbeta, rather than the cyclooxygenases, appears to be the relevant molecular target. Heterozygous deletion (Ikkbeta+/-) protected against the development of insulin resistance during high-fat feeding and in obese Lep(ob/ob) mice. These findings implicate an inflammatory process in the pathogenesis of insulin resistance in obesity and type 2 diabetes mellitus and identify the IKKbeta pathway as a target for insulin sensitization.", "doc-2": "Cyclooxygenase-2 (COX-2) is involved in the process of non-alcoholic steatohepatitis (NASH). However, the role of the COX-2 inhibitor in NASH has not yet been elucidated. Therefore, in the present study, we investigated the role of celecoxib in a rat model of NASH induced by a high-fat diet (HFD). Wistar rats were administered HFD by gavage, and rats administered normal saline by gavage served as the controls. After 4 weeks of HFD feeding, the rats were treated with celecoxib (20 mg/kg/day) or placebo for 4 weeks. At the end of 4 and 8 weeks, histological changes in the livers of the rats were analyzed using hematoxylin and eosin; blood was collected to detect biochemical indicators (serum aminotransferase and triglyceride). Liver triglyceride content was measured using the triglyceride E-test kit. The liver expression of COX-2, nuclear factor- enhancer binding protein (NF-B) subunits p50 and p65 was measured by real-time reverse transcription-polymerase chain reaction and/or Western blotting. Infiltration of steatosis and inflammation in cells was observed in the livers after 4 weeks of HFD administration, and marked steatosis and inflammation was induced after 8 weeks. These histological changes were significantly attenuated after celecoxib treatment. Reduced serum alanine aminotransferase and triglyceride (TG) levels and TG content in the liver were observed in the HFD rats that received celecoxib. Moreover, celecoxib suppressed hepatic COX-2 messenger RNA and protein expression. The NF-B subunit p50 and p65 protein levels in the HFD rats were also attenuated after celecoxib treatment. The results indicate that the induction of COX-2 occurs in association with NF-B activation in HFD-induced NASH rats. Celecoxib may protect against the development of steatohepatitis induced by HFD.", "label": 1}
{"doc-1": "This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a modularization is dependent upon the criteria used in dividing the system into modules. A system design problem is presented and both a conventional and unconventional decomposition are described. It is shown that the unconventional decompositions have distinct advantages for the goals outlined. The criteria used in arriving at the decompositions are discussed. The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. An alternative approach to implementation which does not have this effect is sketched.", "doc-2": "Modularity of an open source software code base has been associated with community growth, incentives for voluntary contribution, and a reduction in free riding. As a theoretical construct, it links open source software to other domains of research, including organization theory, the economics of industry structure, and new product development; however, measuring the modularity of an open source software design has proven difficult, especially for large and complex systems. Building on previous work on Design Structure Matrices (DSMs), this paper describes two contributions towards a method for examining the evolving modularity of large-scale software systems: (1) an algorithm and new modularity metric for comparing code bases of different size; and (2) evolution analysis of Apache Tomcat to illustrate the insights gained from this approach. Over a ten-year period, the modularity of Tomcat continually increased, except in three instances: with each major change to the architecture or implementation, modularity first declined, then increased in the subsequent version to fully compensate for the decline.", "label": 1}
{"doc-1": "A Yersinia effector known as YopT and a Pseudomonas avirulence protein known as AvrPphB define a family of 19 proteins involved in bacterial pathogenesis. We show that both YopT and AvrPphB are cysteine proteases, and their proteolytic activities are dependent upon the invariant C/H/D residues conserved in the entire YopT family. YopT cleaves the posttranslationally modified Rho GTPases near their carboxyl termini, releasing them from the membrane. This leads to the disruption of actin cytoskeleton in host cells. The proteolytic activity of AvrPphB is essential for autoproteolytic cleavage of an AvrPphB precursor as well as for eliciting the hypersensitive response in plants. These findings provide new insights into mechanisms of animal and plant pathogenesis.", "doc-2": "Pathogenicity of Xanthomonas campestris pathovar (pv.) vesicatoria and most other Gram-negative bacterial plant pathogens largely depends on a type III secretion (TTS) system which is encoded by hypersensitive response and pathogenicity (hrp) genes. These genes are induced in the plant and are essential for the bacterium to be virulent in susceptible hosts and for the induction of the hypersensitive response (HR) in resistant host and non-host plants. The TTS machinery secretes proteins into the extracellular milieu and effector proteins into the plant cell cytosol. In the plant, the effectors presumably interfere with cellular processes to the benefit of the pathogen or have an avirulence activity that betrays the bacterium to the plant surveillance system. Type III effectors were identified by their avirulence activity, co-regulation with the TTS system and homology to known effectors. A number of effector proteins are members of families, e.g., the AvrBs3 family in Xanthomonas. AvrBs3 localizes to the nucleus of the plant cell where it modulates plant gene expression. Another family that is also present in Xanthomonas is the YopJ/AvrRxv family. The latter proteins appear to act as SUMO cysteine proteases in the host. Here, we will present an overview about the regulation of the TTS system and its substrates and discuss the function of the AvrRxv and AvrBs3 family members in more detail.", "label": 1}
{"doc-1": "The axonal surface glycoproteins neuronglia cell adhesion molecule (NgCAM) and axonin-1 promote cell-cell adhesion, neurite outgrowth and fasciculation, and are involved in growth cone guidance. A direct binding between NgCAM and axonin-1 has been demonstrated using isolated molecules conjugated to the surface of fluorescent microspheres. By expressing NgCAM and axonin-1 in myeloma cells and performing cell aggregation assays, we found that NgCAM and axonin-1 cannot bind when present on the surface of different cells. In contrast, the cocapping of axonin-1 upon antibody-induced capping of NgCAM on the surface of CV-1 cells coexpressing NgCAM and axonin-1 and the selective chemical cross-linking of the two molecules in low density cultures of dorsal root ganglia neurons indicated a specific and direct binding of axonin-1 and Ng-CAM in the plane of the same membrane. Suppression of the axonin-1 translation by antisense oligonucleotides prevented neurite outgrowth in dissociated dorsal root ganglia neurons cultured on an NgCAM substratum, indicating that neurite outgrowth on NgCAM substratum requires axonin-1. Based on these and previous results, which implicated NgCAM as the neuronal receptor involved in neurite outgrowth on NgCAM substratum, we concluded that neurite outgrowth on an NgCAM substratum depends on two essential interactions of growth cone NgCAM: a trans-interaction with substratum NgCAM and a cis-interaction with axonin-1 residing in the same growth cone membrane.", "doc-2": "Contactin and TAG-1 are glycan phosphatidyl inositol (GPI)-anchored cell adhesion molecules that play a crucial role in the organization of axonal subdomains at the node of Ranvier of myelinating fibers. Contactin and TAG-1 mediate axo-glial selective interactions in association with Caspr-family molecules at paranodes and juxtaparanodes, respectively. How membrane proteins can be confined in these neighbouring domains along the axon has been the subject of intense investigations. This review will specifically examine the properties conferred by the lipid microenvironment to regulate trafficking and selective association of these axo-glial complexes. Increasing evidences from genetic and neuropathological models point to a role of lipid rafts in the formation or stabilization of the paranodal junctions.", "label": 1}
{"doc-1": "MicroRNAs (miRNAs) are endogenous approximately 22 nt RNAs that can play important regulatory roles in animals and plants by targeting mRNAs for cleavage or translational repression. Although they escaped notice until relatively recently, miRNAs comprise one of the more abundant classes of gene regulatory molecules in multicellular organisms and likely influence the output of many protein-coding genes.", "doc-2": "Background:Tumour stroma has important roles in the development of colorectal cancer (CRC) metastasis. We aimed to clarify the roles of microRNAs (miRNAs) and their target genes in CRC stroma in the development of liver metastasis.Methods:Tumour stroma was isolated from formalin-fixed, paraffin-embedded tissues of primary CRCs with or without liver metastasis by laser capture microdissection, and miRNA expression was analysed using TaqMan miRNA arrays.Results:Hierarchical clustering classified 16 CRCs into two groups according to the existence of synchronous liver metastasis. Combinatory target prediction identified tenascin C as a predicted target of miR-198, one of the top 10 miRNAs downregulated in tumour stroma of CRCs with synchronous liver metastasis. Immunohistochemical analysis of tenascin C in 139 primary CRCs revealed that a high staining intensity was correlated with synchronous liver metastasis (P<0.001). Univariate and multivariate analyses revealed that the tenascin C staining intensity was an independent prognostic factor to predict postoperative overall survival (P=0.005; n=139) and liver metastasis-free survival (P=0.001; n=128).Conclusions:Alterations of miRNAs in CRC stroma appear to form a metastasis-permissive environment that can elevate tenascin C to promote liver metastasis. Tenascin C in primary CRC stroma has the potential to be a novel biomarker to predict postoperative prognosis.", "label": 1}
{"doc-1": "Using an improved method of gel electrophoresis, many hitherto unknown proteins have been found in bacteriophage T4 and some of these have been identified with specific gene products. Four major components of the head are cleaved during the process of assembly, apparently after the precursor proteins have assembled into some large intermediate structure.", "doc-2": "Kinetoplastid organisms, such as the protozoan parasite Trypanosoma brucei, compartmentalise several important metabolic pathways in organelles called glycosomes. Glycosomes are related to peroxisomes of yeast and mammalian cells. A subset of glycosomal matrix proteins is routed to the organelles via the peroxisome-targeting signal type 1 (PTS-1). The PEX5 gene homologue has been cloned from T. brucei coding for a protein of the translocation machinery, the PTS-1 receptor. The gene codes for a polypeptide of 654 amino acids with a calculated molecular mass of 70 kDa. Like its homologue in other organisms T. brucei PTS-1 receptor protein (TbPEX5) is a member of the tetratricopeptide repeat (TPR) protein family and contains several copies of the pentapeptide W-X-X-X-F/Y. Northern and Western blot analysis showed that the protein is expressed at different stages of the life cycle of the parasite. The protein has been overproduced in Escherichia coli and purified using immobilized metal affinity chromatography. The purified protein specifically interacts in vitro with glycosomal phosphoglycerate kinase-C (PGK-C) of T. brucei, a PTS-1 containing protein. The equilibrium dissociation constant (Kd) of PGK-C for purified TbPEX5 is 40 nM. Using biochemical and cytochemical techniques a predominantly cytosolic localization was found for TbPEX5. This is consistent with the idea of receptor cycling between the glycosomes and the cytosol.", "label": 1}
{"doc-1": "OBJECTIVEWhile considerable attention has focused on improving the detection of depression, assessment of severity is also important in guiding treatment decisions. Therefore, we examined the validity of a brief, new measure of depression severity.MEASUREMENTSThe Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-9 is the depression module, which scores each of the 9 DSM-IV criteria as \"0\" (not at all) to \"3\" (nearly every day). The PHQ-9 was completed by 6,000 patients in 8 primary care clinics and 7 obstetrics-gynecology clinics. Construct validity was assessed using the 20-item Short-Form General Health Survey, self-reported sick days and clinic visits, and symptom-related difficulty. Criterion validity was assessed against an independent structured mental health professional (MHP) interview in a sample of 580 patients.RESULTSAs PHQ-9 depression severity increased, there was a substantial decrease in functional status on all 6 SF-20 subscales. Also, symptom-related difficulty, sick days, and health care utilization increased. Using the MHP reinterview as the criterion standard, a PHQ-9 score > or =10 had a sensitivity of 88% and a specificity of 88% for major depression. PHQ-9 scores of 5, 10, 15, and 20 represented mild, moderate, moderately severe, and severe depression, respectively. Results were similar in the primary care and obstetrics-gynecology samples.CONCLUSIONIn addition to making criteria-based diagnoses of depressive disorders, the PHQ-9 is also a reliable and valid measure of depression severity. These characteristics plus its brevity make the PHQ-9 a useful clinical and research tool.", "doc-2": "BACKGROUNDSpirituality may influence how patients cope with their illness.OBJECTIVESWe assessed whether spirituality may influence adherence to management of outpatients with heart failure.METHODSCross sectional study enrolling consecutive ambulatory heart failure patients in whom adherence to multidisciplinary treatment was evaluated. Patients were assessed for quality of life, depression, religiosity and spirituality utilizing validated questionnaires. Correlations between adherence and psychosocial variables of interest were obtained. Logistic regression models explored independent predictors of adherence.RESULTSOne hundred and thirty patients (age 60  13 years; 67% male) were interviewed. Adequate adherence score was observed in 38.5% of the patients. Neither depression nor religiosity was correlated to adherence, when assessed separately. Interestingly, spirituality, when assessed by both total score sum (r = 0.26; p = 0.003) and by all specific domains, was positively correlated to adherence. Finally, the combination of spirituality, religiosity and personal beliefs was an independent predictor of adherence when adjusted for demographics, clinical characteristics and psychosocial instruments.CONCLUSIONSpirituality, religiosity and personal beliefs were the only variables consistently associated with compliance to medication in a cohort of outpatients with heart failure. Our data suggest that adequately addressing these aspects on patient's care may lead to an improvement in adherence patterns in the complex heart failure management.", "label": 1}
{"doc-1": "It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for 2^{b} quanta, b=1,2, \\cdots, 7 , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.", "doc-2": "Clustering is a fundamental task in unsupervised machine learning. Lloyds 1957 algorithm for kmeans clustering remains one of the most widely used due to its speed and simplicity, but the greedy approach is sensitive to initialization and often falls short at a poor solution. This paper explores an alternative to Lloyds algorithm that retains its simplicity and mitigates its tendency to get trapped by local minima. Called power k-means, our method embeds the k-means problem in a continuous class of similar, better behaved problems with fewer local minima. Power k-means anneals its way toward the solution of ordinary k-means by way of majorization-minimization (MM), sharing the appealing descent property and low complexity of Lloyds algorithm. Further, our method complements widely used seeding strategies, reaping marked improvements when used together as demonstrated on a suite of simulated and real data examples.", "label": 1}
{"doc-1": "We present a simple image-based method of generating novel visual appearance in which a new image is synthesized by stitching together small patches of existing images. We call this process image quilting. First, we use quilting as a fast and very simple texture synthesis algorithm which produces surprisingly good results for a wide range of textures. Second, we extend the algorithm to perform texture transfer  rendering an object with a texture taken from a different object. More generally, we demonstrate how an image can be re-rendered in the style of a different image. The method works directly on the images and does not require 3D information.", "doc-2": "We propose a system for arranging images from a database into a collage that resembles some target image. These collages exploit large scale visual correspondences between the target image and the images in the database. We ensure that images of multiple sizes are used and are combined so that boundaries between images are not immediately apparently; as a result, the final collage consists of irregularly shaped image sections. The final collages contain a dynamic mixture of textures, images, and shapes that is in contrast to the geometric and regular character of many photomosaic techniques. In service of these tasks, we propose a fast scale-based method for querying an image library, a novel method for composing multiple images using geodesic distance Voronoi tesselations, and a novel base/detail method for shifting the colors of the final collage so that the target image is more accurately represented.", "label": 1}
{"doc-1": "Abstract Three parallel algorithms for classical molecular dynamics are presented. The first assigns each processor a fixed subset of atoms; the second assigns each a fixed subset of inter-atomic forces to compute; the third assigns each a fixed spatial region. The algorithms are suitable for molecular dynamics models which can be difficult to parallelize efficientlythose with short-range forces where the neighbors of each atom change rapidly. They can be implemented on any distributed-memory parallel machine which allows for message-passing of data between independently executing processors. The algorithms are tested on a standard Lennard-Jones benchmark problem for system sizes ranging from 500 to 100,000,000 atoms on several parallel supercomputers--the nCUBE 2, Intel iPSC/860 and Paragon, and Cray T3D. Comparing the results to the fastest reported vectorized Cray Y-MP and C90 algorithm shows that the current generation of parallel machines is competitive with conventional vector supercomputers even for small problems. For large problems, the spatial algorithm achieves parallel efficiencies of 90% and a 1840-node Intel Paragon performs up to 165 faster than a single Cray C9O processor. Trade-offs between the three algorithms and guidelines for adapting them to more complex molecular dynamics simulations are also discussed.", "doc-2": "Abstract With the growth of available computational resource, CFDDEM (computational fluid dynamicsdiscrete element method) becomes an increasingly promising and feasible approach for the study of sediment transport. Several existing CFDDEM solvers are applied in chemical engineering and mining industry. However, a robust CFDDEM solver for the simulation of sediment transport is still desirable. In this work, the development of a three-dimensional, massively parallel, and open-source CFDDEM solver SediFoam is detailed. This solver is built based on open-source solvers OpenFOAM and LAMMPS. OpenFOAM is a CFD toolbox that can perform three-dimensional fluid flow simulations on unstructured meshes; LAMMPS is a massively parallel DEM solver for molecular dynamics. Several validation tests of SediFoam are performed using cases of a wide range of complexities. The results obtained in the present simulations are consistent with those in the literature, which demonstrates the capability of SediFoam for sediment transport applications. In addition to the validation test, the parallel efficiency of SediFoam is studied to test the performance of the code for large-scale and complex simulations. The parallel efficiency tests show that the scalability of SediFoam is satisfactory in the simulations using up to O ( 10 7 ) particles.", "label": 1}
{"doc-1": "One of the fundamental principles of the database approach is that a database allows a nonredundant, unified representation of all data managed in an organization. This is achieved only when methodologies are available to support integration across organizational and application boundaries.Methodologies for database design usually perform the design activity by separately producing several schemas, representing parts of the application, which are subsequently merged. Database schema integration is the activity of integrating the schemas of existing or proposed databases into a global, unified schema.The aim of the paper is to provide first a unifying framework for the problem of schema integration, then a comparative review of the work done thus far in this area. Such a framework, with the associated analysis of the existing approaches, provides a basis for identifying strengths and weaknesses of individual methodologies, as well as general guidelines for future improvements and extensions.", "doc-2": "Today schema matching is a basic task in almost every data intensive distributed application, namely enterprise information integration, collaborating web services, ontology based agents communication, web catalogue integration and schema based P2P database systems. There has been a plethora of algorithms and techniques researched in schema matching and integration for data interoperability. Numerous surveys have been presented in the past to summarize this research. The requirement for extending the previous surveys has been created because of the mushrooming of the dynamic nature of these data intensive applications. Indeed, evolving large scale distributed information systems are further pushing the schema matching research to utilize the processing power not available in the past and directly increasing the industry investment proportion in the matching domain. This article reviews the latest application domains in which schema matching is being utilized. The paper gives a detailed insight about the desiderata for schema matching and integration in the large scale scenarios. Another panorama which is covered by this survey is the shift from manual to automatic schema matching. Finally the paper presents the state of the art in large scale schema matching, classifying the tools and prototypes according to their input, output and execution strategies and algorithms.", "label": 1}
{"doc-1": "The general view of descriptive research as a lower level form of inquiry has influenced some researchers conducting qualitative research to claim methods they are really not using and not to claim the method they are using: namely, qualitative description. Qualitative descriptive studies have as their goal a comprehensive summary of events in the everyday terms of those events. Researchers conducting qualitative descriptive studies stay close to their data and to the surface of words and events. Qualitative descriptive designs typically are an eclectic but reasonable combination of sampling, and data collection, analysis, and re-presentation techniques. Qualitative descriptive study is the method of choice when straight descriptions of phenomena are desired.", "doc-2": "Fourteen women over the age of 55 years with a history of cancer were followed during and after completion of a monitored exercise programme intended to improve body strength, functional performance, balance, activities of daily living and quality of life. A sequential explanatory mixed methods design was employed. The quantitative strand utilised a quasi-experimental, pretest/posttest design. The qualitative strand involved individualised interviews 23 months following completion of the intervention. The main outcomes were (a) physical characteristics of participants; (b) resistive tests; (c) functional ability; (d) cancer-related fatigue and (e) quality of life. Both study strands indicated that all participants showed significant improvement in resistive tests, functional ability and activities of daily living. Though quantitative results of fatigue and quality of life were statistically nonsignificant, qualitative findings indicated clinically significant improvement.", "label": 1}
{"doc-1": "The posttranslational modification with ubiquitin, a process referred to as ubiquitylation, controls almost every process in cells. Ubiquitin can be attached to substrate proteins as a single moiety or in the form of polymeric chains in which successive ubiquitin molecules are connected through specific isopeptide bonds. Reminiscent of a code, the various ubiquitin modifications adopt distinct conformations and lead to different outcomes in cells. Here, we discuss the structure, assembly, and function of this ubiquitin code.", "doc-2": "Deubiquitinating enzymes (DUBs) remove ubiquitin from conjugated substrates to regulate various cellular processes. The Zn2+-dependent DUBs AMSH and AMSH-LP regulate receptor trafficking by specifically cleaving Lys63-linked polyubiquitin chains from internalized receptors. Here we report the crystal structures of the human AMSH-LP DUB domain alone and in complex with a Lys63-linked di-ubiquitin at 1.2 and 1.6 resolutions, respectively. The AMSH-LP DUB domain consists of a Zn2+-coordinating catalytic core and two characteristic insertions, Ins-1 and Ins-2. The distal ubiquitin interacts with Ins-1 and the core, whereas the proximal ubiquitin interacts with Ins-2 and the core. The core and Ins-1 form a catalytic groove that accommodates the Lys63 side chain of the proximal ubiquitin and the isopeptide-linked carboxy-terminal tail of the distal ubiquitin. This is the first reported structure of a DUB in complex with an isopeptide-linked ubiquitin chain, which reveals the mechanism for Lys63-linkage-specific deubiquitination by AMSH family members.", "label": 1}
{"doc-1": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive egative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.", "doc-2": "Linguistically Motivated Combinatory Categorial Grammar Induction Adrienne X. Wang Chair of the Supervisory Committee: Associate Professor Luke Zettlemoyer Department of Computer Science & Engineering Combinatory Categorial Grammar (CCG) is a widely studied grammar formalism that has been used in a variety of NLP applications, e.g., semantic parsing, and machine translation. One key challenge in building effective CCG parsers is a lack of labeled training data, which is expensive to produce manually. Instead, researchers have developed automated approaches for inducing the grammars. These algorithms learn lexical entries that define the syntax and semantics of individual words, and probabilistic models that rank the set of possible parses for each sentence. Various types of universal or language specific prior knowledge and supervising signals can be exploited to prune the grammar search space and constrain parameter estimation. In this thesis, we introduce new methods for inducing linguistically motivated grammars that generalize well from small amounts of labeled training data. We first present a CCG grammar induction scheme for semantic parsing, where the grammar is restricted by modeling a wide range of linguistic constructions, then introduce a new lexical generalization model that abstracts over systematic morphological, syntactic, and semantic variations in languages. Finally, we describe a weakly supervised approach for inducing broad scale CCG syntactic structures for multiple languages. Such approaches would have the greatest utility for low-resource languages, as well as domains where it is prohibitively expensive to gather sufficient amounts of training data.", "label": 1}
{"doc-1": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting.", "doc-2": "Our research is focused on the development of novel machine vision based telematic systems, which provide non-intrusive probing of the state of the driver and driving conditions. In this paper we present a system which allows simultaneous capture of the driver's head pose, driving view, and surroundings of the vehicle. The integrated machine vision system utilizes a video stream of full 360 degree panoramic field of view. The processing modules include perspective transformation, feature extraction, head detection, head pose estimation, driving view synthesis, and motion segmentation. The paper presents a multi-state statistical decision models with Kalman filtering based tracking for head pose detection and face orientation estimation. The basic feasibility and robustness of the approach is demonstrated with a series of systematic experimental studies.", "label": 1}
{"doc-1": "A 36-item short-form (SF-36) was constructed to survey health status in the Medical Outcomes Study. The SF-36 was designed for use in clinical practice and research, health policy evaluations, and general population surveys. The SF-36 includes one multi-item scale that assesses eight health concepts: 1) limitations in physical activities because of health problems; 2) limitations in social activities because of physical or emotional problems; 3) limitations in usual role activities because of physical health problems; 4) bodily pain; 5) general mental health (psychological distress and well-being); 6) limitations in usual role activities because of emotional problems; 7) vitality (energy and fatigue); and 8) general health perceptions. The survey was constructed for self-administration by persons 14 years of age and older, and for administration by a trained interviewer in person or by telephone. The history of the development of the SF-36, the origin of specific items, and the logic underlying their selection are summarized. The content and features of the SF-36 are compared with the 20-item Medical Outcomes Study short-form.", "doc-2": "BACKGROUNDStudies on health-related quality of life (HRQoL) of patients awaiting pacemaker (PM) implantation are scarce, or executed in specific patient subgroups (regarding age or specific cardiac rhythm disorders). The purpose of this study was to systematically assess the HRQoL in a large unselected cohort of patients with a conventional indication for PM therapy.METHODSPre-PM implantation HRQoL (measured with the SF-36 questionnaire, completed at hospital admission) of 818 consecutive Dutch patients included in the FOLLOWPACE study was compared with the HRQoL in a sample of the general Dutch population, and with several cohorts of patients with other conditions. Linear regression analysis was performed to analyze determinants of this HRQoL.RESULTSAlmost all SF-36 subscale scores were substantially and significantly lower in the PM patients compared to the general population, with P-values < 0.001 in all SF-36 subscales except for \"pain\" and \"general health perception.\" In the PM patients, presence of comorbidities, gender, and age were significantly associated with the overall physical component summary score (mean 38.8 +/- 27 standard deviation) whereas the overall mental component summary score (46.8 +/- 27.0) was associated with gender and age.CONCLUSIONThe HRQoL of patients before first PM implantation is significantly lower than that of a general population and also various other patient populations. Physicians should be aware of this unfavorable condition and keep the time interval between the diagnosis of a cardiac rhythm disorder requiring PM implantation and the implantation procedure as short as possible.", "label": 1}
{"doc-1": "Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.", "doc-2": "We study data privacy in the context of information leakage. As more of our sensitive data gets exposed to merchants, health care providers, employers, social sites and so on, there is a higher chance that an adversary can connect the dots and piece together a lot of our information. The more complete the integrated information, the more our privacy is compromised. We present a model that captures this privacy loss (information leakage) relative to a target person, on a continuous scale from 0 (no information about the target is known by the adversary) to 1 (adversary knows everything about the target). The model takes into account the confidence the adversary has for the gathered information (leakage is less if the adversary is not confident), as well as incorrect information (leakage is less if the gathered information does not match the targets). We compare our information leakage model with existing privacy models, and we propose several interesting problems that can be formulated with our model. We also propose efficient algorithms for computing information leakage and evaluate their performance and scalability.", "label": 1}
{"doc-1": "Today's wireless networks are characterized by a fixed spectrum assignment policy. However, a large portion of the assigned spectrum is used sporadically and geographical variations in the utilization of assigned spectrum ranges from 15% to 85% with a high variance in time. The limited available spectrum and the inefficiency in the spectrum usage necessitate a new communication paradigm to exploit the existing wireless spectrum opportunistically. This new networking paradigm is referred to as NeXt Generation (xG) Networks as well as Dynamic Spectrum Access (DSA) and cognitive radio networks. The term xG networks is used throughout the paper. The novel functionalities and current research challenges of the xG networks are explained in detail. More specifically, a brief overview of the cognitive radio technology is provided and the xG network architecture is introduced. Moreover, the xG network functions such as spectrum management, spectrum mobility and spectrum sharing are explained in detail. The influence of these functions on the performance of the upper layer protocols such as routing and transport are investigated and open research issues in these areas are also outlined. Finally, the cross-layer design challenges in xG networks are discussed.", "doc-2": "In a cognitive radio scenario, we consider a single secondary user (SU) accessing a multichannel system. The SU senses the channels sequentially to detect if a primary user (PU) is occupying the channels and stops its search to access a channel if it offers a significantly high throughput. The optimal stopping rule and power control problem is considered. The problem is formulated as an SU's throughput-maximization problem under power, interference, and packet delay constraints. We first show the effect of the optimal stopping rule on packet delay and then solve this optimization problem for both the overlay system, where the SU transmits only at the spectrum holes, and the underlay system, where tolerable interference (or tolerable collision probability) is allowed. We provide closed-form expressions for the optimal stopping rule and show that the optimal power control strategy for this multichannel problem is a modified waterfilling approach. We extend the work to a multi-SU scenario and show that when the number of SUs is large, the complexity of the solution becomes smaller than that of the single-SU case. We discuss the application of this problem in typical networks where packets simultaneously arrive and have the same departure deadline. We further propose an online adaptation policy to the optimal stopping rule that meets the packets' hard-deadline constraint and, at the same time, gives higher throughput than the offline policy.", "label": 1}
{"doc-1": "The transcription factors interferon regulatory factor 3 (IRF3) and NF-kappaB are required for the expression of many genes involved in the innate immune response. Viral infection, or the binding of double-stranded RNA to Toll-like receptor 3, results in the coordinate activation of IRF3 and NF-kappaB. Activation of IRF3 requires signal-dependent phosphorylation, but little is known about the signaling pathway or kinases involved. Here we report that the noncanonical IkappaB kinase homologs, IkappaB kinase-epsilon (IKKepsilon) and TANK-binding kinase-1 (TBK1), which were previously implicated in NF-kappaB activation, are also essential components of the IRF3 signaling pathway. Thus, IKKepsilon and TBK1 have a pivotal role in coordinating the activation of IRF3 and NF-kappaB in the innate immune response.", "doc-2": "New scientific knowledge sometimes remains underutilized as compared to its technological potential. We examine two views of the process of science-based invention at the level of the knowledge-producing organization. In one, widespread access to the new scientific knowledge is crucial, and the academic environment therefore fosters invention. In the other, control is paramount and scientific research conducted in firms leads to more new technologies. Analysis of follow-on inventions, based on 39 simultaneous discoveries between academia and industry involving 90 teams and cited in 533 patents, indicates that a scientific publication originating from a firm is 20-30% more likely to be cited in followon patents than its academic twin. Contrary to the idea that ease of access plays a crucial role, inventors that did not take part in the discovery appear more likely to draw their knowledge from firms rather than from the Ivory Tower.", "label": 1}
{"doc-1": "Chemotherapies often induce drug-resistance in cancer cells and simultaneously stimulate proliferation and activation of Myeloid-Derived Suppressor Cells (MDSCs) to inhibit anti-tumor T cells, thus result in poor prognosis of patients with breast cancers. To date, the mechanism underlying the expansion of MDSCs in response to chemotherapies is poorly understood. In the present study, we used in vitro cell culture and in vivo animal studies to demonstrate that doxorubicin-resistant breast cancer cells secret significantly more prostaglandin E2 (PGE2) than their parental doxorubicin-sensitive cells. The secreted PGE2 can stimulate expansion and polymerization of MDSCs by directly target to its receptors, EP2/EP4, on the surface of MDSCs, which consequently triggers production of miR-10a through activating PKA signaling. More importantly, activated MDSCs can inhibit CD4(+)CD25(-) T cells as evidenced by reduced proliferation and IFN- release. In order to determine the molecular pathway that involves miR-10a mediated activation of MDSCs, biochemical and pharmacological studies were carried out. We found that miR-10a can activate AMPK signaling to promote expansion and activation of MDSCs. Thus, these results reveal, for the first time, a novel role of PGE2/miR-10a/AMPK signaling axis in chemotherapy-induced immune resistance, which might be targeted for treatment of chemotherapy resistant tumors.", "doc-2": "Sorafenib resistance remains a major obstacle for the effective treatment of hepatocellular carcinoma (HCC), and a number of miRNAs contribute to this resistance. However, the regulatory networks of miRNAs are very complex, thus inhibiting a single miRNA may sequentially activate other compensatory pathways. In the present study, we generated an artificial long non-coding RNA (AlncRNA), which simultaneously targets multiple miRNAs including miR-21, miR-153, miR-216a, miR-217, miR-494 and miR-10a-5p. These miRNAs have been shown to be upregulated in sorafenib-resistant cells and participate in the mechanisms underlying sorafenib resistance. The AlncRNA contains tandem sequences of 6 copies of the complementary binding sequences to the target miRNAs and is expressed by an adenoviral vector (Ad5-AlncRNA). Infection of Ad5-AlncRNA into sorafenib-resistant HCC cells blocked the function of miRNAs, and sequentially inhibited the downregulation of PTEN and activation of AKT. Ad5-AlncRNA significantly inhibited proliferation and induced apoptosis of sorafenib-resistant cells and enhanced the effects of sorafenib in vitro and in animal models. Inhibition of autophagy decreased the sensitivity of sorafenib-resistant cells to Ad5-AlncRNA, while its induction had the opposite effect. These results indicate that targeting multiple miRNAs by the artificial lncRNA could be a potential promising strategy for overcoming sorafenib resistance in the treatment of HCC.", "label": 1}
{"doc-1": "The Protein Data Bank [PDB; Berman, Westbrook et al. (2000), Nucleic Acids Res. 28, 235-242; http://www.pdb.org/] is the single worldwide archive of primary structural data of biological macromolecules. Many secondary sources of information are derived from PDB data. It is the starting point for studies in structural bioinformatics. This article describes the goals of the PDB, the systems in place for data deposition and access, how to obtain further information and plans for the future development of the resource. The reader should come away with an understanding of the scope of the PDB and what is provided by the resource.", "doc-2": "In a cyclone separator used for separating solids from gases, we discovered placing at least one opening in a lateral surface of a gas outlet conduit on a side facing away from an inlet to the cyclone separator prevents coke deposits from forming thereon. A plurality of openings may be placed on the side of the lateral surface of the gas outlet conduit facing away from the inlet. In an embodiment, no openings are placed on a side of the lateral surface facing the inlet to the cyclone separator.", "label": 1}
{"doc-1": "We describe MUSCLE, a new computer program for creating multiple alignments of protein sequences. Elements of the algorithm include fast distance estimation using kmer counting, progressive alignment using a new profile function we call the log-expectation score, and refinement using tree-dependent restricted partitioning. The speed and accuracy of MUSCLE are compared with T-Coffee, MAFFT and CLUSTALW on four test sets of reference alignments: BAliBASE, SABmark, SMART and a new benchmark, PREFAB. MUSCLE achieves the highest, or joint highest, rank in accuracy on each of these sets. Without refinement, MUSCLE achieves average accuracy statistically indistinguishable from T-Coffee and MAFFT, and is the fastest of the tested methods for large numbers of sequences, aligning 5000 sequences of average length 350 in 7 min on a current desktop computer. The MUSCLE program, source code and PREFAB test data are freely available at http://www.drive5. com/muscle.", "doc-2": "ABSTRACT Steichen, J.L.; Denby, A.; Windham, R.; Brinkmeyer, R., and Quigg, A., 2015. A tale of two ports: Dinoflagellate and diatom communities found in the high ship traffic region of Galveston Bay, Texas (USA). Ballast water (BW) discharge by shipping vessels is a known transport vector of harmful species of dinoflagellates and diatoms. With a steady growth in global commerce, ship traffic to ports worldwide has intensified, increasing the risk of invasion by nonindigenous species. From 200812, >140 million metric tons of BW was discharged into Galveston Bay, Texas, much more than reported in other highly invaded Bays: San Francisco (96  106 mt) and Chesapeake (25  106 mt) during the same period. Studies conducted specifically on the dinoflagellate and diatom communities within Galveston Bay have been lacking until the present effort, which used both microscopic and genetic methods. Within one year of sampling, 35 genera of dinoflagellates and diatoms were identified from the two deepwater ports of ...", "label": 1}
{"doc-1": "The mediators and cellular effectors of inflammation are important constituents of the local environment of tumours. In some types of cancer, inflammatory conditions are present before a malignant change occurs. Conversely, in other types of cancer, an oncogenic change induces an inflammatory microenvironment that promotes the development of tumours. Regardless of its origin, 'smouldering' inflammation in the tumour microenvironment has many tumour-promoting effects. It aids in the proliferation and survival of malignant cells, promotes angiogenesis and metastasis, subverts adaptive immune responses, and alters responses to hormones and chemotherapeutic agents. The molecular pathways of this cancer-related inflammation are now being unravelled, resulting in the identification of new target molecules that could lead to improved diagnosis and treatment.", "doc-2": "Several studies have reported the association between MAPK signaling pathway gene polymorphisms and papillary thyroid carcinoma (PTC). KRAS gene, an oncogene from the mammalian RAS gene family plays an important role in the MAPK pathway. This study aimed to identify the potential association of KRAS gene polymorphisms with susceptibility to PTC in a Han Chinese population. A total of 861 patients with PTC, 562 disease controls with nodular goiter and 897 healthy controls were recruited. Four tagSNP polymorphisms (rs12427141, rs712, rs7315339 and rs7960917) of KRAS gene were genotyped by matrix-assisted laser desorption/ionization time of flight mass spectrometry (MALDI-TOF-MS). Statistical analyses and haplotype estimations were conducted using Haploview and Unphased softwares. Only significant differences were observed in genotypic frequencies of the rs7315339 polymorphism (2 =7.234, df=2, p=0.027) between PTC and disease controls. Statistically significant differences in both allelic and genotypic genotypes frequencies for rs712 (Genotype, 2=8.258, p=0.016) and rs12427141 (Allele, 2=3.992, p=0.046; Genotype, 2=8.140, p=0.017) were observed between PTC patients and controls. Haplotype analyses revealed higher frequencies of GA and TA haplotypes (p=0.039 and p=0.003, respectively) from rs712- rs12427141 (two-SNP) or TGA and TTG haplotype containing the alleles from rs7960917, rs712 and rs12427141, as well as the GAT haplotype containing the alleles from rs712, rs12427141 and rs7315339 in PTC patients than in healthy controls (p=0.042, p=0.037, p=0.027, respectively). Inversely, the haplotype TTA from rs7960917, rs712 and rs12427141 or the haplotype TAC from rs712, rs12427141 and rs7315339 was significantly less frequent in the PTC patients than in normal control (p=0.003, p=0.003, respectively). These findings suggest the role of these KRAS gene variants in susceptibility to PTC. Moreover, significant differences of the KRAS gene polymorphisms may occur between nodular goiter and PTC.", "label": 1}
{"doc-1": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "doc-2": "Deep Convolutional Neural Networks (CNNs) are a special type of Neural Networks, which have shown state-of-the-art results on various competitive benchmarks. The powerful learning ability of deep CNN is largely achieved with the use of multiple feature extraction stages that can automatically learn hierarchical representations from the data. Availability of a large amount of data and improvements in the hardware processing units have accelerated the research in CNNs, and recently very interesting deep CNN architectures are reported. The recent race in developing deep CNN architectures has shown that the innovative architectural ideas, as well as parameter optimization, can improve the CNN performance on various vision-related tasks. In this regard, different ideas in the CNN design have been explored such as the use of different activation and loss functions, parameter optimization, regularization, and restructuring of the processing units. However, the major improvement in representational capacity of the deep CNN is achieved by the restructuring of the processing units. Especially, the idea of using a block as a structural unit instead of a layer is receiving substantial attention. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature map exploitation, channel boosting, and attention. Additionally, it covers the elementary understanding of the CNN components and sheds light on the current challenges and applications of CNNs.", "label": 1}
{"doc-1": "We present here a framework for the study of molecular variation within a single species. Information on DNA haplotype divergence is incorporated into an analysis of variance format, derived from a matrix of squared-distances among all pairs of haplotypes. This analysis of molecular variance (AMOVA) produces estimates of variance components and F-statistic analogs, designated here as phi-statistics, reflecting the correlation of haplotypic diversity at different levels of hierarchical subdivision. The method is flexible enough to accommodate several alternative input matrices, corresponding to different types of molecular data, as well as different types of evolutionary assumptions, without modifying the basic structure of the analysis. The significance of the variance components and phi-statistics is tested using a permutational approach, eliminating the normality assumption that is conventional for analysis of variance but inappropriate for molecular data. Application of AMOVA to human mitochondrial DNA haplotype data shows that population subdivisions are better resolved when some measure of molecular differences among haplotypes is introduced into the analysis. At the intraspecific level, however, the additional information provided by knowing the exact phylogenetic relations among haplotypes or by a nonlinear translation of restriction-site change into nucleotide diversity does not significantly modify the inferred population genetic structure. Monte Carlo studies show that site sampling does not fundamentally affect the significance of the molecular variance components. The AMOVA treatment is easily extended in several different directions and it constitutes a coherent and flexible framework for the statistical analysis of molecular data.", "doc-2": "Forest musk deer (Moschus berezovskii) were once distributed widely in China. However, wild populations have declined dramatically because of poaching and habitat loss. Captive breeding populations have been established for several decades, but the genetic backgrounds of most captive populations were unclear and the population sizes increased very slowly. To provide useful information for conservation and management of this species, we investigated the genetic diversity and population structure of forest musk deer by analysing a 582-bp fragment of the mitochondrial DNA (mtDNA) control region (CR) in three captive breeding populations in Sichuan Province, China. Ninety-four variable sites and 27 haplotypes were observed in 109 individuals, and the nucleotide and haplotype diversities were relatively high compared with those of other endangered mammals. Of the three investigated populations, the Maerkang population had the highest nucleotide diversity (pi=0.0568), haplotype diversity (h=0.836) and average intra-population genetic distance (0.062). The analysis of molecular variance demonstrated that most variation occurred within samples and that there was significant differentiation of the three populations. Estimates of gene flow indicated that there were few genetic exchanges among the three populations. Building pedigree records and increasing gene flow between populations will be helpful for conserving these populations and this species.", "label": 1}
{"doc-1": "25. Multiple Imputation for Nonresponse in Surveys. By D. B. Rubin. ISBN 0 471 08705 X. Wiley, Chichester, 1987. 258 pp. 30.25.", "doc-2": "Conditional probabilistic graphical models provide a powerful framework for structured regression in spatio-temporal datasets with complex correlation patterns. However, in real-life applications a large fraction of observations is often missing, which can severely limit the representational power of these models. In this paper we propose a Marginalized Gaussian Conditional Random Fields (m-GCRF) structured regression model for dealing with missing labels in partially observed temporal attributed graphs. This method is aimed at learning with both labeled and unlabeled parts and effectively predicting future values in a graph. The method is even capable of learning from nodes for which the response variable is never observed in history, which poses problems for many state-of-the-art models that can handle missing data. The proposed model is characterized for various missingness mechanisms on 500 synthetic graphs. The benefits of the new method are also demonstrated on a challenging application for predicting precipitation based on partial observations of climate variables in a temporal graph that spans the entire continental US. We also show that the method can be useful for optimizing the costs of data collection in climate applications via active reduction of the number of weather stations to consider. In experiments on these real-world and synthetic datasets we show that the proposed model is consistently more accurate than alternative semi-supervised structured models, as well as models that either use imputation to deal with missing values or simply ignore them altogether.", "label": 1}
{"doc-1": "Double-stranded RNA (dsRNA) induces sequence-specific posttranscriptional gene silencing in many organisms by a process known as RNA interference (RNAi). Using a Drosophila in vitro system, we demonstrate that 21- and 22-nt RNA fragments are the sequence-specific mediators of RNAi. The short interfering RNAs (siRNAs) are generated by an RNase III-like processing reaction from long dsRNA. Chemically synthesized siRNA duplexes with overhanging 3' ends mediate efficient target RNA cleavage in the lysate, and the cleavage site is located near the center of the region spanned by the guiding siRNA. Furthermore, we provide evidence that the direction of dsRNA processing determines whether sense or antisense target RNA can be cleaved by the siRNA-protein complex.", "doc-2": "In this study, we formulate a computational reaction model following a chemical kinetic theory approach to predict the binding rate constant for the siRNA-RISC complex formation reaction. The model allowed us to study the potency difference between 2-nt 3' overhangs against blunt-ended siRNA molecules in an RNA interference (RNAi) system. The rate constant predicted by this model was fed into a stochastic simulation of the RNAi system (using the Gillespie stochastic simulator) to study the overall potency effect. We observed that the stochasticity in the transcription/translation machinery has no observable effects in the RNAi pathway. Sustained gene silencing using siRNAs can be achieved only if there is a way to replenish the dsRNA molecules in the cell. Initial findings show about 1.5 times more blunt-ended molecules will be required to keep the mRNA at the same reduced level compared to the 2-nt overhang siRNAs. However, the mRNA levels jump back to saturation after a longer time when blunt-ended siRNAs are used. We found that the siRNA-RISC complex formation reaction rate was 2 times slower when blunt-ended molecules were used pointing to the fact that the presence of the 2-nt overhangs has a greater effect on the reaction in which the bound RISC complex cleaves the mRNA.", "label": 1}
{"doc-1": "Wireless distributed microsensor systems will enable the reliable monitoring of a variety of environments for both civil and military applications. In this paper, we look at communication protocols, which can have significant impact on the overall energy dissipation of these networks. Based on our findings that the conventional protocols of direct transmission, minimum-transmission-energy, multi-hop routing, and static clustering may not be optimal for sensor networks, we propose LEACH (Low-Energy Adaptive Clustering Hierarchy), a clustering-based protocol that utilizes randomized rotation of local cluster based station (cluster-heads) to evenly distribute the energy load among the sensors in the network. LEACH uses localized coordination to enable scalability and robustness for dynamic networks, and incorporates data fusion into the routing protocol to reduce the amount of information that must be transmitted to the base station. Simulations show the LEACH can achieve as much as a factor of 8 reduction in energy dissipation compared with conventional outing protocols. In addition, LEACH is able to distribute energy dissipation evenly throughout the sensors, doubling the useful system lifetime for the networks we simulated.", "doc-2": "Wireless sensor networks (WSNs) consists of large number of inexpensive, low-power, sensors that can be placed in an ad hoc fashion to form a communication network. Efficient techniques for inter sensor communication and information gathering is critical for prolonging the lifetime of the sensor network. Clustering provides an effective way for extending the lifetime of a sensor network. In this paper we propose a distributed and energy driven clustering algorithm where the cluster heads are selected based on relative residual energy level of sensors. Furthermore the cluster head candidacy selection phase, and the cluster head candidacy rotation among phases is triggered only when any of cluster heads energy drops below a dynamic threshold computed by the algorithm. As a result, the overheads in the inter sensor communications will be reduced and thereby the proposed algorithm will favor more powerful nodes over the weaker ones to prolong the lifetime of the entire sensor network in both homogeneous and heterogeneous sensor networks. The results have shown that the the proposed algorithm performs better when compared to existing algorithms such as LEACH, SEP, HEED and ANTCLUST based on the Percentage Node Alive (PNA) and the First Node Dies (FND) metrics.", "label": 1}
{"doc-1": "A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "Looks at the author's research among several companies in Sweden and Finland with regard to marketorientation of service as against physical goods. Found the main difference between them was the difficulty of developing a concrete, tangible service offering. Points out that many experts believe service marketing must differ from goods marketing, but, nevertheless, no radical effort to develop a marketing theory, or ever some marketing concepts, for service firms aiming at solving their problems, seems to have been made  service industry companies deserve a better deal. Discusses this related matter and suggests marketing mix planning to support a hypothetical framework. Investigates, in depth, service industries and their characteristics and weaknesses, accessibility, human resources, auxiliary services and intracorporate elements. Presents two case studies  one inclusive tours marketing and the other barber's shop marketing. Concludes that concepts and models for marketing mix planning do not seem ap...", "label": 1}
{"doc-1": "BACKGROUNDThe HER2 gene, which encodes the growth factor receptor HER2, is amplified and HER2 is overexpressed in 25 to 30 percent of breast cancers, increasing the aggressiveness of the tumor.METHODSWe evaluated the efficacy and safety of trastuzumab, a recombinant monoclonal antibody against HER2, in women with metastatic breast cancer that overexpressed HER2. We randomly assigned 234 patients to receive standard chemotherapy alone and 235 patients to receive standard chemotherapy plus trastuzumab. Patients who had not previously received adjuvant (postoperative) therapy with an anthracycline were treated with doxorubicin (or epirubicin in the case of 36 women) and cyclophosphamide alone (138 women) or with trastuzumab (143 women). Patients who had previously received adjuvant anthracycline were treated with paclitaxel alone (96 women) or paclitaxel with trastuzumab (92 women).RESULTSThe addition of trastuzumab to chemotherapy was associated with a longer time to disease progression (median, 7.4 vs. 4.6 months; P<0.001), a higher rate of objective response (50 percent vs. 32 percent, P<0.001), a longer duration of response (median, 9.1 vs. 6.1 months; P<0.001), a lower rate of death at 1 year (22 percent vs. 33 percent, P=0.008), longer survival (median survival, 25.1 vs. 20.3 months; P=0.01), and a 20 percent reduction in the risk of death. The most important adverse event was cardiac dysfunction of New York Heart Association class III or IV, which occurred in 27 percent of the group given an anthracycline, cyclophosphamide, and trastuzumab; 8 percent of the group given an anthracycline and cyclophosphamide alone; 13 percent of the group given paclitaxel and trastuzumab; and 1 percent of the group given paclitaxel alone. Although the cardiotoxicity was potentially severe and, in some cases, life-threatening, the symptoms generally improved with standard medical management.CONCLUSIONSTrastuzumab increases the clinical benefit of first-line chemotherapy in metastatic breast cancer that overexpresses HER2.", "doc-2": "Theoretically, time from breast cancer diagnosis to therapeutic surgery should affect survival. However, it is unclear whether this holds true in a modern healthcare setting in which breast cancer surgery is carried out within weeks to months of diagnosis. This is a population- and register-based study of all women diagnosed with invasive breast cancer in the Stockholm-Gotland healthcare region in Sweden, 2001-2008, and who were initially operated. Follow-up of vital status ended 2014. 7,017 women were included in analysis. Our main outcome was overall survival. Main analyses were carried out using Cox proportional hazards models. We adjusted for likely confounders and stratified on mode of detection, tumor size and lymph node metastasis. We found that a longer interval between date of morphological diagnosis and therapeutic surgery was associated with a poorer prognosis. Assuming a linear association, the hazard rate of death from all causes increased by 1.011 (95% CI 1.006-1.017) per day. Comparing, for example, surgery 6 weeks after diagnosis to surgery 3 weeks after diagnosis, thereby confers a 1.26-fold increased hazard rate. The increase in hazard rate associated with surgical delay was strongest in women with largest tumors. Whilst there was a clear association between delays and survival in women without lymph node metastasis, the association may be attenuated in subgroups with increasing number of lymph node metastases. We found no evidence of an interaction between time to surgery and mode of detection. In conclusion, unwarranted delays to primary treatment of breast cancer should be avoided.", "label": 1}
{"doc-1": "We have developed a new set of algorithms, collectively called \"Velvet,\" to manipulate de Bruijn graphs for genomic sequence assembly. A de Bruijn graph is a compact representation based on short words (k-mers) that is ideal for high coverage, very short read (25-50 bp) data sets. Applying Velvet to very short reads and paired-ends information only, one can produce contigs of significant length, up to 50-kb N50 length in simulations of prokaryotic data and 3-kb N50 on simulated mammalian BACs. When applied to real Solexa data sets without read pairs, Velvet generated contigs of approximately 8 kb in a prokaryote and 2 kb in a mammalian BAC, in close agreement with our simulated results without read-pair information. Velvet represents a new approach to assembly that can leverage very short reads in combination with read pairs to produce useful assemblies.", "doc-2": "Lentinula edodes is a popular cultivated edible mushroom with high nutritional and medicinal value. To understand the regulation of gene expression in the dikaryotic mycelium and mature fruiting body in the commercially important Korean L. edodes strain, we first performed comparative transcriptomic analysis, using Illumina HiSeq platform. De novo assembly of these sequences revealed 11,675 representative transcripts in two different stages of L. edodes. A total of 9,092 unigenes were annotated and subjected to Gene Ontology, EuKaryotic Orthologous Groups, and Kyoto Encyclopedia of Genes and Genomes (KEGG) analyses. Gene expression analysis revealed that 2,080 genes were differentially expressed, with 1,503 and 577 upregulated in the mycelium and a mature fruiting body, respectively. Analysis of 18 KEGG categories indicated that fruiting body-specific transcripts were significantly enriched in replication and repair and transcription pathways, which are important for premeiotic replication, karyogamy, and meiosis during maturation. We also searched for fruiting body-specific proteins such as aspartic protease, gamma-glutamyl transpeptidase, and cyclohexanone monooxygenase, which are involved in fruiting body maturation and isolation of functional substances. These transcriptomes will be useful in elucidating the molecular mechanisms of mature fruiting body development and beneficial properties, and contribute to the characterization of novel genes in L. edodes.", "label": 1}
{"doc-1": "Analysis of two-dimensional signals and systems foundation of scalar diffraction theory Fresnel and Fraunhofer diffraction wave-optics analysis of coherent optical systems frequency analysis of optical imaging systems wavefront modulation analog optical information processing holography. Appendices: delta function and Fourier transform theorems introduction to paraxial geometrical optics polarization and Jones matrices.", "doc-2": "In third harmonic (3f0) transmit phasing, transmit waveforms comprising fundamental (f0) signal and 3f0 signal are used to generate both frequency-sum and frequency-difference components for manipulation of tissue harmonic amplitude. Nevertheless, the acoustic propagation of 3f0 transmit signal suffers from more severe attenuation and phase aberration than the f0 signal and hence degrades the performance of 3f0 transmit phasing. Besides, 3f0 transmit parameters such as aperture size and signal bandwidth are also influential in 3f0 transmit phasing. In this study, extensive simulations were performed to investigate the effects of these imaging parameters. Results indicate that the harmonic enhancement and suppression in 3f0 transmit phasing are compromised when the magnitude of frequency-difference component decreases in the presence of tissue attenuation and phase aberration. To compensate for the reduced frequency-difference component, a higher 3f0 transmit amplitude can be used. When the transmit parameters are concerned, a smaller 3f0 transmit aperture can provide more axially uniform harmonic enhancement and more effective suppression of harmonic amplitude. In addition, the spectral leakage signal also interferes with tissue harmonics and degrades the efficacy of 3f0 transmit phasing. Our results suggest that, in the method of 3f0 transmit phasing, the transmit amplitude, phase and aperture size of 3f0 signal should remain adjustable for optimization of clinical performance. Besides, multipulse sequences such as pulse inversion are also favorable for leakage removal in 3f0 transmit phasing.", "label": 1}
{"doc-1": "Networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from the individual nodes. These networks require robust wireless communication protocols that are energy efficient and provide low latency. We develop and analyze low-energy adaptive clustering hierarchy (LEACH), a protocol architecture for microsensor networks that combines the ideas of energy-efficient cluster-based routing and media access together with application-specific data aggregation to achieve good performance in terms of system lifetime, latency, and application-perceived quality. LEACH includes a new, distributed cluster formation technique that enables self-organization of large numbers of nodes, algorithms for adapting clusters and rotating cluster head positions to evenly distribute the energy load among all the nodes, and techniques to enable distributed signal processing to save communication resources. Our results show that LEACH can improve system lifetime by an order of magnitude compared with general-purpose multihop approaches.", "doc-2": "Wireless Sensor Networks (WSN) differ from traditional wireless communication networks in several characteristics. One of them is the power awareness since the batteries of sensor nodes have a restricted lifetime and are difficult to be replaced. Therefore, all protocols must be designed to minimize energy consumption and to preserve the longevity of the network. Routing protocols in WSN aim at accomplishing power conservation. Most of researches have focused on energy efficient solutions regardless of the communication between Cluster Heads (CH) and Base Station (BS). When the sensor field is far away from the BS, the CH are burdened with heavier relay traffic and tend to die much faster. To solve this problem, a Multi-hop Energy Efficient routing protocol based on Data Controlling (MEEDC) is proposed in this paper. Our work focuses on (i) a heterogeneous network and (ii) a sensitive data controlling. The role of super nodes in the proposed heterogeneous network is to connect the CH and the BS. They are responsible for transmitting packets received from the CH to the BS, thus the CH can preserve some energy in data forwarding. The control of data transmission tries to reduce the number of transmissions and thus considerable energy conservation is achieved. Simulation results show that the MEEDC protocol significantly prolongs the network survival time.", "label": 1}
{"doc-1": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weightupdate Littlestone Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in R. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line. ] 1997 Academic Press", "doc-2": "The prevalence of mobile phones, the internet-of-things technology, and networks of sensors has led to an enormous and ever increasing amount of data that are now more commonly available in a streaming fashion [1]-[5]. Often, it is assumed - either implicitly or explicitly - that the process generating such a stream of data is stationary, that is, the data are drawn from a fixed, albeit unknown probability distribution. In many real-world scenarios, however, such an assumption is simply not true, and the underlying process generating the data stream is characterized by an intrinsic nonstationary (or evolving or drifting) phenomenon. The nonstationarity can be due, for example, to seasonality or periodicity effects, changes in the users' habits or preferences, hardware or software faults affecting a cyber-physical system, thermal drifts or aging effects in sensors. In such nonstationary environments, where the probabilistic properties of the data change over time, a non-adaptive model trained under the false stationarity assumption is bound to become obsolete in time, and perform sub-optimally at best, or fail catastrophically at worst.", "label": 1}
{"doc-1": "Comparative studies of the nucleotide sequences of ribosomal RNA (rRNA) genes provide a means for analyzing phylogenetic relation ships over a wide range of taxonomic levels (Woese and Olsen 1986; Zimmer et al 1988; Medlin et al 1988; Jorgensen and Cluster 1989). The nuclear small-subunit rDNA sequences (16S-like) evolve rela tively slowly and are useful for studying distantly related organisms, whereas the mitochondrial rRNA genes evolve more rapidly and can be useful at the ordinal or family level. The internal transcribed spacer region and intergenic spacer of the nuclear rRNA repeat units evolve fastest and may vary among species within a genus or among populations. Numerous sequences of rRNA genes have been obtained primarily by isolating and sequencing individual cloned genes (Medlin et al 1988). Direct rRNA sequencing (Lane et al 1985) has also been used to rapidly obtain sequence data. However, this method requires rela tively large amounts of RNA and is prone to errors since only one strand is sequenced. The polymerase chain reaction (PCR) and direct sequencing offer several advantages over cloning and direct rRNA sequencing: (1) the method utilizes relatively crude preparations of total DNA such as", "doc-2": "Agaricus is a genus of saprobic basidiomycetes including species of nutritional and medicinal interest. Historically the temperate species have been grouped into eight classical sections. Recent phylogenetic analyses however, revealed that two-thirds of the tropical taxa do not cluster in these sections, but form exclusively tropical clades. Seven (TR I to TR VII) strongly supported tropical clades have been revealed and it was hypothesized that clade TR I might represent Agaricus section Brunneopicti. This section was initially characterized by the presence of punctiform squamules, the remains of the veil, on the pileus and stipe. The present morphological study and phylogenetic ML, MP and Bayesian analyses based on ITS1+2 sequences show that clade TR I corresponds to Agaricus section Brunneopicti and includes 16 taxa grouped in four strongly supported subclades and two isolated branches. The six species with punctiform squamules which initially characterized the section constitute one of these subclades. We propose the new replacement name Agaricus brunneopunctatus for the illegitimate name Agaricus brunneopictus. All 16 species are discussed, full descriptions are provided for five, among them, A. brunneosquamulosus, A. niveogranulatus, A. sordidocarpus and A. toluenolens are described as new species. We also report on certain members of section Brunneopicti traits which generally characterize species belonging to other sections. These shared characters raise the issue of their origin and complicate the systematics and the identification of the tropical Agaricus species. An artificial dichotomous key is presented for species identification. Section Brunneopicti is the first reconstructed section of tropical Agaricus. Its known geographical distribution range is strictly palaeotropical. We predict that the species richness of other somewhat forgotten or new tropical sections will also increase in coming years.", "label": 1}
{"doc-1": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "doc-2": "This paper presents the implementation of a simulation of a robotic arm whose task is to collect different objects in a virtual environment. To develop this task, the control of the robotic arm is done through 10 different hand gestures, which are recognized by a CNN with a structure type DAG Network (or DAG-CNN), reaching an accuracy of 84.5% in the recognition of gestures. Likewise, real-time tests are carried out on the already trained network, where the user is in a semicontrolled environment indicating the different actions for the robot to perform, where the correct operation of the trained network was verified, obtaining a high precision in the recognition of the commands made, that is, without errors in the control actions followed by the robot.", "label": 1}
{"doc-1": "A method for estimating the cholesterol content of the serum low-density lipoprotein fraction (Sf0-20) is presented. The method involves measurements of fasting plasma total cholesterol, triglyceride, and high-density lipoprotein cholesterol concentrations, none of which requires the use of the preparative ultracentrifuge. Comparison of this suggested procedure with the more direct procedure, in which the ultracentrifuge is used, yielded correlation coefficients of .94 to .99, depending on the patient population compared.", "doc-2": "The most recent guidelines released by the EAS/ESC and the Canadian Cardiovascular Society (CCS) retain low-density lipoprotein cholesterol (LDL-C) as the primary measure of the atherogenic risk of the apolipoprotein B (apoB) lipoproteins and the primary target of LDL-C lowering therapy. Both organizations endorse non-high-density lipoprotein cholesterol (non-HDL-C) and apoB as \"alternate/secondary\" targets, but neither group offers evidence supporting the continued preference of LDL-C as the primary target over non-HDL-C and apoB. Further, both suggest that non-HDL-C and apoB more or less measure the same thing and, therefore, are essentially interchangeable. But what is the evidence that LDL-C should remain the primary target, and are apoB and non-HDL-C mirror images of one another? Furthermore, are estimation of risk and establishment of treatment targets the only relevant issues, or is diagnosis also an essential objective? These are the questions this article will address. Our principal objectives are: (1) to clarify the differences between LDL-C, non-HDL-C, and apoB and to distinguish what they measure; (2) to summarize the evidence relating to LDL-C, non-HDL-C, and apoB as predictors of cardiovascular risk and as targets for treatment; and (3) to demonstrate that diagnosis of atherogenic dyslipoproteinemias should be a fundamental clinical priority.", "label": 1}
{"doc-1": "Using the result that under the null hypothesis of no misspecification an asymptotically efficient estimator must have zero asymptotic covariance with its difference from a consistent but asymptotically inefficient estimator, specification tests are devised for a number of model specifications in econometrics. Local power is calculated for small departures from the null hypothesis. An instrumental variable test as well as tests for a time series cross section model and the simultaneous equation model are presented. An empirical model provides evidence that unobserved individual factors are present which are not orthogonal to the included right-hand-side variable in a common econometric specification of an individual wage equation.", "doc-2": "Many believe that fast food promotion is a significant cause of the obesity epidemic in North America. Industry members argue that promotion only reallocates brand shares and does not increase overall demand. This study weighs into the debate by specifying and estimating a discrete/continuous model of fast food restaurant choice and food expenditure that explicitly accounts for both spatial and temporal determinants of demand. Estimates are obtained using a unique panel of Canadian fast food consumers. The results show that promotion primarily increases demand and has very little effect on restaurant market shares.", "label": 1}
{"doc-1": "MicroRNAs (miRNAs) are a large family of post-transcriptional regulators of gene expression that are 21 nucleotides in length and control many developmental and cellular processes in eukaryotic organisms. Research during the past decade has identified major factors participating in miRNA biogenesis and has established basic principles of miRNA function. More recently, it has become apparent that miRNA regulators themselves are subject to sophisticated control. Many reports over the past few years have reported the regulation of miRNA metabolism and function by a range of mechanisms involving numerous proteinprotein and proteinRNA interactions. Such regulation has an important role in the context-specific functions of miRNAs.", "doc-2": "Preliminary studies showed that miR-21 is overexpressed in some human cancers. However, the role of miR-21 in cancer is still unclear and even controversial. Our purpose was to investigate the biological effects of miR-21 on A549 non-small cell lung cancer (NSCLC) cells and the underlying mechanisms of those effects. The expression of miR-21 was quantified in serum samples from patients with NSCLC. A549 cells were transfected with miR-NC-sponge or miR-21-sponge only, or with miR-21-sponge plus PDCD4 small-interfering RNA (siRNA). The expression of miR-21 and PDCD4 mRNA in transfected cells was quantified by real-time polymerase chain reaction and the expression of PDCD4 protein by Western blot. Cell proliferation, apoptosis, migration, and invasion assays were performed to determine the biological effects of miR-21 expression and PDCD4 inhibition. miR-21 was overexpressed in serum from patients with NSCLC. Reduced miR-21 expression was observed following transfection with miR-21-sponge in A549 NSCLC cells. Co-transfection of miR-21-sponge with PDCD4 siRNA upregulated miR-21 expression in these cells. PDCD4 mRNA and protein levels were increased 2.14-fold and 2.16-fold, respectively, following inhibition of miR-21 expression. Inhibition of miR-21 expression following transfection of miR-21-sponge reduced cell proliferation, migration, and invasion of A549 cells. Depletion of PDCD4 by siRNA transfection reversed the reduction of cell proliferation, migration, and invasion induced by inhibition of miR-21 in A549 cells. It indicates that miR-21 is highly expressed in patients with NSCLC and inhibition of miR-21 expression reduces proliferation, migration, and invasion of A549 cells by upregulating PDCD4 expression. Modulation of miR-21 or PDCD4 expression may provide a potentially novel therapeutic approach for NSCLC.", "label": 1}
{"doc-1": "A technique has been developed for the separation of proteins by two-dimensional polyacrylamide gel electrophoresis. Due to its resolution and sensitivity, this technique is a powerful tool for the analysis and detection of proteins from complex biological sources. Proteins are separated according to isoelectric point by isoelectric focusing in the first dimension, and according to molecular weight by sodium dodecyl sulfate electrophoresis in the second dimension. Since these two parameters are unrelated, it is possible to obtain an almost uniform distribution of protein spots across a two-diminsional gel. This technique has resolved 1100 different components from Escherichia coli and should be capable of resolving a maximum of 5000 proteins. A protein containing as little as one disintegration per min of either 14C or 35S can be detected by autoradiography. A protein which constitutes 10 minus 4 to 10 minus 5% of the total protein can be detected and quantified by autoradiography. The reproducibility of the separation is sufficient to permit each spot on one separation to be matched with a spot on a different separation. This technique provides a method for estimation (at the described sensitivities) of the number of proteins made by any biological system. This system can resolve proteins differing in a single charge and consequently can be used in the analysis of in vivo modifications resulting in a change in charge. Proteins whose charge is changed by missense mutations can be identified. A detailed description of the methods as well as the characteristics of this system are presented.", "doc-2": "In hereditary pyropoikilocytosis (HPP), the red cell membrane skeletons exhibit a mechanical instability that can be correlated to defective self-association of spectrin heterodimers. To determine the underlying molecular defect, we have subjected HPP spectrin to limited tryptic digestion, followed by one- and two-dimensional separations of the peptides. Two of the HPP kindreds exhibited a marked decrease in 80,000-dalton peptide (previously identified as the spectrin dimer-dimer contact domain of the alpha-subunit) and a concomitant increase of the 74,000-dalton polypeptide (presumably derived from the 80,000-dalton domain) and a decrease in a 22,000-dalton polypeptide. We now report tryptic digests of two other HPP kindred that are characterized by a decrease or complete absence of the 80,000-dalton tryptic fragment, with a concomitant increase in fragments at 46,000 and 17,000 daltons. The 46,000-dalton fragment separated into multiple spots on isoelectric focusing, ranging in isoelectric point from 5.25 to 5.35, and the 17,000-dalton fragment focused to a single spot at 5.4. Minor fragments at 56,000 and 22,000 daltons were also decreased, while a 38,000-dalton fragment increased. Limited tryptic digestion of the separated alpha- and beta-subunits revealed that the 74,000-dalton fragment in the first group of patients and the 46,000-dalton fragment in the second group of patients were derived from the alpha-subunit. Both subtypes exhibited a similar defect of spectrin self-association, with 30%-38% of spectrin dimers in O degrees C extracts. The results indicate that at least two distinct forms of structurally defective spectrin may give rise to the clinical presentation of HPP.", "label": 1}
{"doc-1": "Lipid decomposition studies in frozen fish have led to the development of a simple and rapid method for the extraction and purification of lipids from biological materials. The entire procedure can be carried out in approximately 10 minutes; it is efficient, reproducible, and free from deleterious manipulations. The wet tissue is homogenized with a mixture of chloroform and methanol in such proportions that a miscible system is formed with the water in the tissue. Dilution with chloroform and water separates the homogenate into two layers, the chloroform layer containing all the lipids and the methanolic layer containing all the non-lipids. A purified lipid extract is obtained merely by isolating the chloroform layer. The method has been applied to fish muscle and may easily be adapted to use with other tissues.", "doc-2": "Oil quality and content were analyzed in 33 accessions from 13 wild species and 10 accessions of cultivated oat. Wild oat species tended to have higher oil and 18:1 fatty acid (FA) contents and lower amounts of 18:2 and 18:3 FAs as compared to cultivated oats. In addition to common FAs, minor amounts of several hydroxy and epoxy FAs were also present in the oat oil and mainly confined to specific lipid classes. These unusual FAs included the previously reported 15-hydroxy 18:2 (Delta9,12) (avenoleic acid) mostly found among polar lipids and a novel 7-hydroxyhexadecanoic acid located to 1,2-diacylglycerol. The present study highlights the potential of making use of the existing germplasm, consisting of wild oat species, in breeding programs for achieving new oat varieties that produce a range of oils with different FA compositions as well as having high oil contents. However, in one matter, oats apparently lack genetic diversity and that is for oil qualities that are highly enriched in the omega 3 (omega-3) FA 18:3. Consequently, developing oat cultivars with highly unsaturated oils will need involvement of other techniques such as biotechnology.", "label": 1}
{"doc-1": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "doc-2": "While there has been remarkable progress in the performance of visual recognition algorithms, the state-of-the-art models tend to be exceptionally data-hungry. Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models. Lagging behind the growth in model capacity, the available datasets are quickly becoming outdated in terms of size and density. To circumvent this bottleneck, we propose to amplify human effort through a partially automated labeling scheme, leveraging deep learning with humans in the loop. Starting from a large set of candidate images for each category, we iteratively sample a subset, ask people to label them, classify the others with a trained model, split the set into positives, negatives, and unlabeled based on the classification confidence, and then iterate with the unlabeled set. To assess the effectiveness of this cascading procedure and enable further progress in visual recognition research, we construct a new image dataset, LSUN. It contains around one million labeled images for each of 10 scene categories and 20 object categories. We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset.", "label": 1}
{"doc-1": "AbstractA general formula () of which a special case is the Kuder-Richardson coefficient of equivalence is shown to be the mean of all split-half coefficients resulting from different splittings of a test.  is therefore an estimate of the correlation between two random samples of items from a universe of items like those in the test.  is found to be an appropriate index of equivalence and, except for very short tests, of the first-factor concentration in the test. Tests divisible into distinct subtests should be so divided before using the formula. The index$$\\bar r_{ij} $$, derived from , is shown to be an index of inter-item homogeneity. Comparison is made to the Guttman and Loevinger approaches. Parallel split coefficients are shown to be unnecessary for tests of common types. In designing tests, maximum interpretability of scores is obtained by increasing the first-factor concentration in any separately-scored subtest and avoiding substantial group-factor clusters within a subtest. Scalability is not a requisite.", "doc-2": "Brownfield redevelopment has recently become the focus of attention of governments, communities, environmental advocates, scientists, and researchers around the world. The purpose of this study is to provide a framework for establishing and optimizing an evaluation index for brownfield redevelopment projects (BRPs). This framework involves three steps: the initial design, testing and optimization, and verification. With the help of two standard statistical software packages, the reliability and validity of the initialized index system are established, and then the optimization of the initial index system is carried out by means of Factor Analysis. The effectiveness of the optimization of the index system is verified through Structural Equation Modeling. Furthermore, an illustration example is used to show how to apply the established index system in the real world. The paper develops an evaluation index system for brownfield redevelopment projects.The construction is based on an empirical study in China.Main procedure includes initial design, optimization, and verification.An illustration example is used to show the effectiveness and efficiency.", "label": 1}
{"doc-1": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system.", "doc-2": "The article presents a method for real-time tracking of face in video sequences. Algorithms for face detection are often very time-consuming and there are problems with their performance in real-time processing of video sequences or video streams. The algorithm presented in the article solves this problem using the optical flow technique. Face detection can be performed in a longer interval (in the order of hundreds of milliseconds) than the FPS of a given video sequence is performed. A special functionality for the evaluation of partial movements in the area of the face being tracked has been developed. The part of the article focused on testing the algorithm shows a high reduction of computation time with the high-accuracy determination of the face position preserved even in frames where the face detection algorithm was not applied. Key-Words: Face Detection, Optical Flow, Tracking, Digital Video Sequence, Image Processing", "label": 1}
{"doc-1": "The increase in the number of large data sets and the complexity of current probabilistic sequence evolution models necessitates fast and reliable phylogeny reconstruction methods. We describe a new approach, based on the maximum- likelihood principle, which clearly satisfies these requirements. The core of this method is a simple hill-climbing algorithm that adjusts tree topology and branch lengths simultaneously. This algorithm starts from an initial tree built by a fast distance-based method and modifies this tree to improve its likelihood at each iteration. Due to this simultaneous adjustment of the topology and branch lengths, only a few iterations are sufficient to reach an optimum. We used extensive and realistic computer simulations to show that the topological accuracy of this new method is at least as high as that of the existing maximum-likelihood programs and much higher than the performance of distance-based and parsimony approaches. The reduction of computing time is dramatic in comparison with other maximum-likelihood packages, while the likelihood maximization ability tends to be higher. For example, only 12 min were required on a standard personal computer to analyze a data set consisting of 500 rbcL sequences with 1,428 base pairs from plant plastids, thus reaching a speed of the same order as some popular distance-based and parsimony algorithms. This new method is implemented in the PHYML program, which is freely available on our web page: http://www.lirmm.fr/w3ifa/MAAS/.", "doc-2": "Plasmids have long been recognized as an important driver of DNA exchange and genetic innovation in prokaryotes. The success of plasmids has been attributed to their independent replication from the hosts chromosome and their frequent self-transfer. It is thought that plasmids accumulate, rearrange and distribute nonessential genes, which may provide an advantage for host proliferation under selective conditions. In order to test this hypothesis independently of biases from culture selection, we study the plasmid metagenome from microbial communities in two activated sludge systems, one of which receives mostly household and the other chemical industry wastewater. We find that plasmids from activated sludge microbial communities carry among the largest proportion of unknown gene pools so far detected in metagenomic DNA, confirming their presumed role of DNA innovators. At a system level both plasmid metagenomes were dominated by functions associated with replication and transposition, and contained a wide variety of antibiotic and heavy metal resistances. Plasmid families were very different in the two metagenomes and grouped in deep-branching new families compared with known plasmid replicons. A number of abundant plasmid replicons could be completely assembled directly from the metagenome, providing insight in plasmid composition without culturing bias. Functionally, the two metagenomes strongly differed in several ways, including a greater abundance of genes for carbohydrate metabolism in the industrial and of general defense factors in the household activated sludge plasmid metagenome. This suggests that plasmids not only contribute to the adaptation of single individual prokaryotic species, but of the prokaryotic community as a whole under local selective conditions.", "label": 1}
{"doc-1": "Molecular Cloning has served as the foundation of technical expertise in labs worldwide for 30 years. No other manual has been so popular, or so influential. Molecular Cloning, Fourth Edition, by the celebrated founding author Joe Sambrook and new co-author, the distinguished HHMI investigator Michael Green, preserves the highly praised detail and clarity of previous editions and includes specific chapters and protocols commissioned for the book from expert practitioners at Yale, U Mass, Rockefeller University, Texas Tech, Cold Spring Harbor Laboratory, Washington University, and other leading institutions. The theoretical and historical underpinnings of techniques are prominent features of the presentation throughout, information that does much to help trouble-shoot experimental problems. For the fourth edition of this classic work, the content has been entirely recast to include nucleic-acid based methods selected as the most widely used and valuable in molecular and cellular biology laboratories. Core chapters from the third edition have been revised to feature current strategies and approaches to the preparation and cloning of nucleic acids, gene transfer, and expression analysis. They are augmented by 12 new chapters which show how DNA, RNA, and proteins should be prepared, evaluated, and manipulated, and how data generation and analysis can be handled. The new content includes methods for studying interactions between cellular components, such as microarrays, next-generation sequencing technologies, RNA interference, and epigenetic analysis using DNA methylation techniques and chromatin immunoprecipitation. To make sense of the wealth of data produced by these techniques, a bioinformatics chapter describes the use of analytical tools for comparing sequences of genes and proteins and identifying common expression patterns among sets of genes. Building on thirty years of trust, reliability, and authority, the fourth edition of Mol", "doc-2": "SummaryEpichlo typhina is a biotrophic fungal pathogen which causes choke disease of pooid grasses. The anamorphic state, Acremonium typhinum, is placed in the section Albo-lanosa along with related, mutualistic, seeddisseminated endophytes. As an initial study of gene structure and evolution in Epichlo and related endophytes, the -tubulin gene, tub2, of the perennial ryegrass choke pathogen (EtPRG) was cloned and sequenced. The coding sequence and the predicted -tubulin amino acid sequence were highly homologous to the Neurospora crassa homologs, and to one of the two -tubulin genes of Emericella nidulans. However, two introns characteristic of the N. crassa and Em. nidulans genes were absent in the E. typhina gene. Furthermore, one of the remaining introns possessed the uncommon 5 splice junction, GC. In contrast to published observations concerning other Ascomycetes, a mutant of EtPRG, selected for resistance to methyl-2-benzimidazole carbamate (benomyl), possessed no alteration of its -tubulin coding sequence.", "label": 1}
{"doc-1": "BackgroundCandidate single nucleotide polymorphisms (SNPs) from genome-wide association studies (GWASs) were often selected for validation based on their functional annotation, which was inadequate and biased. We propose to use the more than 200,000 microarray studies in the Gene Expression Omnibus to systematically prioritize candidate SNPs from GWASs.ResultsWe analyzed all human microarray studies from the Gene Expression Omnibus, and calculated the observed frequency of differential expression, which we called differential expression ratio, for every human gene. Analysis conducted in a comprehensive list of curated disease genes revealed a positive association between differential expression ratio values and the likelihood of harboring disease-associated variants. By considering highly differentially expressed genes, we were able to rediscover disease genes with 79% specificity and 37% sensitivity. We successfully distinguished true disease genes from false positives in multiple GWASs for multiple diseases. We then derived a list of functionally interpolating SNPs (fitSNPs) to analyze the top seven loci of Wellcome Trust Case Control Consortium type 1 diabetes mellitus GWASs, rediscovered all type 1 diabetes mellitus genes, and predicted a novel gene (KIAA1109) for an unexplained locus 4q27. We suggest that fitSNPs would work equally well for both Mendelian and complex diseases (being more effective for cancer) and proposed candidate genes to sequence for their association with 597 syndromes with unknown molecular basis.ConclusionsOur study demonstrates that highly differentially expressed genes are more likely to harbor disease-associated DNA variants. FitSNPs can serve as an effective tool to systematically prioritize candidate SNPs from GWASs.", "doc-2": "The insulin-degrading enzyme is responsible for the intracellular proteolysis of insulin. Its gene IDE is located on chromosome 10, in an area with suggestive linkage to type 2 diabetes and related phenotypes. Due to the impact of genetic variants of this gene in rodents and the function of its protein product, it has been proposed as a candidate gene for type 2 diabetes. Various groups have explored the role of the common genetic variation of IDE on insulin resistance and reported associations of various single nucleotide polymorphisms (SNPs) and haplotypes on both type 2 diabetes and glycemic traits. We sought to characterize the haplotype structure of IDE in detail and replicate the association of common variants with type 2 diabetes, fasting insulin, fasting glucose, and insulin resistance. We assessed linkage disequilibrium, selected single-marker and multimarker tags, and genotyped these markers in several case-control and family-based samples totalling 4,206 Caucasian individuals. We observed no statistically significant evidence of association between single-marker or multimarker tests in IDE and type 2 diabetes. Nominally significant differences in quantitative traits are consistent with statistical noise. We conclude that common genetic variation at IDE is unlikely to confer clinically significant risk of type 2 diabetes in Caucasians.", "label": 1}
{"doc-1": "......................................................................................................................................... ii Preface ........................................................................................................................................... iv Table of", "doc-2": "The recent introduction of low-cost, moored data-logging acoustic receivers has provided opportunities for tracking marine organisms over small (hundreds of metres) and large scales (hundreds of kilometres). Acoustic receivers have been deployed in many different environments to examine specific hypotheses regarding the movement of aquatic species. This technology provides many advantages for studying aquatic animal movement patterns, but also has limitations and provides unique difficulties for users. Study design, applications, advantages and limitations are discussed with examples from past and current studies. Data management and analysis techniques are in their infancy and few standardised techniques exist. Complications with data management and potential data analysis techniques are discussed. Examples from the literature are utilised wherever possible to provide useful references.", "label": 1}
{"doc-1": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.", "doc-2": "State-of-the-art systems for text-independent speaker recognition use as their features a compact representation of a speaker utterance, known as \"i-vector.\" We recently presented an efficient approach for training a Pairwise Support Vector Machine (PSVM) with a suitable kernel for i-vector pairs for a quite large speaker recognition task. Rather than estimating an SVM model per speaker, according to the \"one versus all\" discriminative paradigm, the PSVM approach classifies a trial, consisting of a pair of i-vectors, as belonging or not to the same speaker class. Training a PSVM with large amount of data, however, is a memory and computational expensive task, because the number of training pairs grows quadratically with the number of training i-vectors. This paper demonstrates that a very small subset of the training pairs is necessary to train the original PSVM model, and proposes two approaches that allow discarding most of the training pairs that are not essential, without harming the accuracy of the model. This allows dramatically reducing the memory and computational resources needed for training, which becomes feasible with large datasets including many speakers. We have assessed these approaches on the extended core conditions of the NIST 2012 Speaker Recognition Evaluation. Our results show that the accuracy of the PSVM trained with a sufficient number of speakers is 10%-30% better compared to the one obtained by a PLDA model, depending on the testing conditions. Since the PSVM accuracy increases with the training set size, but PSVM training does not scale well for large numbers of speakers, our selection techniques become relevant for training accurate discriminative classifiers.", "label": 1}
{"doc-1": "Attractive features of time-hopping spread-spectrum multiple-access systems employing impulse signal technology are outlined, and emerging design issues are described. Performance of such communications systems in terms of achievable transmission rate and multiple-access capability are estimated for both analog and digital data modulation formats under ideal multiple-access channel conditions.", "doc-2": "The capacity of differential pulse-position modulation (DPPM) is considered in this paper. Since the formula of Shannon Capacity is effective only in the AWGN channel with continuous-valued inputs and outputs, while the channel employing M-ary DPPM modulation has discrete-valued inputs and continuous-valued outputs, we derive the modified formula which applies to calculate the capacity of a UWB system with DPPM over an AWGN channel. Then the result is extended to Nakagmi-m fading channels. Monte Carlo simulation is employed to analyze the relationship between the capacity and the signal to noise ratio (SNR), and the relationship between reliable communication distance and channel capacity subject to FCC Part 15 rules is also given. The results show that DPPM is superior to PPM in terms of data transfer rate and capacity performance.", "label": 1}
{"doc-1": "Advances in next generation technologies have driven the costs of DNA sequencing down to the point that genotyping-by-sequencing (GBS) is now feasible for high diversity, large genome species. Here, we report a procedure for constructing GBS libraries based on reducing genome complexity with restriction enzymes (REs). This approach is simple, quick, extremely specific, highly reproducible, and may reach important regions of the genome that are inaccessible to sequence capture approaches. By using methylation-sensitive REs, repetitive regions of genomes can be avoided and lower copy regions targeted with two to three fold higher efficiency. This tremendously simplifies computationally challenging alignment problems in species with high levels of genetic diversity. The GBS procedure is demonstrated with maize (IBM) and barley (Oregon Wolfe Barley) recombinant inbred populations where roughly 200,000 and 25,000 sequence tags were mapped, respectively. An advantage in species like barley that lack a complete genome sequence is that a reference map need only be developed around the restriction sites, and this can be done in the process of sample genotyping. In such cases, the consensus of the read clusters across the sequence tagged sites becomes the reference. Alternatively, for kinship analyses in the absence of a reference genome, the sequence tags can simply be treated as dominant markers. Future application of GBS to breeding, conservation, and global species and population surveys may allow plant breeders to conduct genomic selection on a novel germplasm or species without first having to develop any prior molecular tools, or conservation biologists to determine population structure without prior knowledge of the genome or diversity in the species.", "doc-2": "Height is one of the most heritable and easily measured traits in maize (Zea mays L.). Given a pedigree or estimates of the genomic identity-by-state among related plants, height is also accurately predictable. But, mapping alleles explaining natural variation in maize height remains a formidable challenge. To address this challenge, we measured the plant height, ear height, flowering time, and node counts of plants grown in >64,500 plots across 13 environments. These plots contained >7300 inbreds representing most publically available maize inbreds in the United States and families of the maize Nested Association Mapping (NAM) panel. Joint-linkage mapping of quantitative trait loci (QTL), fine mapping in near isogenic lines (NILs), genome-wide association studies (GWAS), and genomic best linear unbiased prediction (GBLUP) were performed. The heritability of maize height was estimated to be >90%. Mapping NAM family-nested QTL revealed the largest explained 2.1  0.9% of height variation. The effects of two tropical alleles at this QTL were independently validated by fine mapping in NIL families. Several significant associations found by GWAS colocalized with established height loci, including brassinosteroid-deficient dwarf1, dwarf plant1, and semi-dwarf2. GBLUP explained >80% of height variation in the panels and outperformed bootstrap aggregation of family-nested QTL models in evaluations of prediction accuracy. These results revealed maize height was under strong genetic control and had a highly polygenic genetic architecture. They also showed that multiple models of genetic architecture differing in polygenicity and effect sizes can plausibly explain a population's variation in maize height, but they may vary in predictive efficacy.", "label": 1}
{"doc-1": "There is a new trend to use Datalog-style rule-based languages to specify modern distributed applications, notably on the Web. We introduce here such a language for a distributed data model where peers exchange messages (i.e. logical facts) as well as rules. The model is formally defined and its interest for distributed data management is illustrated through a variety of examples. A contribution of our work is a study of the impact on expressiveness of \"delegations\" (the installation of rules by a peer in some other peer) and explicit timestamps. We also validate the semantics of our model by showing that under certain natural conditions, our semantics converges to the same semantics as the centralized system with the same rules. Indeed, we show this is even true when updates are considered.", "doc-2": "We prove a lower bound of (n<sup>k/4</sup>) on the size of constant-depth circuits solving the k-clique problem on n-vertex graphs (for every constant k). This improves a lower bound of (n<sup>k/89d<sup>2</sup></sup>) due to Beame where d is the circuit depth. Our lower bound has the advantage that it does not depend on the constant d in the exponent of n, thus breaking the mold of the traditional size-depth tradeoff. Our k-clique lower bound derives from a stronger result of independent interest. Suppose f<sub>n</sub> :0,1<sup>n/2</sup>  {0,1} is a sequence of functions computed by constant-depth circuits of size O(n<sup>t</sup>). Let G be an Erdos-Renyi random graph with vertex set {1,...,n} and independent edge probabilities n<sup>-</sup> where   1/2t-1. Let A be a uniform random k-element subset of {1,...,n} (where k is any constant independent of n) and let K<sub>A</sub> denote the clique supported on A. We prove that f<sub>n</sub>(G) = f<sub>n</sub>(G  K<sub>A</sub>) asymptotically almost surely. These results resolve a long-standing open question in finite model theory (going back at least to Immerman in 1982). The <i>m-variable fragment of first-order logic</i>, denoted by FO<sup>m</sup>, consists of the first-order sentences which involve at most m variables. Our results imply that the <i>bounded variable hierarchy</i> FO<sup>1</sup>  FO<sup>2</sup>  ...  FO<sup>m</sup>  ... is strict in terms of expressive power on finite ordered graphs. It was previously unknown that FO<sup>3</sup> is less expressive than full first-order logic on finite ordered graphs.", "label": 1}
{"doc-1": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.", "doc-2": "Observable reading behavior, the act of moving the eyes over lines of text, is highly stereotyped among the users of a language, and this has led to the development of reading detectorsmethods that input windows of sequential fixations and output predictions of the fixation behavior during those windows being reading or skimming. The present study introduces a newmethod for reading detection using Region Ranking SVM (RRSVM). An SVM-based classifier learns the local oculomotor features that are important for real-time reading detection while it is optimizing for the global reading/skimming classification, making it unnecessary to hand-label local fixation windows for model training. This RRSVM reading detector was trained and evaluated using eye movement data collected in a laboratory context, where participants viewed modified web news articles and had to either read them carefully for comprehension or skim them quickly for the selection of keywords (separate groups). Ground truth labels were known at the global level (the instructed reading or skimming task), and obtained at the local level in a separate rating task. The RRSVM reading detector accurately predicted 82.5% of the global (article-level) reading/skimming behavior, with accuracy in predicting local window labels ranging from 72-95%, depending on how tuned the RRSVM was for local and global weights. With this RRSVM reading detector, a method now exists for near real-time reading detection without the need for hand-labeling of local fixation windows. With real-time reading detection capability comes the potential for applications ranging from education and training to intelligent interfaces that learn what a user is likely to know based on previous detection of their reading behavior.", "label": 1}
{"doc-1": "The goals of this article are to (a) describe differences between moderator and mediator effects; (b) provide nontechnical descriptions of how to examine each type of effect, including study design, analysis, and interpretation of results; (c) demonstrate how to analyze each type of effect; and (d) provide suggestions for further reading. The authors focus on the use of multiple regression because it is an accessible data-analytic technique contained in major statistical packages. When appropriate, they also note limitations of using regression to detect moderator and mediator effects and describe alternative procedures, particularly structural equation modeling. Finally, to illustrate areas of confusion in counseling psychology research, they review research testing moderation and mediation that was published in the Journal of Counseling Psychology during 2001.", "doc-2": "A major challenge for accumulating knowledge in psychology is the variation in methods and participant populations across studies in a single domain. We offer a systematic approach to addressing this challenge and implement it in the domain of money priming. In three preregistered experiments ( N = 4,649), participants were exposed to one of a number of money manipulations before completing self-report measures of money activation (Study 1); engaging in a behavioral-persistence task (Study 3); completing self-report measures of subjective wealth, self-sufficiency, and communion-agency (Studies 1-3); and completing demographic questions (Studies 1-3). Four of the five manipulations we tested activated the concept of money, but, contrary to what we expected based on the preponderance of the published literature, no manipulation consistently affected any dependent measure. Moderation by sociodemographic characteristics was sparse and inconsistent across studies. We discuss implications for theories of money priming and explain how our approach can complement recent efforts to build a reproducible, cumulative psychological science.", "label": 1}
{"doc-1": "AbstractSimilar-material simulation is generally used in mining engineering. The properties of a similar material vary over time in a certain environment. Due to the time-varying characteristics of the material strength, the model and prototype is dissimilar in dynamics and kinematics, which may affect the reliability of simulation results. The present paper conducts block experiments that investigate the time-varying characteristics of the material strength. The paper further investigates methods of reducing the effects of time-varying characteristics of material strength on simulation results and extends the effective monitoring time of the similar-material model in a natural environment and an environment having constant temperature and humidity. The following results are obtained: (1) The strength and moisture content of the similar material have an exponential relationship, which can be divided into three phases. (2) When a similar-material model is laid in a natural environment, sampling and homemade monitoring equipment can be adopted to control the similar-material models strength. Meanwhile, homemade monitoring equipment for the relative humidity of the similar material can be used to monitor a critical change in the similar materials moisture content. (3) An environment having constant temperature and humidity can extend the effective monitoring time of the similar-material model. (4) High humidity can extend the effective monitoring time while high temperature can decrease the effective monitoring time. In an experiment, the temperature and humidity under the environment of constant temperature and humidity and monitoring time of the model should both be set reasonably. Results provide guidelines for setting the model monitoring period and give evidence for the reliability of simulation results.", "doc-2": "Similar material simulation test was carried out in a geological model of W915101 fully mechanized caving face with large mining height in the Liuhuanggou Colliery, in Xinjiang Uigur Autonomous Region. The roof overlying strata movement law in the stope of a fully mechanized caving face with large mining height was studied and show that the roof overlying strata in the stope of a fully mechanized caving face with large mining height can be formed into a stable arch structure; the fracture rock beam is formed resembling a bond beam, but it has essentially the structure of multi-span beams under the big structure of the stable arch. The roof overlying strata movement law in the stope of a fully mechanized caving face with large mining height is similar to that of the common, fully mechanized caving stope, which is determined by the deformation and instability of the structure of multi-span beams. But because of the differences between the mining heights, the peak pressure in the stope of a fully mechanized caving face with large mining height is smaller while the affected area of abutment pressure is wider in the front of the working face; this is the obvious difference in abutment pressure between the stope of a fully mechanized caving face with large mining height and that of the common.", "label": 1}
{"doc-1": "stargazer produces LaTeX code for well-formatted tables that hold regression analysis results from several models side-by-side, as well as summary statistics. It supports model objects from lm, glm, svyglm, gee, gam, polr, survreg, coxph, as well as from the implementation of these in zelig. It also supports the following zelig models for social network analysis: cloglog.net, gamma.net, and logit.net.", "doc-2": "Sports betting is expanding globally through introduction into new markets and growth in existing markets. Traditionally, bets were placed on the outcome of a match before match commencement, with the outcome not determined for hours or even days. The advent of in-play betting has reduced the delay between bet and outcome. A controversial form of in-play betting is betting on micro events (micro-betting), where consumers bet on outcomes such as the next ball in cricket, or the next point in tennis, with the outcome determined almost immediately. This enables rapid, impulsive and continuous betting and may heighten the risk of problem gambling. We surveyed 1813 Australian sports bettors to determine demographic, behavioural and psychological characteristics of micro event bettors, and of those who place a higher proportion of their bets on micro events. Our two hypotheses were supported: that more highly engaged bettors, including those with gambling problems, are more likely to (1) bet on micro events, and (2) place more of their bets on micro events. Of those who bet on micro events, 78% met criteria for problem gambling, and only 5% non-problem gambling (vs 29% and 28% respectively for non micro event bettors). Placing a higher proportion of bets on micro events was also related to problem gambling. Micro event bettors were likely to: be younger, well educated and single; engaged in a wider variety of gambling activities; and to have high trait impulsivity. Micro event betting appears to appeal almost exclusively to bettors with gambling problems, so a ban would represent a highly targeted intervention to reduce gambling-related harm.", "label": 1}
{"doc-1": "This paper summarizes the current state of the art and recent trends in software engineering economics. It provides an overview of economic analysis techniques and their applicability to software engineering and management. It surveys the field of software cost estimation, including the major estimation techniques available, the state of the art in algorithmic cost models, and the outstanding research issues in software cost estimation.", "doc-2": "Abstract : In response to historically high cost growth in the acquisition of space systems, the Under Secretary of the Air Force, in accordance with National Security Space (NSS) Acquisition Policy, directed the Air Force acquisition community to support the development of independent, accurate, and timely cost analyses to make the acquisition of NSS systems more realistic in terms of estimated costs. In turn, the former commander of Air Force Space Command (AFSPC), Gen Lance W. Lord, and the former commander of the Air Force Space and Missile Systems Center (SMC), Lt Gen Michael Hamel, asked RAND Project AIR FORCE to assess cost-estimating requirements and capabilities of SMC cost-estimating organizations as well as their resources, tools, methods and processes and to recommend an enhanced approach to cost analysis aimed at improving cost-estimating for space systems and increasing the understanding of factors that influence their cost. The study was sponsored by the former commander of SMC, General Hamel. The project technical monitor was Col Delane Aguilar, SMC/FMC. The research was conducted within the Resource Management Program of RAND Project AIR FORCE as part of a multiyear study entitled Air Force Space Systems Costs. The initial data collection was completed in May of 2006 and the final update was provided in February of 2007, with frequent updates in between. The final briefing was presented to General Hamel on March 13, 2007, and to Gen Kevin P. Chilton, the former commander of Air Force Space Command, on March 21, 2007. This monograph should interest government personnel involved in cost estimation and acquisition of defense systems, the military space acquisition communities, and those concerned with current and future acquisition policies.", "label": 1}
{"doc-1": "1", "doc-2": "The possible increase of antibiotic-resistant bacteria in sewage associated with the discharge of wastewater from a hospital and a pharmaceutical plant was investigated by using Acinetobacter species as environmental bacterial indicators. The level of susceptibility to six antimicrobial agents was determined in 385 Acinetobacter strains isolated from samples collected upstream and downstream from the discharge points of the hospital and the pharmaceutical plant. Results indicated that while the hospital waste effluent affected only the prevalence of oxytetracycline resistance, the discharge of wastewater from the pharmaceutical plant was associated with an increase in the prevalence of both single- and multiple-antibiotic resistance among Acinetobacter species in the sewers.", "label": 1}
{"doc-1": "Recent advances in high-throughput cDNA sequencing (RNA-seq) can reveal new genes and splice variants and quantify expression genome-wide in a single assay. The volume and complexity of data from RNA-seq experiments necessitate scalable, fast and mathematically principled analysis software. TopHat and Cufflinks are free, open-source software tools for gene discovery and comprehensive expression analysis of high-throughput mRNA sequencing (RNA-seq) data. Together, they allow biologists to identify new genes and new splice variants of known ones, as well as compare gene and transcript expression under two or more conditions. This protocol describes in detail how to use TopHat and Cufflinks to perform such analyses. It also covers several accessory tools and utilities that aid in managing data, including CummeRbund, a tool for visualizing RNA-seq analysis results. Although the procedure assumes basic informatics skills, these tools assume little to no background with RNA-seq analysis and are meant for novices and experts alike. The protocol begins with raw sequencing reads and produces a transcriptome assembly, lists of differentially expressed and regulated genes and transcripts, and publication-quality visualizations of analysis results. The protocol's execution time depends on the volume of transcriptome sequencing data and available computing resources but takes less than 1 d of computer time for typical experiments and 1 h of hands-on time.", "doc-2": "Energy efficiency is one of the key considerations for various systems, from handheld devices to servers in a data center. Application-specific accelerators can provide 10 - 1000X energy-efficiency improvement over general-purpose processors through customization and by exploiting the application parallelism. The design of memory system is the key to improve performance and energy efficiency for both accelerators and processors. However, even with customization and acceleration, the single-server computation power is still limited and cannot support need of large-scale data processing and analytics. Therefore, the second goal of this dissertation is to provide customization support in the in-memory cluster computing system for such big data applications. The first part of this dissertation investigates the design and optimizations of memory system. Our goal is to design a high-performance and energy-efficient memory system that supports both general-purpose processors and accelerator-rich architectures (ARAs). We proposed hybrid caches architecture and corresponding optimizations for processor caches. We also provide an optimal algorithm to synthesize the ARA memory system. In the second part of this dissertation, we focus on improving the performance of an important domain, DNA sequencing pipeline, which demands huge computation need together with big data characteristics. We adopt the in-memory cluster computing framework, Spark, to provide scalable speedup while providing hardware acceleration support in the cluster. With such system, we can reduce the time of sequence alignment process from tens of hours to 32 minutes.", "label": 1}
{"doc-1": "Microorganisms that invade a vertebrate host are initially recognized by the innate immune system through germline-encoded pattern-recognition receptors (PRRs). Several classes of PRRs, including Toll-like receptors and cytoplasmic receptors, recognize distinct microbial components and directly activate immune cells. Exposure of immune cells to the ligands of these receptors activates intracellular signaling cascades that rapidly induce the expression of a variety of overlapping and unique genes involved in the inflammatory and immune responses. New insights into innate immunity are changing the way we think about pathogenesis and the treatment of infectious diseases, allergy, and autoimmunity.", "doc-2": "The facultative intracellular bacterium Francisella noatunensis causes francisellosis in Atlantic cod (Gadus morhua), but little is known about its survival strategies or how these bacteria evade the host immune response. In this study we show intracellular localisation of F. noatunensis in cod macrophages using indirect immunofluorescence techniques and green fluorescent labelled bacteria. Transmission electron microscopy revealed that F. noatunensis was enclosed by a phagosomal membrane during the initial phase of infection. Bacteria were at a later stage of the infection found in large electron-lucent zones, apparently surrounded by a partially intact or disintegrated membrane. Immune electron microscopy demonstrated the release of bacterial derived vesicles from intracellular F. noatunensis, an event suspected of promoting phagosomal membrane degradation and allowing escape of the bacteria to cytoplasm. Studies of macrophages infected with F. noatunensis demonstrated a weak activation of the inflammatory response genes as measured by increased expression of the Interleukin (IL)-1 and IL-8. In comparison, a stronger induction of gene expression was found for the anti-inflammatory IL-10 indicating that the bacterium exhibits a role in down-regulating the inflammatory response. Expression of the p40 subunit of IL-12/IL-17 genes was highly induced during infection suggesting that F. noatunensis promotes T cell polarisation. The host macrophage responses studied here showed low ability to distinguish between live and inactivated bacteria, although other types of responses could be of importance for such discriminations. The immunoreactivity of F. noatunensis lipopolysaccharide (LPS) was very modest, in contrast to the strong capacity of Escherichia coli LPS to induce inflammatory responsive genes. These results suggest that F. noatunensis virulence mechanisms cover many strategies for intracellular survival in cod macrophages.", "label": 1}
{"doc-1": "The difficulties inherent in obtaining consistent and adequate diagnoses for the purposes of research and therapy have been pointed out by a number of authors. Pasamanick 12 in a recent article viewed the low interclinician agreement on diagnosis as an indictment of the present state of psychiatry and called for \"the development of objective, measurable and verifiable criteria of classification based not on personal or parochial considerations, but on behavioral and other objectively measurable manifestations.\" Attempts by other investigators to subject clinical observations and judgments to objective measurement have resulted in a wide variety of psychiatric rating scales. 4,15 These have been well summarized in a review article by Lorr 11 on \"Rating Scales and Check Lists for the Evaluation of Psychopathology.\" In the area of psychological testing, a variety of paper-and-pencil tests have been devised for the purpose of measuring specific", "doc-2": "A sensitive and specific screening test that would identify the subset of substance-abusing patients at highest risk for relapse would constitute an important advance for treatment planning. This study examined the relative value of quantitative electroencephalography as a rapid, inexpensive, and noninvasive measure of relapse potential. The subjects were 107 substance-dependent patients enrolled in residential treatment programs. All were unmedicated and free of the complicating effects of major medical and neurological disorders. Structured clinical interview data and a 5-minute recording of the resting, eyes-closed electroencephalogram were obtained after patients had verifiably maintained abstinence for 15 months. Patients were then monitored for relapse or successful abstinence by research staff for an ensuing 6-month period. ANCOVAs of EEG power spectral density within pre-defined frequency bands revealed an enhanced amount of high frequency (19.539.8 Hz)  activity among the 48 patients who later relapsed compared to both 59 patients who maintained abstinence and 22 additional subjects with no history of substance dependence. Importantly, in subsequent logistic regression analyses, fast  power was found to be superior to severity of illness, depression level, and childhood conduct problems in predicting relapse. With fast  power as the sole predictor, the sensitivity, specificity, and positive and negative predictive value parameters for discriminating outcomes were 0.61, 0.85, 0.75, and 0.74, respectively. Additional ANCOVAs revealed that the EEG difference between relapse-prone and abstinence-prone groups was related to the interaction of two premorbid factors, viz., childhood Conduct Disorder and paternal alcoholism. The enhancement of fast  electroencephalographic activity in patients who will later relapse most likely originates from a premorbid and subtle dysfunction involving frontal brain regions.", "label": 1}
{"doc-1": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5years of the challenge, and propose future directions and improvements.", "doc-2": "The application of deep learning, specifically deep convolutional neural networks (DCNNs), to the classification of remotely-sensed imagery of natural landscapes has the potential to greatly assist in the analysis and interpretation of geomorphic processes. However, the general usefulness of deep learning applied to conventional photographic imagery at a landscape scale is, at yet, largely unproven. If DCNN-based image classification is to gain wider application and acceptance within the geoscience community, demonstrable successes need to be coupled with accessible tools to retrain deep neural networks to discriminate landforms and land uses in landscape imagery. Here, we present an efficient approach to train/apply DCNNs with/on sets of photographic images, using a powerful graphical method called a conditional random field (CRF), to generate DCNN training and testing data using minimal manual supervision. We apply the method to several sets of images of natural landscapes, acquired from satellites, aircraft, unmanned aerial vehicles, and fixed camera installations. We synthesize our findings to examine the general effectiveness of transfer learning to landscape-scale image classification. Finally, we show how DCNN predictions on small regions of images might be used in conjunction with a CRF for highly accurate pixel-level classification of images.", "label": 1}
{"doc-1": "We show that the large-N limits of certainconformal field theories in various dimensions includein their Hilbert space a sector describing supergravityon the product of anti-de Sitter spacetimes, spheres, and other compact manifolds. This is shown bytaking some branes in the full M/string theory and thentaking a low-energy limit where the field theory on thebrane decouples from the bulk. We observe that, in this limit, we can still trust thenear-horizon geometry for large N. The enhancedsupersymmetries of the near-horizon geometry correspondto the extra supersymmetry generators present in thesuperconformal group (as opposed to just the super-Poincaregroup). The 't Hooft limit of 3 + 1 N = 4 super-YangMills at the conformal pointis shown to contain strings: they are IIB strings. Weconjecture that compactifications of M/string theory on various anti-de Sitterspacetimes is dual to various conformal field theories.This leads to a new proposal for a definition ofM-theory which could be extended to include fivenoncompact dimensions.", "doc-2": "We derive a holographic relation for the de Sitter (dS) static patch with the dual field theory defined on the observer horizon. The starting point is the duality of higher-spin theory on ${\\mathrm{AdS}}_{4}$ and the $\\mathsf{O}(N)$ vector model. We build on a similar analytic continuation as used recently to obtain a realization of dS/CFT and adapt it to the static patch. The resulting duality relates higher-spin theory on the ${\\mathrm{dS}}_{4}$ static patch to a cutoff conformal field theory on the cylinder $\\mathbb{R}\\ifmmode\\times\\else\\texttimes\\fi{}{\\mathrm{S}}^{2}$. The construction permits a derivation of the finite thermodynamic entropy associated to the horizon of the static patch from the dual field theory. As a further brick, we recover the spectrum of quasinormal frequencies from the correlation functions of the boundary theory. In the last part, we incorporate the dS/dS correspondence as an independent proposal for holography on dS and show that a concrete realization can be obtained by similar reasoning.", "label": 1}
{"doc-1": "We quantified the biomass allocation patterns to leaves, stems and roots in vegetative plants, and how this is influenced by the growth environment, plant size, evolutionary history and competition. Dose-response curves of allocation were constructed by means of a meta-analysis from a wide array of experimental data. They show that the fraction of whole-plant mass represented by leaves (LMF) increases most strongly with nutrients and decreases most strongly with light. Correction for size-induced allocation patterns diminishes the LMF-response to light, but makes the effect of temperature on LMF more apparent. There is a clear phylogenetic effect on allocation, as eudicots invest relatively more than monocots in leaves, as do gymnosperms compared with woody angiosperms. Plants grown at high densities show a clear increase in the stem fraction. However, in most comparisons across species groups or environmental factors, the variation in LMF is smaller than the variation in one of the other components of the growth analysis equation: the leaf area : leaf mass ratio (SLA). In competitive situations, the stem mass fraction increases to a smaller extent than the specific stem length (stem length : stem mass). Thus, we conclude that plants generally are less able to adjust allocation than to alter organ morphology.", "doc-2": "Herbivory contributes substantially to plant functional diversity and in ways that move far beyond direct defence trait patterns, as effective growth strategies under herbivory require modification of multiple functional traits that are indirectly related to defence. In order to understand how herbivory has shaped plant functional diversity, we need to consider the physiology and architecture of the herbivores and how this constrains effective defence strategies. Here we consider herbivory by mammals in savanna communities that range from semi-arid to humid conditions. We posited that the saplings of savanna trees can be grouped into two contrasting defence strategies against mammals, namely architectural defence versus low nutrient defence. We provide a mechanistic explanation for these different strategies based on the fact that plants are under competing selection pressures to limit herbivore damage and outcompete neighbouring plants. Plant competitiveness depends on growth rate, itself a function of leaf mass fraction (LMF) and leaf nitrogen per unit mass (Nm). Architectural defence against vertebrates (which includes spinescence) limits herbivore access to plant leaf materials, and partly depends on leaf-size reduction, thereby compromising LMF. Low nutrient defence requires that leaf material is of insufficient nutrient value to support vertebrate metabolic requirements, which depends on low Nm. Thus there is an enforced tradeoff between LMF and Nm, leading to distinct trait suites for each defence strategy. We demonstrate this tradeoff by showing that numerous traits can be distinguished between 28 spinescent (architectural defenders) and non-spinescent (low nutrient defenders) Fabaceae tree species from savannas, where mammalian herbivory is an important constraint on plant growth. Distributions of the strategies along an LMF-Nm tradeoff further provides a predictive and parsimonious explanation for the uneven distribution of spinescent and non-spinescent species across water and nutrient gradients.", "label": 1}
{"doc-1": "SUMMARYThe program MODELTEST uses log likelihood scores to establish the model of DNA evolution that best fits the data.AVAILABILITYThe MODELTEST package, including the source code and some documentation is available at http://bioag.byu. edu/zoology/crandall_lab/modeltest.html.", "doc-2": "Dermatophytes are human and animal pathogenic fungi which cause cutaneous infections and grow exclusively in the stratum corneum, nails and hair. In a culture medium containing soy proteins as sole nitrogen source a substantial proteolytic activity was secreted by Trichophyton rubrum, Trichophyton mentagrophytes and Microsporum canis. This proteolytic activity was 55-75 % inhibited by o-phenanthroline, attesting that metalloproteases were secreted by all three species. Using a consensus probe constructed on previously characterized genes encoding metalloproteases (MEP) of the M36 fungalysin family in Aspergillus fumigatus, Aspergillus oryzae and M. canis, a five-member MEP family was isolated from genomic libraries of T. rubrum, T. mentagrophytes and M. canis. A phylogenetic analysis of genomic and protein sequences revealed a robust tree consisting of five main clades, each of them including a MEP sequence type from each dermatophyte species. Each MEP type was remarkably conserved across species (72-97 % amino acid sequence identity). The tree topology clearly indicated that the multiplication of MEP genes in dermatophytes occurred prior to species divergence. In culture medium containing soy proteins as a sole nitrogen source secreted Meps accounted for 19-36 % of total secreted protein extracts; characterization of protein bands by proteolysis and mass spectrometry revealed that the three dermatophyte species secreted two Meps (Mep3 and Mep4) encoded by orthologous genes.", "label": 1}
{"doc-1": "MOTIVATIONAlthough many next-generation sequencing (NGS) read preprocessing tools already existed, we could not find any tool or combination of tools that met our requirements in terms of flexibility, correct handling of paired-end data and high performance. We have developed Trimmomatic as a more flexible and efficient preprocessing tool, which could correctly handle paired-end data.RESULTSThe value of NGS read preprocessing is demonstrated for both reference-based and reference-free tasks. Trimmomatic is shown to produce output that is at least competitive with, and in many cases superior to, that produced by other tools, in all scenarios tested.AVAILABILITY AND IMPLEMENTATIONTrimmomatic is licensed under GPL V3. It is cross-platform (Java 1.5+ required) and available at http://www.usadellab.org/cms/index.php?page=trimmomaticCONTACTusadel@bio1.rwth-aachen.deSUPPLEMENTARY INFORMATIONSupplementary data are available at Bioinformatics online.", "doc-2": "BackgroundRibosomal RNA (rRNA) accounts for the majority of the RNA in eukaryotic cells, and is encoded by hundreds to thousands of nearly identical gene copies, only a subset of which are active at any given time. In Arabidopsis thaliana, 45S rRNA genes are found in two large ribosomal DNA (rDNA) clusters and little is known about the contribution of each to the overall transcription pattern in the species.ResultsBy taking advantage of genome sequencing data from the 1001 Genomes Consortium, we characterize rRNA gene sequence variation within and among accessions. Notably, variation is not restricted to the pre-rRNA sequences removed during processing, but it is also present within the highly conserved ribosomal subunits. Through linkage mapping we assign these variants to a particular rDNA cluster unambiguously and use them as reporters of rDNA cluster-specific expression. We demonstrate that rDNA cluster-usage varies greatly among accessions and that rDNA cluster-specific expression and silencing is controlled via genetic interactions between entire rDNA cluster haplotypes (alleles).ConclusionsWe show that rRNA gene cluster expression is controlled via complex epistatic and allelic interactions between rDNA haplotypes that apparently regulate the entire rRNA gene cluster. Furthermore, the sequence polymorphism we discovered implies that the pool of rRNA in a cell may be heterogeneous, which could have functional consequences.", "label": 1}
{"doc-1": "Fluorescence methods are being used increasingly in biochemical, medical, and chemical research. This is because of the inherent sensitivity of this technique. and the favorable time scale of the phenomenon of fluorescence. 8 Fluorescence emission occurs about 10- sec (10 nsec) after light absorp tion. During this period of time a wide range of molecular processes can occur, and these can effect the spectral characteristics of the fluorescent compound. This combination of sensitivity and a favorable time scale allows fluorescence methods to be generally useful for studies of proteins and membranes and their interactions with other macromolecules. This book describes the fundamental aspects of fluorescence. and the biochemical applications of this methodology. Each chapter starts with the -theoreticalbasis of each phenomenon of fluorescence, followed by examples which illustrate the use of the phenomenon in the study of biochemical problems. The book contains numerous figures. It is felt that such graphical presentations contribute to pleasurable reading and increased understand ing. Separate chapters are devoted to fluorescence polarization, lifetimes, quenching, energy transfer, solvent effects, and excited state reactions. To enhance the usefulness of this work as a textbook, problems are included which illustrate the concepts described in each chapter. Furthermore, a separate chapter is devoted to the instrumentation used in fluorescence spectroscopy. This chapter will be especially valuable for those perform ing or contemplating fluorescence measurements. Such measurements are easily compromised by failure to consider a number of simple principles.\"", "doc-2": "The present study was undertaken to evaluate the membrane-associating properties of a series of novel antitumor agents, Eu(III) coordination complexes (EC), using the pyrene fluorescence quenching as an analytical instrument. Analysis of EC-induced decrease in pyrene fluorescence intensity in terms of partition and solubility-diffusion models allowed us to evaluate the partition and permeation coefficients of the examined compounds into the lipid vesicles prepared from zwitterionic lipid phosphatidylcholine (PC) and its mixtures with cholesterol (Chol) and anionic lipid cardiolipin (CL). The drug-lipid interactions were found to have the complex nature determined by both EC structure and lipid bilayer composition. High values of the obtained partition and permeation coefficients create the background for the development of EC liposomal formulations.", "label": 1}
{"doc-1": "A set of related medical disorders that lack a proper classification system and diagnostic criteria is like a society without laws. The result is incoherence at best, chaos at worst. For this reason, the International Classification of Headache Disorders (ICHD) is arguably the single most important breakthrough in headache medicine over the last 50 years. The ICHD identifies and categorizes more than a hundred different kinds of headache in a logical, hierarchal system. Even more important, it has provided explicit diagnostic criteria for all of the headache disorders listed. The ICHD quickly became universally accepted, and criticism of the classification has been minor relative to that directed at other disease classification systems. Over the 20 years following publication of the first edition of the ICHD, headache research has rapidly accelerated despite sparse allocation of resources to that effort. In summary, the ICHD has attained widespread acceptance at the international level and has substantially facilitated both clinical research and clinical care in the field of headache medicine.", "doc-2": "Despite being an excruciating headache, little is known about the burden of cluster headache (CH) regarding its various subtypes. In a multicentre, prospective study, patients with chronic CH (n=27), with episodic CH in the active (n=26) and outside the active period (n=22), migraine patients (n=24) and healthy controls (n=31) were included. Epidemiological data, the German version of the Headache Disability Inventory (HDI) and a screening for psychiatric complaints were applied. About 25% of chronic CH patients in our study received invalidity allowance due to CH. HDI scores (total and subscales emotion and function) indicated a severe headache-specific disability (one-way ANOVA: P<0.01). Patients with chronic and active episodic CH were significantly more affected than patients with inactive CH and migraine. Healthy volunteers were significantly less affected than all headache patients. Symptoms suggestive of psychiatric co-morbidity were found predominantly in chronic CH: depressive symptoms (56%), signs of agoraphobia (33%) and suicidal tendencies (25%) were frequently reported. Patients with chronic and active episodic CH were severely impaired in non-economic and economic domains such as disability, working life and psychiatric complaints. Remarkably, psychiatric co-morbidity was highest in chronic CH. Thus, especially chronic CH warrants special medical and further supportive care.", "label": 1}
{"doc-1": "Lateral inhibition, wherein a single cell signals to its neighbors to prevent them from adopting its own fate, is the best-known setting for cell-cell communication via the Notch (N) pathway. During peripheral neurogenesis in Drosophila, sensory organ precursor (SOP) cells arise within proneural clusters (PNCs), small groups of cells endowed with SOP fate potential by their expression of proneural transcriptional activators. SOPs use N signaling to activate in neighboring PNC cells the expression of multiple genes that inhibit the SOP fate. These genes respond transcriptionally to direct regulation by both the proneural proteins and the N pathway transcription factor Suppressor of Hairless [Su(H)], and their activation is generally highly asymmetric; i.e. only in the inhibited (non-SOP) cells of the PNC, and not in SOPs. We show that the substantially higher proneural protein levels in the SOP put this cell at risk of inappropriately activating the SOP-inhibitory genes, even without input from N-activated Su(H). We demonstrate that this is prevented by direct ;default' repression of these genes by Su(H), acting through the same binding sites it uses for activation in non-SOPs. We show that de-repression of even a single N pathway target gene in the SOP can extinguish the SOP cell fate. Finally, we define crucial roles for the adaptor protein Hairless and the co-repressors Groucho and CtBP in conferring repressive activity on Su(H) in the SOP. Our work elucidates the regulatory logic by which N signaling and the proneural proteins cooperate to create the neural precursor/epidermal cell fate distinction during lateral inhibition.", "doc-2": "The proneural genes achaete (ac) and scute (sc) confer to Drosophila epidermal cells the ability to become sensory mother cells (SMCs). In imaginal discs, ac-sc are expressed in groups of cells, the proneural clusters, which are thought to delimit the areas where SMCs arise. We have visualized with the resolution of single cells the initial stages of sensory organ development by following the evolving pattern of proneural clusters and the emergence of SMCs. At reproducible positions within clusters, a small number of cells accumulate increased amounts of ac-sc protein. Subsequently, one of these cells, the SMC, accumulates the highest amount. Later, at least some SMCs become surrounded by cells with reduced ac-sc expression, a phenomenon probably related to lateral inhibition. Genetic mosaic analyses of cells with different doses of ac-sc genes, the sc expression in sc mutants, and the above findings show that the levels of ac-sc products are most important for SMC singling-out and SMC state maintenance. These products do not intervene in the differentiation of SMC descendants. The extramacrochaetae gene, an antagonist of proneural genes, negatively regulates sc expression, probably by interfering with activators of this gene.", "label": 1}
{"doc-1": "Introduction Conclusions References", "doc-2": "What happens to the Earth's climate, environment, and biota when thousands of gigatons of greenhouse gases are rapidly added to the atmosphere? Modern anthropogenic forcing of atmospheric chemistry promises to provide an experiment in such change that has not been matched since the early Paleogene, more than 50 million years ago (Ma),when catastrophic release of carbon to the atmosphere drove abrupt, transient, hyperthermal events.  Research on the Paleocene-Eocene Thermal Maximum(PETM)the best documented of these events, which occurred about 55 Mahas advanced significantly since its discovery 15 years ago. During the PETM, carbon addition to the oceans and atmosphere was of a magnitude similar to that which is anticipated through the 21st century. This event initiated global warming, biotic extinction and migration, and fundamental changes in the carbon and hydrological cycles that transformed the early Paleogene world.", "label": 1}
{"doc-1": "From the Publisher: The updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Like the first edition,this text can also be used for self-study by technical professionals since it discusses engineering issues in algorithm design as well as the mathematical aspects. In its new edition,Introduction to Algorithms continues to provide a comprehensive introduction to the modern study of algorithms. The revision has been updated to reflect changes in the years since the book's original publication. New chapters on the role of algorithms in computing and on probabilistic analysis and randomized algorithms have been included. Sections throughout the book have been rewritten for increased clarity,and material has been added wherever a fuller explanation has seemed useful or new information warrants expanded coverage. As in the classic first edition,this new edition of Introduction to Algorithms presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers. Further,the algorithms are presented in pseudocode to make the book easily accessible to students from all programming language backgrounds. Each chapter presents an algorithm,a design technique,an application area,or a related topic. The chapters are not dependent on one another,so the instructor can organize his or her use of the book in the way that best suits the course's needs. Additionally,the new edition offers a 25% increase over the first edition in the number of problems,giving the book 155 problems and over 900 exercises thatreinforcethe concepts the students are learning.", "doc-2": "Lazy scheduling is a runtime scheduler for task-parallel codes that effectively coarsens parallelism on load conditions in order to significantly reduce its overheads compared to existing approaches, thus enabling the efficient execution of more fine-grained tasks. Unlike other adaptive dynamic schedulers, lazy scheduling does not maintain any additional state to infer system load and does not make irrevocable serialization decisions. These two features allow it to scale well and to provide excellent load balancing in practice but at a much lower overhead cost compared to work stealing, the golden standard of dynamic schedulers. We evaluate three variants of lazy scheduling on a set of benchmarks on three different platforms and find it to substantially outperform popular work stealing implementations on fine-grained codes. Furthermore, we show that the vast performance gap between manually coarsened and fully parallel code is greatly reduced by lazy scheduling, and that, with minimal static coarsening, lazy scheduling delivers performance very close to that of fully tuned code. The tedious manual coarsening required by the best existing work stealing schedulers and its damaging effect on performance portability have kept novice and general-purpose programmers from parallelizing their codes. Lazy scheduling offers the foundation for a declarative parallel programming methodology that should attract those programmers by minimizing the need for manual coarsening and by greatly enhancing the performance portability of parallel code.", "label": 1}
{"doc-1": "Wayne Rasband of NIH has created ImageJ, an open source Java-written program that is now at version 1.31 and is used for many imaging applications, including those that that span the gamut from skin analysis to neuroscience. ImageJ is in the public domain and runs on any operating system (OS). ImageJ is easy to use and can do many imaging manipulations. A very large and knowledgeable group makes up the user community for ImageJ. Topics covered are imaging abilities; cross platform; image formats support as of June 2004; extensions, including macros and plug-ins; and imaging library. NIH reports tens of thousands of downloads at a rate of about 24,000 per month currently. ImageJ can read most of the widely used and significant formats used in biomedical images. Manipulations supported are read/write of image files and operations on separate pixels, image regions, entire images, and volumes (stacks in ImageJ). Basic operations supported include convolution, edge detection, Fourier transform, histogram and particle analyses, editing and color manipulation, and more advanced operations, as well as visualization. For assistance in using ImageJ, users e-mail each other, and the user base is highly knowledgeable and will answer requests on the mailing list. A thorough manual with many examples and illustrations has been written by Tony Collins of the Wright Cell Imaging Facility at Toronto Western Research Institute and is available, along with other listed resources, via the Web.", "doc-2": "Gene flow is the main force opposing divergent selection, and its effects are greater in populations in close proximity. Thus, complete reproductive isolation between parapatric populations is not expected, particularly in the absence of ecological adaptation and sharp environmental differences. Here, we explore the biogeographical patterns of an endemic ant species, Cataglyphis floricola, for which two colour morphs (black and bicolour) coexist in parapatry throughout continuous sandy habitat in southern Spain. Discriminant analyses of six biometric measurements of male genitalia and 27 cuticular hydrocarbons reveal high differentiation between morphs. Furthermore, the low number of shared alleles derived from nuclear markers (microsatellites) between the morphs at their contact zone suggests the absence of recent gene flow. Mitochondrial DNA (COI) phylogenetic analysis and median-joining networks show that the black morph is basal to the bicolour morph, with unique haplotypes recovered for each morph. Mismatch distribution analysis and Bayesian skyline plots suggest that they are undergoing different demographic changes, with the bicolour and black morphs at demographic equilibrium and expansion, respectively. Thus, our results show complete reproductive isolation between the two colour morphs as evidenced from genetic, chemical and morphological data. We suggest that these divergence events could be explained by historical vicariance during the Pleistocene, in which reproductive traits experienced strong divergent selection between the morphs initiating or culminating speciation.", "label": 1}
{"doc-1": "This publication presents an updated procedure for calculating reference and crop evapotranspiration from meteorological data and crop coefficients. The procedure, first presented in FAO Irrigation and Drainage Paper No. 24, Crop water requirements, in 1977, allows estimation of the amount of water used by a crop, taking into account the effect of the climate and the crop characteristics. The publication incorporates advances in research and more accurate procedures for determining crop water use as recommended by a panel of high-level experts organized by FAO in May 1990. The first part of the guidelines includes procedures for determining reference crop evapotranspiration according to the FAO Penman-Monteith method. These are followed by updated procedures for estimating the evapotranspiration of different crops for different growth stages and ecological conditions.", "doc-2": "In the searching of forest species with good wood quality, easy adaptability and high commercial value, the African mahogany (Khaya ivorensis Chev. A.) have been a good alternative. This study aimed evaluate the phenometric responses of African Mahogany submitted to irrigation. The field experiment was carried out in Bonfinopolis-GO, Brazil, with young plants of African mahogany, being 5 irrigated and 5 non-irrigated. The following variables were evaluated: plant height, stem heigh, number of leaves and leaflets, stem diameter and leaf area. A completely randomized design was used in a bi-factorial scheme 2x9 (A: irrigated and non-irrigated; D: 0, 120, 180, 240, 300, 360, 420, 480, 540 days after transplanting). All the variables showed significant differences not only for irrigated and non-irrigated treatments but also for the times of evaluation, except for stem diameter. Irrigation resulted in higher growth of plants and the irrigation of young African mahogany plants should be used mainly in drought period.", "label": 1}
{"doc-1": "After the completion of the human and other genome projects it emerged that the number of genes in organisms as diverse as fruit flies, nematodes, and humans does not reflect our perception of their relative complexity. Here, we provide reliable evidence that the size of protein interaction networks in different organisms appears to correlate much better with their apparent biological complexity. We develop a stable and powerful, yet simple, statistical procedure to estimate the size of the whole network from subnet data. This approach is then applied to a range of eukaryotic organisms for which extensive protein interaction data have been collected and we estimate the number of interactions in humans to be approximately 650,000. We find that the human interaction network is one order of magnitude bigger than the Drosophila melanogaster interactome and approximately 3 times bigger than in Caenorhabditis elegans.", "doc-2": "One of the goals of relation extraction is to identify protein-protein interactions PPIs in biomedical literature. Current systems are capturing binary relations and also the direction and type of an interaction. Besides assisting in the curation PPIs into databases, there has been little real-world application of these algorithms. We describe UPSITE, a text mining tool for extracting evidence in support of a hypothesized interaction. Given a predicted PPI, UPSITE uses a binary relation detector to check whether a PPI is found in abstracts in PubMed. If it is not found, UPSITE retrieves documents relevant to each of the two proteins separately, and extracts contextual information about biological events surrounding each protein, and calculates semantic similarity of the two proteins to provide evidential support for the predicted PPI. In evaluations, relation extraction achieved an Fscore of 0.88 on the HPRD50 corpus, and semantic similarity measured with angular distance was found to be statistically significant. With the development of PPI prediction algorithms, the burden of interpreting the validity and relevance of novel PPIs is on biologists. We suggest that presenting annotations of the two proteins in a PPI side-by-side and a score that quantifies their similarity lessens this burden to some extent.", "label": 1}
{"doc-1": "UNLABELLEDResearch over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.AVAILABILITYhttp://www.broad.mit.edu/mpg/haploview/CONTACTjcbarret@broad.mit.edu", "doc-2": "Total cholesterol, low-density lipoprotein cholesterol, triglyceride, and high-density lipoprotein cholesterol (HDL-C) levels are among the most important risk factors for coronary artery disease. We tested for gene-gene interactions affecting the level of these four lipids based on prior knowledge of established genome-wide association study (GWAS) hits, protein-protein interactions, and pathway information. Using genotype data from 9,713 European Americans from the Atherosclerosis Risk in Communities (ARIC) study, we identified an interaction between HMGCR and a locus near LIPC in their effect on HDL-C levels (Bonferroni corrected P(c)=0.002). Using an adaptive locus-based validation procedure, we successfully validated this gene-gene interaction in the European American cohorts from the Framingham Heart Study (P(c)=0.002) and the Multi-Ethnic Study of Atherosclerosis (MESA; P(c)=0.006). The interaction between these two loci is also significant in the African American sample from ARIC (P(c)=0.004) and in the Hispanic American sample from MESA (P(c)=0.04). Both HMGCR and LIPC are involved in the metabolism of lipids, and genome-wide association studies have previously identified LIPC as associated with levels of HDL-C. However, the effect on HDL-C of the novel gene-gene interaction reported here is twice as pronounced as that predicted by the sum of the marginal effects of the two loci. In conclusion, based on a knowledge-driven analysis of epistasis, together with a new locus-based validation method, we successfully identified and validated an interaction affecting a complex trait in multi-ethnic populations.", "label": 1}
{"doc-1": "Several explicit identifiability results are derived for deterministic blind beamforming in incoherent multipath with small delay spread. For example, it is shown that if the sum of spatial and fractional sampling diversities exceeds two times the total number of paths, then identifiability can be guaranteed even for one symbol snapshot. The tools come from the theory of low-rank three-way array decomposition (commonly referred to as parallel factor analysis (PARAFAC) and data smoothing in one and two dimensions. New results regarding the Kruskal-rank of certain structured matrices are also included, and they are of interest in their own right.", "doc-2": "In a multipath communication scenario, it is often relevant to estimate the directions and relative delays of each multipath ray. We derive a closed-form subspace-based method for the simultaneous estimation of these parameters from an estimated channel impulse response, using knowledge of the transmitted pulse shape function. The algorithm uses a two-dimensional (2-D) ESPRIT-like shift-invariance technique to separate and estimate the phase shifts due to delay and direction of incidence with automatic pairing of the two parameter sets. Improved resolution is obtained by enlarging the data matrix with shifted and conjugated copies of itself.", "label": 1}
{"doc-1": "Citing this paper Please note that where the full-text provided on King's Research Portal is the Author Accepted Manuscript or Post-Print version this may differ from the final Published version. If citing, it is advised that you check and use the publisher's definitive version for pagination, volume/issue, and date of publication details. And where the final published version is provided on the Research Portal, if citing you are again advised to check the publisher's website for any subsequent corrections.", "doc-2": "BackgroundTo date, the majority of protein-based radiopharmaceuticals have been radiolabelled using non-site-specific conjugation methods, with little or no control to ensure retained protein function post-labelling. The incorporation of a hexahistidine sequence (His-tag) in a recombinant protein can be used to site-specifically radiolabel with 99mTc-tricarbonyl ([99mTc(CO)3]+). This chemistry has been made accessible via a technetium tricarbonyl kit; however, reports of radiolabelling efficiencies and specific activities have varied greatly from one protein to another. Here, we aim to optimise the technetium tricarbonyl radiolabelling method to produce consistently >95% radiolabelling efficiencies with high specific activities suitable for in vivo imaging.MethodsFour different recombinant His-tagged proteins (recombinant complement receptor 2 (rCR2) and three single chain antibodies, -CD33 scFv, -VCAM-1 scFv and -PSMA scFv), were used to study the effect of kit volume, ionic strength, pH and temperature on radiolabelling of four proteins.ResultsWe used 260 and 350L [99mTc(CO)3]+ kits enabling us to radiolabel at higher [99mTc(CO)3]+ and protein concentrations in a smaller volume and thus increase the rate at which maximum labelling efficiency and specific activity were reached. We also demonstrated that increasing the ionic strength of the reaction medium by increasing [Na+] from 0.25 to 0.63M significantly increases the rate at which all four proteins reach a >95% labelling efficiency by at least fourfold, as compared to the conventional IsoLink kit (Covidien, Petten, The Netherlands) and 0.25M [Na+].ConclusionWe have found optimised kit and protein radiolabelling conditions suitable for the reproducible, fast, efficient radiolabelling of proteins without the need for post-labelling purification.", "label": 1}
{"doc-1": "The Agrobacterium vacuum infiltration method has made it possible to transform Arabidopsis thaliana without plant tissue culture or regeneration. In the present study, this method was evaluated and a substantially modified transformation method was developed. The labor-intensive vacuum infiltration process was eliminated in favor of simple dipping of developing floral tissues into a solution containing Agrobacterium tumefaciens, 5% sucrose and 500 microliters per litre of surfactant Silwet L-77. Sucrose and surfactant were critical to the success of the floral dip method. Plants inoculated when numerous immature floral buds and few siliques were present produced transformed progeny at the highest rate. Plant tissue culture media, the hormone benzylamino purine and pH adjustment were unnecessary, and Agrobacterium could be applied to plants at a range of cell densities. Repeated application of Agrobacterium improved transformation rates and overall yield of transformants approximately twofold. Covering plants for 1 day to retain humidity after inoculation also raised transformation rates twofold. Multiple ecotypes were transformable by this method. The modified method should facilitate high-throughput transformation of Arabidopsis for efforts such as T-DNA gene tagging, positional cloning, or attempts at targeted gene replacement.", "doc-2": "Plants react to pathogen attack via recognition of, and response to, pathogen-specific molecules at the cell surface and inside the cell. Pathogen effectors (virulence factors) are monitored by intracellular nucleotide-binding leucine-rich repeat (NB-LRR) sensor proteins in plants and mammals. Here, we study the genetic requirements for defense responses of an autoactive mutant of ADR1-L2, an Arabidopsis coiled-coil (CC)-NB-LRR protein. ADR1-L2 functions upstream of salicylic acid (SA) accumulation in several defense contexts, and it can act in this context as a \"helper\" to transduce specific microbial activation signals from \"sensor\" NB-LRRs. This helper activity does not require an intact P-loop. ADR1-L2 and another of two closely related members of this small NB-LRR family are also required for propagation of unregulated runaway cell death (rcd) in an lsd1 mutant. We demonstrate here that, in this particular context, ADR1-L2 function is P-loop dependent. We generated an autoactive missense mutation, ADR1-L2D484V, in a small homology motif termed MHD. Expression of ADR1-L2D848V leads to dwarfed plants that exhibit increased disease resistance and constitutively high SA levels. The morphological phenotype also requires an intact P-loop, suggesting that these ADR1-L2D484V phenotypes reflect canonical activation of this NB-LRR protein. We used ADR1-L2D484V to define genetic requirements for signaling. Signaling from ADR1-L2D484V does not require NADPH oxidase and is negatively regulated by EDS1 and AtMC1. Transcriptional regulation of ADR1-L2D484V is correlated with its phenotypic outputs; these outputs are both SA-dependent and -independent. The genetic requirements for ADR1-L2D484V activity resemble those that regulate an SA-gradient-dependent signal amplification of defense and cell death signaling initially observed in the absence of LSD1. Importantly, ADR1-L2D484V autoactivation signaling is controlled by both EDS1 and SA in separable, but linked pathways. These data allows us to propose a genetic model that provides insight into an SA-dependent feedback regulation loop, which, surprisingly, includes ADR1-L2.", "label": 1}
{"doc-1": "Overexpression of HER-2 receptor is associated with poor prognosis and aggressive forms of breast cancer. Scientific literature indicates a preventive role of isoflavones in cancer. Since activation of HER-2 receptor initiates growth-promoting events in cancer cells, we studied the effect of biochanin A (an isoflavone) on associated signaling events like receptor activation, downstream signaling, and invasive pathways. HER-2-positive SK-BR-3 breast cancer cells, MCF-10A normal breast epithelial cells, and NIH-3T3 normal fibroblast cells were treated with biochanin A (2-100 muM) for 72 hours. Subsequently cell viability assay, western blotting and zymography were carried out. The data indicate that biochanin A inhibits cell viability, signaling pathways, and invasive enzyme expression and activity in SK-BR-3 cancer cells. Biochanin A did not inhibit MCF-10A and NIH-3T3 cell viability. Therefore, biochanin A could be a unique natural anticancer agent which can selectively target cancer cells and inhibit multiple signaling pathways in HER-2-positive breast cancer cells.", "doc-2": "Genistein (GEN) and biochanin A (BCA), dietary isoflavones, possess breast cancer-preventive properties. Our objective was to examine the effect of physiologically relevant concentrations of BCA and GEN on gene expression in normal (HMEC), immortalized but nontumorigenic (MCF12A), and tumorigenic (MCF7) mammary cells and to determine whether the differences in gene expression are related to differences in metabolism in the three types of mammary cells. Using cDNA arrays, we compared the gene expression after a 48-h incubation with 1 microM BCA, GEN, or vehicle. Treatment with GEN or BCA produced the greatest number of significant changes in HMEC compared with MCF12A or MCF7 cells. Unlike GEN, effects of BCA on gene expression were mostly beneficial, involving induction of tumor suppressor genes. Different extents of metabolism were observed in the three mammary cell types; however, GEN concentrations were very low following either GEN or BCA administration in all of the three cell types. Because there were only very low concentrations of GEN, compared with BCA concentrations, in HMEC and MCF12A cells treated with BCA and different gene expression changes were found after BCA and GEN treatment, these findings suggest that BCA has distinct effects compared with GEN. The results suggest that BCA may represent a better breast cancer-preventive agent than GEN.", "label": 1}
{"doc-1": "A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "Laser interference patterning is a versatile tool for the fabrication of nano patterns. For this study, regular nano line patterns with feature sizes between 100 and 1000nm were produced on polymers polyimide, polyetheretherketone, and polydimethylsiloxane. Cell culture experiments with B35 neuronal cells revealed the alignment of cellular extensions along nano grooves of different feature sizes. Especially, when feature depth exceeds a distinct threshold (aspect ratio > 0.6), more than 50% of cells are oriented parallel, i.e., within angles of 030 to the direction of the line pattern. The presented techniques enable new materials to be processed and offer a promising approach for nerve repair in the central nervous system.", "label": 1}
{"doc-1": "A new family of highly fluorescent indicators has been synthesized for biochemical studies of the physiological role of cytosolic free Ca2+. The compounds combine an 8-coordinate tetracarboxylate chelating site with stilbene chromophores. Incorporation of the ethylenic linkage of the stilbene into a heterocyclic ring enhances the quantum efficiency and photochemical stability of the fluorophore. Compared to their widely used predecessor, \"quin2\", the new dyes offer up to 30-fold brighter fluorescence, major changes in wavelength not just intensity upon Ca2+ binding, slightly lower affinities for Ca2+, slightly longer wavelengths of excitation, and considerably improved selectivity for Ca2+ over other divalent cations. These properties, particularly the wavelength sensitivity to Ca2+, should make these dyes the preferred fluorescent indicators for many intracellular applications, especially in single cells, adherent cell layers, or bulk tissues.", "doc-2": "Mislocalization and aggregation of the axonal protein tau are hallmarks of Alzheimer's disease and other tauopathies. Here, we studied the relationship between tau aggregation, loss of spines and neurons, and reversibility by aggregation inhibitors. To this end we established an in vitro model of tauopathy based on regulatable transgenic hippocampal organotypic slice cultures prepared from mice expressing proaggregant Tau repeat domain with mutation K280 (Tau(RD)K). Transgene expression was monitored by a bioluminescence reporter assay. We observed abnormal tau phosphorylation and mislocalization of exogenous and endogenous tau into the somatodendritic compartment. This was paralleled by a reduction of dendritic spines, altered dendritic spine morphology, dysregulation of Ca(++) dynamics and elevated activation of microglia. Neurotoxicity was mediated by Caspase-3 activation and correlated with the expression level of proaggregant Tau(RD)K. Finally, tau aggregates appeared in areas CA1 and CA3 after three weeks in vitro. Neurodegeneration was relieved by aggregation inhibitors or by switching off transgene expression. Thus the slice culture model is suitable for monitoring the development of tauopathy and the therapeutic benefit of antiaggregation drugs.", "label": 1}
{"doc-1": "In chronic inflammatory diseases, such as asthma, rheumatoid arthritis, inflammatory bowel disease, and psoriasis, several cytokines recruit activated immune and inflammatory cells to the site of lesions, thereby amplifying and perpetuating the inflammatory state.1 These activated cells produce many other mediators of inflammation. What causes these diseases is still a mystery, but the disease process results from an interplay of genetic and environmental factors. Genes, such as those for atopy in asthma and for HLA antigens in rheumatoid arthritis and inflammatory bowel disease, may determine a patient's susceptibility to the disease and the disease's severity, but environmental factors, often unknown, ...", "doc-2": "RNA degradation plays a fundamental role in maintaining cellular homeostasis whether it occurs as a surveillance mechanism eliminating aberrant mRNAs or during RNA processing to generate mature transcripts. 3'-5' exoribonucleases are essential mediators of RNA decay pathways, and one such evolutionarily conserved enzyme is polynucleotide phosphorylase (PNPase). The human homologue of this fascinating enzymatic protein (hPNPaseold-35) was cloned a decade ago in the context of terminal differentiation and senescence through a novel \"overlapping pathway screening\" approach. Since then, significant insights have been garnered about this exoribonuclease and its repertoire of expanding functions. The objective of this review is to provide an up-to-date perspective of the recent discoveries made relating to hPNPaseold-35 and the impact they continue to have on our comprehension of its expanding and diverse array of functions.", "label": 1}
{"doc-1": "With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.", "doc-2": "The goal of this study was to assess the extent to which transposable elements (TEs) have contributed to protein-coding regions in Arabidopsis thaliana. To do this, we first characterized the extent of chimeric TE-gene constructs. We compared a genome-wide TE database to genomic sequences, annotated coding regions, and EST data. The comparison revealed that 7.8% of expressed genes contained a region with close similarity to a known TE sequence. Some groups of TEs, such as helitrons, were underrepresented in exons relative to their genome-wide distribution; in contrast, Copia-like and En/Spm-like sequences were overrepresented in exons. These 7.8% percent of genes were enriched for some GO-based functions, particularly kinase activity, and lacking in other functions, notably structural molecule activity. We also examined gene family evolution for these genes. Gene family information helped clarify whether the sequence similarity between TE and gene was due to a TE contributing to the gene or, instead, the TE co-opting a portion of the gene. Most (66%) of these genes were not easily assigned to a gene family, and for these we could not infer the direction of the relationship between TE and gene. For the remainder, where appropriate, we built phylogenetic trees to infer the direction of the TE-gene relationship by parsimony. By this method, we verified examples where TEs contributed to expressed proteins. Our results are undoubtedly conservative but suggest that TEs may have contributed small protein segments to as many as 1.2% of all expressed, annotated A. thaliana genes.", "label": 1}
{"doc-1": "Researchers in the ontology-design field have developed the content for ontologies in many domain areas. This distributed nature of ontology development has led to a large number of ontologies covering overlapping domains. In order for these ontologies to be reused, they first need to be merged or aligned to one another. We developed a suite of tools for managing multiple ontologies. These suite provides users with a uniform framework for comparing, aligning, and merging ontologies, maintaining versions, translating between different formalisms. Two of the tools in the suite support semi-automatic ontology merging: IPROMPT is an interactive ontology-merging tool that guides the user through the merging process, presenting him with suggestions for next steps and identifying inconsistencies and potential problems. ANCHORPROMPT uses a graph structure of ontologies to find correlation between concepts and to provide additional information for IPROMPT.", "doc-2": "Due to the ever-growing amount of information available on Web shops, it has become increasingly difficult to get an overview of Web-based product information. There are clear indications that better search capabilities, such as the exploitation of annotated data, are needed to keep online shopping transparent for the user. For example, annotations can help present information from multiple sources in a uniform manner. This paper proposes an algorithm that can autonomously map heterogeneous product taxonomies forWeb shop data integration purposes. The proposed approach uses word sense disambiguation techniques, approximate lexical matching, and a mechanism that deals with composite categories. Our algorithms performance on three real-life datasets was compared favourably against two other state-of-the-art taxonomy mapping algorithms. The experiments show that our algorithm performs at least twice as good compared to the other algorithms w.r.t. precision and F-measure.", "label": 1}
{"doc-1": "Tumor endothelial cells (TECs) are therapeutic targets in anti-angiogenic therapy. Contrary to the traditional assumption, TECs can be genetically abnormal and might also acquire drug resistance. In this study, mouse TECs and normal ECs were isolated to investigate the drug resistance of TECs and the mechanism by which it is acquired. TECs were more resistant to paclitaxel with the up-regulation of multidrug resistance (MDR) 1 mRNA, which encodes the P-glycoprotein, compared with normal ECs. Normal human microvascular ECs were cultured in tumor-conditioned medium (CM) and became more resistant to paclitaxel through MDR1 mRNA up-regulation and nuclear translocation of Y-box-binding protein 1, which is an MDR1 transcription factor. Vascular endothelial growth factor (VEGF) receptor 2 (VEGFR2) and Akt were activated in human microvascular ECs by tumor CM. We observed that tumor CM contained a significantly high level of VEGF. A VEGFR kinase inhibitor, Ki8751, and a phosphatidylinositol 3-kinase-Akt inhibitor, LY294002, blocked tumor CM-induced MDR1 up-regulation. MDR1 up-regulation, via the VEGF-VEGFR pathway in the tumor microenvironment, is one of the mechanisms of drug resistance acquired by TECs. We observed that VEGF secreted from tumors up-regulated MDR1 through the activation of VEGFR2 and Akt. This process is a novel mechanism of the acquisition of drug resistance by TECs in the tumor microenvironment.", "doc-2": "Tumour growth is dependent on angiogenesis, and tumour blood vessels are recognized as an important target for cancer therapy. Tumour endothelial cells (TECs) are the main targets of anti-angiogenic therapy. Unlike the traditionally held view, some TECs may be genetically abnormal and might acquire drug resistance. Therefore, we investigated the drug resistance of TECs and the mechanism by which it is acquired. TECs show resistance to paclitaxel through greater mRNA expression of multidrug resistance 1, which encodes P-glycoprotein, as compared with normal endothelial cells. We found that high levels of vascular endothelial growth factor in tumour-conditioned medium may be responsible for upregulated P-glycoprotein expression. This is a novel mechanism for the acquisition of drug resistance by TECs in a tumour microenvironment. This review focuses on the possibility that TECs can acquire drug resistance.", "label": 1}
{"doc-1": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Dept. of Linguistics and Philosophy, 1987.", "doc-2": "In this paper, we provide a comprehensive Minimalist analysis of the apparent free variation between pronouns and anaphors in snake-sentences. Three sets of data provide the basis for the analysis: hitherto unobserved restrictions on quantifier-pronoun relationships, classical observations about the role of perspective or point of view (Cantrall 1974), and interpretive effects concerning the nature of the locative relationship (Kuno 1987). We propose an analysis of spatial prepositions in terms of Svenonius (2006) AxPartP. Spatial interpretations may be object-centered or observer-centered. We correlate these two interpretations with two distinct grammatical representations. The object-centered interpretation involves an Agree relation between AxPart and the complement of P, the observer-centered interpretation is the result of a binding relationship between AxPart and the Speaker, represented in MoodEvid P. An Agree relation requires the presence of the complex anaphor himself, whereas binding of AxPart by the Speaker is only compatible with the pronoun him.", "label": 1}
{"doc-1": "Estimates of the worldwide incidence, mortality and prevalence of 26 cancers in the year 2002 are now available in the GLOBOCAN series of the International Agency for Research on Cancer. The results are presented here in summary form, including the geographic variation between 20 large \"areas\" of the world. Overall, there were 10.9 million new cases, 6.7 million deaths, and 24.6 million persons alive with cancer (within three years of diagnosis). The most commonly diagnosed cancers are lung (1.35 million), breast (1.15 million), and colorectal (1 million); the most common causes of cancer death are lung cancer (1.18 million deaths), stomach cancer (700,000 deaths), and liver cancer (598,000 deaths). The most prevalent cancer in the world is breast cancer (4.4 million survivors up to 5 years following diagnosis). There are striking variations in the risk of different cancers by geographic area. Most of the international variation is due to exposure to known or suspected risk factors related to lifestyle or environment, and provides a clear challenge to prevention.", "doc-2": "Hepatocellular carcinoma (HCC) is one of the most serious health problems worldwide. As in many other diseases, environment and genetic factors are believed to be involved in the pathogenesis of HCC. Numerous epidemiologic investigations including casecontrol and cohort studies have suggested the association of glutathione S-transferase (GST) genetic polymorphisms and HCC risk. However, some studies have produced conflicting results. Therefore, we performed an updated meta-analysis to clarify this inconsistency and to establish a comprehensive picture of the association of the polymorphisms of GSTM1 and GSTT1 with HCC susceptibility. We searched PubMed, Embase, ISI Web of Science, and CNKI databases to identify eligible studies meeting the inclusion criteria up to August 30, 2013. Odds ratios (ORs) and 95% confidence intervals (CIs) were used to assess the strength of association. Finally, there were a total of 33 studies with 4,232 cases and 6,601 controls included in this meta-analysis. In the pooled analysis, significantly increased HCC risks were found for null genotype of GSTM1 (OR=1.31, 95% CI=1.071.61, P=0.010, Pheterogeneity<105) and GSTT1 (OR=1.47, 95% CI=1.251.74, P<105, Pheterogeneity<105). Potential sources of heterogeneity were explored by subgroup analysis based on ethnicity, sample size, and source of control. Significant results were found among East Asians and Indians when stratified by ethnicity, while no evidence of significant associations was observed among Caucasian and African populations. In the genegene interaction analysis, a statistically significant increased risk for HCC was detected for individuals with combined deletion mutations in both genes compared to those with wild genotypes (OR=1.88, 95% CI=1.412.50, P<104, Pheterogeneity=0.004). The present meta-analysis demonstrated that the GSTM1 and GSTT1 null genotype may be associated with an increased risk of HCC and that individuals having the combination of both defective GST genotypes may be more susceptible to developing HCC.", "label": 1}
{"doc-1": "A new heuristic approach for minimizing possiblynonlinear and non-differentiable continuous spacefunctions is presented. By means of an extensivetestbed it is demonstrated that the new methodconverges faster and with more certainty than manyother acclaimed global optimization methods. The newmethod requires few control variables, is robust, easyto use, and lends itself very well to parallelcomputation.", "doc-2": "Orthogonal design method (ODM) is widely used in real world application while it is not used for antenna design yet. It is employed to optimize roughly designed antenna in this paper. The geometrical factors of the antenna are relaxed within specific region and each factor is divided into some levels, and the performance of the antenna is constructed as objective. Then the ODM samples small number of antennas over the relaxed space and finds a prospective antenna. In an experiment of designing ST5 satellite miniantenna, we first get a roughly evolved antenna. The reason why we evolve roughly is because the evolving is time consuming even if numerical electromagnetics code 2 (NEC2) is employed (NEC2 source code is openly available and is fast in wire antenna simulation but not much feasible). Then the ODM method is employed to locally optimize the antenna with HFSS (HFSS is a commercial and feasible electromagnetics simulation software). The result shows the ODM optimizes successfully the roughly evolved antenna.", "label": 1}
{"doc-1": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?.", "doc-2": "The recent growth of anonymous social network services -- such as 4chan, Whisper, and Yik Yak -- has brought online anonymity into the spotlight. For these services to function properly, the integrity of user anonymity must be preserved. If an attacker can determine the physical location from where an anonymous message was sent, then the attacker can potentially use side information (for example, knowledge of who lives at the location) to de-anonymize the sender of the message. In this paper, we investigate whether the popular anonymous social media application Yik Yak is susceptible to localization attacks, thereby putting user anonymity at risk. The problem is challenging because Yik Yak application does not provide information about distances between user and message origins or any other message location information. We provide a comprehensive data collection and supervised machine learning methodology that does not require any reverse engineering of the Yik Yak protocol, is fully automated, and can be remotely run from anywhere. We show that we can accurately predict the locations of messages up to a small average error of 106 meters. We also devise an experiment where each message emanates from one of nine dorm colleges on the University of California Santa Cruz campus. We are able to determine the correct dorm college that generated each message 100\\% of the time.", "label": 1}
{"doc-1": "We wish to thank Terry Schoop of Biomed Arts Associates, San Francisco, for preparation of the figures, Cori Bargmann and Zena Werb for insightful comments on the manuscript, and Normita Santore for editorial assistance. In addition, we are indebted to Joe Harford and Richard Klausner, who allowed us to adapt and expand their depiction of the cell signaling network, and we appreciate suggestions on signaling pathways from Randy Watnick, Brian Elenbas, Bill Lundberg, Dave Morgan, and Henry Bourne. R. A. W. is a Ludwig Foundation and American Cancer Society Professor of Biology. His work has been supported by the Department of the Army and the National Institutes of Health. D. H. acknowledges the support and encouragement of the National Cancer Institute. Editorial policy has rendered the citations illustrative but not comprehensive.", "doc-2": "Several mammalian cell lines, including Madin-Darby canine kidney (MDCK) cells have been approved by regulators for manufacturing of human vaccines. A new MDCK 9B9-1E4 cloned cell line has been created which is capable of producing live attenuated influenza vaccine (LAIV) with high yield. This cell line was shown to be non tumorigenic in eight week old adult athymic nude mouse model. This property is desirable for vaccine production and is unique to this cell line and is not known to be shared by other MDCK cell lines that are currently used for vaccine production. This significant difference in tumorigenic phenotype required further characterization of this cell line to ensure its safety for use in vaccine production. This is particularly important for LAIV production where it is not possible to incorporate a virus inactivation and/or removal step during manufacturing. Characterization of this cell line included extensive adventitious agent testing, tumorigenicity and oncogenicity assessment studies. Here, we describe the development of tumorigenic MDCK cell lines for use as positive controls and in vitro methods to aid in the evaluation of the tumorigenicity of MDCK 9B9-1E4 cloned cells. Tumorigenic MDCK cells were successfully generated following Hras and cMyc oncogene transfection of MDCK 9B9-1E4 cloned cells. In this study we demonstrate the lack of tumorigenic potential of the MDCK 9B9-1E4 cloned cell line in adult athymic nude mice model.", "label": 1}
{"doc-1": "Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such \"exemplars\" can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called \"affinity propagation,\" which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.", "doc-2": "How to address the challenges of the curse of dimensionality and scalability in clustering simultaneously? In this paper, we propose arbitrarily oriented synchronized clusters (ORSC), a novel effective and efficient method for subspace clustering inspired by synchronization. Synchronization is a basic phenomenon prevalent in nature, capable of controlling even highly complex processes such as opinion formation in a group. Control of complex processes is achieved by simple operations based on interactions between objects. Relying on the weighted interaction model and iterative dynamic clustering, our approach ORSC (a) naturally detects correlation clusters in arbitrarily oriented subspaces, including arbitrarily shaped nonlinear correlation clusters. Our approach is (b) robust against noise and outliers. In contrast to previous methods, ORSC is (c) easy to parameterize, since there is no need to specify the subspace dimensionality or other difficult parameters. Instead, all interesting subspaces are detected in a fully automatic way. Finally, (d) ORSC outperforms most comparison methods in terms of runtime efficiency and is highly scalable to large and high-dimensional data sets. Extensive experiments have demonstrated the effectiveness and efficiency of our approach.", "label": 1}
{"doc-1": "In this paper, we present a family of adaptive protocols, called SPIN (Sensor Protocols for Information via Negotiation), that efficiently disseminates information among sensors in an energy-constrained wireless sensor network. Nodes running a SPIN communication protocol name their data using high-level data descriptors, called meta-data. They use meta-data negotiations to eliminate the transmission of redundant data throughout the network. In addition, SPIN nodes can base their communication decisions both upon application-specific knowledge of the data and upon knowledge of the resources that are available to them. This allows the sensors to efficiently distribute data given a limited energy supply. We simulate and analyze the performance of two specific SPIN protocols, comparing them to other possible approaches and a theoretically optimal protocol. We find that the SPIN protocols can deliver 60% more data for a given amount of energy than conventional approaches. We also find that, in terms of dissemination rate and energy usage, the SPlN protocols perform close to the theoretical optimum.", "doc-2": "The research contents of the VANET simulating involve in computer, traffic engineering, statistics, psychology, etc., presenting a multidisciplinary tendency. Started from the researching significance and contents of the VANET simulation, this paper introduced the development history and research status of VANET simulation, classified the VANET simulators, introduced and compared typical VANET simulators.", "label": 1}
{"doc-1": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.", "doc-2": "Autonomic communications seek to improve the ability of network and services to cope with unpredicted change, including changes in topology, load, task, the physical and logical characteristics of the networks that can be accessed, and so forth. Broad-ranging autonomic solutions require designers to account for a range of end-to-end issues affecting programming models, network and contextual modeling and reasoning, decentralised algorithms, trust acquisition and maintenance---issues whose solutions may draw on approaches and results from a surprisingly broad range of disciplines. We survey the current state of autonomic communications research and identify significant emerging trends and techniques.", "label": 1}
{"doc-1": "In this paper we report exploratory analyses of high-density oligonucleotide array data from the Affymetrix GeneChip system with the objective of improving upon currently used measures of gene expression. Our analyses make use of three data sets: a small experimental study consisting of five MGU74A mouse GeneChip arrays, part of the data from an extensive spike-in study conducted by Gene Logic and Wyeth's Genetics Institute involving 95 HG-U95A human GeneChip arrays; and part of a dilution study conducted by Gene Logic involving 75 HG-U95A GeneChip arrays. We display some familiar features of the perfect match and mismatch probe (PM and MM) values of these data, and examine the variance-mean relationship with probe-level data from probes believed to be defective, and so delivering noise only. We explain why we need to normalize the arrays to one another using probe level intensities. We then examine the behavior of the PM and MM using spike-in data and assess three commonly used summary measures: Affymetrix's (i) average difference (AvDiff) and (ii) MAS 5.0 signal, and (iii) the Li and Wong multiplicative model-based expression index (MBEI). The exploratory data analyses of the probe level data motivate a new summary measure that is a robust multi-array average (RMA) of background-adjusted, normalized, and log-transformed PM values. We evaluate the four expression summary measures using the dilution study data, assessing their behavior in terms of bias, variance and (for MBEI and RMA) model fit. Finally, we evaluate the algorithms in terms of their ability to detect known levels of differential expression using the spike-in data. We conclude that there is no obvious downside to using RMA and attaching a standard error (SE) to this quantity using a linear model which removes probe-specific affinities.", "doc-2": "BACKGROUNDNumerous germline genetic variants are associated with prostate cancer risk, but their biologic role is not well understood. One possibility is that these variants influence gene expression in prostate tissue. We therefore examined the association of prostate cancer risk variants with the expression of genes nearby and genome-wide.METHODSWe generated mRNA expression data for 20,254 genes with the Affymetrix GeneChip Human Gene 1.0 ST microarray from normal prostate (N = 160) and prostate tumor (N = 264) tissue from participants of the Physicians' Health Study and Health Professionals Follow-up Study. With linear models, we tested the association of 39 risk variants with nearby genes and all genes, and the association of each variant with canonical pathways using a global test.RESULTSIn addition to confirming previously reported associations, we detected several new significant (P < 0.05) associations of variants with the expression of nearby genes including C2orf43, ITGA6, MLPH, CHMP2B, BMPR1B, and MTL5. Genome-wide, five genes (MSMB, NUDT11, RBPMS2, NEFM, and KLHL33) were significantly associated after accounting for multiple comparisons for each SNP (P < 2.5  10(-6)). Many more genes had an FDR <10%, including SRD5A1 and PSCA, and we observed significant associations with pathways in tumor tissue.CONCLUSIONSThe risk variants were associated with several genes, including promising prostate cancer candidates and lipid metabolism pathways, suggesting mechanisms for their impact on disease. These genes should be further explored in biologic and epidemiologic studies.IMPACTDetermining the biologic role of these variants can lead to improved understanding of prostate cancer etiology and identify new targets for chemoprevention.", "label": 1}
{"doc-1": "SummaryWe present here some new families of non conforming finite elements in 3. These two families of finite elements, built on tetrahedrons or on cubes are respectively conforming in the spacesH(curl) andH(div). We give some applications of these elements for the approximation of Maxwell's equations and equations of elasticity.", "doc-2": "Abstract In recent years there have been tremendous advances in the theoretical understanding of boundary integral equations for Maxwell problems. In particular, stable dual pairings of discretisation spaces have been developed that allow robust formulations of the preconditioned electric field, magnetic field and combined field integral equations. Within the BEM++ boundary element library we have developed implementations of these frameworks that allow an intuitive formulation of the typical Maxwell boundary integral formulations within a few lines of code. The basis for these developments is an efficient and robust implementation of Calderon identities together with a product algebra that hides and automates most technicalities involved in assembling Galerkin boundary integral equations. In this paper we demonstrate this framework and use it to derive very simple and robust software formulations of the standard preconditioned electric field, magnetic field and regularised combined field integral equations for Maxwell.", "label": 1}
{"doc-1": "Introduction to the Logistic Regression Model Multiple Logistic Regression Interpretation of the Fitted Logistic Regression Model Model-Building Strategies and Methods for Logistic Regression Assessing the Fit of the Model Application of Logistic Regression with Different Sampling Models Logistic Regression for Matched Case-Control Studies Special Topics References Index.", "doc-2": "The aim of this study was to estimate the prevalence of dental and gingival pain and associated factors among Brazilian adolescents (15-19 years of age). Data from 16,126 adolescents who participated in the Brazilian Oral Health Survey SB-Brazil 2002-2003 were used. The outcome measured was dental and gingival pain in the last six months. Independent variables were per capita income, schooling, school enrollment, gender, skin color, age, area of residence, time since last dental appointment, type of dental service, DMFT index and its components, dental calculus, and Dental Aesthetic Index. Simple and multiple Poisson regression analyses were performed. Prevalence of dental and gingival pain was 35.6% (95%CI: 34.8-36.4). Increased prevalence of pain was associated with: female gender, low income, non-students, students enrolled in public schools, and grade-for-age lag. In addition, adolescents with high levels of dental caries and dental calculus also reported higher prevalence of dental pain. Dental and gingival pain can be considered a relevant public health problem, suggesting the need for preventive measures.", "label": 1}
{"doc-1": "A new method of total RNA isolation by a single extraction with an acid guanidinium thiocyanate-phenol-chloroform mixture is described. The method provides a pure preparation of undegraded RNA in high yield and can be completed within 4 h. It is particularly useful for processing large numbers of samples and for isolation of RNA from minute quantities of cells or tissue samples.", "doc-2": "The hypersensitive response (HR) is a powerful resistance system that plants have developed against pathogen attack. There are two major pathways for HR induction; one is through recognition of the pathogen by a specific host protein, and is known as the host HR. The other is through common biochemical changes upon infectionthe nonhost HR. We previously demonstrated that hydrogen peroxide derived from polyamine degradation by polyamine oxidase triggers the typical host HR in tobacco plants upon infection with tobacco mosaic virus. However, it remains to be determined whether or not polyamines are involved in the nonhost HR in tobacco, and in the host HR in other plant species. When tobacco plants were infected with Pseudomonas cichorii, a representative nonhost pathogen, transcripts for six genes encoding enzymes for polyamine metabolism were simultaneously induced, and polyamines were accumulated in apoplasts. Hydrogen peroxide was concomitantly produced and hypersensitive cell death occurred at infected sites. Silencing of polyamine oxidase by the virus-induced gene silencing method resulted in suppression of hydrogen peroxide production and in disappearance of visible hypersensitive cell death with an increase in bacterial growth. Our results indicated that polyamines served as the source of hydrogen peroxide during the nonhost HR in tobacco plants. Further analysis revealed that polyamines were accumulated in apoplasts of Arabidopsis thaliana infected with Pseudomonas syringae, and of rice infected with Magnaporthe grisea, both causing the typical host HR. As in tobacco, it is conceivable that the same mechanism operates for nonhost HR in these plants. Our present observations thus suggested that polyamines are commonly utilized as the source of hydrogen peroxide during host- and nonhost HRs in higher plants.", "label": 1}
{"doc-1": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet.", "doc-2": "We propose an algorithm for coreference resolution based on analogy with shift-reduce parsing. By reconceptualising the task in this way, we unite ranking- and cluster-based approaches to coreference resolution, which have until now been largely orthogonal. Additionally, our framework naturally lends itself to rich discourse modelling, which we use to define a series of psycholinguistically motivated features. We achieve CoNLL scores of 63.33 and 62.91 on the CoNLL-2012 DEV and TEST splits of the OntoNotes 5 corpus, beating the publicly available state of the art systems. These results are also competitive with the best reported research systems despite our system having low memory requirements and a simpler model.", "label": 1}
{"doc-1": "The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.", "doc-2": "BackgroundIn sequence analysis the multiple alignment builds the fundament of all proceeding analyses. Errors in an alignment could strongly influence all succeeding analyses and therefore could lead to wrong predictions. Hand-crafted and hand-improved alignments are necessary and meanwhile good common practice. For RNA sequences often the primary sequence as well as a secondary structure consensus is well known, e.g., the cloverleaf structure of the t-RNA. Recently, some alignment editors are proposed that are able to include and model both kinds of information. However, with the advent of a large amount of reliable RNA sequences together with their solved secondary structures (available from e.g. the ITS2 Database), we are faced with the problem to handle sequences and their associated secondary structures synchronously.Results4SALE fills this gap. The application allows a fast sequence and synchronous secondary structure alignment for large data sets and for the first time synchronous manual editing of aligned sequences and their secondary structures. This study describes an algorithm for the synchronous alignment of sequences and their associated secondary structures as well as the main features of 4SALE used for further analyses and editing. 4SALE builds an optimal and unique starting point for every RNA sequence and structure analysis.Conclusion4SALE, which provides an user-friendly and intuitive interface, is a comprehensive toolbox for RNA analysis based on sequence and secondary structure information. The program connects sequence and structure databases like the ITS2 Database to phylogeny programs as for example the CBCAnalyzer. 4SALE is written in JAVA and therefore platform independent. The software is freely available and distributed from the website at http://4sale.bioapps.biozentrum.uni-wuerzburg.de", "label": 1}
{"doc-1": "A mathematical tool to build a fuzzy model of a system where fuzzy implications and reasoning are used is presented. The premise of an implication is the description of fuzzy subspace of inputs and its consequence is a linear input-output relation. The method of identification of a system using its input-output data is then shown. Two applications of the method to industrial processes are also discussed: a water cleaning process and a converter in a steel-making process.", "doc-2": "Stability issues for switched systems whose subsystems are all fuzzy systems, either continuous-time or discrete-time, are studied and new results derived. Innovated representation models for switched fuzzy systems are proposed. The single Lyapunov function method has been adopted to study the stability of this class of switched fuzzy systems. Sufficient conditions for quadratic asymptotic stability are presented and stabilizing switching laws of the state-dependent form are designed. The elaborated illustrative examples and the respective simulation experiments demonstrate the effectiveness of the proposed method", "label": 1}
{"doc-1": "OBJECTIVEWhile considerable attention has focused on improving the detection of depression, assessment of severity is also important in guiding treatment decisions. Therefore, we examined the validity of a brief, new measure of depression severity.MEASUREMENTSThe Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-9 is the depression module, which scores each of the 9 DSM-IV criteria as \"0\" (not at all) to \"3\" (nearly every day). The PHQ-9 was completed by 6,000 patients in 8 primary care clinics and 7 obstetrics-gynecology clinics. Construct validity was assessed using the 20-item Short-Form General Health Survey, self-reported sick days and clinic visits, and symptom-related difficulty. Criterion validity was assessed against an independent structured mental health professional (MHP) interview in a sample of 580 patients.RESULTSAs PHQ-9 depression severity increased, there was a substantial decrease in functional status on all 6 SF-20 subscales. Also, symptom-related difficulty, sick days, and health care utilization increased. Using the MHP reinterview as the criterion standard, a PHQ-9 score > or =10 had a sensitivity of 88% and a specificity of 88% for major depression. PHQ-9 scores of 5, 10, 15, and 20 represented mild, moderate, moderately severe, and severe depression, respectively. Results were similar in the primary care and obstetrics-gynecology samples.CONCLUSIONIn addition to making criteria-based diagnoses of depressive disorders, the PHQ-9 is also a reliable and valid measure of depression severity. These characteristics plus its brevity make the PHQ-9 a useful clinical and research tool.", "doc-2": "BACKGROUNDDespite stress being considered a key factor in the pathophysiology of the functional gastrointestinal (GI) disorder irritable bowel syndrome (IBS), there is a paucity of information regarding the ability of IBS patients to respond to acute experimental stress. Insights into the stress response in IBS could open the way to novel therapeutic interventions. To this end, we assessed the response of a range of physiological and psychological parameters to the Trier Social Stress Test (TSST) in IBS.METHODThirteen female patients with IBS and 15 healthy female age-matched control participants underwent a single exposure to the TSST. Salivary cortisol, salivary C-reactive protein (CRP), skin conductance level (SCL), GI symptoms, mood and self-reported stress were measured pre- and post-exposure to the TSST.RESULTSThe hypothalamic-pituitary-adrenal (HPA) axis response to the TSST was sustained in IBS, as shown by a greater total cortisol output throughout (p = 0.035) and higher cortisol levels measured by an area under the curve with respect to ground (AUCG) analysis (p = 0.044). In IBS patients, GI symptoms increased significantly during the recovery period following exposure to the TSST (p = 0.045). Salivary CRP and SCL activity showed significant changes in relation to stress but with no differential effect between experimental groups.CONCLUSIONSPatients with IBS exhibit sustained HPA axis activity, and an increase in problematic GI symptoms in response to acute experimental psychosocial stress. These data pave the way for future interventional studies aimed at identifying novel therapeutic approaches to modulate the HPA axis and GI symptom response to acute psychosocial stress in IBS.", "label": 1}
{"doc-1": "The green fluorescent protein (GFP) is responsible for the green bioluminescence of the jellyfish Aequorea victoria. Many classes of GFP mutants exist that display modified fluorescence spectra and an increased extinction coefficient. We produced transgenic mouse lines with an 'enhanced' GFP (EGFP) cDNA under the control of a chicken beta-actin promoter and cytomegalovirus enhancer. All of the tissues from these transgenic lines, with the exception of erythrocytes and hair, were green under excitation light. The fluorescent nature of the cells from these transgenic mouse lines would facilitate their use in many kinds of cell transplantation experiments.", "doc-2": "Musculoskeletal tissues regeneration requires rapid expansion of seeding cells both in vitro and in vivo while maintaining their multilineage differentiation ability. Human adipose-derived stem cells (ASCs) are considered to contain multipotent mesenchymal stem cells. Monolayer cultures of human ASCs were isolated from human lipoaspirates and passaged 3 times and then infected with replication-incompetent adenoviral vectors carrying green fluorescent protein (Ad/GFP) genes. Then, Ad/GFP infected human ASCs were transferred to osteogenic, chondrogenic, adipogenic, and myogenic medium. The morphological characterization of induced cells was observed using phase-contrast microscopy and fluorescence microscopy. The expression of marker proteins or genes was measured by immunocytochemical and RT-PCR analysis. Osteopontin (OPN), and osteocalcin (OCN) were positive in osteogenic lineages, aggrecan and SOX9 were positive in chondrogenic ones, peroxisome proliferator-activated receptor (PPAR-2) and lipoprotein lipase (LPL) were positive in adipogenic ones, and myogenin and myod1 was positive in myogenic ones. At the same time, the results of fluorescence microscopic imaging proved that the high level of GFP expression during ASCs differentiation maintained stable nearly 2 months. So the exogenous GFP and multilineage potential of human ASCs had no severe influences on each other. Since the human ASCs can be easily obtained and abundant, it is proposed that they may be promising candidate cells for further studies on tissue engineering. Imaging with expression of GFP facilitates the research on ASCs physiological behavior and application in tissue engineering during differentiation both in vitro and in vivo.", "label": 1}
{"doc-1": "Information theory research has shown that the rich-scattering wireless channel is capable of enormous theoretical capacities if the multipath is properly exploited. In this paper, we describe a wireless communication architecture known as vertical BLAST (Bell Laboratories Layered Space-Time) or V-BLAST, which has been implemented in real-time in the laboratory. Using our laboratory prototype, we have demonstrated spectral efficiencies of 20-40 bps/Hz in an indoor propagation environment at realistic SNRs and error rates. To the best of our knowledge, wireless spectral efficiencies of this magnitude are unprecedented and are furthermore unattainable using traditional techniques.", "doc-2": "Orthogonal frequency division multiplexing( OFDM ) is a multi-carrier modulation scheme, which may be combined with antenna arrays at the transmitter and receiver to increase the diversity gain and/or to enhance the system capacity on time-variant and frequency-selective channels, resulting in a multiple-input multiple-output (MIMO) configuration .This paper presents an overview of the OFDM-MIMO wireless technology covering channel models, performance limits and trans-receiver system .The significance of OFDM lies in its inherent capability to reduce inter-symbol interference(ISI) using cyclic prefix. Using simulations, the OFDM signal has been generated with the help of mathematical transforms namely the Fourier transform. The comparison of bit error rate (BER) and signal to noise ratio (SNR) for various modulation schemes has been performed and the best one is selected for transmission. Also the comparison of BER and SNR for Single Input Single Output (SISO), Single Input Multiple Output (SIMO) and Multiple Input Multiple Output (MIMO) is graphically observed. And with MIMO proving to be the best, the effect on capacity is observed for increased number of antennas.For MIMO systems, Vertical Bell Labs Space Time Algorithm (V-BLAST) is an ordered successive cancellation method applied to receiver and at every stage the stream with the highest SNR is decoded.This paper also presents an overview of the V-BLAST architechture.", "label": 1}
{"doc-1": "Boken presenterer en helhetlig strategi for hvordan myndigheter, helsepersonell, industri og forbrukere kan redusere medisinske feil.", "doc-2": "BACKGROUNDComputer-based clinical decision support systems (CDSSs) vary greatly in design and function. A taxonomy for classifying CDSS structure and function would help efforts to describe and understand the variety of CDSSs in the literature, and to explore predictors of CDSS effectiveness and generalizability.OBJECTIVETo define and test a taxonomy for characterizing the contextual, technical, and workflow features of CDSSs.METHODSWe retrieved and analyzed 150 English language articles published between 1975 and 2002 that described computer systems designed to assist physicians and/or patients with clinical decision making. We identified aspects of CDSS structure or function and iterated our taxonomy until additional article reviews did not result in any new descriptors or taxonomic modifications.RESULTSOur taxonomy comprises 95 descriptors along 24 descriptive axes. These axes are in 5 categories: Context, Knowledge and Data Source, Decision Support, Information Delivery, and Workflow. The axes had an average of 3.96 coded choices each. 75% of the descriptors had an inter-rater agreement kappa of greater than 0.6.CONCLUSIONSWe have defined and tested a comprehensive, multi-faceted taxonomy of CDSSs that shows promising reliability for classifying CDSSs reported in the literature.", "label": 1}
{"doc-1": "The adipose-derived hormone resistin is postulated to link obesity to insulin resistance and diabetes. Here, the infusion of either resistin or the resistin-like molecule-beta (RELMbeta) rapidly induced severe hepatic but not peripheral insulin resistance. In the presence of physiologic hyperinsulinemia, the infusion of purified recombinant resistin, increasing circulating resistin levels by approximately twofold to 15-fold, inhibited glucose metabolism such that lower rates of glucose infusion were required to maintain the plasma glucose concentration at basal levels. The effects of resistin and RELMbeta on in vivo insulin action were completely accounted for by a marked increase in the rate of glucose production. These results support the notion that a novel family of fat- and gut-derived circulating proteins modulates hepatic insulin action.", "doc-2": "PurposeThis review aimed to discuss the conflicting findings from resistin research in rodents and humans as well as recent advances in our understanding of resistins role in obesity and insulin resistance.MethodsA comprehensive review and synthesis of resistins role in obesity and insulin resistance as well as conflicting findings from resistin research in rodents and humans.ResultsIn rodents, resistin is increased in high-fat/high-carbohydrate-fed, obese states characterized by impaired glucose uptake and insulin sensitivity. Resistin plays a causative role in the development of insulin resistance in rodents via 5 AMP-activated protein kinase (AMPK)-dependent and AMPK-independent suppressor of cytokine signaling-3 (SOCS-3) signaling. In contrast to rodents, human resistin is primarily secreted by peripheral-blood mononuclear cells (PBMCs) as opposed to white adipocytes. Circulating resistin levels have been positively associated with central/visceral obesity (but not BMI) as well as insulin resistance, while other studies show no such association. Human resistin has a role in pro-inflammatory processes that have been conclusively associated with obesity and insulin resistance. PBMCs, as well as vascular cells, have been identified as the primary targets of resistins pro-inflammatory activity via nuclear factor-B (NF-B, p50/p65) and other signaling pathways.ConclusionMounting evidence reveals a continuing disconnect between resistins role in rodents and humans due to significant differences between these two species with respect to resistins gene and protein structure, differential gene regulation, tissue-specific distribution, and insulin resistance induction as well as a paucity of evidence regarding the resistin receptor and downstream signaling mechanisms of action.", "label": 1}
{"doc-1": "BACKGROUNDThe 7-item Generalized Anxiety Disorder Scale (GAD-7) is a practical self-report anxiety questionnaire that proved valid in primary care. However, the GAD-7 was not yet validated in the general population and thus far, normative data are not available.OBJECTIVESTo investigate reliability, construct validity, and factorial validity of the GAD-7 in the general population and to generate normative data.RESEARCH DESIGNNationally representative face-to-face household survey conducted in Germany between May 5 and June 8, 2006.SUBJECTSFive thousand thirty subjects (53.6% female) with a mean age (SD) of 48.4 (18.0) years.MEASURESThe survey questionnaire included the GAD-7, the 2-item depression module from the Patient Health Questionnaire (PHQ-2), the Rosenberg Self-Esteem Scale, and demographic characteristics.RESULTSConfirmatory factor analyses substantiated the 1-dimensional structure of the GAD-7 and its factorial invariance for gender and age. Internal consistency was identical across all subgroups (alpha = 0.89). Intercorrelations with the PHQ-2 and the Rosenberg Self-Esteem Scale were r = 0.64 (P < 0.001) and r = -0.43 (P < 0.001), respectively. As expected, women had significantly higher mean (SD) GAD-7 anxiety scores compared with men [3.2 (3.5) vs. 2.7 (3.2); P < 0.001]. Normative data for the GAD-7 were generated for both genders and different age levels. Approximately 5% of subjects had GAD-7 scores of 10 or greater, and 1% had GAD-7 scores of 15 or greater.CONCLUSIONSEvidence supports reliability and validity of the GAD-7 as a measure of anxiety in the general population. The normative data provided in this study can be used to compare a subject's GAD-7 score with those determined from a general population reference group.", "doc-2": "We evaluated the usefulness of case-finding instruments for identifying patients with major depression or dysthymia in primary care settings using English language literature from Medline, a specialized trials registry and bibliographies of selected papers. Studies were done in primary care settings with unselected patients and compared case-finding instruments with accepted diagnostic criterion standards for major depression were selected. A total of 16 case-finding instruments were assessed in 38 studies. More than 32,000 patients received screening with a case-finding instrument; approximately 12,900 of these received criterion standard assessment. Case-finding instruments ranged in length from 1 to 30 questions. Average administration times ranged from less than 2 min to 6 min. Median sensitivity for major depression was 85% (range 50% to 97%); median specificity was 74% (range 51% to 98%). No significant differences between instruments were found. However for individual instruments, estimates of sensitivity and specificity varied significantly between studies. For the combined diagnoses of major depression or dysthymia, overall sensitivity was 79% (CI, 74% to 83%) and overall specificity 75% (CI, 70% to 81%). Stratified analyses showed no significant effects on overall instrument performance for study methodology, criterion standard choice, or patient characteristics. We found that multiple instruments with reasonable operating characteristics are available to help primary care clinicians identify patients with major depression. Because operating characteristics of these instruments are similar, selection of a particular instrument should depend on issues such as feasibility, administration and scoring times, and the instruments' ability to serve additional purposes, such as monitoring severity or response to therapy.", "label": 1}
{"doc-1": "Discusses the notion that the ability to exploit external knowledge is crucial to a firm's innovative capabilities. In addition, it is argued that the ability to evaluate and use outside knowledge is largely a function of the level of prior related knowledge--i.e., absorptive capacity. Prior research has shown that firms that conduct their own research and development (R&D) are better able to use information from external sources. Therefore, it is possible that the absorptive capacity of a firm is created as a byproduct of the firm's R&D investment. A simple model of firm R&D intensity is constructed in a broader context of what applied economists call the three classes of industry-level determinants of R&D intensity: demand, appropriability, and technological opportunity conditions. Several predictions are made, including the notions that absorptive capacity does have a direct effect on R&D spending and spillovers will provide a positive incentive to conduct R&D. All hypotheses are tested using cross-sectional survey data on technological opportunity and appropriability conditions--collected over the period 1975 to 1977 for 1,719 business units--in the American manufacturing sector from Levin et al. (1983, 1987) and the Federal Trade Commission's Line of Business Program data on business unit sales, transfers, and R&D expenditures. Results confirm that firms are sensitive to the characteristics of the learning environment in which they operate and that absorptive capacity does appear to be a part of a firm's decisions regarding resource allocation for innovative activity. Results also suggest that, although the analysis showing a positive effect of spillovers in two industry groups do not represent a direct test of the model, positive absorption incentive associated with spillovers may be sufficiently strong in some cases to more than offset the negative appropribility incentive. (SFL)", "doc-2": "This paper focuses on the issues of effective prevalence of different knowledge management (KM) processes/practices in organizations. An effective knowledge management program largely depends on organizational members willingness and ability to participate in knowledge creation, knowledge sharing, knowledge acquisition, and knowledge codification activities. This paper theoretically conceptualizes the role of organizational vision and adaptability in developing employees willingness and ability to effectively participate in different knowledge management activities. A dearth of studies has, so far, exclusively investigated the joint impact of organizational vision and adaptability on four key knowledge management processes/practices. Paper begins with a theoretical analysis of different aspects of knowledge management and issues related to the effective prevalence of different KM processes in organization. It then includes organizations vision and adaptability to conceptualize their link with different knowledge management processes. Finally, based on the extensive review of the literature related to knowledge management, organizations vision, and adaptability, a conceptual understanding is developed and proposed impact of organizational vision and adaptability on employees willingness and ability to effectively participate in different KM processes is presented. This paper may contribute to the existing body of knowledge by creating new insights for researchers as well as practitioners to help their organizations strengthening their knowledge management initiatives by building strong organizational vision and employees adaptive behaviors. It will also be an opportunity for empiricist to empirically validate the proposed relationships between variables of", "label": 1}
{"doc-1": "The cancer stem cell (CSC) hypothesis suggests that neoplastic clones are maintained exclusively by a rare fraction of cells with stem cell properties1,2. Although the existence of CSCs in human leukaemia is established3,4, little evidence exists for CSCs in solid tumours, except for breast cancer5. Recently, we prospectively isolated a CD133+ cell subpopulation from human brain tumours that exhibited stem cell properties in vitro6. However, the true measures of CSCs are their capacity for self renewal and exact recapitulation of the original tumour1,2,7. Here we report the development of a xenograft assay that identified human brain tumour initiating cells that initiate tumours in vivo. Only the CD133+ brain tumour fraction contains cells that are capable of tumour initiation in NOD-SCID (non-obese diabetic, severe combined immunodeficient) mouse brains. Injection of as few as 100 CD133+ cells produced a tumour that could be serially transplanted and was a phenocopy of the patient's original tumour, whereas injection of 105 CD133- cells engrafted but did not cause a tumour. Thus, the identification of brain tumour initiating cells provides insights into human brain tumour pathogenesis, giving strong support for the CSC hypothesis as the basis for many solid tumours5, and establishes a previously unidentified cellular target for more effective cancer therapies.", "doc-2": "Background:Brain tumour stem cells (BTSCs) are a small population of cancer cells that exhibit self-renewal, multi-drug resistance, and recurrence properties. We have shown earlier that peroxisome proliferator-activated receptor gamma (PPAR) agonists inhibit the expansion of BTSCs in T98G and U87MG glioma. In this study, we analysed the influence of PPAR agonists on the expression of stemness and differentiation genes in BTSCs.Methods:The BTSCs were isolated from T98G and DB29 glioma cells, and cultured in neurobasal medium with epidermal growth factor+basic fibroblast growth factor. Proliferation was measured by WST-1 (4-[3-(4-iodophenyl)-2-(4-nitrophenyl)-2H-5-tetrazolio]-1,3-benzene disulphonate) and 3H thymidine uptake assays, and gene expression was analysed by quantitative reverse--transcription PCR and Taqman array. The expression of CD133, SRY box 2, and nanog homeobox (Nanog) was also evaluated by western blotting, immunostaining, and flow cytometry.Results:We found that PPAR agonists, ciglitazone and 15-deoxy-12,14-ProstaglandinJ2, inhibited cell viability and proliferation of T98G- and DB29-BTSCs. The PPAR agonists reduced the expansion of CD133+ BTSCs and altered the expression of stemness and differentiation genes. They also inhibited Sox2 while enhancing Nanog expression in BTSCs.Conclusion:These findings highlight that PPAR agonists inhibit BTSC proliferation in association with altered expression of Sox2, Nanog, and other stemness genes. Therefore, targeting stemness genes in BTSCs could be a novel strategy in the treatment of glioblastoma.", "label": 1}
{"doc-1": "Research dealing with various aspects of* the theory of planned behavior (Ajzen, 1985, 1987) is reviewed, and some unresolved issues are discussed. In broad terms, the theory is found to be well supported by empirical evidence. Intentions to perform behaviors of different kinds can be predicted with high accuracy from attitudes toward the behavior, subjective norms, and perceived behavioral control; and these intentions, together with perceptions of behavioral control, account for considerable variance in actual behavior. Attitudes, subjective norms, and perceived behavioral control are shown to be related to appropriate sets of salient behavioral, normative, and control beliefs about the behavior, but the exact nature of these relations is still uncertain. Expectancy value formulations are found to be only partly successful in dealing with these relations. Optimal rescaling of expectancy and value measures is offered as a means of dealing with measurement limitations. Finally, inclusion of past behavior in the prediction equation is shown to provide a means of testing the theory*s sufficiency, another issue that remains unresolved. The limited available evidence concerning this question shows that the theory is predicting behavior quite well in comparison to the ceiling imposed by behavioral reliability.  1991 Academic Press. Inc.", "doc-2": "The purpose of the present study was to explore the role of an extended version of the theory of planned behaviour (TPB) in predicting intentions to quit smoking among Norwegian smoking students (N=211) and Spanish students (N=205). As hypothesised, subjective norm predicted quitting intentions more strongly in Spain (a collectivistic culture) than in Norway (an individualistic culture). Group identity predicted quitting intentions more strongly in Norway than in Spain. Consistent with the predictions the predictive role of self-identity and moral norm did not differ between the countries. Self-identity did not predict intention significantly, while this was the case for moral norm. Thus the study provided evidence of the moderating role of culture in the TPB, and indications of a stronger conflict between smokers and non-smokers in countries with high level of regulatory anti-smoking measures.", "label": 1}
{"doc-1": "Genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. Knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. The goal of the Gene Ontology Consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. To this end, three independent ontologies accessible on the World-Wide Web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component.", "doc-2": "Metazoan species, from sponges to insects and mammals, possess successful defence systems against their pathogens and parasites. The evolutionary origins of these diverse systems are beginning to be more comprehensively investigated and mapped out. We have collected 1811 metazoan immunity genes from literature and gene ontology annotations. Tentative orthologs of these genes were identified using reciprocal protein-protein Blast searches against proteins from the GenBank and RefSeq databases. We have defined different levels or classes of ortholog group according to the order of reciprocal ortholog pairs among the seed immunity genes. The genes were clustered into these different ortholog groups. Initial phylogenetic analysis of these ortholog groups suggests that by this approach, we can collect a spectrum of immunity genes representing well the taxa in which they appear. All the immunity genes and their evidence of immune function, orthologs and ortholog groups have been combined into an open access database -- ImmunomeBase, which is publicly available from (http://bioinf.uta.fi/ImmunomeBase).", "label": 1}
{"doc-1": "The complete sequence of the 16,569-base pair human mitochondrial genome is presented. The genes for the 12S and 16S rRNAs, 22 tRNAs, cytochrome c oxidase subunits I, II and III, ATPase subunit 6, cytochrome b and eight other predicted protein coding genes have been located. The sequence shows extreme economy in that the genes have none or only a few noncoding bases between them, and in many cases the termination codons are not coded in the DNA but are created post-transcriptionally by polyadenylation of the mRNAs.", "doc-2": "The genomes of mammalian mitochondria encode 13 hydrophobic membrane proteins. All of them are subunits of the respiratory complexes found in the inner membranes of the organelle. Although the sequences of human and bovine mitochondrial DNA were described in 1981 and 1982, respectively, and the encoded proteins were identified at the same time or soon after, because of their hydrophobic properties, the chemical compositions of some of these proteins have never been characterized. Therefore, we have developed procedures to extract them with organic solvents from the inner membranes of bovine mitochondria and from purified respiratory complexes and to fractionate the extracts, allowing the precise molecular masses of all 13 proteins to be measured by electrospray ionization mass spectrometry. It was found that, with one exception, the proteins retain their translational initiator formyl-methionine residues, and the only posttranslational modification detected was the removal of the formyl group or the formyl-methionine from the Cox III protein. These procedures can be adapted for analyzing the proteins encoded in mitochondrial DNAs in other species, for analyzing the subunit compositions of their respiratory complexes, and for establishing accurate and comprehensive proteomes of other cellular membranes. Because many membrane proteins have few proteolytic enzyme cleavage sites, identifying them by mass spectrometric sequencing of proteolytic peptides can be difficult. Therefore, we have studied the tandem mass spectra of fragment ions from a range of membrane proteins from mitochondria, including 10 of the 13 proteins encoded in mitochondrial DNA. In contrast to the highly complex spectra produced in this way by globular proteins, the spectra of membrane proteins are simple and easy to interpret, and so they provide sequence tags for the identification of membrane proteins.", "label": 1}
{"doc-1": "Newborn mice homozygous for a targeted disruption of insulin-like growth factor gene (Igf-1) exhibit a growth deficiency similar in severity to that previously observed in viable Igf-2 null mutants (60% of normal birthweight). Depending on genetic background, some of the Igf-1(-/-) dwarfs die shortly after birth, while others survive and reach adulthood. In contrast, null mutants for the Igf1r gene die invariably at birth of respiratory failure and exhibit a more severe growth deficiency (45% normal size). In addition to generalized organ hypoplasia in Igf1r(-/-) embryos, including the muscles, and developmental delays in ossification, deviations from normalcy were observed in the central nervous system and epidermis. Igf-1(-/-)/Igf1r(-/-) double mutants did not differ in phenotype from Igf1r(-/-) single mutants, while in Igf-2(-)/Igf1r(-/-) and Igf-1(-/-)/Igf-2(-) double mutants, which are phenotypically identical, the dwarfism was further exacerbated (30% normal size). The roles of the IGFs in mouse embryonic development, as revealed from the phenotypic differences between these mutants, are discussed.", "doc-2": "Previous studies of the GH-IGF system gene expression in growth plate using immunohistochemistry and in situ hybridization have yielded conflicting results. We therefore studied the spatial and temporal patterns of mRNA expression of the GH-IGF system in the rat proximal tibial growth plate quantitatively. Growth plates were microdissected into individual zones. RNA was extracted, reverse transcribed and analyzed by real-time PCR. In 1-week-old animals, IGF-I mRNA expression was minimal in growth plate compared with perichondrium, metaphyseal bone, muscle, and liver (70-, 130-, 215-, and 400-fold less). In contrast, IGF-II mRNA was expressed at higher levels than in bone and liver (65- and 2-fold). IGF-II expression was higher in the proliferative and resting zones compared with the hypertrophic zone (P < 0.001). GH receptor and type 1 and 2 IGF receptors were expressed throughout the growth plate. Expression of IGF-binding proteins (IGFBPs)-1 through -6 mRNA was low throughout the growth plate compared with perichondrium and bone. With increasing age (3-, 6-, 9-, and 12-week castrated rats), IGF-I mRNA levels increased in the proliferative zone (PZ) but remained at least tenfold lower than levels in perichondrium and bone. IGF-II mRNA decreased dramatically in PZ (780-fold; P < 0.001) whereas, type 2 IGF receptor and IGFBP-1, IGFBP-2, IGFBP-3, and IGFBP-4 increased significantly with age in growth plate and/or surrounding perichondrium and bone. These data suggest that IGF-I protein in the growth plate is not produced primarily by the chondrocytes themselves. Instead, it derives from surrounding perichondrium and bone. In addition, the decrease in growth velocity that occurs with age may be caused, in part, by decreasing expression of IGF-II and increasing expression of type 2 IGF receptor and multiple IGFBPs.", "label": 1}
{"doc-1": "UNLABELLEDRAxML-VI-HPC (randomized axelerated maximum likelihood for high performance computing) is a sequential and parallel program for inference of large phylogenies with maximum likelihood (ML). Low-level technical optimizations, a modification of the search algorithm, and the use of the GTR+CAT approximation as replacement for GTR+Gamma yield a program that is between 2.7 and 52 times faster than the previous version of RAxML. A large-scale performance comparison with GARLI, PHYML, IQPNNI and MrBayes on real data containing 1000 up to 6722 taxa shows that RAxML requires at least 5.6 times less main memory and yields better trees in similar times than the best competing program (GARLI) on datasets up to 2500 taxa. On datasets > or =4000 taxa it also runs 2-3 times faster than GARLI. RAxML has been parallelized with MPI to conduct parallel multiple bootstraps and inferences on distinct starting trees. The program has been used to compute ML trees on two of the largest alignments to date containing 25,057 (1463 bp) and 2182 (51,089 bp) taxa, respectively.AVAILABILITYicwww.epfl.ch/~stamatak", "doc-2": "Major taxa of Ehretiaceae (including parasitic Lennoaceae) have not all been included in previous molecular phylogenetic analyses. As a result, the generic limits and their circumscriptions have not been satisfactorily resolved, despite its importance for floristic studies. To clarify which monophyletic groups can be recognized within the Ehretiaceae, sequences from one nuclear (ITS) and three plastid loci (rps16, trnL-trnF, trnS-trnG) were obtained from 67 accessions tentatively assigned to the Ehretiaceae (including 91 new GenBank entries) and covering the known diversity of the group. In phylogenetic analyses, Ehretiaceae were monophyletic when Lennoaceae were included and segregated into nine monophyletic lineages that correspond to accepted, morphologically distinct taxonomic units, namely Bourreria (s.l., paraphyletic in its current circumscription if not including Hilsenbergia), monotypic Cortesia, Ehretia (s.l., paraphyletic in its current circumscription if not including Carmona and Rotula), Halgania, monotypic Lennoa, Lepidocordia, Pholisma, Rochefortia, and Tiquilia. Bourreria and Ehretia have representatives in both the Old World and the New World, but all other taxa are restricted to the tropical and subtropical Americas (Cortesia, Lennoa, Lepidocordia, Pholisma, Rochefortia, Tiquilia) or Australia (Halgania). The historical biogeography of Ehretiaceae can be explained by few colonization events. The molecular trees are also discussed with respect to fruit evolution, where the fusion of endocarp parts may have taken place several times independently.", "label": 1}
{"doc-1": "The Internet has a very complex connectivity recently modeled by the class of scale-free networks. This feature, which appears to be very efficient for a communications network, favors at the same time the spreading of computer viruses. We analyze real data from computer virus infections and find the average lifetime and persistence of viral strains on the Internet. We define a dynamical model for the spreading of infections on scale-free networks, finding the absence of an epidemic threshold and its associated critical behavior. This new epidemiological framework rationalizes data of computer viruses and could help in the understanding of other spreading phenomena on communication and social networks.", "doc-2": "A recent research thread focused on Unattended Wireless Sensor Networks (UWSNs), that are characterized by the intermittent presence of the sink. An adversary can take advantage of this behavior trying to erase a piece of information sensed by the network before the sink collects it. Therefore, without a mechanism in place to assure data availability, the sink will not ever know that a datum has been compromised. In this paper, we adopt data replication to assure data survivability in UWSNs. In particular, we revisit an epidemic model and show that, even if the data replication process can be modelled as the spreading of a disease in a finite population, new problems that have not been discovered before arise: optimal parameters choice for the model do not assure the intended data survivability. The problem is complicated by the fact that it is driven by two conflicting parameters: On the one hand the flooding of the datum has to be avoided---due to the sensor resource constraints---, while on the other hand data survivability depends on the data replication rate. Using advanced probabilistic tools we achieve a theoretically sound result that assures at the same time: Data survivability, an optimal usage of sensors resources, and a fast and predictable collecting time. These results have been achieved in both the full visibility and the geometrical model. Finally, extensive simulation results support our findings.", "label": 1}
{"doc-1": "A new approach to rapid sequence comparison, basic local alignment search tool (BLAST), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair (MSP) score. Recent mathematical results on the stochastic properties of MSP scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. The basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straightforward DNA and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long DNA sequences. In addition to its flexibility and tractability to mathematical analysis, BLAST is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity.", "doc-2": "Oil refining industry has used a great amount of catalysts, which once exhausted due to metal and hydrocarbon poisoning are disposed in special confining sites. Catalyst disposal represents a serious environmental problem due to the potential risk of metal leaching by natural events. The necessity to treat great amounts of catalysts and the existence of microorganisms that coexist with metals suggest that microorganisms can be used for the treatment of hazardous wastes such as spent catalysts. The aim of the present study was to isolate microorganisms from rich metal sites, mines, soils and water from rivers close to mines and then evaluate their ability to remove Ni and V from spent catalyst. Twenty-six isolates were obtained from samples using 9K liquid media and from them, only twelve isolates presented a minimum inhibitory concentration (MIC) higher than 200 ppm of Ni and V, then were evaluated for their ability to remove Ni and V in 9K liquid media added with 16% (w/v) pulp density of the catalyst. Results showed that isolates MNSH1-9K-1 and PRGSd-9K-4 had the highest removal for Ni and V corresponding to 149.5 mg Kg and 920.5 mg Kg, respectively and were identified by sequencing of 16S ribosomal RNA gene as Bacillus megaterium and Bacillus subtilis, respectively.", "label": 1}
{"doc-1": "The development of a 10-item self-report scale (EPDS) to screen for Postnatal Depression in the community is described. After extensive pilot interviews a validation study was carried out on 84 mothers using the Research Diagnostic Criteria for depressive illness obtained from Goldberg's Standardised Psychiatric Interview. The EPDS was found to have satisfactory sensitivity and specificity, and was also sensitive to change in the severity of depression over time. The scale can be completed in about 5 minutes and has a simple method of scoring. The use of the EPDS in the secondary prevention of Postnatal Depression is discussed.", "doc-2": "OBJECTIVETo determine demographic, maternal, and child factors associated with socioemotional (SE) problems and chronic stress in 1-year-old children.STUDY DESIGNThis was a prospective, longitudinal, community-based study, which followed mother-infant dyads (n= 1070; representative of race, education, and income status of Memphis/Shelby County, Tennessee) from midgestation into early childhood. Child SE development was measured using the Brief Infant-Toddler Social and Emotional Assessment in all 1097 1-year-olds. Chronic stress was assessed by hair cortisol in a subsample of 1-year-olds (n = 297). Multivariate regression models were developed to predict SE problems and hair cortisol levels.RESULTSMore black mothers than white mothers reported SE problems in their 1-year-olds (32.9% vs 10.2%; P < .001). In multivariate regression, SE problems in blacks were predicted by lower maternal education, greater parenting stress and maternal psychological distress, and higher cyclothymic personality score. In whites, predictors of SE problems were Medicaid insurance, higher maternal depression score at 1 year, greater parenting stress and maternal psychological distress, higher dysthymic personality score, and male sex. SE problem scores were associated with higher hair cortisol levels (P = .01). Blacks had higher hair cortisol levels than whites (P < .001). In the entire subsample, increased hair cortisol levels were associated with higher parenting stress (P = .001), lower maternal depression score (P = .01), lower birth length (P < .001), and greater length at 1 year of age (P = .003).CONCLUSIONDifferences in maternal education, insurance, mental health, and early stress may disrupt SE development in children. Complex relationships between hair cortisol level in 1-year-olds and maternal parenting stress and depression symptoms suggest dysregulation of the child's hypothalamic-pituitary-adrenal axis.", "label": 1}
{"doc-1": "A new family of highly fluorescent indicators has been synthesized for biochemical studies of the physiological role of cytosolic free Ca2+. The compounds combine an 8-coordinate tetracarboxylate chelating site with stilbene chromophores. Incorporation of the ethylenic linkage of the stilbene into a heterocyclic ring enhances the quantum efficiency and photochemical stability of the fluorophore. Compared to their widely used predecessor, \"quin2\", the new dyes offer up to 30-fold brighter fluorescence, major changes in wavelength not just intensity upon Ca2+ binding, slightly lower affinities for Ca2+, slightly longer wavelengths of excitation, and considerably improved selectivity for Ca2+ over other divalent cations. These properties, particularly the wavelength sensitivity to Ca2+, should make these dyes the preferred fluorescent indicators for many intracellular applications, especially in single cells, adherent cell layers, or bulk tissues.", "doc-2": "In addition to the proinflammatory cytokines tumor necrosis factor-, interleukin-6 and interleukin-1, the cytokine interleukin-17 (IL-17) is considered an important mediator of autoimmune diseases such as rheumatoid arthritis. Because tumor necrosis factor- and interleukin-1 have the potential to influence the expression of transduction molecules such as transient receptor potential vanilloid 1 (TRPV1) in dorsal root ganglion (DRG) neurons and thus to contribute to pain we explored in the present study whether IL-17A activates DRG neurons and influences the expression of TRPV1. The IL-17A receptor was visualized in most neurons in dorsal root ganglion (DRG) sections as well as in cultured DRG neurons. Upon long-term exposure to IL-17A, isolated and cultured rat DRG neurons showed a significant upregulation of extracellular-regulated kinase (ERK) and nuclear factor B (NFB). Long-term exposure of neurons to IL-17A did not upregulate the expression of TRPV1. However, we found a pronounced upregulation of transient receptor potential vanilloid 4 (TRPV4) which is considered a candidate transduction molecule for mechanical hyperalgesia. Upon the injection of zymosan into the paw, IL-17A-deficient mice showed less mechanical hyperalgesia than wild type mice but thermal hyperalgesia was not attenuated in IL-17A-deficient mice. These data show, therefore, a particular role of IL-17 in mechanical hyperalgesia, and they suggest that this effect is linked to an activation and upregulation of TRPV4.", "label": 1}
{"doc-1": "AIMWe estimated the number of people worldwide with diabetes for the years 2010 and 2030.METHODSStudies from 91 countries were used to calculate age- and sex-specific diabetes prevalences, which were applied to national population estimates, to determine national diabetes prevalences for all 216 countries for 2010 and 2030. Studies were identified using Medline, and contact with all national and regional International Diabetes Federation offices. Studies were included if diabetes prevalence was assessed using a population-based methodology, and was based on World Health Organization or American Diabetes Association diagnostic criteria for at least three separate age-groups within the 20-79 year range. Self-report or registry data were used if blood glucose assessment was not available.RESULTSThe world prevalence of diabetes among adults (aged 20-79 years) will be 6.4%, affecting 285 million adults, in 2010, and will increase to 7.7%, and 439 million adults by 2030. Between 2010 and 2030, there will be a 69% increase in numbers of adults with diabetes in developing countries and a 20% increase in developed countries.CONCLUSIONThese predictions, based on a larger number of studies than previous estimates, indicate a growing burden of diabetes, particularly in developing countries.", "doc-2": "OBJECTIVEThe goal of the genetic investigation was to identify the associations of serum lipid levels and DPP-4 variants in Chinese type 2 diabetes patients.METHODSWe detected four variants of the DPP4 gene in 190 Chinese individuals with type 2 diabetes and tested for an association with dyslipidemia in 82 selected samples. Data including basic information, HbA1c, FPG, serum lipid parameters were collected. Statistical analysis was performed by SPSS 13.0 through ANOVA and 2 test.RESULTSThe genetic polymorphism of rs4664443, rs3788979, rs7608798 and rs1558957 in Chinese type 2 diabetes were consistent with Hardy-Weinberg equilibrium. The CT genotype of rs4664443 suffered from higher serum TG (P=0.013), LDL (P=0.044) and ApoB (P=0.006) levels, whereas the TT genotype of rs7608798 exhibited a lower serum TG level (P=0.037). For rs3788979, the serum TG level (P=0.034) and BMI (P=0.04) were significantly different among genotypes. Moreover, serum TG and TC levels and BMI showed a positive correlation with the number unfavorable alleles, and individuals with more than two unfavorable alleles had higher TG (P=0.004), TC (P=0.011), and BMI (P=0.044) values.CONCLUSIONSThis is the first study to investigate DPP4 allelic distributions and their association with dyslipidemia in Chinese type 2 diabetes patients, which may have clinical significance.", "label": 1}
{"doc-1": "A stochastic frontier production function is defined for panel data on firms, in which the non-negative technical inefficiency effects are assumed to be a function of firm-specific variables and time. The inefficiency effects are assumed to be independently distributed as truncations of normal distributions with constant variance, but with means which are a linear function of observable variables. This panel data model is an extension of recently proposed models for inefficiency effects in stochastic frontiers for cross-sectional data. An empirical application of the model is obtained using up to ten years of data on paddy farmers from an Indian village. The null hypotheses, that the inefficiency effects are not stochastic or do not depend on the farmer-specific variables and time of observation, are rejected for these data.", "doc-2": "BackgroundOur aim was to explore the technical efficiency (TE) of the Iranian rural primary healthcare (PHC) system for diabetes treatment coverage rate using the stochastic frontier analysis (SFA) as well as to examine the strength and significance of the effect of human resources density on diabetes treatment.MethodsIn the SFA model diabetes treatment coverage rate, as a output, is a function of health system inputs (Behvarz worker density, physician density, and rural health center density) and non-health system inputs (urbanization rate, median age of population, and wealth index) as a set of covariates. Data about the rate of self-reported diabetes treatment coverage was obtained from the Non-Communicable Disease Surveillance Survey, data about health system inputs were collected from the health census database and data about non-health system inputs were collected from the census data and household survey.ResultsIn 2008, rate of diabetes treatment coverage was 67% (95% CI: 63%71%) nationally, and at the provincial level it varied from 44% to 81%. The TE score at the national level was 87.84%, with considerable variation across provinces (from 59.65% to 98.28%).Among health system and non-health system inputs, only the Behvarz density (per 1000 population)was significantly associated with diabetes treatment coverage ( (95%CI): 0.50 (0.290.70),p<0.001).ConclusionOur findings show that although the rural PHC system can considered efficient in diabetes treatment at the national level, a wide variation exists in TE at the provincial level. Because the only variable that is predictor of TE is the Behvarz density, the PHC system may extend the diabetes treatment coverage by using this group of health care workers.", "label": 1}
{"doc-1": "Despite the prevalence of sleep complaints among psychiatric patients, few questionnaires have been specifically designed to measure sleep quality in clinical populations. The Pittsburgh Sleep Quality Index (PSQI) is a self-rated questionnaire which assesses sleep quality and disturbances over a 1-month time interval. Nineteen individual items generate seven \"component\" scores: subjective sleep quality, sleep latency, sleep duration, habitual sleep efficiency, sleep disturbances, use of sleeping medication, and daytime dysfunction. The sum of scores for these seven components yields one global score. Clinical and clinimetric properties of the PSQI were assessed over an 18-month period with \"good\" sleepers (healthy subjects, n = 52) and \"poor\" sleepers (depressed patients, n = 54; sleep-disorder patients, n = 62). Acceptable measures of internal homogeneity, consistency (test-retest reliability), and validity were obtained. A global PSQI score greater than 5 yielded a diagnostic sensitivity of 89.6% and specificity of 86.5% (kappa = 0.75, p less than 0.001) in distinguishing good and poor sleepers. The clinimetric and clinical properties of the PSQI suggest its utility both in psychiatric clinical practice and research activities.", "doc-2": "BackgroundInsomnia is a major public health problem in western countries. Previous small pilot studies showed that the administration of constant white noise can improve sleep quality, increase acoustic arousal threshold, and reduce sleep onset latency. In this randomized controlled trial, we tested the effect of surrounding broadband sound administration on sleep onset latency, sleep architecture, and subjective sleep quality in healthy subjects.MethodsEighteen healthy subjects were studied with two overnight sleep studies approximately one week apart. They were exposed in random order to normal environmental noise (40.1 [1.3]dB) or to broadband sound administration uniformly distributed in the room by two speakers (46.0 [0.9]dB). To model transient insomnia, subjects went to bed (\"lights out\") 90min before usual bedtime.ResultsBroadband sound administration reduced sleep onset latency to stage 2 sleep (time from lights out to first epoch of non-rapid eye movement-sleep stage 2) (19 [16] vs. 13 [23]min, p=0.011; median reduction 38% baseline). In a subgroup reporting trouble initiating sleep at home (Pittsburgh Sleep Quality Index section 2 score1), sound administration improved subjective sleep quality (p=0.037) and the frequency of arousals from sleep (p=0.03).ConclusionIn an experimental model of transient insomnia in young healthy individuals, broadband sound administration significantly reduced sleep onset latency by 38% compared to normal environmental noise. These findings suggest that broadband sound administration might be helpful to minimize insomnia symptoms in selected individuals.", "label": 1}
{"doc-1": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to  everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.", "doc-2": "We propose a novel conditional GAN (cGAN) model for continuous fine-grained human action segmentation, that utilises multi-modal data and learned scene context information. The proposed approach utilises two GANs: termed Action GAN and Auxiliary GAN, where the Action GAN is trained to operate over the current RGB frame while the Auxiliary GAN utilises supplementary information such as depth or optical flow. The goal of both GANs is to generate similar 'action codes', a vector representation of the current action. To facilitate this process a context extractor that incorporates data and recent outputs from both modes is used to extract context information to aids recognition performance. The result is a recurrent GAN architecture which learns a task specific loss function from multiple feature modalities. Extensive evaluations on variants of the proposed model to show the importance of utilising different streams of information such as context and auxiliary information in the proposed network; and show that our model is capable of outperforming state-of-the-art methods for three widely used datasets: 50 Salads, MERL Shopping and Georgia Tech Egocentric Activities, comprising both static and dynamic camera settings.", "label": 1}
{"doc-1": "Using an improved method of gel electrophoresis, many hitherto unknown proteins have been found in bacteriophage T4 and some of these have been identified with specific gene products. Four major components of the head are cleaved during the process of assembly, apparently after the precursor proteins have assembled into some large intermediate structure.", "doc-2": "Abstract An extracellular xylanase was purified to homogeneity from a culture of Aspergillus carneus M34. In contrast to xylanases from other microorganisms, only a low-molecular weight xylanase, approximately 18.8kDa with a p I value of 7.77.9, was purified in this investigation. The optimum temperature and pH of this purified xylanase activity were 50C and 6, respectively. The xylanase was more stable under alkaline conditions and retained more than 50% activity after 12h incubation at pH 79. Considering of its characteristics and N-terminal sequence, this xylanase was concluded as a new one belonging to the group I of family 11 endoxylanases. In addition, hemicellulose of coba husk was selected as the substrate for xylooligosaccharide preparation owing to its higher specificity for this xylanase. Feruloyl xylooligosaccharides were separated and shown potential antioxidative capacity in a cell model of ultraviolet B (UVB)-induced oxidative damage to keratinocyte xb-2.", "label": 1}
{"doc-1": "Topics considered include characteristics of power generation units, transmission losses, generation with limited energy supply, control of generation, and power system security. This book is a graduate-level text in electric power engineering as regards to planning, operating, and controlling large scale power generation and transmission systems. Material used was generated in the post-1966 period. Many (if not most) of the chapter problems require a digital computer. A background in steady-state power circuit analysis is required.", "doc-2": "Coupled biological and chemical systems, neural networks, social interacting species, the Internet and the World Wide Web, are only a few examples of systems composed by a large number of highly interconnected dynamical units. The first approach to capture the global properties of such systems is to model them as graphs whose nodes represent the dynamical units, and whose links stand for the interactions between them. On the one hand, scientists have to cope with structural issues, such as characterizing the topology of a complex wiring architecture, revealing the unifying principles that are at the basis of real networks, and developing models to mimic the growth of a network and reproduce its structural properties. On the other hand, many relevant questions arise when studying complex networks dynamics, such as learning how a large ensemble of dynamical systems that interact through a complex wiring topology can behave collectively. We review the major concepts and results recently achieved in the study of the structure and dynamics of complex networks, and summarize the relevant applications of these ideas in many different disciplines, ranging from nonlinear science to biology, from statistical mechanics to medicine and engineering.  2005 Elsevier B.V. All rights reserved.", "label": 1}
{"doc-1": "ERA-Interim is the latest global atmospheric reanalysis produced by the European Centre for Medium-Range Weather Forecasts (ECMWF). The ERA-Interim project was conducted in part to prepare for a new atmospheric reanalysis to replace ERA-40, which will extend back to the early part of the twentieth century. This article describes the forecast model, data assimilation method, and input datasets used to produce ERA-Interim, and discusses the performance of the system. Special emphasis is placed on various difficulties encountered in the production of ERA-40, including the representation of the hydrological cycle, the quality of the stratospheric circulation, and the consistency in time of the reanalysed fields. We provide evidence for substantial improvements in each of these aspects. We also identify areas where further work is needed and describe opportunities and objectives for future reanalysis projects at ECMWF. Copyright  2011 Royal Meteorological Society", "doc-2": "Wind waves may play an important role in the evolution of sea ice. That role is largely determined by how fast the ice layer dissipates the wave energy. The transition from a continuous layer of ice to a series of broken floes is expected to have a strong impact on the several attenuation processes. Here we explore the possible effects of basal friction, scattering, and dissipation within the ice layer. The ice is treated as a single layer that can be fractured in many floes. Dissipation associated with ice flexure is evaluated using an anelastic linear dissipation and a cubic inelastic viscous dissipation. Tests aiming to reproduce a Marginal Ice Zone are used to discuss the effects of each process separately. Attenuation is exponential for friction and scattering. Scattering produces an increase in the wave height near the ice edge and broadens the wave directional spectrum, especially for short-period waves. The nonlinear inelastic dissipation is larger for larger wave heights as long as the ice is not broken. These effects are combined in a realistic simulation of an ice break-up event observed south of Svalbard in 2010. The recorded rapid shift from a strong attenuation to little attenuation when the ice is broken is only reproduced when using a nonlinear dissipation that vanishes when the ice is broken. A preliminary pan-Arctic test of these different parameterizations suggests that inelastic dissipation alone is not enough and requires its combination with basal friction.", "label": 1}
{"doc-1": "Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.", "doc-2": "Recently a quantization scheme for the phenomenological Maxwell theory of the full electromagnetic field in an inhomogeneous three-dimensional, dispersive, and absorbing dielectric medium has been developed and applied to a system consisting of two infinite half-spaces with a common planar interface (H.T. Dung, L. Kn\\\"oll, and D.-G. Welsch, Phys. Rev. A 57, 3931 (1998)). Here we show that the scheme, which is based on the classical Green-tensor integral representation of the electromagnetic field, applies to any inhomogeneous medium. For this purpose we prove that the fundamental equal-time commutation relations of QED are preserved for an arbitrarily space-dependent, Kramers-Kronig consistent permittivity. Further, an extension of the quantization scheme to linear media with bounded regions of amplification is given, and the problem of anisotropic media is briefly addressed.", "label": 1}
{"doc-1": "Since 1922 when Wu proposed the use of the Folin phenol reagent for the measurement of proteins, a number of modified analytical procedures utilizing this reagent have been reported for the determination of proteins in serum, in antigen-antibody precipitates, and in insulin. Although the reagent would seem to be recommended by its great sensitivity and the simplicity of procedure possible with its use, it has not found great favor for general biochemical purposes. In the belief that this reagent, nevertheless, has considerable merit for certain application, but that its peculiarities and limitations need to be understood for its fullest exploitation, it has been studied with regard to effects of variations in pH, time of reaction, and concentration of reactants, permissible levels of reagents commonly used in handling proteins, and interfering substances. Procedures are described for measuring protein in solution or after precipitation with acids or other agents, and for the determination of as little as 0.2 gamma of protein.", "doc-2": "Group housed and individually housed mice were compared in (1) the motor activity responses to direct and indirect dopamine (DA) agonists, (2) in vivo presynaptic autoreceptor sensitivity and (3) in vitro binding of 3H-spiperone. Relative to group housed mice, individually housed mice showed an increased motor activity response to amphetamine, 1.25 and 0.625 mg/kg. Using two in vivo measures of presynaptic DA receptor sensitivity, the antagonism of spontaneous locomotor activity and the antagonism of dihydroxyphenylalanine (DOPA) accumulation by apomorphine (APO), individually housed mice showed greater activity counts and higher DOPA accumulations than group housed mice. Levels of tyrosine were significantly greater in individually housed mice. Significant effects of housing were also noted with the motor activity response to APO, 0.0750.300 mg/kg, following pretreatment with reserpine, an in vivo measure of postsynaptic receptor sensitivity. However, there was no effect of housing on the number or affinity of 3H-spiperone binding sites in the striatum. These results are discussed in terms of the presynaptic activity of catecholaminergic neurons and the postsynaptic receptor sensitivity to APO in individually housed mice.", "label": 1}
{"doc-1": "BACKGROUNDThe 7-item Generalized Anxiety Disorder Scale (GAD-7) is a practical self-report anxiety questionnaire that proved valid in primary care. However, the GAD-7 was not yet validated in the general population and thus far, normative data are not available.OBJECTIVESTo investigate reliability, construct validity, and factorial validity of the GAD-7 in the general population and to generate normative data.RESEARCH DESIGNNationally representative face-to-face household survey conducted in Germany between May 5 and June 8, 2006.SUBJECTSFive thousand thirty subjects (53.6% female) with a mean age (SD) of 48.4 (18.0) years.MEASURESThe survey questionnaire included the GAD-7, the 2-item depression module from the Patient Health Questionnaire (PHQ-2), the Rosenberg Self-Esteem Scale, and demographic characteristics.RESULTSConfirmatory factor analyses substantiated the 1-dimensional structure of the GAD-7 and its factorial invariance for gender and age. Internal consistency was identical across all subgroups (alpha = 0.89). Intercorrelations with the PHQ-2 and the Rosenberg Self-Esteem Scale were r = 0.64 (P < 0.001) and r = -0.43 (P < 0.001), respectively. As expected, women had significantly higher mean (SD) GAD-7 anxiety scores compared with men [3.2 (3.5) vs. 2.7 (3.2); P < 0.001]. Normative data for the GAD-7 were generated for both genders and different age levels. Approximately 5% of subjects had GAD-7 scores of 10 or greater, and 1% had GAD-7 scores of 15 or greater.CONCLUSIONSEvidence supports reliability and validity of the GAD-7 as a measure of anxiety in the general population. The normative data provided in this study can be used to compare a subject's GAD-7 score with those determined from a general population reference group.", "doc-2": "The serotonin-noradrenaline reuptake inhibitor (SNRI) duloxetine is an effective treatment for major depression and generalised anxiety disorder. Neuropsychological models of antidepressant drug action suggest therapeutic effects might be mediated by the early correction of maladaptive biases in emotion processing, including the recognition of emotional expressions. Sub-chronic administration of duloxetine (for two weeks) produces adaptive changes in neural circuitry implicated in emotion processing; however, its effects on emotional expression recognition are unknown. Forty healthy participants were randomised to receive either 14 days of duloxetine (60 mg/day, titrated from 30 mg after three days) or matched placebo (with sham titration) in a double-blind, between-groups, repeated-measures design. On day 0 and day 14 participants completed a computerised emotional expression recognition task that measured sensitivity to the six primary emotions. Thirty-eight participants (19 per group) completed their course of tablets and were included in the analysis. Results provide evidence that duloxetine, compared to placebo, may reduce the accurate recognition of sadness. Drug effects were driven by changes in participants' ability to correctly detect subtle expressions of sadness, with greater change observed in the placebo relative to the duloxetine group. These effects occurred in the absence of changes in mood. Our preliminary findings require replication, but complement recent evidence that sadness recognition is a therapeutic target in major depression, and a mechanism through which SNRIs could resolve negative biases in emotion processing to achieve therapeutic effects.", "label": 1}
{"doc-1": "The present invention provides a method for effectively inducing pluripotent stem cells from germ stem cells. Pluripotent stem cell cells can be induced with greater efficiency than in conventional methods by using germ stem cells in which Sox2 and/or Oct4 is overexpressed. With regard to the germ stem cells, one or more kind of gene selected from Dnmt1 gene, Dmap1 gene, Dmrt1 gene and Oct1 gene is inhibited, or Sox2 gene and/or Oct4 gene is overexpressed, or alternatively the protein of Sox2 and/or Oct4 is directly introduced. Said method enables pluripotent stem cells to be more efficiently induced from germ stem cells than in conventional methods.", "doc-2": "In the adult pancreas, there has been a long-standing dispute as to whether stem/precursor populations that retain plasticity to differentiate into endocrine or acinar cell types exist in ducts. We previously reported that adult Sox9-expressing duct cells are sufficiently plastic to supply new acinar cells in Sox9-IRES-CreERT2 knock-in mice. In the present study, using Sox9-IRES-CreERT2 knock-in mice as a model, we aimed to analyze how plasticity is controlled in adult ducts. Adult duct cells in these mice express less Sox9 than do wild-type mice but Hes1 equally. Acinar cell differentiation was accelerated by Hes1 inactivation, but suppressed by NICD induction in adult Sox9-expressing cells. Quantitative analyses showed that Sox9 expression increased with the induction of NICD but did not change with Hes1 inactivation, suggesting that Notch regulates Hes1 and Sox9 in parallel. Taken together, these findings suggest that Hes1-mediated Notch activity determines the plasticity of adult pancreatic duct cells and that there may exist a dosage requirement of Sox9 for keeping the duct cell identity in the adult pancreas. In contrast to the extended capability of acinar cell differentiation by Hes1 inactivation, we obtained no evidence of islet neogenesis from Hes1-depleted duct cells in physiological or PDL-induced injured conditions.", "label": 1}
{"doc-1": "Approach your problems from the right end It isn't that they can't see the solution. It is and begin with the answers. Then one day, that they can't see the problem. perhaps you will find the final question. G. K. Chesterton. The Scandal of Father 'The Hermit Clad in Crane Feathers' in R. Brown 'The point of a Pin'. van Gulik's The Chinese Maze Murders. Growing specialization and diversification have brought a host of monographs and textbooks on increasingly specialized topics. However, the \"tree\" of knowledge of mathematics and related fields does not grow only by putting forth new branches. It also happens, quite often in fact, that branches which were thought to be completely disparate are suddenly seen to be related. Further, the kind and level of sophistication of mathematics applied in various sciences has changed drastically in recent years: measure theory is used (non-trivially) in regional and theoretical economics; algebraic geometry interacts with physics; the Minkowsky lemma, coding theory and the structure of water meet one another in packing and covering theory; quantum fields, crystal defects and mathematical programming profit from homotopy theory; Lie algebras are relevant to filtering; and prediction and electrical engineering can use Stein spaces. And in addition to this there are such new emerging subdisciplines as \"experimental mathematics\", \"CFD\", \"completely integrable systems\", \"chaos, synergetics and large-scale order\", which are almost impossible to fit into the existing classification schemes. They draw upon widely different sections of mathematics.", "doc-2": "In this paper we present a switching control strategy to incrementally stabilize a class of nonlinear dynamical systems. Exploiting recent results on contraction analysis of switched Filippov systems derived using regularization, sufficient conditions are presented to prove incremental stability of the closed-loop system. Furthermore, based on these sufficient conditions, a design procedure is proposed to design a switched control action that is active only where the open-loop system is not sufficiently incrementally stable in order to reduce the required control effort. The design procedure to either locally or globally incrementally stabilize a dynamical system is then illustrated by means of a representative example.", "label": 1}
{"doc-1": "In observational studies, investigators have no control over the treatment assignment. The treated and non-treated (that is, control) groups may have large differences on their observed covariates, and these differences can lead to biased estimates of treatment effects. Even traditional covariance analysis adjustments may be inadequate to eliminate this bias. The propensity score, defined as the conditional probability of being treated given the covariates, can be used to balance the covariates in the two groups, and therefore reduce this bias. In order to estimate the propensity score, one must model the distribution of the treatment indicator variable given the observed covariates. Once estimated the propensity score can be used to reduce bias through matching, stratification (subclassification), regression adjustment, or some combination of all three. In this tutorial we discuss the uses of propensity score methods for bias reduction, give references to the literature and illustrate the uses through applied examples.", "doc-2": "Economic differences and proximal risk factors do not fully explain the persistent high infant mortality rates of African Americans (blacks). The authors hypothesized that racial residential segregation plays an independent role in high black infant mortality rates. Segregation restricts social and economic advantage and imposes negative environmental exposures that black women and infants experience. The study sample was obtained from the 2000-2002 US Linked Birth/Infant Death records and included 677,777 black infants residing in 64 cities with 250,000 or more residents. Outcomes were rates of all-cause infant mortality, postneonatal mortality, and external causes of death. Segregation was measured by using the isolation index (dichotomized at 0.60) from the 2000 US Census Housing Patterns. Propensity score matching methods were used. After matching on propensity scores, no independent effect of segregation on black infant mortality rates was found. Results show little statistical evidence that segregation plays an independent role in black infant mortality. However, a key finding is that it is difficult to disentangle contextual effects from the characteristics of individuals.", "label": 1}
{"doc-1": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.", "doc-2": "Neural networks are powering the deployment of embedded devices and Internet of Things. Applications range from personal assistants to critical ones such as self-driving cars. It has been shown recently that models obtained from neural nets can be trojaned ; an attacker can then trigger an arbitrary model behavior facing crafted inputs. This has a critical impact on the security and reliability of those deployed devices. We introduce novel algorithms to detect the tampering with deployed models, classifiers in particular. In the remote interaction setup we consider, the proposed strategy is to identify markers of the model input space that are likely to change class if the model is attacked, allowing a user to detect a possible tampering. This setup makes our proposal compatible with a wide rage of scenarios, such as embedded models, or models exposed through prediction APIs. We experiment those tampering detection algorithms on the canonical MNIST dataset, over three different types of neural nets, and facing five different attacks (trojaning, quantization, fine-tuning, compression and watermarking). We then validate over five large models (VGG16, VGG19, ResNet, MobileNet, DenseNet) with a state of the art dataset (VGGFace2), and report results demonstrating the possibility of an efficient detection of model tampering.", "label": 1}
{"doc-1": "1. Introduction. 2. Partitioning Around Medoids (Program PAM). 3. Clustering large Applications (Program CLARA). 4. Fuzzy Analysis. 5. Agglomerative Nesting (Program AGNES). 6. Divisive Analysis (Program DIANA). 7. Monothetic Analysis (Program MONA). Appendix 1. Implementation and Structure of the Programs. Appendix 2. Running the Programs. Appendix 3. Adapting the Programs to Your Needs. Appendix 4. The Program CLUSPLOT. References. Author Index. Subject Index.", "doc-2": "Relational clustering is an extension of clustering for relational data. Fuzzy c-Medoids (FCMdd) based linear fuzzy clustering extracts intrinsic local linear substructures from relational data. However this linear clustering was affected by noise or outliers because of using Euclidean distance. Alternative Fuzzy c-Means (AFCM) is an extension of Fuzzy c-means, in which a modified distance measure based on the robust M-estimation concept can decrease the influence of noise or outliers more than the conventional Euclidean distance. In this paper, robust FCMddbased linear clustering model is proposed in order to extract linear substructure from relational data including outliers, using a pseudo-M-estimation procedure with a weight function for the modified distance measure in AFCM.", "label": 1}
{"doc-1": "Platelet-derived growth factor (PDGF) exerts its stimulatory effects on cell growth and motility by binding to two related protein tyrosine kinase receptors. Ligand binding induces receptor dimerization and autophosphorylation, allowing binding and activation of cytoplasmic SH2-domain containing signal transduction molecules. Thereby, a number of different signaling pathways are initiated leading to cell growth, actin reorganization migration and differentiation. Recent observations suggest that extensive cross-talk occurs between different signaling pathways, and that stimulatory signals are modulated by inhibitory signals arising in parallel.", "doc-2": "The biophysical interactions between cells and type I collagen are controlled by the level of cell adhesion, which is dictated primarily by the density of ligands on collagen and the density of integrin receptors on cells. The native adhesivity of collagen was modulated by covalently grafting glycine-arginine-glycine-aspartic acid-serine (GRGDS), which includes the bioactive RGD sequence, or glycine-arginine-aspartic acid-glycine-serine (GRDGS), which includes the scrambled RDG sequence, to collagen with the hetero-bifunctional coupling agent 1-ethyl-3-(3-dimethylaminopropyl) carbodiimide. The peptide-grafted collagen self-assembled into a fibrillar gel with negligible changes in gel structure and rheology. Rat dermal fibroblasts (RDFs) and human smooth muscle cells demonstrated increased levels of adhesion on gels prepared from RGD-grafted collagen, and decreased levels of adhesion on RDG-grafted collagen. Both cell types demonstrated an increased ability to compact free-floating RGD-grafted collagen gels, and an impaired ability to compact RDG-grafted gels. RDF migration on and within collagen was increased with RDG-grafted collagen and decreased with RGD-grafted collagen, and dose-response experiments indicated a biphasic response of RDF migration to adhesion. Smooth muscle cells demonstrated similar, though not statistically significant, trends. The ability to both positively and negatively modulate cell adhesion to collagen increases the versatility of this natural biomaterial for regenerative therapies.", "label": 1}
{"doc-1": "BackgroundGene-expression analysis is increasingly important in biological research, with real-time reverse transcription PCR (RT-PCR) becoming the method of choice for high-throughput and accurate expression profiling of selected genes. Given the increased sensitivity, reproducibility and large dynamic range of this methodology, the requirements for a proper internal control gene for normalization have become increasingly stringent. Although housekeeping gene expression has been reported to vary considerably, no systematic survey has properly determined the errors related to the common practice of using only one control gene, nor presented an adequate way of working around this problem.ResultsWe outline a robust and innovative strategy to identify the most stably expressed control genes in a given set of tissues, and to determine the minimum number of genes required to calculate a reliable normalization factor. We have evaluated ten housekeeping genes from different abundance and functional classes in various human tissues, and demonstrated that the conventional use of a single gene for normalization leads to relatively large errors in a significant proportion of samples tested. The geometric mean of multiple carefully selected housekeeping genes was validated as an accurate normalization factor by analyzing publicly available microarray data.ConclusionsThe normalization strategy presented here is a prerequisite for accurate RT-PCR expression profiling, which, among other things, opens up the possibility of studying the biological relevance of small expression differences.", "doc-2": "We examined the genotype-phenotype interactions of Cyp51+/- mice carrying one functional allele of lanosterol 14-demethylase from cholesterol biosynthesis. No distinct developmental or morphological abnormalities were observed by routine visual inspection of Cyp51+/- and Cyp51+/+ mice and fertility was similar. We further collected a large data-set from female and male Cyp51+/- mice and controls fed for 16 weeks with three diets and applied linear regression modeling. We used 3 predictor variables (genotype, sex, diet), and 39 response variables corresponding to the organ characteristics (7), plasma parameters (7), and hepatic gene expression (25). We observed significant differences between Cyp51+/- and wild-type mice in organ characteristics and blood lipid profile. Hepatomegaly was observed in Cyp51+/- males, together with elevated total and low-density lipoprotein cholesterol. Cyp51+/- females fed high-fat, high-cholesterol diet were leaner and had elevated plasma corticosterone compared to controls. We observed elevated hepatocyte apoptosis, mitosis and lipid infiltration in heterozygous knockouts of both sexes. The Cyp51+/- females had a modified lipid storage homeostasis protecting them from weight-gain when fed high-fat high-cholesterol diet. Malfunction of one Cyp51 allele therefore initiates disease pathways towards cholesterol-linked liver pathologies and sex-dependent response to dietary challenge.", "label": 1}
{"doc-1": "We examine the growing number of studies of survey respondents' global self-ratings of health as predictors of mortality in longitudinal studies of representative community samples. Twenty-seven studies in U.S. and international journals show impressively consistent findings. Global self-rated health is an independent predictor of mortality in nearly all of the studies, despite the inclusion of numerous specific health status indicators and other relevant covariates known to predict mortality. We summarize and review these studies, consider various interpretations which could account for the association, and suggest several approaches to the next stage of research in this field.", "doc-2": "BackgroundPrevious mixed findings regarding socioeconomic differentials among adolescents can be partly attributed to problems in measuring socioeconomic position (SEP) among adolescents. Accordingly, the Family Affluence Scale (FAS) was developed and used in European countries, where it yielded good predictions of socioeconomic differentials in health. However, no prior study has examined whether this new measure for SEP among adolescents is applicable outside Europe.MethodsThe study subjects comprised 71,404 middle and high school students (37,204 boys and 34,200 girls) selected through stratified random cluster sampling of 400 middle schools and 400 high schools in Korea. The predictor variables included the FAS, parental education levels, self-rated school achievement, perceived household economic status, and cohabitation with parents. The outcome variable was self-rated health (SRH); age-adjusted odds ratios were calculated with SRH as an outcome variable.ResultsAbout 10% of the adolescents studied reported poor SRH. The correlation coefficients between each component of the FAS were modest (0.110.24). Lower FAS was related to a lower level in other SEP indicators and living without parents. All SEP indicators showed a positive relationship between lower SEP and worse SRH for both genders, with gradients being greater among boys than girls. The higher risk of poor SRH being reported by adolescents with low FAS was significantly decreased by adjustment for perceived household economic status.ConclusionSignificant differentials in SRH by many SEP indicators were found among Korean adolescents. The FAS garnered a high completion rate and appeared useful as a measure of SEP for studying adolescents outside of Europe.", "label": 1}
{"doc-1": "We address a problem of increasing practical interest: control charting in the absence of an assumed normal distribution. We analyze the sampling uncertainties inherent in selecting control limits from the empirical distribution of a large sample of wha..", "doc-2": "Owing to the extreme quantiles involved, standard control charts are very sensitive to the effects of parameter estimation and non-normality. More general parametric charts have been devised to deal with the latter complication and corrections have been derived to compensate for the estimation step, both under normal and parametric models. The resulting procedures offer a satisfactory solution over a broad range of underlying distributions. However, situations do occur where even such a large model is inadequate and nothing remains but to consider nonparametric charts. In principle, these form ideal solutions, but the problem is that huge sample sizes are required for the estimation step. Otherwise the resulting stochastic error is so large that the chart is very unstable, a disadvantage that seems to outweigh the advantage of avoiding the model error from the parametric case. Here we analyse under what conditions non-parametric charts actually become feasible alternatives for their parametric counterparts. In particular, corrected versions are suggested for which a possible change point is reached at sample sizes that are markedly less huge (but still larger than the customary range). These corrections serve to control the behaviour during in-control (markedly wrong outcomes of the estimates only occur sufficiently rarely). The price for this protection will clearly be some loss of detection power during out-of-control. A change point comes in view as soon as this loss can be made sufficiently small.", "label": 1}
{"doc-1": "Pathological angiogenesis is a hallmark of cancer and various ischaemic and inflammatory diseases. Concentrated efforts in this area of research are leading to the discovery of a growing number of pro- and anti-angiogenic molecules, some of which are already in clinical trials. The complex interactions among these molecules and how they affect vascular structure and function in different environments are now beginning to be elucidated. This integrated understanding is leading to the development of a number of exciting and bold approaches to treat cancer and other diseases. But owing to several unanswered questions, caution is needed.", "doc-2": "Key PointsThe pathological interactions between cancer cells and host immune cells in the tumour microenvironment create an immunosuppressive network that promotes tumour growth, protects the tumour from immune attack and attenuates immunotherapeutic efficacy.Poor tumour-associated antigen (TAA)-specific immunity is not simply due to a passive process whereby adaptive immunity is shielded from detecting TAAs. There is an active process of 'tolerization' taking place in the tumour microenvironment.Tumour tolerization is the result of imbalances in the tumour microenvironment, including alterations in antigen-presenting-cell subsets, co-stimulatory and co-inhibitory molecule alterations and altered ratios of effector T cells and regulatory T cells.Human tumorigenesis is a slow process that can occur over several years and in this respect is similar to chronic infection. The lack of an acute phase in the course of tumorigenesis might profoundly shape T-cell immune responses, including the quality of antigen release, T-cell priming and activation.Current immunotherapies often target patients with advanced-stage tumours, which have high levels of inflammatory molecules, cytokines, chemokines, tumour-infiltrating T cells, dendritic cells and macrophages. It is arguable whether we need to incorporate more of these components into tumour treatments.Immune tolerization is predominant in the immune system in patients with advanced-stage tumours. It is time to consider combinatorial tumour therapies, including those that subvert the immune-tolerizing conditions within the tumour.AbstractIt is well known that many tumours are potentially immunogenic, as corroborated by the presence of tumour-specific immune responses in vivo. Nonetheless, spontaneous clearance of established tumours by endogenous immune mechanisms is rare. Therefore, the focus of most cancer immunotherapies is to supplement essential immunogenic elements to boost tumour-specific immunity. Why then has tumour immunotherapy resulted in a generally poor clinical efficiency? The reason might lie in the increasingly documented fact that tumours develop diverse strategies that escape tumour-specific immunity.", "label": 1}
{"doc-1": "Valid measurement scales for predicting user acceptance of computers are in short supply. Most subjective measures used in practice are unvalidated, and their relationship to system usage is unknown. The present research develops and validates new scales for two specific variables, perceived usefulness and perceived ease of use, which are hypothesized to be fundamental determinants of user acceptance. Definitions of these two variables were used to develop scale items that were pretested for content validity and then tested for reliability and construct validity in two studies involving a total of 152 users and four application programs. The measures were refined and streamlined, resulting in two six-item scales with reliabilities of .98 for usefulness and .94 for ease of use. The scales exhibited hgih convergent, discriminant, and factorial validity. Perceived usefulness was significnatly correlated with both self-reported current usage r = .63, Study 1) and self-predicted future usage r = .85, Study 2). Perceived ease of use was also significantly correlated with current usage r = .45, Study 1) and future usage r = .59, Study 2). In both studies, usefulness had a signficnatly greater correaltion with usage behavior than did ease of use. Regression analyses suggest that perceived ease of use may actually be a causal antecdent to perceived usefulness, as opposed to a parallel, direct determinant of system usage. Implications are drawn for future research on user acceptance.", "doc-2": "A lot of studies for acceptance of new technology have been conducted in context of work settings, but some technologies can be used for amusement also. Is enjoyment a necessary or garniture? The authors develop scenarios about the relative importance of enjoyment to the adoption of new technology. Empirical analysis of a survey of 570 consumers shows that while both practical and enjoyable function are important, user perceived enjoyment will affect his acceptance of new technology. In particular, contents quality will influence user perceived enjoyment, then performance expectancy and behavioral intention. These findings imply that user s enjoyment needs should be considered in the development of a new technology.", "label": 1}
{"doc-1": "A submitted manuscript is the author's version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "Pre-crash functionality is defined in three functional steps: PRESET, PREFIRE and PREACT. The functional steps are in the order that they require a increasing situation analysis performance and an growing amount of application effort. Each functional step makes it necessary to define the appropriate range of view, the virtual barrier. It is subject to various constraints and the configurations possible in pre-crash sensing. Pre-crash sensing technology uses platform radar sensors being designed for the functional integration of all possible functions that rely on sensor information from the close surrounding of the vehicle. This approach guarantees a high cost efficiency, flexibility and modularity of the sensor system still guaranteeing the full pre-crash functionality.", "label": 1}
{"doc-1": "Blowfish, a new secret-key block cipher, is proposed. It is a Feistel network, iterating a simple encryption function 16 times. The block size is 64 bits, and the key can be any length up to 448 bits. Although there is a complex initialization phase required before any encryption can take place, the actual encryption of data is very efficient on large microprocessors.", "doc-2": "This paper describes a new practical DoS attack that can be mounted against the encryptiononly configuration (i.e. without authenticated integrity) of ESP as allowed by IPSec. This finding can serve as a strong argument to convince those in charge of the IPSec standardization to improve it by banning the encryption-only configuration from the standard.", "label": 1}
{"doc-1": "NA", "doc-2": "Network traffic have several attributes with different range of values. These attributes can be qualitative or quantitative in nature. Attributes with large values significantly influence the performance of intrusion classifier making it bias towards them. Attribute normalization eliminates such dominance of the attributes by scaling the values of all the attributes within a specific range. The paper discusses various normalization techniques and their influence on intrusion classifiers such as Random Forest, Bayes Net, Naive Bayes, NB Tree and Decision Tree. Furthermore, the concept of hybrid normalization is applied by normalizing the qualitative and quantitative attributes differently. Experiments on KDD Cup 99 suggests that the hybrid normalization can achieve better results as compared to conventional normalization.", "label": 1}
{"doc-1": "Copyright () 19992012 R Foundation for Statistical Computing. Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies. Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one. Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions, except that this permission notice may be stated in a translation approved by the R Core Team.", "doc-2": "Polycotylidae is a clade of plesiosaurians that appeared during the Early Cretaceous and became speciose and abundant early in the Late Cretaceous. However, this radiation is poorly understood. Thililua longicollis from the Middle Turonian of Morocco is an enigmatic taxon possessing an atypically long neck and, as originally reported, a series of unusual cranial features that cause unstable phylogenetic relationships for polycotylids. We reinterpret the holotype specimen of Thililua longicollis and clarify its cranial anatomy. Thililua longicollis possesses an extensive, foramina-bearing jugal, a premaxilla-parietal contact and carinated teeth. Phylogenetic analyses of a new cladistic dataset based on first-hand observation of most polycotylids recover Thililua and Mauriciosaurus as successive lineages at the base of the earliest Late Cretaceous polycotyline radiation. A new dataset summarizing the Bauplan of polycotylids reveals that their radiation produced an early burst of disparity during the Cenomanian-Turonian interval, with marked plasticity in relative neck length, but this did not arise as an ecological release following the extinction of ichthyosaurs and pliosaurids. This disparity vanished during and after the Turonian, which is consistent with a model of 'early experimentation/late constraint'. Two polycotylid clades, Occultonectia clade nov. and Polycotylinae, survived up to the Maastrichtian, but with low diversity.", "label": 1}
{"doc-1": "OBJECTIVETo evaluate the association between physical activity and all case mortality in postmenopausal women.DESIGNProspective cohort study with 7 years of follow-up through December 31, 1992.SETTING AND PARTICIPANTSSubjects were 40417 postmenopausal Iowa women, aged 55 to 69 years at baseline in 1986. Physical activity was assessed by mailed questionnaire.MAIN OUTCOME MEASUREAll-cause mortality (n=2260).RESULTSAfter adjustment for potential confounders and excluding women who reported having cancer or heart disease and those who died in the first 3 years of follow-up, women who reported regular physical activity were at significantly reduced risk of death during follow-up compared with women who did not (relative risk [RR], 0.77; 95% confidence interval [CI], 0.66-0.90). Increasing frequency of moderate physical activity was associated with reduced risk of death during follow-up (from rarely or never engaging in activity to activity at least 4 times per week, RRs, 1.0 [referent], 0.76, 0.70, and 0.62; P value for trend<.001). A similar pattern was seen for vigorous physical activity (corresponding RRs, 1.0, 0.89, 0.74, and 0.57; Pvalue for trend=.06). Reduced risks of death with increased physical activity were evident for cardiovascular diseases (n=729) and respiratory illnesses (n=147). Women who engaged only in moderate but not vigorous physical activity also benefited, with moderate activity as infrequently as once per week demonstrating a reduced mortality risk of 0.78 (95% CI, 0.64-0.96).CONCLUSIONSThese results demonstrate a graded, inverse association between physical activity and all-cause mortality in postmenopausal women. These findings strengthen the confidence that population recommendations to engage in regular physical activity are applicable to postmenopausal women.", "doc-2": "Why has research-based practice become so important and why is everyone talking about evidence-based health care? But most importantly, how is nursing best placed to maximise the benefits which evidence-based care can bring?Research has been used to legitimise nursing as a profession, education has been radically reformed to reflect a research base, and academic nurses have built their careers around it. However, despite the length of time that research has been on the agenda and the influential bodies involved, only a moderate proportion of nurses use research as a basis for practice.1 What has gone wrong?Part of the difficulty is that although nurses perceive research positively,2 they either cannot access the information, or cannot judge the value of the studies which they find.3 This journal has evolved as a direct response to the dilemma of practitioners who want to use research, but are thwarted by overwhelming clinical demands, an ever burgeoning research literature, and for many, a lack of skills in critical appraisal. Evidence-Based Nursing should therefore be exceptionally useful, and its target audience of practitioners is a refreshing move in the right direction. The worlds of researchers and practitioners have been separated by seemingly impenetrable barriers for too long.4Tiptoeing in the wake of the movement for evidence-based medicine, however, we must ensure that evidence-based nursing attends to what is important for nursing. Part of the difficulty that practitioners face relates to the ambiguity which research, and particularly scientific research, has within nursing. Ambiguous, because we need to be clear as to what nursing is, and what nurses do before we can identify the types of evidence needed to improve the effectiveness of patient care. Then we can explore the type of questions which practitioners need answers to and what sort of research", "label": 1}
{"doc-1": "Visual attention is a mechanism which filters out redundant visual information and detects the most relevant parts of our visual field. Automatic determination of the most visually relevant areas would be useful in many applications such as image and video coding, watermarking, video browsing, and quality assessment. Many research groups are currently investigating computational modeling of the visual attention system. The first published computational models have been based on some basic and well-understood human visual system (HVS) properties. These models feature a single perceptual layer that simulates only one aspect of the visual system. More recent models integrate complex features of the HVS and simulate hierarchical perceptual representation of the visual input. The bottom-up mechanism is the most occurring feature found in modern models. This mechanism refers to involuntary attention (i.e., salient spatial visual features that effortlessly or involuntary attract our attention). This paper presents a coherent computational approach to the modeling of the bottom-up visual attention. This model is mainly based on the current understanding of the HVS behavior. Contrast sensitivity functions, perceptual decomposition, visual masking, and center-surround interactions are some of the features implemented in this model. The performances of this algorithm are assessed by using natural images and experimental measurements from an eye-tracking system. Two adequate well-known metrics (correlation coefficient and Kullbacl-Leibler divergence) are used to validate this model. A further metric is also defined. The results from this model are finally compared to those from a reference bottom-up model.", "doc-2": "To explore the world around us, we move without cease our eyes altering between rapid movements, saccades, and immobile moments, fixations. What factors guide these eye movements ? How to interpret and evaluate quantitatively them ? This thesis addressed these problems in the context of free viewing of natural scenes according two aspects : modeling and behavioural data recording with eye movements experiments. The proposed model was inspired mainly by the biology of the human visual system and predicted the salient regions (which attract the eyes) by using some lowlevel visual features according to the bottom-up architecture, which is compatible with the context of free viewing of natural scenes. Even though considering static scenes, we also proposed a spatio-temporal model to take into account temporal sequences of stabilization phases during fixations and movement phases during saccades. The behavioural and physiological data helped to build, improve successively and validate the model. We presented that although colour was often used in most models in the literature, it had little influence on subjects eye movements. We also showed that programming several saccades in parallel from a fixation point, which had been observed in the context of visual search, was not compatible with the experimental data. This thesis also described several methodological tools to compare experimental data with the data predicted by the model and proposed a method to evaluate the relative contributions of low-level visual features to the prediction of eye movements.", "label": 1}
{"doc-1": "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes.", "doc-2": "BackgroundIn developing countries, many cases with rare neurological diseases remain undiagnosed due to limited diagnostic experience. We encountered a case in China where two siblings both began to develop idiopathic progressive cognitive decline starting from age six, and were suspected to have an undiagnosed neurological disease.MethodsInitial clinical assessments included review of medical history, comprehensive physical examination, genetic testing for metabolic diseases, blood tests and brain imaging. We performed exome sequencing with Agilent SureSelect exon capture and Illumina HiSeq2000 platform, followed by variant annotation and selection of rare, shared mutations that fit a recessive model of inheritance. To assess functional impacts of candidate variants, we performed extensive biochemical tests in blood and urine, and examined their possible roles by protein structure modeling.ResultsExome sequencing identified NAGLU as the most likely candidate gene with compound heterozygous mutations (chr17:40695717C>T and chr17:40693129A>G in hg19 coordinate), which were documented to be pathogenic. Sanger sequencing confirmed the recessive patterns of inheritance, leading to a genetic diagnosis of Sanfilippo syndrome (mucopolysaccharidosis IIIB). Biochemical tests confirmed the complete loss of activity of alpha-N-acetylglucosaminidase (encoded by NAGLU) in blood, as well as significantly elevated dermatan sulfate and heparan sulfate in urine. Structure modeling revealed the mechanism on how the two variants affect protein structural stability.ConclusionsSuccessful diagnosis of a rare genetic disorder with an atypical phenotypic presentation confirmed that such genotype-first approaches can particularly succeed in areas of the world with insufficient medical genetics expertise and with cost-prohibitive in-depth phenotyping.", "label": 1}
{"doc-1": "Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist prolific patterns and/or long patterns.In this study, we propose a novel frequent pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a highly condensed, much smaller data structure, which avoids costly, repeated database scans, (2) our FP-tree-based mining adopts a pattern fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. Our performance study shows that the FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent pattern mining methods.", "doc-2": "Weighted association rule mining reflects semantic significance of item by considering its weight. Classification extracts set of rules and constructs a classifier to predict the new data instance. This paper proposes compact weighted associative classification method, which integrates weighted association rule mining and classification for constructing an efficient weighted associative classifier. Compact weighted associative classification algorithm randomly chooses one non class attribute from dataset and all the weighted class association rules are generated based on that attribute. The weight of the item is considered as one of the parameter in generating the weighted class association rules. In this proposed work, weight of item is computed by considering quality of the transaction using link based model. Experimental results show that the proposed system generates less number of high quality rules.", "label": 1}
{"doc-1": "The EM algorithm performs maximum likelihood estimation for data in which some variables are unobserved. We present a function that resembles negative free energy and show that the M step maximizes this function with respect to the model parameters and the E step maximizes it with respect to the distribution over the unobserved variables. From this perspective, it is easy to justify an incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step. This variant is shown empirically to give faster convergence in a mixture estimation problem. A variant of the algorithm that exploits sparse conditional distributions is also described, and a wide range of other variant algorithms are also seen to be possible.", "doc-2": "Salojrvi, J. (2008): Inferring Relevance from Eye Movements with Wrong Models. Doctoral thesis, Helsinki University of Technology, Dissertations in Information and Computer Science, TKK-ICS-D8, Espoo, Finland.", "label": 1}
{"doc-1": "The increase in the number of large data sets and the complexity of current probabilistic sequence evolution models necessitates fast and reliable phylogeny reconstruction methods. We describe a new approach, based on the maximum- likelihood principle, which clearly satisfies these requirements. The core of this method is a simple hill-climbing algorithm that adjusts tree topology and branch lengths simultaneously. This algorithm starts from an initial tree built by a fast distance-based method and modifies this tree to improve its likelihood at each iteration. Due to this simultaneous adjustment of the topology and branch lengths, only a few iterations are sufficient to reach an optimum. We used extensive and realistic computer simulations to show that the topological accuracy of this new method is at least as high as that of the existing maximum-likelihood programs and much higher than the performance of distance-based and parsimony approaches. The reduction of computing time is dramatic in comparison with other maximum-likelihood packages, while the likelihood maximization ability tends to be higher. For example, only 12 min were required on a standard personal computer to analyze a data set consisting of 500 rbcL sequences with 1,428 base pairs from plant plastids, thus reaching a speed of the same order as some popular distance-based and parsimony algorithms. This new method is implemented in the PHYML program, which is freely available on our web page: http://www.lirmm.fr/w3ifa/MAAS/.", "doc-2": "A survey of the endohelminth fauna of Indo-West Pacific Lutjanidae (Perciformes) revealed the presence of the species Siphoderina manilensis (Velasquez, 1961) Miller & Cribb, 2008 and S. marina (Hafeezullah & Siddiqi, 1970) Miller & Cribb, 2008 in seven Lutjanus spp. from sites off the Great Barrier Reef, the Maldives, New Caledonia and Ningaloo Reef, Western Australia. A combination of morphological and ribosomal DNA analyses of these cryptogonimids prompted the transfer of these taxa to a new genus, Euryakaina n. g., as E. manilensis n. comb. and E. marina n. comb., based on comparative analysis with other cryptogonimid taxa. Euryakaina n. g. is distinguished from all other cryptogonimid genera by the combination of a fusiform body, the few relatively small, widely spaced oral spines (sometimes absent), a highly lobed ovary, opposite to slightly oblique testes, vitelline follicles that extend from the anterior margin of the testes to slightly posterior to the intestinal bifurcation, and an excretory vesicle that bifurcates dorsal to the ovary and reunites briefly slightly posterior to the intestinal bifurcation. Morphometric analysis of these taxa alone suggests they should be reduced to synonymy, but DNA sequence analyses and ecological niche partitioning provide evidence that they form a cryptic species complex in sympatric lutjanids in the Indo-West Pacific. The secondary structure of the ITS2 rDNA for species of Euryakaina was also modelled and analysed for the presences of compensatory base changes (CBCs) or hemi-CBCs in order to explore the usefulness of these changes as a tool to help elucidate the taxonomy of this complex system. We also report what we interpret here as intraspecific variation in the ITS2 rDNA between individuals of E. manilensis from Lutjanus vitta recovered off the Great Barrier Reef and New Caledonia.", "label": 1}
{"doc-1": "We have presented recommendations for the optimum acquisition of quantitative two-dimensional data in the current echocardiographic environment. It is likely that advances in imaging may enhance or supplement these approaches. For example, three-dimensional reconstruction methods may greatly augment the accuracy of volume determination if they become more efficient. The development of three-dimensional methods will depend in turn on vastly improved transthoracic resolution similar to that now obtainable by transesophageal echocardiography. Better resolution will also make the use of more direct methods of measuring myocardial mass practical. For example, if the epicardium were well resolved in the long-axis apical views, the myocardial shell volume could be measured directly by the biplane method of discs rather than extrapolating myocardial thickness from a single short-axis view. At present, it is our opinion that current technology justifies the clinical use of the quantitative two-dimensional methods described in this article. When technically feasible, and if resources permit, we recommend the routine reporting of left ventricular ejection fraction, diastolic volume, mass, and wall motion score.", "doc-2": "Diastolic dysfunction is usually identified by the combination of characteristic mitral and pulmonary vein flow patterns. However, obtaining a complete set of echocardiographic parameters can be technically difficult and data may conflict. We hypothesized that as a stand-alone variable, (ventricular) diastolic dominant pulmonary vein flow would predict heart failure (HF) hospitalizations and cardiovascular death. Standard transthoracic echocardiograms were obtained in 906 subjects from the Heart and Soul Study, a prospective study of the effects of depression on coronary heart disease. Pulmonary vein flow pattern was determined using the dominant velocity-time integral. Cardiac events were determined by 2 independent adjudicators, and Cox proportional hazards models were used. Systolic dominant pulmonary vein flow was present in 89% of subjects, and diastolic dominant, in the remaining 11%. During an average 4.1 years of follow-up, subjects with diastolic dominant pulmonary vein flow had a 25% rate of HF hospitalization and 9% rate of cardiovascular death. After multivariate adjustment including left ventricular ejection fraction, diastolic pulmonary vein flow was associated with a 3-fold risk of HF hospitalization (p = 0.001) and a 2-fold risk of HF hospitalization or death (p = 0.004). In conclusion, diastolic dominant pulmonary vein flow pattern was a stand-alone predictor of adverse cardiac events, and its presence was associated with significantly higher rates of HF hospitalizations and cardiovascular death.", "label": 1}
{"doc-1": "UNLABELLEDResearch over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.AVAILABILITYhttp://www.broad.mit.edu/mpg/haploview/CONTACTjcbarret@broad.mit.edu", "doc-2": "BACKGROUNDWe examined host genetic factors to identify those more common in individuals whose human papillomavirus (HPV) infections were most likely to persist and progress to cervical intraepithelial neoplasia grade 3 (CIN3) and cancer.METHODSWe genotyped 92 single-nucleotide polymorphisms (SNPs) from 49 candidate immune response and DNA repair genes obtained from 469 women with CIN3 or cancer, 390 women with persistent HPV infections (median duration, 25 months), and 452 random control subjects from the 10,049-woman Guanacaste Costa Rica Natural History Study. We calculated odds ratios and 95% confidence intervals (CIs) for the association of SNP and haplotypes in women with CIN3 or cancer and HPV persistence, compared with random control subjects.RESULTSA SNP in the Fanconi anemia complementation group A gene (FANCA) (G501S) was associated with increased risk of CIN3 or cancer. The AG and GG genotypes had a 1.3-fold (95% CI, 0.95-1.8-fold) and 1.7-fold (95% CI, 1.1-2.6-fold) increased risk for CIN3 or cancer, respectively (P(trend) = .008; referent, AA). The FANCA haplotype that included G501S also conferred increased risk of CIN3 or cancer, as did a different haplotype that included 2 other FANCA SNPs (G809A and T266A). A SNP in the innate immune gene IRF3 (S427T) was associated with increased risk for HPV persistence (P(trend) = .009).CONCLUSIONSOur results require replication but support the role of FANCA variants in cervical cancer susceptibility and of IRF3 in HPV persistence.", "label": 1}
{"doc-1": "Abstract We suggest a means of obtaining certain Green's functions in 3+1-dimensional N =4 supersymmetric Yang-Mills theory with a large number of colors via non-critical string theory. The non-critical string theory is related to critical string theory in anti-deSitter background. We introduce a boundary of the anti-deSitter space analogous to a cut-off on the Liouville coordinate of the two-dimensional string theory. Correlation functions of operators in the gauge theory are related to the dependence of the supergravity action on the boundary conditions. From the quadratic terms in supergravity we read off the anomalous dimensions. For operators that couple to massless string states it has been established through absorption calculations that the anomalous dimensions vanish, and we rederive this result. The operators that couple to massive string states at level n acquire anomalous dimensions that grow as 2 ng YM 2N 1/2 for large `t Hooft coupling. This is a new prediction about the strong coupling behavior of large N SYM theory.", "doc-2": "The enhancon mechanism is a specific phenomenon in string theory which resolves a certain naked spacetime singularity arising in the supergravity description related to N = 2 supersymmetric pure gauge theory. After reviewing the problem of singularities in general relativity as well as in string theory, and discussing the prototypical enhancon example constructed by wrapping D6-branes on a K3 surface, the thesis presents three generalisations to this static spherically symmetric case pertaining to large N SU{N) gauge theory. First we will use orientifolds to show how the enhancon mechanism also works in similar situations related to SO(2N + 1), USp(2N) and SO{2N) gauge theories. Second we will wrap D-brane distributions on K3 to obtain the enhancon in oblate, toroidal and prolate shapes. Third we will study a rotating enhancon configuration and consider its implications for the black hole entropy and the second law of thermodynamics.", "label": 1}
{"doc-1": "We describe a model-based clustering method for using multilocus genotype data to infer population structure and assign individuals to populations. We assume a model in which there are K populations (where K may be unknown), each of which is characterized by a set of allele frequencies at each locus. Individuals in the sample are assigned (probabilistically) to populations, or jointly to two or more populations if their genotypes indicate that they are admixed. Our model does not assume a particular mutation process, and it can be applied to most of the commonly used genetic markers, provided that they are not closely linked. Applications of our method include demonstrating the presence of population structure, assigning individuals to populations, studying hybrid zones, and identifying migrants and admixed individuals. We show that the method can produce highly accurate assignments using modest numbers of loci-e.g. , seven microsatellite loci in an example using genotype data from an endangered bird species. The software used for this article is available from http://www.stats.ox.ac.uk/ approximately pritch/home. html.", "doc-2": "Ginger is a vegetable with medicinal and culinary properties widely cultivated in the Southern and Southeastern Brazil. The knowledge of ginger species genetic variability is essential to direct correctly future studies of conservation and genetic improvement, but in Brazil, little is known about this species genetic variability. In this study, we analyzed the genetic diversity and structure of 55 Brazilian accessions and 6 Colombian accessions of ginger, using AFLP (Amplified Fragment Length Polymorphism) molecular markers. The molecular characterization was based on 13 primers combinations, which generated an average of 113.5 polymorphic loci. The genetic diversity estimates of Nei (Hj), ShannonWeiner index (I) and an effective number of alleles (ne) were greater in the Colombian accessions in relation to the Brazilian accessions. The analysis of molecular variance showed that most of the genetic variation occurred between the two countries while in the Brazilian populations there is no genetic structure and probably each region harbors 100% of genetic variation found in the samples. The bayesian model-based clustering and the dendrogram using the dissimilaritys coefficient of Jaccard were congruent with each other and showed that the Brazilian accessions are highly similar between themselves, regardless of the geographic region of origin. We suggested that the exploration of the interspecific variability and the introduction of new varieties of Z.officinale are viable alternatives for generating diversity in breeding programs in Brazil. The introduction of new genetic materials will certainly contribute to a higher genetic basis of such crop.", "label": 1}
{"doc-1": "Generalized gradient approximations (GGAs) for the exchange-correlation energy improve upon the local spin density (LSD) description of atoms, molecules, and solids. We present a simple derivation of a simple GGA, in which all parameters (other than those in LSD) are fundamental constants. Only general features of the detailed construction underlying the Perdew-Wang 1991 (PW91) GGA are invoked. Improvements over PW91 include an accurate description of the linear response of the uniform electron gas, correct behavior under uniform scaling, and a smoother potential. [S0031-9007(96)01479-2] PACS numbers: 71.15.Mb, 71.45.Gm Kohn-Sham density functional theory [1,2] is widely used for self-consistent-field electronic structure calculations of the ground-state properties of atoms, molecules, and solids. In this theory, only the exchange-correlation energy EXC  EX 1 EC as a functional of the electron spin densities n\"srd and n#srd must be approximated. The most popular functionals have a form appropriate for slowly varying densities: the local spin density (LSD) approximation Z d 3 rn e unif", "doc-2": "The topological aspects of electrons in solids can emerge in real materials, as represented by topological insulators. In theory, they show a variety of new magneto-electric phenomena, and especially the ones hosting superconductivity are strongly desired as candidates for topological superconductors. While efforts have been made to develop possible topological superconductors by introducing carriers into topological insulators, those exhibiting indisputable superconductivity free from inhomogeneity are very few. Here we report on the observation of topologically protected surface states in a centrosymmetric layered superconductor, -PdBi2, by utilizing spin- and angle-resolved photoemission spectroscopy. Besides the bulk bands, several surface bands are clearly observed with symmetrically allowed in-plane spin polarizations, some of which crossing the Fermi level. These surface states are precisely evaluated to be topological, based on the Z2 invariant analysis in analogy to three-dimensional strong topological insulators. -PdBi2 may offer a solid stage to investigate the topological aspect in the superconducting condensate.", "label": 1}
{"doc-1": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.", "doc-2": "OBJECTIVEOptical techniques for recording and manipulating neural activity have traditionally been constrained to superficial brain regions due to light scattering. New techniques are needed to extend optical access to large 3D volumes in deep brain areas, while retaining local connectivity.APPROACHWe have developed a method to implant bundles of hundreds or thousands of optical microfibers, each with a diameter of 8 m. During insertion, each fiber moves independently, following a path of least resistance. The fibers achieve near total internal reflection, enabling optically interfacing with the tissue near each fiber aperture.MAIN RESULTSAt a depth of 3mm, histology shows fibers consistently splay over 1mm in diameter throughout the target region. Immunohistochemical staining after chronic implants reveals neurons in close proximity to the fiber tips. Models of photon fluence indicate that fibers can be used as a stimulation light source to precisely activate distinct patterns of neurons by illuminating a subset of fibers in the bundle. By recording fluorescent beads diffusing in water, we demonstrate the recording capability of the fibers.SIGNIFICANCEOur histology, modeling and fluorescent bead recordings suggest that the optical microfibers may provide a minimally invasive, stable, bidirectional interface for recording or stimulating genetic probes in deep brain regions-a hyper-localized form of fiber photometry.", "label": 1}
{"doc-1": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade.", "doc-2": "High-resolution Synthetic Aperture Radar (SAR) data represent an essential resource for the extraction of Ground Control Points (GCP) with sub-metric accuracy without in situ measurement campaigns. Conceptually, SAR-based GCP extraction consists of the following two steps: (i) identification of the same local feature on more SAR images and determination of their range/azimuth coordinates; (ii) spatial 3D positioning retrieval from the 2D radar coordinates, through spatial triangulation (stereo analysis) and inversion methods. In order to boost the geolocation accuracy, SAR images must be acquired from different line of sights, with intersection angles typically wider than 10 degrees, or even in opposite looking directions. In the present study, we present an algorithm specifically designed for ensuring robustness and accuracy in the fully automatic detection of bright isolated targets (steel light poles or towers) even when dealing with opposite looking data takes. In particular, the popular Harris algorithm has been selected as detector because it is the most stable and robust-to-noise algorithm for corners detection on SAR images. We outline the designed algorithmic solution and discusses the results derived over the urban area of Pisa (Italy), where more than ten COSMO-SkyMed Enhanced Spotlight (ES) stereo images are available, thus resulting an optimal test site for an assessment of the performances of the processing chain. The experimental analysis proofs that, assumed timing has been properly recalibrated, we are capable to automatically extract GCP from CSK ES data takes consisting in a very limited number of images.", "label": 1}
{"doc-1": "This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.", "doc-2": "Development of patellofemoral pain syndrome (PFPS) is considered to be multifactorial. The aims of this systematic review were to (i) summarise and critique the body of literature addressing kinematic gait characteristics associated with PFPS; and (ii) provide recommendations for future research addressing kinematic gait characteristics associated with PFPS. A comprehensive search of MEDLINE, EMBASE, CINAHL, and Current Contents revealed 561 citations for review. Each citation was assessed for inclusion and quality using a modified version of the 'Quality Index' and a novel inclusion/exclusion criteria checklist by two independent reviewers. A total of 24 studies were identified. No prospective studies with adequate data to complete effect size calculations were found. Quality of included case-control studies varied, with a number of methodological issues identified. Heterogeneity between studies made meta-analysis inappropriate. Reductions in gait velocity were indicated during walking, ramp negotiation, and stair negotiation in individuals with PFPS. Findings indicated delayed timing of peak rearfoot eversion and increased rearfoot eversion at heel strike transient during walking; and delayed timing of peak rearfoot eversion, increased rearfoot eversion at heel strike, reduced rearfoot eversion range, greater knee external rotation at peak knee extension moment, and greater hip adduction during running in individuals with PFPS. There is a clear need for prospective evaluation of kinematic gait characteristics in a PFPS population to distinguish between cause and effect. Where possible, future PFPS case-control studies should consider evaluating kinematics of the knee, hip and foot/ankle simultaneously with larger participant numbers. Completing between sex comparisons when practical and considering spatiotemporal gait characteristics during methodological design and data analysis is also recommended.", "label": 1}
{"doc-1": "Table of", "doc-2": "Ten new extensive quantities that appear to be independent of stressenergy, but that analogously characterize the physical state of an electromagnetic field, are exhibited and are shown to be conserved in vacuum because of Maxwell's equations. These new quantities are shown to be capable of retrograde flow in a circularly polarized planewave field.", "label": 1}
{"doc-1": "The activity of the DAF-2 insulin-like receptor is required for Caenorhabditis elegans reproductive growth and normal adult life span. Informatic analysis identified 37 C. elegans genes predicted to encode insulin-like peptides. Many of these genes are divergent insulin superfamily members, and many are clustered, indicating recent diversification of the family. The ins genes are primarily expressed in neurons, including sensory neurons, a subset of which are required for reproductive development. Structural predictions and likely C-peptide cleavage sites typical of mammalian insulins suggest that ins-1 is most closely related to insulin. Overexpression of ins-1, or expression of human insulin under the control of ins-1 regulatory sequences, causes partially penetrant arrest at the dauer stage and enhances dauer arrest in weak daf-2 mutants, suggesting that INS-1 and human insulin antagonize DAF-2 insulin-like signaling. A deletion of the ins-1 coding region does not enhance or suppress dauer arrest, indicating a functional redundancy among the 37 ins genes. Of five other ins genes tested, the only other one bearing a predicted C peptide also antagonizes daf-2 signaling, whereas four ins genes without a C peptide do not, indicating functional diversity within the ins family.", "doc-2": "Nutrients are necessary for life, as they are a crucial requirement for biological processes including reproduction, somatic growth, and tissue maintenance. Therefore, signaling systems involved in detecting and interpreting nutrient or energy levels-most notably, the insulin/insulin-like growth factor 1 (IGF-1) signaling pathway, mechanistic target of rapamycin (mTOR), and adenosine monophosphate-activated protein kinase (AMPK)-play important roles in regulating physiological decisions to reproduce, grow, and age. In this review, we discuss the connections between reproductive senescence and somatic aging and give an overview of the involvement of nutrient-sensing pathways in controlling both reproductive function and lifespan. Although the molecular mechanisms that affect these processes can be influenced by distinct tissue-, temporal-, and pathway-specific signaling events, the progression of reproductive aging and somatic aging is systemically coordinated by integrated nutrient-sensing signaling pathways regulating somatic tissue maintenance in conjunction with reproductive capacity.", "label": 1}
{"doc-1": "Functional annotation of proteins is a fundamental problem in the post-genomic era. The recent availability of protein interaction networks for many model species has spurred on the development of computational methods for interpreting such data in order to elucidate protein function. In this review, we describe the current computational approaches for the task, including direct methods, which propagate functional information through the network, and module-assisted methods, which infer functional modules within the network and use those for the annotation task. Although a broad variety of interesting approaches has been developed, further progress in the field will depend on systematic evaluation of the methods and their dissemination in the biological community.", "doc-2": "Assigning biological functions to uncharacterized proteins is a fundamental problem in the postgenomic era. The increasing availability of large amounts of data on protein-protein interactions (PPIs) has led to the emergence of a considerable number of computational methods for determining protein function in the context of a network. These algorithms, however, treat each functional class in isolation and thereby often suffer from the difficulty of the scarcity of labeled data. In reality, different functional classes are naturally dependent on one another. We propose a new algorithm, Multi-label Correlated Semi-supervised Learning (MCSL), to incorporate the intrinsic correlations among functional classes into protein function prediction by leveraging the relationships provided by the PPI network and the functional class network. The guiding intuition is that the classification function should be sufficiently smooth on subgraphs where the respective topologies of these two networks are a good match. We encode this intuition as regularized learning with intraclass and interclass consistency, which can be understood as an extension of the graph-based learning with local and global consistency (LGC) method. Cross validation on the yeast proteome illustrates that MCSL consistently outperforms several state-of-the-art methods. Most notably, it effectively overcomes the problem associated with scarcity of label data. The supplementary files are freely available at http://sites.google.com/site/csaijiang/MCSL.", "label": 1}
{"doc-1": "From the Publisher: Probabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertaintyand offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognitionin short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. Probabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability.", "doc-2": "The sparse information captured by the sensory systems is used by the brain to apprehend the environment, for example, to spatially locate the source of audiovisual stimuli. This is an ill-posed inverse problem whose inherent uncertainty can be solved by jointly processing the information, as well as introducing constraints during this process, on the way this multisensory information is handled. This process and its result--the percept--depend on the contextual conditions perception takes place in. To date, perception has been investigated and modeled on the basis of either one of two of its dimensions: the percept or the temporal dynamics of the process. Here, we extend our previously proposed audiovisual perception model to predict both these dimensions to capture the phenomenon as a whole. Starting from a behavioral analysis, we use a data-driven approach to elicit a bayesian network which infers the different percepts and dynamics of the process. Context-specific independence analyses enable us to use the model's structure to directly explore how different contexts affect the way subjects handle the same available information. Hence, we establish that, while the percepts yielded by a unisensory stimulus or by the non-fusion of multisensory stimuli may be similar, they result from different processes, as shown by their differing temporal dynamics. Moreover, our model predicts the impact of bottom-up (stimulus driven) factors as well as of top-down factors (induced by instruction manipulation) on both the perception process and the percept itself.", "label": 1}
{"doc-1": "This paper attempts to explain how the separation of security ownership and control, typical of large corporations, can be an efficient form of economic organization. We first set aside the presumption that a corporation has owners in any meaningful sense. The entrepreneur is also laid to rest, at least for the purposes of the large modern corporation. The two functions usually attributed to the entrepreneur-management and risk bearing-are treated as naturally separate factors within the set of contracts called a firm. The firm is disciplined by competition from other firms, which forces the evolution of devices for efficiently monitoring the performance of the entire team and of its individual members. Individual participants in the firm, and in particular its managers, face both the discipline and opportunities provided by the markets for their services, both within and outside the firm.", "doc-2": "This paper assesses the extent of corporate governance voluntary disclosure and the impact of a comprehensive set of corporate governance (CG) attributes (board composition, board size, CEO duality, director ownership, blockholder ownership and the existence of audit committee) on the extent of corporate governance voluntary disclosure in Egypt. The measurement of disclosure is based on published data created from a checklist developed by the United Nations, which was gathered from a manual review of financial statements and websites of a sample of Egyptian companies listed on Egyptian Stock Exchange (EGX). Although the levels of CG disclosure are found to be minimal, disclosure is high for items that are mandatory under the Egyptian Accounting Standards (EASs). The failure of companies to disclose such information clearly shows some ineffectiveness and inadequacy in the regulatory framework in Egypt. Moreover, the phenomenon of non-compliance may also be attributed to socio-economic factors in Egypt. Therefore, it is expected that Egyptian firms will take a long time to appraise the payback of increased CG disclosure. The findings indicate that thatceteris paribusthe extent of CG disclosure is (1) lower for companies with duality in position and higher ownership concentration as measured by blockholder ownership; and (2) increases with the proportion of independent directors on the board and firm size. The results of the study support theoretical arguments that companies disclose corporate governance information in order to reduce information asymmetry and agency costs and to improve investor confidence in the reported accounting information. The empirical evidence from this study enhances the understanding of the corporate governance disclosure environment in Egypt as one of the emerging markets in the Middle East.", "label": 1}
{"doc-1": "In modern face recognition, the conventional pipeline consists of four stages: detect => align => represent => classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4, 000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27%, closely approaching human-level performance.", "doc-2": "Face recognition is one research area that has benefited from the recent popularity of deep learning, namely the convolutional neural network (CNN) model. Nevertheless, the recognition performance is still compromised by the models dependency on the scale of input images and the limited number of feature maps in each layer of the network. To circumvent these issues, we propose PSI-CNN, a generic pyramid-based scale-invariant CNN architecture which additionally extracts untrained feature maps across multiple image resolutions, thereby allowing the network to learn scale-independent information and improving the recognition performance on low resolution images. Experimental results on the LFW dataset and our own CCTV database show PSI-CNN consistently outperforming the widely-adopted VGG face model in terms of face matching accuracy.", "label": 1}
{"doc-1": "The goals of this article are to (a) describe differences between moderator and mediator effects; (b) provide nontechnical descriptions of how to examine each type of effect, including study design, analysis, and interpretation of results; (c) demonstrate how to analyze each type of effect; and (d) provide suggestions for further reading. The authors focus on the use of multiple regression because it is an accessible data-analytic technique contained in major statistical packages. When appropriate, they also note limitations of using regression to detect moderator and mediator effects and describe alternative procedures, particularly structural equation modeling. Finally, to illustrate areas of confusion in counseling psychology research, they review research testing moderation and mediation that was published in the Journal of Counseling Psychology during 2001.", "doc-2": "This study targeted college students to determine the moderating effect of immersion in the relationship among stress, satisfaction with life, and satisfaction with college life. To this end, the level of stress, satisfaction with life, satisfaction with college life, and immersion were measured in353 students attending S University. First of all, correlation analysis showed that stress had a negative correlation with immersion, satisfaction with life, and satisfaction with college life and immersion had a positive correlation with satisfaction with life and satisfaction with college life. Hierarchical regression analysis was conducted to determine the moderating effects of immersion in the relationship among stress, satisfaction with life, and satisfaction with college life. The results showed that immersion had a moderating effect on the relationship between stress and satisfaction with life, while immersion did not have a mitigating effect on the relationship between stress and satisfaction with college life. Based on these findings, this paper suggests raising the ability of immersion as a measure of intervention in handling the stress of college students and discusses the significance and limitations of this study.", "label": 1}
{"doc-1": "NAMD is a parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems. NAMD scales to hundreds of processors on high-end parallel platforms, as well as tens of processors on low-cost commodity clusters, and also runs on individual desktop and laptop computers. NAMD works with AMBER and CHARMM potential functions, parameters, and file formats. This article, directed to novices as well as experts, first introduces concepts and methods used in the NAMD program, describing the classical molecular dynamics force field, equations of motion, and integration methods along with the efficient electrostatics evaluation algorithms employed and temperature and pressure controls used. Features for steering the simulation across barriers and for calculating both alchemical and conformational free energy differences are presented. The motivations for and a roadmap to the internal design of NAMD, implemented in C++ and based on Charm++ parallel objects, are outlined. The factors affecting the serial and parallel performance of a simulation are discussed. Finally, typical NAMD use is illustrated with representative applications to a small, a medium, and a large biomolecular system, highlighting particular features of NAMD, for example, the Tcl scripting language. The article also provides a list of the key features of NAMD and discusses the benefits of combining NAMD with the molecular graphics/sequence analysis software VMD and the grid computing/collaboratory software BioCoRE. NAMD is distributed free of charge with source code at www.ks.uiuc.edu.", "doc-2": "Atypical antipsychotic drugs, such as clozapine and risperidone, have a high affinity for the serotonin 5-HT(2A) G protein-coupled receptor (GPCR), the 2AR, which signals via a G(q) heterotrimeric G protein. The closely related non-antipsychotic drugs, such as ritanserin and methysergide, also block 2AR function, but they lack comparable neuropsychological effects. Why some but not all 2AR inhibitors exhibit antipsychotic properties remains unresolved. We now show that a heteromeric complex between the2AR and the G(i)-linked GPCR, metabotropic glutamate 2 receptor (mGluR2), integrates ligand input,modulating signaling output and behavioral changes. Serotonergic and glutamatergic drugs bind the mGluR2/2AR heterocomplex, which then balances Gi- and Gq-dependent signaling. We find that the mGluR2/2AR-mediated changes in Gi and Gq activity predict the psychoactive behavioral effects of a variety of pharmocological compounds. These observations provide mechanistic insight into antipsychotic action that may advance therapeutic strategies for disorders including schizophrenia and dementia.", "label": 1}
{"doc-1": "The Protein Data Bank [PDB; Berman, Westbrook et al. (2000), Nucleic Acids Res. 28, 235-242; http://www.pdb.org/] is the single worldwide archive of primary structural data of biological macromolecules. Many secondary sources of information are derived from PDB data. It is the starting point for studies in structural bioinformatics. This article describes the goals of the PDB, the systems in place for data deposition and access, how to obtain further information and plans for the future development of the resource. The reader should come away with an understanding of the scope of the PDB and what is provided by the resource.", "doc-2": "Normal mode analyses of homologous proteins at the family and superfamily level show that slow dynamics are similar and are preserved through evolution. This study investigates how the slow dynamics of proteins is affected by variation in the protein architecture and fold. For this purpose, we have used computer-generated protein models based on idealized protein structures with varying folds. These are shown to be protein-like in their behavior, and they are used to investigate the influence of architecture and fold on the slow dynamics. We compared the dynamics of models having different folds but similar architecture and found the architecture to be the dominant factor for the slow dynamics.", "label": 1}
{"doc-1": "The mediators and cellular effectors of inflammation are important constituents of the local environment of tumours. In some types of cancer, inflammatory conditions are present before a malignant change occurs. Conversely, in other types of cancer, an oncogenic change induces an inflammatory microenvironment that promotes the development of tumours. Regardless of its origin, 'smouldering' inflammation in the tumour microenvironment has many tumour-promoting effects. It aids in the proliferation and survival of malignant cells, promotes angiogenesis and metastasis, subverts adaptive immune responses, and alters responses to hormones and chemotherapeutic agents. The molecular pathways of this cancer-related inflammation are now being unravelled, resulting in the identification of new target molecules that could lead to improved diagnosis and treatment.", "doc-2": "The tumour microenvironment (TME) represents a dynamic network that plays an important role in tumour initiation, proliferation, growth, and metastasis. Cell behaviour may be regulated by interplay of molecular interactions involving positive and negative reinforcement as well as a high level of cross-talk, which determines this system. Additionally, cancer involves cell proliferation, its malignancy defined by the tumours ability to break down normal tissue architecture and by a dynamic process of invasion and metastasis. The metastatic cascade is regulated by a chain of molecular steps which triggers the progression of the developing cancer cell in the primary tumour into a number of transformations, leading to invasion and proceeding to metastases. Tumour-associated macrophages (TAMs) play a key-role in the progression from inflammatory conditions to cancer; TAMs are also capable of infiltrating the tumour microenvironment. Furthermore, myeloid-derived suppressor cells (MDSCs), a population of inhibitory immune cells, have been reported to increase in various cancer types, although characterising human MDSCs remains difficult, as their phenotype is quite variable. The future of cancer treatment is likely to involve creating more drugs that target these elements as well as others. An overview of the tumours microenvironment is, therefore, presented in this paper, focusing on the metastatic pathways of primary colorectal cancer to the liver.", "label": 1}
{"doc-1": "BackgroundThe number of prokaryotic genome sequences becoming available is growing steadily and is growing faster than our ability to accurately annotate them.DescriptionWe describe a fully automated service for annotating bacterial and archaeal genomes. The service identifies protein-encoding, rRNA and tRNA genes, assigns functions to the genes, predicts which subsystems are represented in the genome, uses this information to reconstruct the metabolic network and makes the output easily downloadable for the user. In addition, the annotated genome can be browsed in an environment that supports comparative analysis with the annotated genomes maintained in the SEED environment.The service normally makes the annotated genome available within 1224 hours of submission, but ultimately the quality of such a service will be judged in terms of accuracy, consistency, and completeness of the produced annotations. We summarize our attempts to address these issues and discuss plans for incrementally enhancing the service.ConclusionBy providing accurate, rapid annotation freely to the community we have created an important community resource. The service has now been utilized by over 120 external users annotating over 350 distinct genomes.", "doc-2": "Enterococci are lactic acid bacteria that are commonly found in food and in animal gut. Since 16S ribosomal RNA (rRNA) sequences, genetic markers for bacterial identification, are similar among several Enterococcus species, it is very difficult to determine the correct species based on only 16S rRNA sequences. Therefore, we developed a rapid method for the identification of different Enterococcus species using comparative genomics. We compared 38 genomes of 13 Enterococcus species retrieved from the National Center of Biotechnology Information database and identified 25,623 orthologs. Among the orthologs, four genes were specific to four Enterococcus species (Enterococcus faecalis, Enterococcus faecium, Enterococcus hirae, and Enterococcus durans). We designed species-specific primer sets targeting the genes and developed a multiplex PCR using primer sets that could distinguish the four Enterococcus species among the nine strains of Enterococcus species that were available locally. The multiplex PCR method also distinguished the four species isolated from various environments, such as feces of chicken and cow, meat of chicken, cow, and pigs, and fermented soybeans (Cheonggukjang and Doenjang). These results indicated that our novel multiplex PCR using species-specific primers could identify the four Enterococcus species in a rapid and easy way. This method will be useful to distinguish Enterococcus species in food, feed, and clinical settings.", "label": 1}
{"doc-1": "The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.", "doc-2": "Oxidant stress has been implicated in the pathogenesis of chronic lung disorders like idiopathic pulmonary fibrosis. However, mechanisms that link oxidant stress to fibrogenesis remain partially elucidated. Emerging data suggest an important role for the extracellular thiol/disulfide redox environment. The cysteine (Cys)/cystine (CySS) redox couple represents the predominant low-molecular-weight thiol/disulfide pool found in plasma and is sensitive to aging, smoking, and other host factors. We hypothesized that an oxidized extracellular Cys/CySS redox potential (E(h) Cys/CySS) affects lung fibroblasts by inducing intracellular signals that stimulate proliferation and matrix expression. We tested this hypothesis in primary murine lung fibroblasts and found that an oxidized E(h) Cys/CySS (-46 mV) stimulated lung fibroblast proliferation. Furthermore, it stimulated their expression of fibronectin, a matrix glycoprotein highly expressed in fibrotic lung diseases and implicated in lung injury. This stimulatory effect was dependent on protein kinase C activation. Oxidant stress also increased the phosphorylation of cAMP response element binding protein, a transcription factor known for its ability to stimulate fibronectin expression, and increased the expression of mRNAs and proteins coding for the transcription factors nuclear factor (NF)-kappaB and mothers against decapentaplegic homolog 3. Fibroblasts cultured in normal (-80 mV) or reduced (-131 mV) E(h) Cys/CySS showed less induction. Furthermore, fibronectin expression in response to an oxidized E(h) Cys/CySS was associated with expression of transforming growth factor-beta1 (TGF-beta1) and was inhibited by an anti-TGF-beta1 antibody and SB-431542, a TGF-beta1 receptor inhibitor. These studies suggest that extracellular oxidant stress activates redox-sensitive pathways that stimulate lung fibroblast proliferation and matrix expression through upregulation of TGF-beta1.", "label": 1}
{"doc-1": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.", "doc-2": "Recent CNN-based research reveals that the multi-scale information plays an important role in boosting the performance of object detection. There are several network structures proposed to explore an effective multi-scale feature representation. In these structures, the allocation of information in multi-scale representation has a bias toward very few layers. In this paper, we present a novel module named Adaptive Multi-Scale Information Flow (ASIF) to break the bias and find the proper multi-scale representation for each layer. In ASIF, information from different layers in the feature pyramid is weighted and aggregated. The allocation of information is adaptive from each layer to other layers. To ensure both speed and accuracy at the same time, we follow the SSD detection framework and apply ASIF to it. We evaluate the performance of proposed method on PASCAL VOC and MSCOCO datasets. Experiments show that ASIF is superior to many state-of-the-art methods. Given the image size of 320320, the mAP could reach 80.2% (45 FPS) on PASCAL VOC 2007 test, and 29.3% on COCO test-dev2015.", "label": 1}
{"doc-1": "A system of cluster analysis for genome-wide expression data from DNA microarray hybridization is described that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. The output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. We have found in the budding yeast Saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. Thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. Also, coexpression of genes of known function with poorly characterized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently.", "doc-2": "OBJECTIVETo critically examine the feasibility, benefits, and limitations of an inpatient penicillin skin testing service and how pharmacists can be utilized.DATA SOURCESA PubMed search was performed from July 2016 through September 2016 using the following search terms: penicillin skin testing, penicillin allergy, -lactam allergy. Additional references were identified from a review of literature citations.STUDY SELECTION AND DATA EXTRACTIONAll English-language studies assessing the use of penicillin skin testing as well as management and clinical outcomes of patients with a -lactam allergy were evaluated.DATA SYNTHESISThe prevalence of people self-identifying as penicillin allergic ranges from 10% to 20% in the United States. Being improperly labeled as penicillin allergic is associated with higher health care costs, worse clinical outcomes, and an increased prevalence of multidrug-resistant infections. Penicillin skin testing can be a tool used to clarify penicillin allergies and has been demonstrated to be a successful addition to antimicrobial stewardship programs in multiple health care settings. Prior to implementing a penicillin skin testing service, institutions will need to perform a feasibility analysis of who will supply labor and accept the financial burden as well as identify if the positive benefits of a penicillin skin testing service overcome the limitations of this diagnostic test.CONCLUSIONWe conclude that institutions with high percentages of patients receiving non--lactams because of penicillin allergy labels would likely benefit the most from a penicillin skin testing service.", "label": 0}
{"doc-1": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade.", "doc-2": "The last few years have witnessed an explosion in the information about chromosome abnormalities in human sperm and the meiotic events that predispose to these abnormalities. We have determined that all chromosomes are susceptible to nondisjunction, but chromosomes 21 and 22 and, especially, the sex chromosomes have an increased frequency of aneuploidy. Studies are just beginning on the effects of potential mutagens on the chromosomal constitution of human sperm. The effects of pesticides and cancer therapeutic agents have been reviewed. In the last decade, there has been a great impetus to study chromosome abnormalities in sperm from infertile men because the advent of intracytoplasmic sperm injection (ICSI) made it possible for these men to father pregnancies. A large number of studies have demonstrated that infertile men have an increased frequency of chromosomally abnormal sperm and children, even when they have a normal somatic karyotype. Meiotic studies on the pachytene stage of spermatogenesis have demonstrated that infertile men have impaired chromosome synapsis, a significantly decreased frequency of recombination, and an increased frequency of chromosomes completely lacking a recombination site. Such errors make these cells susceptible to meiotic arrest and the production of aneuploid gametes.", "label": 0}
{"doc-1": "DOCUMENT RESUME", "doc-2": "In this article, the optical properties of the In x Ga 1x N/GaN quantum well(QW) are investigated. The refractive index spectrum of a QW is essential to the design and implementation of optoelectronic devices. Yet, the refractive index of the InGaN/GaN QW system over a wide spectral range has been unavailable so far. This article presents a comprehensive model, which includes the excitoneffect and most of the major critical points, to calculate the complex index of refraction of the InGaN/GaN QW at room temperature. The calculations have been performed for QWs with various alloy compositions and well widths in the spectral range from 1 to 9 eV. The model presented here fully considers transitions near the band edge and above barrier gap contributions.", "label": 0}
{"doc-1": "From the Publisher: This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts.", "doc-2": "A 14-year-old boy was admitted with a 1-week history of fatigue, fever, vomiting, and swelling and pain of the ankle. With physical examination, arthritis of the right ankle was diagnosed. The sedimentation rate and C-reactive protein level were 133 mm/hour and 47 mg/I, respectively. Staphylococcus aureus was cultured from blood, joint fluid, and bone. During follow-up, septic arthritis also was observed in the right wrist and left elbow, and osteomyelitis developed in the tibia, mandible, and the 9th to 11th ribs. Computed tomography of the brain was performed to explain his persistent vomiting. During treatment, various antibiotics were used and surgical interventions were performed. He was discharged from the hospital without complications.", "label": 0}
{"doc-1": "", "doc-2": "SUMMARY Moment methods for analysing repeated binary responses using the marginal odds ratio as a measure of association have recently been proposed by several researchers. Using the generalized estimating equation (GEE) methodology, they estimated the regression parameters associated with the expected value of an individual's vector of binary responses. In addition, they estimated the marginal odds ratio between pairs of binary responses. In this paper, we discuss a model for binary time series data where the repeated responses on each individual may be unequally spaced in time. This model allows both the number of observations per individual and the times of measurement to vary between individuals. Our approach is to model the association between the binary responses using serial odds ratio patterns. This model can be thought of as a binary time series analogue of the exponential correlation pattern so commonly assumed for continuous time series data. Parameter estimates are obtained by using the GEE methodology. The model is illustrated with data from an arthritis clinical trial where the response variable is a binary self-assessment measurement.", "label": 0}
{"doc-1": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index.", "doc-2": "Preliminary modeling efforts for the Hanford Site`s Low Level Waste-Performance Assessment (LLW PA) identified {sup 129}I, {sup 237}Np, {sup 79}Se, {sup 99}Tc, and {sup 234},{sup 235},{sup 238}U as posing the greatest potential health hazard. It was also determined that the outcome of these simulations was very sensitive to the parameter describing the extent to which radionuclides sorb to the subsurface matrix, i.e., the distribution coefficient (K{sub d}). The distribution coefficient is a ratio of the radionuclide concentration associated with the solid phase to that in the liquid phase. The objectives of this study were to (1) measure iodine, neptunium, technetium, and uranium K{sub d} values using laboratory conditions similar to those expected at the LLW PA disposal site, and (2) evaluate the effect of selected environmental parameters, such as pH, ionic strength, moisture concentration, and radio nuclide concentration, on K{sub d} values of selected radionuclides. It is the intent of these studies to develop technically defensible K{sub d} values for the PA. The approach taken throughout these studies was to measure the key radio nuclide K{sub d} values as a function of several environmental parameters likely to affect their values. Such an approach provides technical defensibility by identifying the mechanisms responsible for trends in K{sub d} values. Additionally, such studies provide valuable guidance regarding the range of K{sub d} values likely to be encountered in the proposed disposal site.", "label": 0}
{"doc-1": "Simple sugars, oligosaccharides, polysaccharides, and their derivatives, including the methyl ethers with free or potentially free reducing groups, give an orangeyellow color w-hen treated with phenol and concentrated sulfuric acid. The reaction is sensitive and the color is stable. By use of this phenol-sulfuric acid reaction, a method has been developed to determine submicro amounts of sugars and related substances. In conjunction with paper partition chromatography the method is useful for the determination of the composition of polysaccharides and their methyl derivatives.", "doc-2": "Imipenem, a very potent carbapenem derivative beta-lactam antibiotic, has recently found a major place in the treatment of antibiotic-resistant nosocomial infections. However, a convulsive side effect is seen in 0.2-3 percent of patients. Although it is suggested that this effect is due to the inhibition of gamma-aminobutyric acid (GABA) mediated inhibitory transmission, no study has been reported so far showing its effect on the cerebral cortex free inhibitory and excitatory amino acid levels. Twenty-one male TO albino mice were divided into three equal groups and given therapeutic (40 mg/kg/day) or excessive (500 mg/kg/day) doses of Imipenem/cilastatine (I/C) or saline solution intraperitoneally for 7 days. All animals in the excessive dose group showed seizure-like acivity with ataxia and loss of gait. However, no differences in aspartate, glumatate, glycine or GABA levels were seen on gas chromatographic evaluation of the cerebral cortexes of all three groups of animals, which were dispatched on the 7th day. Therefore it is suggested that imipenem exerts its convulsive effect without causing any change in neurotansmitter levels of barin, possibly by effecting the neuronal receptors directly.", "label": 0}
{"doc-1": "Estimates of the worldwide incidence, mortality and prevalence of 26 cancers in the year 2002 are now available in the GLOBOCAN series of the International Agency for Research on Cancer. The results are presented here in summary form, including the geographic variation between 20 large \"areas\" of the world. Overall, there were 10.9 million new cases, 6.7 million deaths, and 24.6 million persons alive with cancer (within three years of diagnosis). The most commonly diagnosed cancers are lung (1.35 million), breast (1.15 million), and colorectal (1 million); the most common causes of cancer death are lung cancer (1.18 million deaths), stomach cancer (700,000 deaths), and liver cancer (598,000 deaths). The most prevalent cancer in the world is breast cancer (4.4 million survivors up to 5 years following diagnosis). There are striking variations in the risk of different cancers by geographic area. Most of the international variation is due to exposure to known or suspected risk factors related to lifestyle or environment, and provides a clear challenge to prevention.", "doc-2": "A tobacco-specific carcinogen, 4-(methylnitrosamino)-1-(3-pyridyl)-1-butanol (NNAL), and its metabolite, 4-[(methylnitrosamino)-1-(3-pyridyl)but-1-yl]beta-O-D-glucosiduronic+ ++ acid (NNAL-Gluc), have been found in the urine of newborns whose mothers smoked during pregnancy. We set out to determine whether this carcinogen is present in the fetus in early pregnancy. Cell-free amniotic fluid (AF) was obtained through routine amniocentesis for prenatal genetic studies from groups of smokers and non-smokers. NNAL and NNAL-Gluc were quantified by previously published methods. A history of smoking was confirmed by assays for cotinine plus N-beta-D-glucosiduronosyl-(S)-(-) cotinine inner salt (cotinine-Gluc) in AF. NNAL was detected in the AF of 11/21 (52.4%) of smokers and in 2/30 (6.7%) of non-smokers, a statistically significant difference (p=0.0006). There was not convincing evidence of NNAL-Gluc in the AF. This study documents for the first time that the tobacco-specific carcinogen NNAL is present in the fetus in early pregnancy. Further rigorous epidemiological studies are needed to determine whether the offspring of smoking mothers have an increased lifetime risk of cancer.", "label": 0}
{"doc-1": "p53 protein levels have been shown to increase in a number of cells after treatment with genotoxic agents through a post-transcriptional mechanism. In gamma-irradiated human cells, the accumulation of p53 protein is accompanied by an increase in the association of p53 mRNA with large polysomes without any change in the level of p53 mRNA. This redistribution of p53 mRNA on polysomes in response to irradiation is consistent with enhanced translational activity of p53 mRNA. We demonstrate that a region of the p53 3'-untranslated region (3'UTR) inhibits translation of a chimeric reporter mRNA in vivo. Induced elevation of reporter activity after gamma-irradiation was seen in cells expressing chimeric reporter-p53 3'UTR transcripts. These data taken together demonstrate translational control of p53 gene expression after gamma-irradiation and denote a previously unsuspected and novel role for the p53 3'UTR in controlling translation.", "doc-2": "Muscari turcicum Uysal, Ertugrul & Dural (Liliaceae/Hyacinthaceae) is described and illustrated from south Anatolia, Turkey. This species grows on alpine steppe in the Middle Taurus (C4 Konya Province). Muscari turcicum, an endemic confined to the Middle Taurus, is closely related to M.discolor Boiss. & Hausskn. and M.anatolicum Cowley & Ozhatay. Diagnostic morphological characters are discussed and compared with those of closely related taxa. 2007 The Linnean Society of London, Botanical Journal of the Linnean Society, 2007, 154, 233236.", "label": 0}
{"doc-1": "The objective of this study was to develop a prospectively applicable method for classifying comorbid conditions which might alter the risk of mortality for use in longitudinal studies. A weighted index that takes into account the number and the seriousness of comorbid disease was developed in a cohort of 559 medical patients. The 1-yr mortality rates for the different scores were: \"0\", 12% (181); \"1-2\", 26% (225); \"3-4\", 52% (71); and \"greater than or equal to 5\", 85% (82). The index was tested for its ability to predict risk of death from comorbid disease in the second cohort of 685 patients during a 10-yr follow-up. The percent of patients who died of comorbid disease for the different scores were: \"0\", 8% (588); \"1\", 25% (54); \"2\", 48% (25); \"greater than or equal to 3\", 59% (18). With each increased level of the comorbidity index, there were stepwise increases in the cumulative mortality attributable to comorbid disease (log rank chi 2 = 165; p less than 0.0001). In this longer follow-up, age was also a predictor of mortality (p less than 0.001). The new index performed similarly to a previous system devised by Kaplan and Feinstein. The method of classifying comorbidity provides a simple, readily applicable and valid method of estimating risk of death from comorbid disease for use in longitudinal studies. Further work in larger populations is still required to refine the approach because the number of patients with any given condition in this study was relatively small.", "doc-2": "Background Large multicenter studies validating the prognostic value of coronary computed tomographic angiography (CCTA) and left ventricular ejection fraction (LVEF) are lacking. We sought to confirm the independent and incremental prognostic value of coronary artery disease (CAD) severity measured using 64-slice CCTA over LVEF and clinical variables.Methods and Results A large international multicenter registry (CONFIRM Registry) was queried, and CCTA patients with LVEF data on CCTA were screened. Patients with a history of myocardial infarction, coronary revascularization, or cardiac transplantation were excluded. The National Cholesterol Education Program-Adult Treatment Panel III risk was calculated for each patient, and CCTA was evaluated for CAD severity (normal, nonobstructive, nonhigh-risk, or high-risk CAD) and LVEF <50%. Patients were followed for an end point of all-cause mortality; 27 125 patients underwent CCTA at 12 participating centers, with a total of 14 064 patients meeting the analysis criteria. Follow-up was available for 13 966 (99.3%) patients (mean follow-up of 22.5 months; 95% confidence interval, 22.3 to 22.7 months). All-cause mortality (271 deaths) occurred in 0.65% of patients without coronary atherosclerosis, 1.99% of patients with nonobstructive CAD, 2.90% of patients with nonhigh-risk CAD, and 4.95% for patients with high-risk CAD. Multivariable analysis confirmed that LVEF <50% (hazard ratio, 2.74; 95% confidence interval, 2.12 to 3.51) and CAD severity (hazard ratio,1.58; 95% confidence interval, 1.42 to 1.76) were predictors of all-cause mortality, and CAD severity had incremental value over LVEF and clinical variables.Conclusions Our results demonstrate that CCTA measures of CAD severity and LVEF have independent prognostic value. Incorporation of CAD severity provides incremental value for predicting all-cause death over routine clinical predictors and LVEF in patients with suspected obstructive CAD.", "label": 0}
{"doc-1": "Molecular Cloning has served as the foundation of technical expertise in labs worldwide for 30 years. No other manual has been so popular, or so influential. Molecular Cloning, Fourth Edition, by the celebrated founding author Joe Sambrook and new co-author, the distinguished HHMI investigator Michael Green, preserves the highly praised detail and clarity of previous editions and includes specific chapters and protocols commissioned for the book from expert practitioners at Yale, U Mass, Rockefeller University, Texas Tech, Cold Spring Harbor Laboratory, Washington University, and other leading institutions. The theoretical and historical underpinnings of techniques are prominent features of the presentation throughout, information that does much to help trouble-shoot experimental problems. For the fourth edition of this classic work, the content has been entirely recast to include nucleic-acid based methods selected as the most widely used and valuable in molecular and cellular biology laboratories. Core chapters from the third edition have been revised to feature current strategies and approaches to the preparation and cloning of nucleic acids, gene transfer, and expression analysis. They are augmented by 12 new chapters which show how DNA, RNA, and proteins should be prepared, evaluated, and manipulated, and how data generation and analysis can be handled. The new content includes methods for studying interactions between cellular components, such as microarrays, next-generation sequencing technologies, RNA interference, and epigenetic analysis using DNA methylation techniques and chromatin immunoprecipitation. To make sense of the wealth of data produced by these techniques, a bioinformatics chapter describes the use of analytical tools for comparing sequences of genes and proteins and identifying common expression patterns among sets of genes. Building on thirty years of trust, reliability, and authority, the fourth edition of Mol", "doc-2": "This chapter highlights some issues that are being addressed, discussed, and analyzed by part-time faculty in the California Community College system.", "label": 0}
{"doc-1": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "doc-2": "A rapid method for the detection of simian immunodeficiency virus (SIV) RNA from peripheral blood mononuclear cells (PBMC) of experimentally infected rhesus macaques by the polymerase chain reaction (PCR) is reported. The PCR was carried out with a complementary DNA (cDNA) template using 3 pairs of primers that were designed to anneal to homologous sequences in conserved regions of 3 molecular clones of SIVmac. The specificity of the primers was confirmed by performing the PCR with template DNA from the 3 molecular clones. SIV-specific RNA was detected from 30 and 50 infected PBMC/6.25 x 10(5) PBMC of two animals.", "label": 0}
{"doc-1": "We examined the role of ATP in the RNA interference (RNAi) pathway. Our data reveal two ATP-dependent steps and suggest that the RNAi reaction comprises at least four sequential steps: ATP-dependent processing of double-stranded RNA into small interfering RNAs (siRNAs), incorporation of siRNAs into an inactive approximately 360 kDa protein/RNA complex, ATP-dependent unwinding of the siRNA duplex to generate an active complex, and ATP-independent recognition and cleavage of the RNA target. Furthermore, ATP is used to maintain 5' phosphates on siRNAs. A 5' phosphate on the target-complementary strand of the siRNA duplex is required for siRNA function, suggesting that cells check the authenticity of siRNAs and license only bona fide siRNAs to direct target RNA destruction.", "doc-2": "Combined ab initio and micromagnetic simulations are carried out to demonstrate the feasibility on the electrical manipulation of spin-wave propagation in ultrathin Fe films. It is discovered that the exchange interaction can be substantially weakened under the influence of electric field applied perpendicular to the magnetic film surface. Furthermore, we demonstrate that the electric field modified exchange constant could effectively control the propagation of spin waves. To be specific, an external applied electric field of 5V m can effectively weaken exchange interaction by 80% and is sufficient to induce nearly twofold change of the wavenumber. This discovery may open a door to energy-efficient local manipulation of the spin wave propagation utilizing electric fields, which is crucial for both fundamental research and spin wave based logic applications.", "label": 0}
{"doc-1": "Elevated testosterone concentrations induce cardiac hypertrophy but the molecular mechanisms are poorly understood. Anabolic properties of testosterone involve an increase in protein synthesis. The mammalian target of rapamycin complex 1 (mTORC1) pathway is a major regulator of cell growth, but the relationship between testosterone action and mTORC1 in cardiac cells remains unknown. Here, we investigated whether the hypertrophic effects of testosterone are mediated by mTORC1 signaling in cultured cardiomyocytes. Testosterone increases the phosphorylation of mTOR and its downstream targets 40S ribosomal protein S6 kinase 1 (S6K1; also known as RPS6KB1) and eukaryotic initiation factor 4E-binding protein 1 (4E-BP1). The S6K1 phosphorylation induced by testosterone was blocked by rapamycin and small interfering RNA to mTOR. Moreover, the hormone increased both extracellular-regulated kinase (ERK1/2) and protein kinase B (Akt) phosphorylation. ERK1/2 inhibitor PD98059 blocked the testosterone-induced S6K1 phosphorylation, whereas Akt inhibition (Akt-inhibitor-X) had no effect. Testosterone-induced ERK1/2 and S6K1 phosphorylation increases were blocked by either 1,2-bis(2-aminophenoxy)ethane-N,N,N,N-tetraacetic acid-acetoxymethylester or by inhibitors of inositol 1,4,5-trisphosphate (IP(3)) pathway: U-73122 and 2-aminoethyl diphenylborate. Finally, cardiomyocyte hypertrophy was evaluated by, the expression of beta-myosin heavy chain, alpha-skeletal actin, cell size, and amino acid incorporation. Testosterone increased all four parameters and the increase being blocked by mTOR inhibition. Our findings suggest that testosterone activates the mTORC1/S6K1 axis through IP(3)/Ca(2+) and MEK/ERK1/2 to induce cardiomyocyte hypertrophy.", "doc-2": "This paper presents a novel approach for the technical and economic assessment of Li-ion battery energy storage systems (BESS) in smart grids supported by renewable energy sources. The approach is based on the definition of a statistical battery degradation cost model (SBDCM), able to estimate the expected costs related to BESS aging, according to the statistical properties of its expected cycling patterns. This new approach can improve the assessment of the economical sustainability of BESSs in this kind of applications, helping in this way the planning processes in electricity infrastructures in presence of high penetration of intermittent renewable energy sources. The SBDCM proposed in this paper is a statistical generalization of a battery degradation model presented in the literature. The proposed approach has been validated numerically comparing the results with those of the deterministic model considering for the BESS a stochastic dataset of input signals. In order to test the usefulness of the proposed model in a real world application, the proposed SBDCM has been applied to the evaluation of the economic benefit associated to the development of distributed energy storage system scenarios in the Italian power system, aimed to provide ancillary services for supporting electricity market.", "label": 0}
{"doc-1": "Interest in the problem of method biases has a long history in the behavioral sciences. Despite this, a comprehensive summary of the potential sources of method biases and how to control for them does not exist. Therefore, the purpose of this article is to examine the extent to which method biases influence behavioral research results, identify potential sources of method biases, discuss the cognitive processes through which method biases influence responses to measures, evaluate the many different procedural and statistical techniques that can be used to control method biases, and provide recommendations for how to select appropriate procedural and statistical remedies for different types of research settings.", "doc-2": "Full skin auto-grafts are required for reconstruction of skin burns and trauma scars. However, currently available clinical approaches such as sheet skin graft, mesh skin grafts, artificial skin graft, and in vivo skin expansion have limitations due to their potential danger for secondary damage and scar formation at the donor site, and discomfort during skin expansion. We developed an advanced bioreactor system and evaluated its function in skin expansion using porcine full skin. The reactor was designed as a pneumatic cylinder type, was programmed to adjust the pressure and the operating time. The system was composed of culture chamber unit, environmental control unit, and monitoring unit. Skins were expanded at 200 kPa pneumatic force and the expanded skins were analyzed by immunohistochemistry and histology. Furthermore we carried out auto-grafting experiment of the expanded skins in vivo using Yucatan pigs and skins were harvested and histologically analyzed after 8 weeks. The results showed that the bioreactor expanded skins to 160% in 4 hours. Histological analysis of the expanded skins revealed that epidermal cells and dermal fibroblasts were viable and remained integrity. The results of auto-grafting experiment indicated that fibrosis and scars were not detected in the grafted skins. This study demonstrates that the newly developed skin bioreactor enabled to obtain large sized full skin rapidly and successful grating.", "label": 0}
{"doc-1": "The high-level language of R is recognized as one of the most powerful and flexible statistical software environments, and is rapidly becoming the standard setting for quantitative analysis, statistics and graphics. R provides free access to unrivalled coverage and cutting-edge applications, enabling the user to apply numerous statistical methods ranging from simple regression to time series or multivariate analysis. Building on the success of the authors bestselling Statistics: An Introduction using R, The R Book is packed with worked examples, providing an all inclusive guide to R, ideal for novice and more accomplished users alike. The book assumes no background in statistics or computing and introduces the advantages of the R environment, detailing its applications in a wide range of disciplines. Provides the first comprehensive reference manual for the R language, including practical guidance and full coverage of the graphics facilities. Introduces all the statistical models covered by R, beginning with simple classical tests such as chi-square and t-test. Proceeds to examine more advance methods, from regression and analysis of variance, through to generalized linear models, generalized mixed models, time series, spatial statistics, multivariate statistics and much more. The R Book is aimed at undergraduates, postgraduates and professionals in science, engineering and medicine. It is also ideal for students and professionals in statistics, economics, geography and the social sciences.", "doc-2": "The carbonyl oxide intermediates in the ozonolysis of alkenes, often known as Criegee intermediates, are potentially important reactants in Earth's atmosphere. For decades, careful analysis of ozonolysis systems was employed to derive an understanding of the formation and reactions of these species. Recently it has proved possible to synthesize at least some of these intermediates separately from ozonolysis, and hence to measure their reaction kinetics directly. Direct measurements have allowed new or more detailed understanding of each type of gas-phase reaction that carbonyl oxides undergo, often acting as a complement to highly detailed ozonolysis experiments. Moreover, the use of direct characterization methods to validate increasingly accurate theoretical investigations can enhance their impact well beyond the set of specific reactions that have been measured. Reactions that initiate particles or fuel their growth could be a new frontier for direct measurements of Criegee intermediate chemistry.", "label": 0}
{"doc-1": "The axonal surface glycoproteins neuronglia cell adhesion molecule (NgCAM) and axonin-1 promote cell-cell adhesion, neurite outgrowth and fasciculation, and are involved in growth cone guidance. A direct binding between NgCAM and axonin-1 has been demonstrated using isolated molecules conjugated to the surface of fluorescent microspheres. By expressing NgCAM and axonin-1 in myeloma cells and performing cell aggregation assays, we found that NgCAM and axonin-1 cannot bind when present on the surface of different cells. In contrast, the cocapping of axonin-1 upon antibody-induced capping of NgCAM on the surface of CV-1 cells coexpressing NgCAM and axonin-1 and the selective chemical cross-linking of the two molecules in low density cultures of dorsal root ganglia neurons indicated a specific and direct binding of axonin-1 and Ng-CAM in the plane of the same membrane. Suppression of the axonin-1 translation by antisense oligonucleotides prevented neurite outgrowth in dissociated dorsal root ganglia neurons cultured on an NgCAM substratum, indicating that neurite outgrowth on NgCAM substratum requires axonin-1. Based on these and previous results, which implicated NgCAM as the neuronal receptor involved in neurite outgrowth on NgCAM substratum, we concluded that neurite outgrowth on an NgCAM substratum depends on two essential interactions of growth cone NgCAM: a trans-interaction with substratum NgCAM and a cis-interaction with axonin-1 residing in the same growth cone membrane.", "doc-2": "Natural hazards pose a threat to population, its goods and the environment. Urban areas are particularly vulnerable not only because of the concentration of population but due to the interplay that exists between people, buildings, and technological systems. Disasters have the potential to destroy decades of investment and effort, and cause the deviation of resources intended for primary tasks such as education, health and infrastructure. Disaster management is therefore an important component of urban planning and management as disasters pose a serious threat to sustainable development.There are basically three very important weaknesses in the way disaster management is currently being carried out. The first relates to the reliance upon hazard zonations alone rather than using risk as input for the selection and prioritisation of mitigation strategies. This is unfortunately in part due to the lack of empirical-historical data on damage and due to the high costs of generating and updating building inventories. The second relates to the reliance upon response rather than a concerted effort in both the pre-disaster and the postdisaster phases. The last relates to the lack of disaster information networks which coordinate efforts amongst the many institutions involved.The case of the Costa Rican city of Cartago was chosen as an example of the challenges that lie ahead in terms of geo-information for urban disaster management. The city provides an interesting case study; it represents a typical example of a medium-sized Costa Rican city that is located in a highly hazard-prone area. Cartago is also representative of a financially constrained local government authority with very basic baseline information where plans are elaborated without proper disaster-related information inputs.The research addresses building and population risk by integrating a hazard intensity map, damage curves derived from historical damage records and a building inventory.", "label": 0}
{"doc-1": "The aim of this study was to estimate a range of clinically important difference (CID) values of the visual analog scale for pain intensity (VAS-PI), and to assess the effect of patient baseline characteristics on VAS change scores. Data from a prospective cohort study with 678 patients with subacute and chronic temporomandibular disorder pain were analyzed. Patients were divided into 9 cohorts on the basis of the baseline VAS score and the duration of pain. The CID was estimated over a 12-week period, and 2 different methods were used: (1) mean change scores, and (2) optimal cutoff point in receiver operator characteristic curves. The patient's global impression of change was used as an external criterion. The general linear model univariate analysis was applied to assess the effect of baseline pain level and duration of pain on the raw VAS change scores, while adjusting for age and sex. The CID mean change ranged from 20.9 to 57.5 mm (64.1-76.3%), and the CID optimal cutoff point from 11.5 to 28.5 mm (29.9-47.7%). For the VAS change scores, the main effect of the variable baseline pain level was significant (F=107.09, P<.001). However, there was no significant baseline pain level by duration of pain interaction effect (F=1.13, P=.340). On the basis of the results, we advocate the choice of a single CID value according to the context of the patient's baseline level of pain.", "doc-2": "School children are affected by various eye disorders like refractive errors, squint (strabismus), Vitamin A deficiency and eye infections. Eye diseases in childhood are important causes of medical consultation and it affects learning ability, adjustment in school and personality. Most children do not complain of defective vision, as they may not recognize such conditions as a problem. Uncorrected refractive errors form the primary cause for visual impairment and blindness in India. This warrants early detection and treatment of these problems to prevent future blindness. The study was conducted with the objective of estimating the prevalence of ocular problems among school going children in rural area and to create eye-health awareness among them. This was a cross-sectional study of school children attending the ophthalmology OPD of Vikhe Patil Memorial Hospital. All the patients were examined by ophthalmologists. The patient sunder went detailed ocular examinations. Visual acuity measurement with the help of Snellens chart for distant vision and any child having visual acuity of 6/9 or worse was examined for refractive error. Extraocular movements, Hirschberg test, coveruncover test fordetection of squint was done. Gross examination of cornea, conjunctiva, anterior chamber, iris, and pupil was done with a torch light. Examination of the anterior segment with slit lamp was done when needed. Retinoscopy and subjective refraction was done for all the patients suspected of having refractive error. Cycloplegicre fraction was done when needed..Examination of fundus with direct ophthalmoscope was also done. Indirect ophthalmoscopy when needed.", "label": 0}
{"doc-1": "The most highly conserved noncoding elements (HCNEs) in mammalian genomes cluster within regions enriched for genes encoding developmentally important transcription factors (TFs). This suggests that HCNE-rich regions may contain key regulatory controls involved in development. We explored this by examining histone methylation in mouse embryonic stem (ES) cells across 56 large HCNE-rich loci. We identified a specific modification pattern, termed \"bivalent domains,\" consisting of large regions of H3 lysine 27 methylation harboring smaller regions of H3 lysine 4 methylation. Bivalent domains tend to coincide with TF genes expressed at low levels. We propose that bivalent domains silence developmental genes in ES cells while keeping them poised for activation. We also found striking correspondences between genome sequence and histone methylation in ES cells, which become notably weaker in differentiated cells. These results highlight the importance of DNA sequence in defining the initial epigenetic landscape and suggest a novel chromatin-based mechanism for maintaining pluripotency.", "doc-2": "The problem of automatically generating hardware modules from high level application representations has been at the forefront of EDA research during the last few years. In this paper, we introduce a methodology to automatically synthesize hardware accelerators from OpenCL applications. OpenCL is a recent industry supported standard for writing programs that execute on multicore platforms and accelerators such as GPUs. Our methodology maps OpenCL kernels into hardware accelerators, based on architectural templates that explicitly decouple computation from memory communication whenever this is possible. The templates can be tuned to provide a wide repertoire of accelerators that meet user performance requirements and FPGA device characteristics. Furthermore, a set of high- and low-level compiler optimizations is applied to generate optimized accelerators. Our experimental evaluation shows that the generated accelerators are tuned efficiently to match the applications memory access pattern and computational complexity, and to achieve user performance requirements. An important objective of our tool is to expand the FPGA development user base to software engineers, thereby expanding the scope of FPGAs beyond the realm of hardware design.", "label": 0}
{"doc-1": "We present an efficient interactive identification scheme and a related signature scheme that are based on discrete logarithms and which are particularly suited for smart cards. Previous cryptoschemes, based on the discrete logarithm, have been proposed by El Gamal (1985), Chaum, Evertse, Graaf (1988), Beth (1988) and Gunter (1989). The new scheme comprises the following novel features.", "doc-2": "Natural language communications using social networking and blogging services can result in the undesired revelation of private information. Existing disclosure control is tedious and error-prone because the user must set the disclosure level manually and must reconsider the level every time a new text is to be uploaded. This can lead to the revelation of private information or reduced enjoyment of the communication due to either disclosing too much text or hiding text that is meant to be shared. To solve these problems, we are developing a new disclosure control mechanism called DCNL or disclosure control of natural language information. DCNL automatically checks texts uploaded to social networking services or blog pages, detects words that might reveal private information, and warns the user about them. The granularity of DCNL is not the text but the words in the text. Consequently, it is not tiresome for the user and balances the protection of privacy with the enjoyment of communications. DCNL checks not only words that directly represent private information but also those that indirectly suggest it. Combinations of words are also checked. Analysis of the co-occurrence between words and reachability analysis with a search engine are used to infer what words imply what information.", "label": 0}
{"doc-1": "Sample selection bias as a specification error This paper discusses the bias that results from using non-randomly selected samples to estimate behavioral relationships as an ordinary specification error or omitted variables bias. A simple consistent two stage estimator is considered that enables analysts to utilize simple regression methods to estimate behavioral functions by least squares methods. The asymptotic distribution of the estimator is derived.", "doc-2": "Abstract. The synthesis of compliant mechanisms yield optimized topologies that combine several stiff parts with highly elastic flexure hinges. The hinges are often represented in finite element analysis by a single node (one-node hinge) leaving doubts on the physical meaning as well as an uncertainty in the manufacturing process. To overcome this one-node hinge problem of optimized compliant mechanisms' topologies, one-node hinges need to be replaced by real flexure hinges providing desired deflection range and the ability to bear internal loads without failure. Therefore, several common types of planar flexure hinges with different geometries are characterized and categorized in this work providing a comprehensive guide with explicit analytical expressions to replace one-node hinges effectively. Analytical expressions on displacements, stresses, maximum elastic deformations, bending stiffness, center of rotation and first natural frequencies are derived in this work. Numerical simulations and experimental studies are performed validating the analytical results. More importance is given to practice-oriented flexure hinge types in terms of cost-saving manufacturability, i.e. circular notch type hinges and rectangular leaf type hinges.", "label": 0}
{"doc-1": "Recombination initiates at double-stranded DNA breaks and at single-stranded DNA gaps. These DNA strand discontinuities can arise from DNA-damaging agents and from normal DNA replication when the DNA polymerase encounters an imperfection in the DNA template or another protein. The machinery of homologous recombination acts at these breaks and gaps to promote the events that result in gene recombination, as well as the reattachment of detached replication arms and the resumption of DNA replication. In Escherichia coli, these events require collaboration (RecA, RecBCD, RecFOR, RecQ, RuvABC and SSB proteins) and DNA replication (PriABC proteins and the DNA polymerases). The initial steps common to these recombination and recombination-dependent replication processes are reviewed.", "doc-2": "Magnetic resonance imaging of the prostate was performed in eight patients prior to radical prostatectomy. The results of the imaging studies were then directly compared to histopathologic findings from whole-mount histologic sections. Magnetic resonance imaging identified 82% of cancers greater than 5 mm in minimal diameter. Cancers were identified as areas of decreased signal intensity compared to the high signal intensity peripheral zone on long TR/TE sequences. Cancers were best detected when they involved the middle level of the gland and the posterior half of the prostate. Of the individual tumors identified by imaging, the amount of tumor involvement was underestimated by 37% and overestimated by 22% by MRI. We conclude that magnetic resonance imaging can identify prostate cancer, but has limitations as a screening modality and in accurately assessing the amount of involvement of the prostate gland by cancer.", "label": 0}
{"doc-1": "Scientific knowledge grows at a phenomenal pace--but few books have had as lasting an impact or played as important a role in our modern world as The Mathematical Theory of Communication, published originally as a paper on communication theory more than fifty years ago. Republished in book form shortly thereafter, it has since gone through four hardcover and sixteen paperback printings. It is a revolutionary work, astounding in its foresight and contemporaneity. The University of Illinois Press is pleased and honored to issue this commemorative reprinting of a classic.", "doc-2": "This paper deals with the social place relation between native and non-native speakers in a corpus of intercultural misunderstandings reported by non-natives. It analyzes, as they emerge from the data, the representation of the native built by the non-native, and also hierarchic features of native's behaviour, as well as the processes by which non-native manage situations of misunderstanding. The analysis leads to the conclusion that besides interaction and joint negociation, intercultural encounters basically are characterized as inequal encounters where the native exercices power through language and reinforces non-native's inferior position. The development of a syncretic intercultural style is thus hardly possible", "label": 0}
{"doc-1": "Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.", "doc-2": "The phylogenetic affiliations of organisms responsible for aerobic CO oxidation in hypersaline soils and sediments were assessed using media containing 3.8 M NaCl. CO-oxidizing strains of the euryarchaeotes, Haloarcula, Halorubrum, Haloterrigena and Natronorubrum, were isolated from the Bonneville Salt Flats (UT) and Atacama Desert salterns (Chile). A halophilic euryarchaeote, Haloferax strain Mke2.3(T), was isolated from Hawai'i Island saline cinders. Haloferax strain Mke2.3(T) was most closely related to Haloferax larsenii JCM 13917(T) (97.0% 16S rRNA sequence identity). It grew with a limited range of substrates, and oxidized CO at a headspace concentration of 0.1%. However, it did not grow with CO as a sole carbon and energy source. Its ability to oxidize CO, its polar lipid composition, substrate utilization and numerous other traits distinguished it from H. larsenii JCM 13917(T), and supported designation of the novel isolate as Haloferax namakaokahaiae Mke2.3(T), sp. nov (= DSM 29988, = LMG 29162). CO oxidation was also documented for 'Natronorubrum thiooxidans' HG1 (Sorokin, Tourova and Muyzer 2005), N. bangense (Xu, Zhou and Tian 1999) and N. sulfidifaciens AD2(T) (Cui etal. 2007). Collectively, these results established a previously unsuspected capacity for extremely halophilic aerobic CO oxidation, and indicated that the trait might be widespread among the Halobacteriaceae, and occur in a wide range of hypersaline habitats.", "label": 0}
{"doc-1": "SUMMARY The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses -the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.", "doc-2": "ObjectivesIn order to evaluate the improvement of the photodynamic therapy (PDT) due to sodium butyrate (NaBu), its effectiveness in U373-MG and D54-MG astrocytoma cell lines was evaluated.MethodsCells were exposed to delta-aminolevulinic acid (-ALA) as a precursor to endogenous photosensitizer protoporphyrin IX (PpIX). In both astrocytoma cells, an important increase by ALA was observed in uroporphyrinogen synthetase gene expression: 1.8- and 52-fold for D54-MG and U373-MG cells, respectively. After irradiation, they showed 16.67 and 28.9% of mortality in U373-MG and D54-MG, respectively. These mortalities increased to 70.62 and 96.7% when U373-MG and D54-MG cells, respectively, were exposed 24h to 8mM NaBu, before to PpIX induction. NaBu induced expression of caspase-3, caspase-9, and Bcl-2 and increased Bax in U373-MG cells. ALA-induced morphological changes are compatible to differentiation.ConclusionsGenes and differentiation induced mainly by NaBu improve cell death performed by PDT in astrocytoma cells. These facts prove the synergistic effect of NaBu on cytotoxic damage induced by PDT.", "label": 0}
{"doc-1": "Osteoclasts are specialized cells derived from the monocyte/macrophage haematopoietic lineage that develop and adhere to bone matrix, then secrete acid and lytic enzymes that degrade it in a specialized, extracellular compartment. Discovery of the RANK signalling pathway in the osteoclast has provided insight into the mechanisms of osteoclastogenesis and activation of bone resorption, and how hormonal signals impact bone structure and mass. Further study of this pathway is providing the molecular basis for developing therapeutics to treat osteoporosis and other diseases of bone loss.", "doc-2": "Devolution in Scotland has had a major impact upon local government. Local government, at both political and managerial levels, perceives central government in the shape of the Scottish Executive to be closer (geographically and politically) and more open to local government in terms of access to ministers and civil servants. However, Scottish centrallocal relations continues to be characterised by a sense of mistrust of local government, especially among civil servants and a continuing desire for central control of key policy agendas. Equally, the policy process continues to display features of fragmentation across major policy areas. Moreover, Westminster has not yet departed the scene of Scottish politics in both financial and policy terms but also in the enduring presence of a Westminster political culture", "label": 0}
{"doc-1": "Since 1922 when Wu proposed the use of the Folin phenol reagent for the measurement of proteins, a number of modified analytical procedures utilizing this reagent have been reported for the determination of proteins in serum, in antigen-antibody precipitates, and in insulin. Although the reagent would seem to be recommended by its great sensitivity and the simplicity of procedure possible with its use, it has not found great favor for general biochemical purposes. In the belief that this reagent, nevertheless, has considerable merit for certain application, but that its peculiarities and limitations need to be understood for its fullest exploitation, it has been studied with regard to effects of variations in pH, time of reaction, and concentration of reactants, permissible levels of reagents commonly used in handling proteins, and interfering substances. Procedures are described for measuring protein in solution or after precipitation with acids or other agents, and for the determination of as little as 0.2 gamma of protein.", "doc-2": "Four pharmacological subtypes of the alpha-2 adrenergic receptor have been identified; however, only three subtypes exist in any given species. Although the alpha-2A adrenergic receptor, as defined by the human platelet, and the alpha-2D receptor, as defined in the bovine pineal, have very different pharmacological characteristics, they are more similar to each other than either is to the alpha-2B or alpha-2C subtype. The human alpha-2-C10 clone (alpha-2A) and the rat RG20 clone have an 89% identity in their predicted amino acid sequence and are considered to be species orthologs. Although the expressed RG20 clone appears to have alpha-2D pharmacology, a careful comparison of its pharmacological characteristics with the bovine pineal has not been reported previously. Based on the pKi values of a panel of 13 alpha-2 adrenergic agents that have been used previously to compare the alpha-2A, alpha-2B and alpha-2C subtypes, the pharmacological characteristics of the bovine pineal alpha-2D receptor appear to be very similar to the rat RG20 clone (correlation coefficient, r, of 0.93). The porcine ortholog of the human alpha-2-C10 receptor has pharmacological characteristics identical to the human alpha-2A receptor (r = 0.99). Because of its higher affinity for the alpha-2D receptor, [3H]RX821002 is a better radioligand than [3H]rauwolscine for studying this receptor subtype.", "label": 0}
{"doc-1": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.", "doc-2": "Cellular blue nevi (CBN) are benign tumors of the skin derived from dermal melanocytes histologically characterized by increased cellularity and often by a dual cell population of nevoid cells. CBN rarely tend to invade the underlying tissues. Only six cases of CBN of the scalp invading the skull have been reported. A new case of a CBN infiltrating the underlying bone is presented. The patient, a 23-year-old woman, had a large hairless area on her right parietal scalp, present since the early months of life. Her past medical history included, on the same site, the presence, at birth, of a raised, dark, soft and hairless mass that was subsequently electrodesiccated. Radiographs of the skull showed an area of osteolysis underlying the cutaneous lesion. Histologic examination of a biopsy specimen revealed a CBN of the scalp infiltrating the underlying bone. Surgical resection of the entire lesion was planned. There were no other anomalies or malignancies. The patient is currently being followed in our clinic.", "label": 0}
{"doc-1": "At its simplest, voxel-based morphometry (VBM) involves a voxel-wise comparison of the local concentration of gray matter between two groups of subjects. The procedure is relatively straightforward and involves spatially normalizing high-resolution images from all the subjects in the study into the same stereotactic space. This is followed by segmenting the gray matter from the spatially normalized images and smoothing the gray-matter segments. Voxel-wise parametric statistical tests which compare the smoothed gray-matter images from the two groups are performed. Corrections for multiple comparisons are made using the theory of Gaussian random fields. This paper describes the steps involved in VBM, with particular emphasis on segmenting gray matter from MR images with nonuniformity artifact. We provide evaluations of the assumptions that underpin the method, including the accuracy of the segmentation and the assumptions made about the statistical distribution of the data.", "doc-2": "Summary. The growth and differentiation of post-implantation rat embryos together with their embryonic membranes, when grown in vitro in different blood sera, has been assessed by examination of the final stage of development attained and by the weight of protein synthesized. Rat embryos of early somite stages develop well to early limb bud stages when grown in homologous serum. This medium has some advantages over plasma clots. Maximum growth of the embryos is obtained in 0\\m=.\\5 to 1\\m=.\\0 ml serum/embryo. No advantage is gained by adding more serum, or transferring the embryos to fresh serum after a period in culture. It is immaterial whether the serum is obtained from male rats, pregnant or non-pregnant females, from the same individual as the embryos or some other, or from the same variety of rats as the embryos or some other. Heterologous sera are unsatisfactory as culture media. Rabbit serum is rapidly lethal to rat embryos, but will support some development if pre-heated at 56 to 57\\s=deg\\C for 30 min. Some samples of fowl serum are rapidly lethal to the rat embryos unless pre-heated, but others support some development.", "label": 0}
{"doc-1": "Simple sugars, oligosaccharides, polysaccharides, and their derivatives, including the methyl ethers with free or potentially free reducing groups, give an orangeyellow color w-hen treated with phenol and concentrated sulfuric acid. The reaction is sensitive and the color is stable. By use of this phenol-sulfuric acid reaction, a method has been developed to determine submicro amounts of sugars and related substances. In conjunction with paper partition chromatography the method is useful for the determination of the composition of polysaccharides and their methyl derivatives.", "doc-2": "Abstract A model fermentation system has been designed which utilizes pure catechins and partially purified polyphenol oxidase (EC 1.14.18.1 from green tea shoots. HPLC analysis of the products formed during in vitro oxidation has demonstrated a close similarity between this system and in vivo oxidation occurring during factory fermentation. Furthermore, changes in theaflavin and thearubigin levels, revealed by time courses of fermentation, show in vitro and in vivo systems to be qualitatively similar, although the former system produces considerably higher levels of both components. The model fermentation system, therefore, appears to be a suitable experimental system for studying the formation of theaflavin and thearubigin pigments under strictly controlled conditions. In preliminary experiments the theaflavins have been identified on HPLC profiles by enzymic oxidation of the relevant catechin pairs. Similarly, major coloured components other than theaflavins, which are considered to be thearubigins, have been shown to be formed by the oxidation and reaction of two gallocatechins (epigallocatechin and epigallocatechin gallate). The model fermentation system, in conjunction with HPLC as described in this paper, provides a means whereby precise data on theaflavin and thearubigin formation can be obtained and, in the case of the thearubigins, one which could yield additional structural information.", "label": 0}
{"doc-1": "Many formal organizational structures arise as reflections of rationalized institutional rules. The elaboration of such rules in modern states and societies accounts in part for the expansion and increased complexity of formal organizational structures. Institutional rules function as myths which organizations incorporate, gaining legitimacy, resources, stability, and enhanced survival prospects. Organizations whose structures become isomorphic with the myths of the institutional environment-in contrast with those primarily structured by the demands of technical production and exchange-decrease internal coordination and control in order to maintain legitimacy. Structures are decoupled from each other and from ongoing activities. In place of coordination, inspection, and evaluation, a logic of confidence and good faith is employed.", "doc-2": "More and more camera concepts are being investigated to try and seize the opportunity of instantaneous range verification of proton therapy treatments offered by prompt gammas emitted along the proton tracks. Focusing on one-dimensional imaging with a passive collimator, the present study experimentally compared in combination with the first, clinically compatible, dedicated camera device the performances of instances of the two main options: a knife-edge slit (KES) and a multi-parallel slit (MPS) design. These two options were experimentally assessed in this specific context as they were previously demonstrated through analytical and numerical studies to allow similar performances in terms of Bragg peak retrieval precision and spatial resolution in a general context. Both collimators were prototyped according to the conclusions of Monte Carlo optimization studies under constraints of equal weight (40mm tungsten alloy equivalent thickness) and of the specificities of the camera device under consideration (in particular 4mm segmentation along beam axis and no time-of-flight discrimination, both of which less favorable to the MPS performance than to the KES one). Acquisitions of proton pencil beams of 100, 160, and 230MeV in a PMMA target revealed that, in order to reach a given level of statistical precision on Bragg peak depth retrieval, the KES collimator requires only half the dose the present MPS collimator needs, making the KES collimator a preferred option for a compact camera device aimed at imaging only the Bragg peak position. On the other hand, the present MPS collimator proves more effective at retrieving the entrance of the beam in the target in the context of an extended camera device aimed at imaging the whole proton track within the patient.", "label": 0}
{"doc-1": "In experiments with tobacco tissue cultured on White's modified medium (basal meditmi hi Tnhles 1 and 2) supplemenk'd with kiticthi and hidoleacctic acid, a slrikin^' fourlo (ive-told intTease iu yield was ohtaitu-d within a three to Tour week j^rowth period on addition of an aqtteotis exlrarl of tobacco leaves (Fi^'ures 1 and 2). Subse(iueutly it was found Ihiit this jnoniotiou oi' f^rowih was due mainly though nol entirely to inorj^auic rather than organic con.stitttenls in the extract. In the isolation of Rrowth factors from plant tissues and other sources inorj 'anic salts are fre(|uently carried along with fhe organic fraclioits. When tissue cultures are used for bioassays, therefore, il is necessary lo lake into account increases in growth which may result from nutrient elements or other known constituents of the medium which may he present in the te.st materials. To minimize interference trom rontaminaitis of this type, an altempt has heen made to de\\eh)p a nieditmi with such adequate supplies of all re(iuired tnineral nutrients and cotntnott orgattic cottslitueitls that no apprecialle change in growth rate or yield will result from the inlroduclion of additional amounts in the range ordinarily expected to be present in tnaterials to be assayed. As a point of referetice for this work some of the culture media in mc)st common current use will he cotisidered briefly. For ease of comparis4)n Iheir mineral compositions are listed in Tables 1 and 2. White's nutrient .solution, designed originally for excised root cultures, was based on Uspeuski and Uspetiskaia's medium for algae and Trelease and Trelease's micronutrieni solution. This medium also was employed successfully in the original cttltivation of callus from the tobacco Iiybrid Nicotiana gtauca x A', tanijadorffii, atitl as further modified by White in 194 ^ and by others it has been used for the", "doc-2": "Priority effects are an important ecological force shaping biotic communities and ecosystem processes, in which the establishment of early colonists alters the colonization success of later-arriving organisms via competitive exclusion and habitat modification. However, we do not understand which biotic and abiotic conditions lead to strong priority effects and lasting historical contingencies. Using saprotrophic fungi in a model leaf decomposition system, we investigated whether compositional and functional consequences of initial colonization were dependent on initial colonizer traits, resource availability or a combination thereof. To test these ideas, we factorially manipulated leaf litter biochemistry and initial fungal colonist identity, quantifying subsequent community composition, using neutral genetic markers, and community functional characteristics, including enzyme potential and leaf decay rates. During the first 3months, initial colonist respiration rate and physiological capacity to degrade plant detritus were significant determinants of fungal community composition and leaf decay, indicating that rapid growth and lignolytic potential of early colonists contributed to altered trajectories of community assembly. Further, initial colonization on oak leaves generated increasingly divergent trajectories of fungal community composition and enzyme potential, indicating stronger initial colonizer effects on energy-poor substrates. Together, these observations provide evidence that initial colonization effects, and subsequent consequences on litter decay, are dependent upon substrate biochemistry and physiological traits within a regional species pool. Because microbial decay of plant detritus is important to global C storage, our results demonstrate that understanding the mechanisms by which initial conditions alter priority effects during community assembly may be key to understanding the drivers of ecosystem-level processes.", "label": 0}
{"doc-1": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.", "doc-2": "Electromigration as a possible thin-film module failure mechanism was investigated using several specially made, fully aluminized thin-film photovoltaic (TF-PV) modules. The effect of electromigration, as determined experimentally by measuring increases in electrical resistance across scribe lines, can be expressed as the product of a damage function, which correlates degradation rate with operating conditions such as current density and temperature, and a susceptibility function, which is defined by module design parameters, particularly aluminium purity and the configuration of the intercell region. Experimental measurements and derived acceleration factors suggest that open-circuit failure resulting from electromigration should not be a serious problem in present state-of-the-art TF-PV modules. Nevertheless, significant intercell resistance increases can result from long-term electromigration exposure, especially in future high-efficiency modules. The problem can be alleviated, however, by appropriate metallization applications and/or proper design of the intercell region.<<ETX>>", "label": 0}
{"doc-1": "EXAMINATION of the mental state is essential in evaluating psychiatric patients.1 Many investigators have added quantitative assessment of cognitive performance to the standard examination, and have documented reliability and validity of the several clinical tests of the sensorium.2*3 The available batteries are lengthy. For example, WITHERS and HINTONS test includes 33 questions and requires about 30 min to administer and score. The standard WAIS requires even more time. However, elderly patients, particularly those with delirium or dementia syndromes, cooperate well only for short periods.4 Therefore, we devised a simplified, scored form of the cognitive mental status examination, the Mini-Mental State (MMS) which includes eleven questions, requires only 5-10 min to administer, and is therefore practical to use serially and routinely. It is mini because it concentrates only on the cognitive aspects of mental functions, and excludes questions concerning mood, abnormal mental experiences and the form of thinking. But within the cognitive realm it is thorough. We have documented the validity and reliability of the MMS when given to 206 patients with dementia syndromes, affective disorder, affective disorder with cognitive impairment pseudodementia5T6), mania, schizophrenia, personality disorders, and in 63 normal subjects.", "doc-2": "Dehydroepiandrosterone (DHEA) and its active metabolite, DHEA sulfate (DHEAS), are endogenous hormones synthesized and excreted primarily by the zona reticularis of the adrenal cortex in response to adrenocorticotropic hormone. The exact mechanism of action and clinical role, if any, of DHEA and DHEAS remain unclear. Epidemiological data indicate an inverse relationship between serum DHEA and DHEAS levels and the frequency of cancer, cardiovascular disease (in men only), Alzheimer's disease and other age-related disorders, immune function, and progression of HIV infection. Animal (primarily rodent) studies have suggested many beneficial effects of DHEA, including improved immune function and memory and prevention of atherosclerosis, cancer, diabetes, and obesity. Many of the benefits seen in animal studies have yet to be shown in humans.", "label": 0}
{"doc-1": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.", "doc-2": "ZET Tp etkinliinde ortaya kan etik sorunlarn z mnde baz etik ilkelerden yararlanlmaktadr. Tp etiinin geleneksel ilkeleri ile birlikte, yzylmzda gelitirilmi olan \"Prima Facie\" devler, gnmz tp etii ilkelerinin belirlenmesinde etkili olmutur. ok sayda ilke arasnda genel olarak; yararllk, zerklie sayg, aydnlatlm onam, kt davranmama ve adalet ilkeleri \"temel\" etik ilkeler olarak benimsenmektedir.", "label": 0}
{"doc-1": "Quadriceps muscle and fibre cross-sectional areas (CSA), torque and neural activation were studied in seven healthy males during 6 months of weight training on alternate days with six series of eight unilateral leg extensions at 80% of one repetition maximum. After training, the quadriceps cross-sectional area increased by 18.8 +/- 7.2% (P < 0.001) and 19.3 +/- 6.7% (P < 0.001) in the distal and proximal regions respectively, and by 13.0 +/- 7.2% (P < 0.001) in the central region of the muscle. Hypertrophy was significantly different between and within the four constituents of the quadriceps. Biopsies of the vastus lateralis at mid-thigh did not show any increase in mean fibre cross-sectional area. Maximum isometric voluntary torque increased by 29.6 +/- 7.9%-21.1 +/- 8.6% (P < 0.01-0.05) between 100 degrees and 160 degrees of knee extension, but no change in the optimum angle (110 degrees-120 degrees) for torque generation was found. A 12.0 +/- 10.8% (P < 0.02) increase in torque per unit area together with a right shift in the IEMG-torque relation and no change in maximum IEMG were observed. Time to peak isometric torque decreased by 45.8% (P < 0.03) but no change in time to maximum IEMG was observed. In conclusion, strength training of the quadriceps results in a variable hypertrophy of its components without affecting its angle-torque relation. The increase in torque per unit area, in the absence of changes in IEMG, may indicate changes in muscle architecture. An increase in muscle-tendon stiffness may account for the decrease in time to peak torque.", "doc-2": "The CRISPR/Cas9 system has successfully been used in various organisms for precise targeted gene editing. Although it has been demonstrated that CRISPR/Cas9 system can induce mutation in tomato plants, the stability of heredity in later generations and mutant specificity induced by the CRISPR/Cas9 system in tomato plants have not yet been elucidated in detail. In this study, two genes, SlPDS and SlPIF4, were used for testing targeted mutagenesis in tomato plants through an Agrobacterium tumefaciens-mediated transformation method. A high mutation frequency was observed in all tested targets in the T0 transgenic tomato plants, with an average frequency of 83.56%. Clear albino phenotypes were observed for the psd mutants. High frequencies of homozygous and biallelic mutants were detected even in T0 plants. The majority of the detected mutations were 1- to 3-nucleotide deletions, followed by 1-bp insertions. The target mutations in the T0 lines were stably transmitted to the T1 and T2 generations, without new modifications or revision. Off-target activities associated with SlPDS and SlPIF4 were also evaluated by sequencing the putative off-target sites, and no clear off-target events were detected. Our results demonstrate that the CRISPR/Cas9 system is an efficient tool for generating stable and heritable modifications in tomato plants.", "label": 0}
{"doc-1": "Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.", "doc-2": "The paper presents the first comprehensive account of congener profiles of polycyclic aromatic hydrocarbons (PAHs) in intertidal bivalve mollusks [Meretrix meretrix, Macoma birmanica, and Sanguilonaria (Soletellina) acuminata] of Sunderban mangrove wetland (India). The main aim of this work was to use the bivalves as bioindicators of the contamination of the 16 USEPA PAH. The PAH profile in bivalves is largely dominated by a petrogenic fingerprint, with over-imposition of pyrolytic PAH sources, as evidenced by diagnostic molecular ratios. Bioaccumulation factors (BAF) of individual compounds from the sediments were calculated, and it reveals overall higher values in the visceral mass of the bivalves. S acuminata showed significantly higher levels of PAHs, especially the high molecular weight (HMW) PAHs, compared to the other two species as a sensitive indicator of trace organic stress in future monitoring programs.", "label": 0}
{"doc-1": "Determining whether two terms in text have an ancestor relation (e.g. Toyota and car) or a sibling relation (e.g. Toyota and Honda) is an essential component of textual inference in NLP applications such as Question Answering, Summarization, and Recognizing Textual Entailment. Significant work has been done on developing stationary knowledge sources that could potentially support these tasks, but these resources often suffer from low coverage, noise, and are inflexible when needed to support terms that are not identical to those placed in them, making their use as general purpose background knowledge resources difficult. In this paper, rather than building a stationary hierarchical structure of terms and relations, we describe a system that, given two terms, determines the taxonomic relation between them using a machine learning-based approach that makes use of existing resources. Moreover, we develop a global constraint optimization inference process and use it to leverage an existing knowledge base also to enforce relational constraints among terms and thus improve the classifier predictions. Our experimental evaluation shows that our approach significantly outperforms other systems built upon existing well-known knowledge sources.", "doc-2": "Many women may be reluctant to perform breast self-examination (B.S.E.) regularly due to motivational or self-regulatory deficits. The Health Action Process Approach (Schwarzer, R. (1992). Self-efficacy in the adoption and maintenance of health behaviors: theoretical approaches and a new model. In: Schwarzer, R. (Ed.), Self-efficacy: Thought Control of Action , pp. 217-243. Hemisphere, Washington DC; Schwarzer, R. (2001). Social-cognitive factors in changing health-related behavior. Current Directions in Psychological Science , 10 , 47-51.), a health behavior change model that advocates the separation of motivation and action phases, such as goal setting and goal pursuit, was applied to data from 418 young women whose risk perceptions, outcome expectancies, self-efficacy, intention to perform B.S.E., planning, and reported examination behaviors were examined at two points in time. Risk perception was found to have a negligible influence in a path analysis, whereas self-efficacy emerged as the best predict...", "label": 0}
{"doc-1": "Analysis of two-dimensional signals and systems foundation of scalar diffraction theory Fresnel and Fraunhofer diffraction wave-optics analysis of coherent optical systems frequency analysis of optical imaging systems wavefront modulation analog optical information processing holography. Appendices: delta function and Fourier transform theorems introduction to paraxial geometrical optics polarization and Jones matrices.", "doc-2": "Do the intersections between officer race and driver race/ethnicity influence the frequency in citizens reports of receiving a traffic ticket during a routine traffic stop in 1999 and 2008? To fully grasp the importance of traffic ticket outcomes, we must first understand how extralegal factors, particularly the intersections between officer racedriver race/ethnicity and the number of vehicle occupants, impact these outcomes. Thus, the current study utilizes the 1999 and 2008 PolicePublic Contact Survey to assess the relationship between extralegal factors and traffic ticket receipt during routine traffic stops. Findings illustrate that according to citizens reports, extralegal factors, including the intersections between officer racedriver race/ethnicity and the number of vehicle occupants, differentially impact traffic ticket receipt in both the years.", "label": 0}
{"doc-1": "SUMMARYIt is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data.AVAILABILITYThe package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org).", "doc-2": "Samples of kidney cortex, diaphragm, and atrial and ventricular muscle were taken from hamsters and ground squirrels to determine whether the low body temperature of hibernation caused loss of potassium and gain of sodium. Gradients between tissues and plasma are maintained or even increased during hibernation.", "label": 0}
{"doc-1": "A submitted manuscript is the author's version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "Assessment and characterization of gut microbiota has become a major research area in human disease, including type 2 diabetes, the most prevalent endocrine disease worldwide. To carry out analysis on gut microbial content in patients with type 2 diabetes, we developed a protocol for a metagenome-wide association study (MGWAS) and undertook a two-stage MGWAS based on deep shotgun sequencing of the gut microbial DNA from 345 Chinese individuals. We identified and validated approximately 60,000 type-2-diabetes-associated markers and established the concept of a metagenomic linkage group, enabling taxonomic species-level analyses. MGWAS analysis showed that patients with type 2 diabetes were characterized by a moderate degree of gut microbial dysbiosis, a decrease in the abundance of some universal butyrate-producing bacteria and an increase in various opportunistic pathogens, as well as an enrichment of other microbial functions conferring sulphate reduction and oxidative stress resistance. An analysis of 23 additional individuals demonstrated that these gut microbial markers might be useful for classifying type 2 diabetes.", "label": 0}
{"doc-1": "Attractive features of time-hopping spread-spectrum multiple-access systems employing impulse signal technology are outlined, and emerging design issues are described. Performance of such communications systems in terms of achievable transmission rate and multiple-access capability are estimated for both analog and digital data modulation formats under ideal multiple-access channel conditions.", "doc-2": "Zur quantitativen Bestimmung des Schlpffaktors der Kartoffelnematode, entweder mit sogenanntem Schlpftest, oder durch unsere, vor kurzem beschriebene Froschherzmethode, muss die Ionenkonzentration in der Lsung kontrolliert werden. Eine Methode zur Herstellung geeigneter Lsungen wird beschrieben.", "label": 0}
{"doc-1": "It has been suggested that the quality of clinical trials should be assessed by blinded raters to limit the risk of introducing bias into meta-analyses and systematic reviews, and into the peer-review process. There is very little evidence in the literature to substantiate this. This study describes the development of an instrument to assess the quality of reports of randomized clinical trials (RCTs) in pain research and its use to determine the effect of rater blinding on the assessments of quality. A multidisciplinary panel of six judges produced an initial version of the instrument. Fourteen raters from three different backgrounds assessed the quality of 36 research reports in pain research, selected from three different samples. Seven were allocated randomly to perform the assessments under blind conditions. The final version of the instrument included three items. These items were scored consistently by all the raters regardless of background and could discriminate between reports from the different samples. Blind assessments produced significantly lower and more consistent scores than open assessments. The implications of this finding for systematic reviews, meta-analytic research and the peer-review process are discussed.", "doc-2": "Abstract Reduced graphene oxide (RGO) is synthesized and added in situ into the reaction system of polyaniline (PANI) electrodeposition using activated carbon cloth (ACC) as the substrate. The effect of RGO on the morphology, structure, and electrochemical properties of the ACC/PANI composite is investigated. A more compact and uniform layer of PANI film is observed via scanning electronic microscopy after the addition of RGO. Raman spectroscopy shows that RGO has been simultaneously deposited with PANI onto the surface of ACC. X-ray photoelectron spectroscopy reveals that the sample with RGO exhibits a higher sulfur-to-nitrogen ratio. The reversibility of the redox reaction of PANI is improved, as confirmed via cyclic voltammetry. The electrochemical impedance spectroscopy data shows that the introduction of RGO lowers the charge-transfer resistance of ACC/PANI, meanwhile, improves the coverage percentage of PANI on the ACC surface to a significant extent, primarily because of the interactions between RGO, ACC, and PANI. The as-prepared composite with RGO shows improved rate performance and cyclability as a supercapacitor electrode.", "label": 0}
{"doc-1": "Mobile users' data rate and quality of service are limited by the fact that, within the duration of any given call, they experience severe variations in signal attenuation, thereby necessitating the use of some type of diversity. In this two-part paper, we propose a new form of spatial diversity, in which diversity gains are achieved via the cooperation of mobile users. Part I describes the user cooperation strategy, while Part II (see ibid., p.1939-48) focuses on implementation issues and performance analysis. Results show that, even though the interuser channel is noisy, cooperation leads not only to an increase in capacity for both users but also to a more robust system, where users' achievable rates are less susceptible to channel variations.", "doc-2": "BACKGROUND: Biopolymers produced by microbes are in demand as their biodegradable and biocompatible properties make them suitable for disposable products and for potential use as biomaterials for medical applications. The effective microbial production of copolyesters of 3-hydroxybutyrate (3HB) and 4-hydroxybutyrate(4HB) with high molar fractions of 4HB unit by a wild-type Wautersia eutropha H16 was investigated in culture media containing 4-hydroxybutyric acid (4HBA) and different carbon substrates in the presence of various -amino acids.    RESULTS: The addition of carbon sources such as glucose, fructose and acetic acid to the culture medium containing 4HBA in the presence of -amino acids resulted in the production of random poly(3HB-co-4HB) with compositions of up to 77 mol% 4HB unit, but the yields of copolyesters with 6077 mol% 4HB units were less than 15 wt% of dried cell weights. In contrast, when carbon sources such as propionic acid and butyric acid were used as the co-substrates of 4HBA in the presence of -amino acids, poly(3HB-co-4HB) copolyesters with compositions of 7286 mol% 4HB were produced at maximally 47.2 wt% of dried cell weight (11.3 g L1) and the molar conversion yield of 4HBA to 4HB fraction in copolyesters was as high as 31.4 mol%. Further, poly(3HB-co-4HB) copolyesters with compositions of 9396 mol% 4HB were isolated at up to 35.2 wt% of dried cell weights by fractionation of the above copolymers with chloroform -hexane.    CONCLUSION: The productivity of copolyesters with over 80 mol% 4HB fractions was as high as 0.146 g L1 h1 (3.51 g L1 for 24 h) by flask batch cultivation. Copyright  2007 Society of Chemical Industry", "label": 0}
{"doc-1": "Use of the real-time polymerase chain reaction (PCR) to amplify cDNA products reverse transcribed from mRNA is on the way to becoming a routine tool in molecular biology to study low abundance gene expression. Real-time PCR is easy to perform, provides the necessary accuracy and produces reliable as well as rapid quantification results. But accurate quantification of nucleic acids requires a reproducible methodology and an adequate mathematical model for data analysis. This study enters into the particular topics of the relative quantification in real-time RT-PCR of a target gene transcript in comparison to a reference gene transcript. Therefore, a new mathematical model is presented. The relative expression ratio is calculated only from the real-time PCR efficiencies and the crossing point deviation of an unknown sample versus a control. This model needs no calibration curve. Control levels were included in the model to standardise each reaction run with respect to RNA integrity, sample loading and inter-PCR variations. High accuracy and reproducibility (<2.5% variation) were reached in LightCycler PCR using the established mathematical model.", "doc-2": "O objetivo eanalisara importncia do Programa Nacional de Alimentacao Escolar (PNAE) como mecanismo de inclusao e de politica com foco na demanda, e explicar as transformacoes que o PNAE tem possibilitado na estrutura da agricultura familiar da regiao Nordeste do Brasil. Como metodologia, os dados utilizados no trabalho sao de base secundaria, extraidos dos sites do Instituto Nacional de Estudos e Pesquisa Educacionais Anisio Teixeira (INEP), do Fundo Nacional de Desenvolvimento da Educacao (FNDE) e do Portal da Transparencia do Governo Federal, tendo como foco o numero de alunos das escolas municipais e estaduais e os repasses do PNAE nos municipios, bem como a compra da agricultura familiar por meio da Lei 11.947/2009. A pesquisa buscara demonstrar que o PNAE tem contribuido para a diversificacao da agricultura familiar, na formacao de habitos alimentares mais saudaveis, e no surgimento e consolidacao de organizacoes coletivas (cooperativas) dos agricultores familiares, contribuindo para a construcao de mercados e para a dinamizacao no nivel dos municipios. Concluindo, buscaremos revelar que a regiao Nordeste possui significativo potencial especialmente atraves dos pequenos municipios, mas que necessita de mecanismos legais para a insercao dos produtos da agricultura familiar nos mercados, a exemplo do Servico de Inspecao Municipal (SIM), entre outros desafios.", "label": 0}
{"doc-1": "Abstract In lifetesting, medical follow-up, and other fields the observation of the time of occurrence of the event of interest (called a death) may be prevented for some of the items of the sample by the previous occurrence of some other event (called a loss). Losses may be either accidental or controlled, the latter resulting from a decision to terminate certain observations. In either case it is usually assumed in this paper that the lifetime (age at death) is independent of the potential loss time; in practice this assumption deserves careful scrutiny. Despite the resulting incompleteness of the data, it is desired to estimate the proportion P(t) of items in the population whose lifetimes would exceed t (in the absence of such losses), without making any assumption about the form of the function P(t). The observation for each item of a suitable initial event, marking the beginning of its lifetime, is presupposed. For random samples of size N the product-limit (PL) estimate can be defined as follows: L...", "doc-2": "The paper presents a calculation technique of high-coercivity magnets DC motor. With the input data (nominal and maximum torques, rate of rotation, voltage supply, efficiency output), the technique allows obtaining basic parameters of electrical machines and simplification of motor designing. Basic parameters of the permanent magnet motor are calculated based on the developed technique. A permanent magnet motor model has been generated and the tests have been conducted.", "label": 0}
{"doc-1": "\"Grid\" computing has emerged as an important new field, distinguished from conventional distributed computing by its focus on large-scale resource sharing, innovative applications, and, in some cases, high performance orientation. In this article, the authors define this new field. First, they review the \"Grid problem,\" which is defined as flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources--what is referred to as virtual organizations. In such settings, unique authentication, authorization, resource access, resource discovery, and other challenges are encountered. It is this class of problem that is addressed by Grid technologies. Next, the authors present an extensible and open Grid architecture, in which protocols, services, application programming interfaces, and software development kits are categorized according to their roles in enabling resource sharing. The authors describe requirements that they believe any such mechanisms must satisfy and discuss the importance of defining a compact set of intergrid protocols to enable interoperability among different Grid systems. Finally, the authors discuss how Grid technologies relate to other contemporary technologies, including enterprise integration, application service provider, storage service provider, and peer-to-peer computing. They maintain that Grid concepts and technologies complement and have much to contribute to these other approaches.", "doc-2": "Using a Ca 2+ ionophore, A23187, the free Ca 2+ concentration ([Ca 2+ ]) in the cytoplasm of pollen tubes of Lilium longiflorum was controlled from the cell exterior. At [Ca 2+ ] higher than 1.0x10 5 M (pCa5.0), cytoplasmic streaming was inhibited, and the inhibition was irreversible. The ATP content did not change, but actin filaments were fragmented and formed aggregates. A subsequent decrease in [Ca 2+ ] almost stopped the progress of the actin filament fragmentation, but filamentous actin did not re-form from the fragmented actin. In a previous paper, we reported that pollen tube organelle movement along characean actin bundles was inhibited by Ca 2+ at 10 5 M levels and the inhibition was reversible. In the present study, the reversibility was also demonstrated using an in situ Ca 2+ treatment. Organelles were isolated from pollen tubes that had been treated with high [Ca 2+ ] and A23187. They moved along characean actin bundles in Ca 2+ -free medium. It is concluded that Ca 2+ inhibition of cytoplasmic streaming can be attributed to both inactivation of myosin and fragmentation of actin. The irreversibility of Ca 2+ inhibition in situ is attributed to the irreversible fragmentation of actin filaments.", "label": 0}
{"doc-1": "pression, Journal of Clinical Psychiatry, 51, 61-69 (1990). 11. L.R. Baxter, Jr., J.M. Schwartz, B.H. Guze, J.C. Mazziotta, M.P. Szuba, K. Bergman, A. Alazraki, C.E. Selin, H.K. Freng, P. Munford, and M.E. Phelps, Obsessive-compulsive disorder vs. Tourette's disorder: Differential function in subdivi sions of the neostriatum, paper presented at the an nual meeting of the American College of Neuropsy chopharmacology, San Juan, Puerto Rico (December 1991). 12. E.M. Reiman, M.E. Raichle, F.K. Butler, P. Herscovitch, and E. Robins, A focal brain abnormal ity in panic disorder, a severe form of anxiety, Na ture, 310, 683-685 (1984); E.M. Reiman, M.E. Ra ichle, E. Robins, F.K. Butler, P. Herscovitch, P. Fox, and J. Perlmutter, The application of positron emis sion tomography to the study of panic disorder, American Journal of Psychiatry, 143, 469-477 (1986); T.E. Nordahl, W.E. Semple, M. Gross, T.A. Mellman, M.B. Stein, P. Goyer, A.C. King, T.W. Uhde, and R.M. Cohen, Cerebral glucose metabolic differences in patients with panic disorder, Neuro psychopharmacology, 3, 261-272 (1990).", "doc-2": "The forensic scientist is used to evaluate lesions with regard to their age, the weapon used, the seriousness, etc. Based on a material of examinations of alleged victims of torture some of the types of lesions are discussed. The importance of being strictly objective and using a scientific approach is stressed. The Committee of Concerned Forensic Scientists and Physicians for the Documentation of Human Rights Abuses (CCFS) was formed in 1984. The aims and the work of the committee are described.", "label": 0}
{"doc-1": "SUMMARY The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses -the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.", "doc-2": "Treatments of autoclaving, high temperature aging (aged-black garlic), crushing, and roasting at 100, 150, and 200C were applied to alter the volatile profiles of garlic (Allium sativum L.). Headspace volatiles in samples were analyzed by a solid phase microextraction (SPME)-GC/MS. Total peak areas of crushed-raw garlic were the highest and those of aged-black garlic clove were the lowest. Crushing effects were clearly observed in raw garlic, aged-black garlic, and roasted garlic at 200C for 60 min. Sulfur-containing volatiles including diallyl disulfide and diallyl trisulfide were major volatiles. Generally, peak areas of diallyl disulfide decreased when garlic received autoclaving and roasting treatment while diallyl trisulfide and allyl methyl trisulfide increased during heat treatment compared to raw garlic. Roasting at 200C for 60 min caused the formation of pyrazines greatly in garlic. Principal component analysis (PCA) for the volatile profiles by SPME-GC/MS could discriminate types of processed garlic successfully.", "label": 0}
{"doc-1": "CCP4mg is a project that aims to provide a general-purpose tool for structural biologists, providing tools for X-ray structure solution, structure comparison and analysis, and publication-quality graphics. The map-fitting tools are available as a stand-alone package, distributed as 'Coot'.", "doc-2": "Shape control in metal-organic frameworks still remains a challenge. We propose a strategy based on the capping agent modulator method to control the shape of ZIF-8 nanocrystals. This approach requires the use of a surfactant, cetyltrimethylammonium bromide (CTAB), and a second capping agent, tris(hydroxymethyl)aminomethane (TRIS), to obtain ZIF-8 nanocrystals with morphology control in aqueous media. Semiempirical computational simulations suggest that both shape-inducing agents adsorb onto different surface facets of ZIF-8, thereby slowing down their crystal growth rates. While CTAB molecules preferentially adsorb onto the {100} facets, leading to ZIF-8 particles with cubic morphology, TRIS preferentially stabilizes the {111} facets, inducing the formation of octahedral crystals. Interestingly, the presence of both capping agents leads to nanocrystals with irregular shapes and higher index facets, such as hexapods and burr puzzles. Additionally, the combination of ZIF-8 nanocrystals with other materials is expected to impart additional properties due to the hybrid nature of the resulting nanocomposites. In the present case, the presence of CTAB and TRIS molecules as capping agents facilitates the synthesis of metal nanoparticle@ZIF-8 nanocomposites, due to synergistic effects which could be of use in a number of applications such as catalysis, gas sensing and storage.", "label": 0}
{"doc-1": "A system of cluster analysis for genome-wide expression data from DNA microarray hybridization is described that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. The output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. We have found in the budding yeast Saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. Thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. Also, coexpression of genes of known function with poorly characterized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently.", "doc-2": "The growth of available online learning programmes has created a wide range of new ways for global organizations to train their staff effectively. Previously, global training entailed substantial costs for organizations  costs that had to be endured if the knowledge and skills of the workforce were to be updated. In this context, virtual communities of learning, defined as groups of people engaging in the collaborative learning and reflective practice involved in transformative learning, are of increasing interest for global organizations because of their potential usefulness in workplace practice and training. This article examines how a community of learning has been developed and implemented for 174 staff from 81 offices worldwide of a large international organization by facilitating the collaborative exchange of knowledge and experience. Based on the participants' perceptions, several key insights are provided that should be taken into account when engaging in community of learning initiatives.", "label": 0}
{"doc-1": "OBJECTIVEFunnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test of asymmetry of funnel plots predicts discordance of results when meta-analyses are compared to large trials, and we assessed the prevalence of bias in published meta-analyses.DESIGNMedline search to identify pairs consisting of a meta-analysis and a single large trial (concordance of results was assumed if effects were in the same direction and the meta-analytic estimate was within 30% of the trial); analysis of funnel plots from 37 meta-analyses identified from a hand search of four leading general medicine journals 1993-6 and 38 meta-analyses from the second 1996 issue of the Cochrane Database of Systematic Reviews.MAIN OUTCOME MEASUREDegree of funnel plot asymmetry as measured by the intercept from regression of standard normal deviates against precision.RESULTSIn the eight pairs of meta-analysis and large trial that were identified (five from cardiovascular medicine, one from diabetic medicine, one from geriatric medicine, one from perinatal medicine) there were four concordant and four discordant pairs. In all cases discordance was due to meta-analyses showing larger effects. Funnel plot asymmetry was present in three out of four discordant pairs but in none of concordant pairs. In 14 (38%) journal meta-analyses and 5 (13%) Cochrane reviews, funnel plot asymmetry indicated that there was bias.CONCLUSIONSA simple analysis of funnel plots provides a useful test for the likely presence of bias in meta-analyses, but as the capacity to detect bias will be limited when meta-analyses are based on a limited number of small trials the results from such analyses should be treated with considerable caution.", "doc-2": "We report on 240240 silicon photonic MEMS switches on 4cm  4cm dies realized by wafer-scale integration and reticle stitching. The maximum on-chip loss is measured to be 9.8dB and the crosstalk is below 70dB.", "label": 0}
{"doc-1": "Analysis of two-dimensional signals and systems foundation of scalar diffraction theory Fresnel and Fraunhofer diffraction wave-optics analysis of coherent optical systems frequency analysis of optical imaging systems wavefront modulation analog optical information processing holography. Appendices: delta function and Fourier transform theorems introduction to paraxial geometrical optics polarization and Jones matrices.", "doc-2": "The 10 MWe Solar One central receiver pilot plant used a water/steam receiver coupled directly to the turbine-generator, and an oil/rock thermal storage system from which the turbogenerator was operated at reduced steam conditions during cloudy weather and at night. The Solar Two project replaces the Solar One receiver and thermal storage systems with nitrate salt receiver, thermal storage, and steam generation systems. The existing collector system and electric power generation systems are retained, with some modifications, to hold project costs to a minimum. The paper presents a summary of the plant final design.", "label": 0}
{"doc-1": "Malaria: a world viewA new malaria map suggests that the disease is far more common than was thought. There is still no reliable estimate of the global distribution of the public health burden posed by malaria, making it impossible to allocate resources for malaria control on the basis of objective evidence. Snow et al. set out to improve the situation by developing a map of the global distribution of clinical episodes of Plasmodium falciparum malaria incorporating epidemiological, geographic and demographic data. The bottom line is a total of around 500 million cases in 2002, which is 50% higher than the WHO figure. For areas outside Africa the new estimate is twice the WHO figure, reflecting lax reporting procedures in some countries.AbstractInterest in mapping the global distribution of malaria is motivated by a need to define populations at risk for appropriate resource allocation1,2 and to provide a robust framework for evaluating its global economic impact3,4. Comparison of older5,6,7 and more recent1,4 malaria maps shows how the disease has been geographically restricted, but it remains entrenched in poor areas of the world with climates suitable for transmission. Here we provide an empirical approach to estimating the number of clinical events caused by Plasmodium falciparum worldwide, by using a combination of epidemiological, geographical and demographic data. We estimate that there were 515 (range 300660) million episodes of clinical P. falciparum malaria in 2002. These global estimates are up to 50% higher than those reported by the World Health Organization (WHO) and 200% higher for areas outside Africa, reflecting the WHO's reliance upon passive national reporting for these countries. Without an informed understanding of the cartography of malaria risk, the global extent of clinical disease caused by P. falciparum will continue to be underestimated.", "doc-2": "Development of surface coatings with high antimicrobial activity is urgently required to fight bacteria and other microorganisms on technical and hygiene relevant surfaces. Control over structure and topology of the surface coatings, combined with the ability to include functional molecules within the structure, is crucial for optimizing their performance. Herein, we describe a novel strategy to synthesize structurally well-defined porphyrin polymer thin films via a template approach. In this approach, bisazido-functionalized porphyrin molecules are preorganized within a metal-organic framework (MOF) structure. Afterward, porphyrin units within the MOF are covalently connected via a secondary linker. Removal of the metal ions of the MOF results in water-stable porphyrin polymer thin films that demonstrate high antibacterial activity against pathogens via visible-light-promoted generation of reactive oxygen species. In addition, this approach offers the inherent possibility to incorporate guest molecules within the structures, to functionalize the surface with biomolecules, and to create hierarchically structured materials.", "label": 0}
{"doc-1": "Alternatively activated macrophages prevent lethal intestinal pathology caused by worm ova in mice infected with the human parasite Schistosoma mansoni through mechanisms that are currently unclear. This study demonstrates that arginase I (Arg I), a major product of IL-4- and IL-13-induced alternatively activated macrophages, prevents cachexia, neutrophilia, and endotoxemia during acute schistosomiasis. Specifically, Arg I-positive macrophages promote TGF-beta production and Foxp3 expression, suppress Ag-specific T cell proliferation, and limit Th17 differentiation. S. mansoni-infected Arg I-deficient bone marrow chimeras develop a marked accumulation of worm ova within the ileum but impaired fecal egg excretion compared with infected wild-type bone marrow chimeras. Worm ova accumulation in the intestines of Arg I-deficient bone marrow chimeras was associated with intestinal hemorrhage and production of molecules associated with classical macrophage activation (increased production of IL-6, NO, and IL-12/IL-23p40), but whereas inhibition of NO synthase-2 has marginal effects, IL-12/IL-23p40 neutralization abrogates both cachexia and intestinal inflammation and reduces the number of ova within the gut. Thus, macrophage-derived Arg I protects hosts against excessive tissue injury caused by worm eggs during acute schistosomiasis by suppressing IL-12/IL-23p40 production and maintaining the Treg/Th17 balance within the intestinal mucosa.", "doc-2": "Mycotoxin induced hepatoxocity has been linked to oxidative stress, resulting from either an increase in levels of reactive oxygen species (ROS) above normal levels and/or the suppression of antioxidant protective pathways. However, few detailed molecular studies of mycotoxicoses in animals have been carried out. This study use current RNA-seq based approaches to investigate the effects of mycotoxin exposure in a ruminant model. Having first assembled a de novo reference transcriptome, we use RNA-Seq technology to define in vivo hepatic gene expression changes resulting from mycotoxin exposure in relationship to pathological effect. As expected, characteristic oxidative stress related gene expression is markedly different in animals exhibiting poorer outcomes. However, expression of multiple genes critical for detoxification, particularly members of the cytochrome P450 gene family, was significantly higher in animals exhibiting mycotoxin tolerance ('resistance'). Further, we present novel evidence for the amplification of Wnt signalling pathway activity in 'resistant' animals, resulting from the marked suppression of multiple key Wnt inhibitor genes. Notably, 'resistance' may be determined primarily by the ability of an individual to detoxify secondary metabolites generated by the metabolism of mycotoxins and the potentiation of Wnt signalling may be pivotal to achieving a favourable outcome upon challenge.", "label": 0}
{"doc-1": "The remarkable properties of graphene have renewed interest in inorganic, two-dimensional materials with unique electronic and optical attributes. Transition metal dichalcogenides (TMDCs) are layered materials with strong in-plane bonding and weak out-of-plane interactions enabling exfoliation into two-dimensional layers of single unit cell thickness. Although TMDCs have been studied for decades, recent advances in nanoscale materials characterization and device fabrication have opened up new opportunities for two-dimensional layers of thin TMDCs in nanoelectronics and optoelectronics. TMDCs such as MoS(2), MoSe(2), WS(2) and WSe(2) have sizable bandgaps that change from indirect to direct in single layers, allowing applications such as transistors, photodetectors and electroluminescent devices. We review the historical development of TMDCs, methods for preparing atomically thin layers, their electronic and optical properties, and prospects for future advances in electronics and optoelectronics.", "doc-2": "The financial and economic analysis of the effectiveness is a mandatory element of investment documentation of transport projects. The evaluating social and economic effectiveness of an investment project is based on the identification and appraisal of its expected impact on society as a whole. The effects of transport infrastructure projects include the so-called direct impacts, which affect the users of transportation infrastructure and also external impacts caused to society and the environment, which are not taken into the account. The wider social and economic impacts or the so-called indirect impacts are also included. In the economic appraisal of a transport project the monetised effects are usually appraised with the method of cost-benefit analysis, while other effects are included in the whole appraisal with the qualitative descriptions. This diploma thesis studies the costbenefit analysis within the process of the economic appraisal of transport projects necessary calculation of the user benefit, with the main focus on transport economic appraisal software TUBA, which was developed by the Department for Transport of Great Britain. The calculation method is based on the matrix input data, these are trip matrices and cost matrices, extracted directly from the traffic model. This method provides a good estimate of user benefits gained through savings in travel time and is even greater when the traffic demand exceeds network capacity that leads to congestion and delays, and consequently, longer travel times. For the appraisal of transport infrastructure projects planned in urban areas, the program has been in use for several years in Slovenia.", "label": 0}
{"doc-1": "It is suggested that the motion of pedestrians can be described as if they would be subject to ``social forces.'' These ``forces'' are not directly exerted by the pedestrians' personal environment, but they are a measure for the internal motivations of the individuals to perform certain actions (movements). The corresponding force concept is discussed in more detail and can also be applied to the description of other behaviors. In the presented model of pedestrian behavior several force terms are essential: first, a term describing the acceleration towards the desired velocity of motion; second, terms reflecting that a pedestrian keeps a certain distance from other pedestrians and borders; and third, a term modeling attractive effects. The resulting equations of motion of nonlinearly coupled Langevin equations. Computer simulations of crowds of interacting pedestrians show that the social force model is capable of describing the self-organization of several observed collective effects of pedestrian behavior very realistically.", "doc-2": "Most of the recent advances in activity-based models (ABMs) have been on the demand side, that is, description of the individual needs for certain types of activities and travel as a function of person, household, and accessibility variables. The supply side of activities that describes characteristics of the locations where a certain activity can be undertaken remains largely unexplored. Two examples of specific activity generators for which the supply side of activity is essential for modeling are major universities and special events. Travel behavior and activity patterns of university students are different from that of the general population, and therefore modeling them with the necessary level of detail enhances the ABM forecasting ability. The same is true about special events such as sporting events. Special events participants can form a substantial part of the overall travel demand in the subarea on the event day, and therefore it is important to model them properly. Although previous studies ha...", "label": 0}
{"doc-1": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?.", "doc-2": "Energy efficiency (EE) has become an important design goal for future cellular systems. In this paper, we study the EE problem for limited-feedback coordinated beamforming systems providing real-time services with constant date rate. To maximize the EE, we jointly optimize the transmit power among users and the feedback bits of each user to quantize the desired and interfering channel directions, subject to the constraints of outage probability and number of feedback bits. An iterative optimization algorithm is proposed for alternating power and bit allocation by employing Yates framework. To further reduce the computational complexity, a suboptimal algorithm is proposed in closed form by decoupling the problem into subproblems under asymptotical analysis. Simulation results show that the suboptimal algorithm performs closely to the iterative optimization algorithm under high-quantization resolution. Moreover, the proposed two algorithms provide substantial EE gain over existing schemes with equal power and bit allocation, and the EE depends on the target data rate and outage probability of each user as well as the circuit power consumption at the base stations.", "label": 0}
{"doc-1": "Mobile users' data rate and quality of service are limited by the fact that, within the duration of any given call, they experience severe variations in signal attenuation, thereby necessitating the use of some type of diversity. In this two-part paper, we propose a new form of spatial diversity, in which diversity gains are achieved via the cooperation of mobile users. Part I describes the user cooperation strategy, while Part II (see ibid., p.1939-48) focuses on implementation issues and performance analysis. Results show that, even though the interuser channel is noisy, cooperation leads not only to an increase in capacity for both users but also to a more robust system, where users' achievable rates are less susceptible to channel variations.", "doc-2": "[1]Heterogeneous N2O5 uptake onto aerosol is the primary nocturnal path for removal of NOx (= NO+NO2) from the atmosphere and can also result in halogen activation through production of ClNO2. The N2O5 uptake coefficient has been the subject of numerous laboratory studies; however, only a few studies have determined the uptake coefficient from ambient measurements, and none has been focused on winter conditions, when the portion of NOx removed by N2O5 uptake is the largest. In this work, N2O5 uptake coefficients are determined from ambient wintertime measurements of N2O5 and related species at the Boulder Atmospheric Observatory in Weld County, CO, a location that is highly impacted by urban pollution from Denver, as well as emissions from agricultural activities and oil and gas extraction. A box model is used to analyze the nocturnal nitrate radical chemistry and predict the N2O5 concentration. The uptake coefficient in the model is iterated until the predicted N2O5 concentration matches the measured concentration. The results suggest that during winter, the most important influence that might suppress N2O5 uptake is aerosol nitrate but that this effect does not suppress uptake coefficients enough to limit the rate of NOx loss through N2O5 hydrolysis. N2O5 hydrolysis was found to dominate the nocturnal chemistry during this study consuming ~80% of nocturnal gas phase nitrate radical production. Typically, less than 15% of the total nitrate radical production remained in the form of nocturnal species at sunrise when they are photolyzed and reform NO2.", "label": 0}
{"doc-1": "Linear algebra and matrix theory are fundamental tools in mathematical and physical science, as well as fertile fields for research. This new edition of the acclaimed text presents results of both classic and recent matrix analyses using canonical forms as a unifying theme, and demonstrates their importance in a variety of applications. The authors have thoroughly revised, updated, and expanded on the first edition. The book opens with an extended summary of useful concepts and facts and includes numerous new topics and features, such as: - New sections on the singular value and CS decompositions - New applications of the Jordan canonical form - A new section on the Weyr canonical form - Expanded treatments of inverse problems and of block matrices - A central role for the Von Neumann trace theorem - A new appendix with a modern list of canonical forms for a pair of Hermitian matrices and for a symmetric-skew symmetric pair - Expanded index with more than 3,500 entries for easy reference - More than 1,100 problems and exercises, many with hints, to reinforce understanding and develop auxiliary themes such as finite-dimensional quantum systems, the compound and adjugate matrices, and the Loewner ellipsoid - A new appendix provides a collection of problem-solving hints.", "doc-2": "Native cyclodextrins (CDx) and some of their derivatives were reacted with poly(carboxylic acid)s (PCAs) (citric acid (CTR), 1,2,3,4-butanetetracarboxylic acid (BTCA), and poly(acrylic acid) (PAA)). These reactions were carried out in the dry state at a temperature greater than 140C in air or in vacuo. They resulted in water-soluble and insoluble polymers formed by polyesterification between CDx and PCA. In this study, the parameters of the reaction were studied, and their influence on the water solubility or swellability of the obtained polymers was investigated. High reaction temperatures, high PCA/CDx molar ratios, and long reaction times preferably yielded insoluble gels, whereas softer conditions resulted in very soluble polymers. The gels could swell up to 10 times their initial volume in water, and the water-soluble fraction had a solubility of 1 g/mL. A reaction mechanism was proposed that required the use of PCA carrying at least three neighboring carboxylic groups (CTR, BTCA, and PAA), and it was confirmed ex- perimentally by the unsuccessful use of some dicarboxylic acids. A preliminary characterization by Fourier transform infrared spectroscopy and size exclusion chromatography was also conducted.  2005 Wiley Periodicals, Inc. J Appl Polym Sci 97: 433- 442, 2005", "label": 0}
{"doc-1": "A hypothesized need to form and maintain strong, stable interpersonal relationships is evaluated in light of the empirical literature. The need is for frequent, nonaversive interactions within an ongoing relational bond. Consistent with the belongingness hypothesis, people form social attachments readily under most conditions and resist the dissolution of existing bonds. Belongingness appears to have multiple and strong effects on emotional patterns and on cognitive processes. Lack of attachments is linked to a variety of ill effects on health, adjustment, and well-being. Other evidence, such as that concerning satiation, substitution, and behavioral consequences, is likewise consistent with the hypothesized motivation. Several seeming counterexamples turned out not to disconfirm the hypothesis. Existing evidence supports the hypothesis that the need to belong is a powerful, fundamental, and extremely pervasive motivation.", "doc-2": "The identification of RNA-binding residues in proteins is important in several areas such as protein function, posttranscriptional regulation and drug design. We have developed PRBR (Prediction of RNA Binding Residues), a novel method for identifying RNA-binding residues from amino acid sequences. Our method combines a hybrid feature with the enriched random forest (ERF) algorithm. The hybrid feature is composed of predicted secondary structure information and three novel features: evolutionary information combined with conservation information of the physicochemical properties of amino acids and the information about dependency of amino acids with regards to polarity-charge and hydrophobicity in the protein sequences. Our results demonstrate that the PRBR model achieves 0.5637 Matthew's correlation coefficient (MCC) and 88.63% overall accuracy (ACC) with 53.70% sensitivity (SE) and 96.97% specificity (SP). By comparing the performance of each feature we found that all three novel features contribute to the improved predictions. Area under the curve (AUC) statistics from receiver operating characteristic curve analysis was compared between PRBR model and other models. The results show that PRBR achieves the highest AUC value (0.8675) which represents that PRBR attains excellent performance on predicting the RNA-binding residues in proteins. The PRBR web-server implementation is freely available at http://www.cbi.seu.edu.cn/PRBR/.", "label": 0}
{"doc-1": "The activity of the DAF-2 insulin-like receptor is required for Caenorhabditis elegans reproductive growth and normal adult life span. Informatic analysis identified 37 C. elegans genes predicted to encode insulin-like peptides. Many of these genes are divergent insulin superfamily members, and many are clustered, indicating recent diversification of the family. The ins genes are primarily expressed in neurons, including sensory neurons, a subset of which are required for reproductive development. Structural predictions and likely C-peptide cleavage sites typical of mammalian insulins suggest that ins-1 is most closely related to insulin. Overexpression of ins-1, or expression of human insulin under the control of ins-1 regulatory sequences, causes partially penetrant arrest at the dauer stage and enhances dauer arrest in weak daf-2 mutants, suggesting that INS-1 and human insulin antagonize DAF-2 insulin-like signaling. A deletion of the ins-1 coding region does not enhance or suppress dauer arrest, indicating a functional redundancy among the 37 ins genes. Of five other ins genes tested, the only other one bearing a predicted C peptide also antagonizes daf-2 signaling, whereas four ins genes without a C peptide do not, indicating functional diversity within the ins family.", "doc-2": "We give characterizations of (forward and reverse) Carleson conditions in terms of inequalities that involve functions in BergmanOrlicz spaces.", "label": 0}
{"doc-1": "The identification of genetically homogeneous groups of individuals is a long standing issue in population genetics. A recent Bayesian algorithm implemented in the software STRUCTURE allows the identification of such groups. However, the ability of this algorithm to detect the true number of clusters (K) in a sample of individuals when patterns of dispersal among populations are not homogeneous has not been tested. The goal of this study is to carry out such tests, using various dispersal scenarios from data generated with an individual-based model. We found that in most cases the estimated 'log probability of data' does not provide a correct estimation of the number of clusters, K. However, using an ad hoc statistic DeltaK based on the rate of change in the log probability of data between successive K values, we found that STRUCTURE accurately detects the uppermost hierarchical level of structure for the scenarios we tested. As might be expected, the results are sensitive to the type of genetic marker used (AFLP vs. microsatellite), the number of loci scored, the number of populations sampled, and the number of individuals typed in each sample.", "doc-2": "Data were collected from 8,126 employees in a large government service agency using an anonymous survey measuring 9 aspects of quality culture and 10 aspects of organizational climate. Results show that supervisors perceived all 19 aspects of the culture and climate measured on the survey significantly more positively than did non-supervisors. Results are discussed in terms of their implications for organizational effectiveness.", "label": 0}
{"doc-1": "SUMMARYThe program MRBAYES performs Bayesian inference of phylogeny using a variant of Markov chain Monte Carlo.AVAILABILITYMRBAYES, including the source code, documentation, sample data files, and an executable, is available at http://brahms.biology.rochester.edu/software.html.", "doc-2": "Intracerebroventricular injections of [D-arginine2, sarcosine4]-dermorphin (1-4) (DAS-DER 1-4) and morphine produced a dose-dependent inhibition of the tail-flick response to thermal stimulation. The ED50 value for each drug was 3.23 (1.35-7.73) nmol/rat and 32.0 (13.3-76.6) nmol/rat, respectively. When injected into the spinal subarachnoid space, the ED50 value was 0.035 (0.015-0.086) nmol/rat for the tetrapeptide and 11.9 (5.7-25.2) nmol/rat for morphine, respectively. Antinociception induced by DAS-DER 1-4 and morphine, through the intracerebroventricular and intrathecal routes, was clearly reduced by pretreatment with a small dose of naloxone. After spinal transection, the antinociceptive potency of systemically-administered morphine was significantly reduced while that of DAS-DER 1-4 was unaltered. The activity of DAS-DER 1-4 and morphine was also reversed by naloxone in spinal animals. It is concluded that DAS-DER 1-4, a dermorphin analogue, has a minor supraspinal action but acts mainly at the level of the spinal cord, in contrast to the action of morphine.", "label": 0}
{"doc-1": "This Paper Proposes Some New Tests for Detecting the Presence of a Unit Root in Quite General Time Series Modesl. Our Approach Is Nonparametric with Respect to Nuisance Parameters and Thereby Allows for a Very Wide Class of Weakly Dependent and Possibly Heterogeneously Distributed Data. the Tests Accomodate Models with a Fitted Drift and a Time Trend So That They May Be Used to Discriminate Between Unit Root Nonstationarity and Stationarity About a Deterministic Trend. the Limiting Distributions of the Statistics Are Obtained Under Both the Unit Root Null and a Sequence of Local Alternatives. Th Latter Noncentral Distribution Theory Yields Local Asymptotic Power Functions for the Tests. These Are Compared with Alternative Procedures Due to Dickey and Fuller. an Exemple Is Provided.", "doc-2": "In the precondition of getting the same feature points, the selection of different transformation models can greatly affect the speed and effectiveness of image mosaic. In this paper, the focus was on the determination of a transformation model from a given set of feature points. The high-resolution images captured by UAV (unmanned aerial vehicle) in the water-resource-investigation field were selected as source data. Four different transformation models-Affine Transformation, Quadratic Polynomial Transformation, Delaunay Triangulation and Homography Matrix were compared and analyzed for the optimal mosaic model of stereo pair in this situation. The experiment results indicated that Homography Matrix was the best in this case. Finally, it was given some useful advice for the selection of transformation models for the entire air strip mosaic.", "label": 0}
{"doc-1": "viii", "doc-2": "Antibiotics are critical defenses in the fight against bacterial infections, but they can also be used as probes to explore basic microbiology, including cell division, stress responses and cell wall biosynthesis, and will be valuable tools in deciphering bacterial networks and complexity.", "label": 0}
{"doc-1": "The present invention provides a method for effectively inducing pluripotent stem cells from germ stem cells. Pluripotent stem cell cells can be induced with greater efficiency than in conventional methods by using germ stem cells in which Sox2 and/or Oct4 is overexpressed. With regard to the germ stem cells, one or more kind of gene selected from Dnmt1 gene, Dmap1 gene, Dmrt1 gene and Oct1 gene is inhibited, or Sox2 gene and/or Oct4 gene is overexpressed, or alternatively the protein of Sox2 and/or Oct4 is directly introduced. Said method enables pluripotent stem cells to be more efficiently induced from germ stem cells than in conventional methods.", "doc-2": "The maximum likelihood (ML) approach for estimating direction of arrival (DOA) is a well known and popular technique in array processing. Its statistical properties such as consistency and efficiency have been extensively studied in the literature. A common assumption made in previous works is that the assumed number of signals equals the true one. However, this information is not always available and usually needs to be estimated together with the DOA parameter. Thus it is crucial to know whether ML estimator provides any significant information when we are not certain about the number signals. In this work, we show that ML estimator under misspecified number of signals converges to aw ell defined limit. In the case of well separated sources, components of ML estimates coincide with the true parameters. Our theoretical analysis is validated by numerical experiments.", "label": 0}
{"doc-1": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.", "doc-2": "Topic summarization and analysis is very important to understand an academic document collection and is very paramount for scientific research, which can help researchers find the hot field. Many scholars used the topic model to analyze the theme development, such as LDA. However, these methods need a pre-specified number of latent topics and manual topic labeling, which is usually difficult for people. Aiming to this problem, this paper proposes a method to analyze theme development with topic clustering. Different from the existing works, this paper uses the sliding window to cluster topics extracted in different time incrementally, the topic distance can be measured with KL-divergence. Some experiments on real data sets validate the effectiveness of our proposed method.", "label": 0}
{"doc-1": "p53 protein levels have been shown to increase in a number of cells after treatment with genotoxic agents through a post-transcriptional mechanism. In gamma-irradiated human cells, the accumulation of p53 protein is accompanied by an increase in the association of p53 mRNA with large polysomes without any change in the level of p53 mRNA. This redistribution of p53 mRNA on polysomes in response to irradiation is consistent with enhanced translational activity of p53 mRNA. We demonstrate that a region of the p53 3'-untranslated region (3'UTR) inhibits translation of a chimeric reporter mRNA in vivo. Induced elevation of reporter activity after gamma-irradiation was seen in cells expressing chimeric reporter-p53 3'UTR transcripts. These data taken together demonstrate translational control of p53 gene expression after gamma-irradiation and denote a previously unsuspected and novel role for the p53 3'UTR in controlling translation.", "doc-2": "A continuum model of the macroscopic behaviour of solids capable of undergoing displacive phase transitions is applied to determine the response of such materials to mechanical loading by impact. The solid is modelled using one-dimensional finite thermoelasticity, and the model incorporates both a kinetic relation and a nucleation criterion controlling the evolution and initiation of the phase transition, respectively.", "label": 0}
{"doc-1": "Research electronic data capture (REDCap) is a novel workflow methodology and software solution designed for rapid development and deployment of electronic data capture tools to support clinical and translational research. We present: (1) a brief description of the REDCap metadata-driven software toolset; (2) detail concerning the capture and use of study-related metadata from scientific research teams; (3) measures of impact for REDCap; (4) details concerning a consortium network of domestic and international institutions collaborating on the project; and (5) strengths and limitations of the REDCap system. REDCap is currently supporting 286 translational research projects in a growing collaborative network including 27 active partner institutions.", "doc-2": "In the literature on PERT methodology, four subfamilies of beta distributions have appeared: classical, of constant variance, mesokurtic and Caballer. To date, these four subfamilies have been used independently to resolve economic valuation problems. The only differences between using one or another lie in the means or variances obtained by each. For example, following a criterion of prudence the maximum variance is required, and for a riskier criterion the minimum variance is preferred. With respect to the mean, we are interested in the one closest to the centre of the interval, i.e. the model that provides a more centered expected value and hence more moderate estimations. This work focuses on the field of valuation, more specifically on the valuation method of the two distribution functions (recommended when there are limited data). The aim of this work was to develop an iterative process that uses the four families of beta distributions simultaneously with the objective of using all the information provided by each of them. The practical application of this process can conclude either with an interval of possible values or a precise valuation. Then the concepts of stability and convergence of the valuation process appear.", "label": 0}
{"doc-1": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.", "doc-2": "Little research has been conducted in higher education settings that focuses on how tertiary educators understand informal learning or on their role in fostering students informal learning to facilitate formal learning. In this article we partially fill this knowledge gap by reporting findings from a case study exploring how 30 New Zealand tertiary educators from one university conceptualised informal learning and the strategies they implemented to support students informal learning as an enhancement to formal learning.", "label": 0}
{"doc-1": "The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.", "doc-2": "The cadmium mobilizing efficiency of a combined treatment with a novel cadmium chelating agent disodium N,N'-bis(D-glucosyl)-1,9-nonanediamine-N,N'-biscarbodithioate++ + (C9G2DTC) and with sodium N-benzyl-D-glucamine-N-carbodithioate (BGDTC) was evaluated in albino rats. They received 109Cd intraperitoneally once and 1 week later chelation therapy six times over 12 days at 2-day intervals. The treatment groups were: 1, control; 2, BGDTC six times; 3, C9G2DTC six times; 4, C9G2DTC three times followed by BGDTC three times; 5, C9G2DTC twice followed by BGDTC four times; 6, C9G2DTC once followed by BGDTC five times. The radioactivity in liver, kidney and brain was determined 19 days after 109Cd administration. Results were expressed as a percentage of the 109Cd dose and differences were analyzed by Duncan's multiple range test (P < 0.05). Treatment with C9G2DTC resulted in higher Cd reduction in the liver and lower in the kidney than with BGDTC, which is in agreement with our previous findings. Combined treatment resulted in a greater reduction of Cd in the liver and kidney than by using either chelating agent alone, irrespective of the number of C9G2DTC or BGDTC treatments, and without causing redistribution to the brain. The important aspect of this work is that C9G2DTC--the novel cadmium chelating agent which is extremely efficient in reducing Cd liver deposits and about three times more toxic than BGDTC--has to be used only once at the beginning of the treatment to obtain optimal reduction of aged organ cadmium deposits.", "label": 0}
{"doc-1": "A technique for conveniently radiolabeling DNA restriction endonuclease fragments to high specific activity is described. DNA fragments are purified from agarose gels directly by ethanol precipitation and are then denatured and labeled with the large fragment of DNA polymerase I, using random oligonucleotides as primers. Over 70% of the precursor triphosphate is routinely incorporated into complementary DNA, and specific activities of over 10(9) dpm/microgram of DNA can be obtained using relatively small amounts of precursor. These \"oligolabeled\" DNA fragments serve as efficient probes in filter hybridization experiments.", "doc-2": "AbstractHorizontal lifeline system (HLLS) is one of the most widely used fall arrest systems for mitigating the risk of work-at-height in the construction and building industry. A HLLS must ensure the maximum arrest load created during a fall arrest does not exceed the capacity of the anchors and other system components. In addition, the maximum arrest force experienced by the user of the HLLS has to be kept below 6kN (Europe, Australia, and Singapore) or 8kN (North America). Finally, the height clearance must be sufficient to prevent the user from hitting the ground or obstacles. To achieve these safety criteria, a HLLS should be designed using appropriate calculation methods. This study evaluated 11 HLLS designs in Singapore based on common standards. A comprehensive calculation template was developed based on energy balance method to facilitate the evaluation. It was discovered that all 11 designs were not adequately endorsed or calculated. This is a potentially dangerous situation because HLLSs are ...", "label": 0}
{"doc-1": "A new public key cryptosystem is proposed and analyzed. The scheme is quite practical, and is provably secure against adaptive chosen ciphertext attack under standard intractability assumptions. There appears to be no previous cryptosystem in the literature that enjoys both of these properties simultaneously.", "doc-2": "Abstract In a population-based cardiovascular disease study with a response rate of 82.1%, we obtained information on cardiovascular risk factors and diseases in both respondents and non-respondents. In general participants were a somewhat biased subset of the target population in that they tended to overrepresent the worried well, i.e. those with risk factors but without disease. This response bias represents independent bias in both risk factor and disease distribution. This combined bias produced minor to moderate errors in risk ratio calculations in our study. However, greater error in risk ratios could occur in a study with a similarly biased respondent sample and a lower response rate.", "label": 0}
{"doc-1": "In molecular dynamics (MD) simulations the need often arises to maintain such parameters as temperature or pressure rather than energy and volume, or to impose gradients for studying transport properties in nonequilibrium MD. A method is described to realize coupling to an external bath with constant temperature or pressure with adjustable time constants for the coupling. The method is easily extendable to other variables and to gradients, and can be applied also to polyatomic molecules involving internal constraints. The influence of coupling time constants on dynamical variables is evaluated. A leapfrog algorithm is presented for the general case involving constraints with coupling to both a constant temperature and a constant pressure bath.", "doc-2": "Transport studies using intestinal brush-border membrane vesicles isolated from rats and rabbits have failed to demonstrate proton- or Na+-dependent carrier-mediated transport of thyrotropin-releasing hormone (TRH), despite a pharmacologically relevant oral bioavailability. To examine the hypothesis that reported levels of oral bioavailability reflect predominately a paracellular rather than transcellular route for transepithelial transport of TRH, we have studied TRH transport in cultured epithelial cell types of intestinal (Caco-2 and T84) and renal (MDCK I, MDCK II, and LLC-PK1 origin, whose paracellular pathways span the range of permeability values observed in natural epithelia. Transport of TRH across monolayers of intestinal Caco-2 cells was similar to the flux of mannitol (14% per 4 hr), and unlike other putative substrates for the di-/tripeptide carrier, apical-to-basolateral transport was not increased by the presence of an acidic pH in the apical chamber. TRH transport did not show saturation, being uneffected in the presence of 20 mM cold TRH. In each cell type studied TRH and mannitol transport were similar and positively correlated with the conductance of the cell layers, consistent with a passive mechanism of absorption. This evidence suggests that, providing that a peptide is resistant to luminal hydrolysis, small but pharmacologically significant amounts of peptide absorption may be achieved by passive absorption across a paracellular route.", "label": 0}
{"doc-1": "Telomere dysfunction may result in chromosomal abnormalities, DNA damage responses, and even cancer. Early studies in lower organisms have helped to establish the crucial role of telomerase and telomeric proteins in maintaining telomere length and protecting telomere ends. In Oxytricha nova, telomere G-overhangs are protected by the TEBP-/ heterodimer. Human telomeres contain duplex telomeric repeats with 3 single-stranded G-overhangs, and may fold into a t-loop structure that helps to shield them from being recognized as DNA breaks. Additionally, the TEBP- homologue, POT1, which binds telomeric single-stranded DNA (ssDNA), associates with multiple telomeric proteins (for example, TPP1, TIN2, TRF1, TRF2 and RAP1) to form the six-protein telosome/shelterin and other subcomplexes. These telomeric protein complexes in turn interact with diverse pathways to form the telomere interactome for telomere maintenance. However, the mechanisms by which the POT1-containing telosome communicates with telomerase to regulate telomeres remain to be elucidated. Here we demonstrate that TPP1 is a putative mammalian homologue of TEBP- and contains a predicted amino-terminal oligonucleotide/oligosaccharide binding (OB) fold. TPP1POT1 association enhanced POT1 affinity for telomeric ssDNA. In addition, the TPP1 OB fold, as well as POT1TPP1 binding, seemed critical for POT1-mediated telomere-length control and telomere-end protection in human cells. Disruption of POT1TPP1 interaction by dominant negative TPP1 expression or RNA interference (RNAi) resulted in telomere-length alteration and DNA damage responses. Furthermore, we offer evidence that TPP1 associates with the telomerase in a TPP1-OB-fold-dependent manner, providing a physical link between telomerase and the telosome/shelterin complex. Our findings highlight the critical role of TPP1 in telomere maintenance, and support a yinyang model in which TPP1 and POT1 function as a unit to protect human telomeres, by both positively and negatively regulating telomerase access to telomere DNA.", "doc-2": "In this study, paraffin-/ultrasonic-treated diatomite was characterized for use as phase change material (PCM) for thermal energy storage in buildings. The diatomite was treated with ultrasound at various periods of time. The diatomite treated with ultrasound for 60min (DA-60) was the optimum condition providing the highest surface area without structural degradation. The melting point and latent heat of the paraffin/DA-60 composite PCM were 59C and 45.90Jg1, respectively. The obtained form-stable PCM had good thermal reliability after 500 cycles of thermal cycling test. The thermal performance of PCM was tested by incorporating the paraffin/DA-60 composite PCM into gypsum board. The results showed that the gypsum board containing the paraffin/DA-60 composite PCM had better thermal energy absorption and release characteristics than those of the control sample. The incorporation of paraffin/DA-60 composite PCM into suitable building materials could thus considerably reduce the energy consumption of cooling system in buildings.", "label": 0}
{"doc-1": "From the Publisher: This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts.", "doc-2": "Interleukin-2 (IL-2) is a central cytokine required for the activation of T, B, and NK cells. It propagates the immune response and terminates it by promoting the activation induced cell death of T cells. IL-2 production is altered in T cells of patients with systemic lupus erythematosus (SLE). The consequence of reduced IL-2 production in SLE is decreased immune response to infectious agents. Decreased IL-2 production by SLE T cells is the result of transcriptional repression of the IL-2 gene. This article will review the defective transcription regulation of IL-2 in SLE T cells, which is the result of decreased expression of the enhancers NF-kappa B and AP1 and the increased expression of the transcriptional repressor CREM.", "label": 0}
{"doc-1": "This publication contains reprint articles for which IEEE does not hold copyright. Full text is not available on IEEE Xplore for these articles.", "doc-2": "We recently reported the positional cloning of a candidate gene for hereditary hemochromatosis called HFE. The gene product, a member of the major histocompatibility complex class I-like family, was found to have a mutation, Cys-282 --> Tyr (C282Y), in 85% of patient chromosomes. This mutation eliminates the ability of HFE to associate with beta2-microglobulin (beta2m) and prevents cell-surface expression. A second mutation that has no effect on beta2m association, H63D, was found in eight out of nine patients heterozygous for the C282Y mutant. In this report, we demonstrate in cultured 293 cells overexpressing wild-type or mutant HFE proteins that both the wild-type and H63D HFE proteins form stable complexes with the transferrin receptor (TfR). The C282Y mutation nearly completely prevents the association of the mutant HFE protein with the TfR. Studies on cell-associated transferrin at 37 degrees C suggest that the overexpressed wild-type HFE protein decreases the affinity of the TfR for transferrin. The overexpressed H63D protein does not have this effect, providing the first direct evidence for a functional consequence of the H63D mutation. Addition of soluble wild-type HFE/beta2m heterodimers to cultured cells also decreased the apparent affinity of the TfR for its ligand under steady-state conditions, both in 293 cells and in HeLa cells. Furthermore, at 4 degrees C, the added soluble complex of HFE/beta2m inhibited binding of transferrin to HeLa cell TfR in a concentration-dependent manner. Scatchard plots of these data indicate that the added heterodimer substantially reduced the affinity of TfR for transferrin. These results establish a molecular link between HFE and a key protein involved in iron transport, the TfR, and raise the possibility that alterations in this regulatory mechanism may play a role in the pathogenesis of hereditary hemochromatosis.", "label": 0}
{"doc-1": "SUMMARY The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses -the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.", "doc-2": "In the UK, the leaky pipeline metaphor has been used to describe the relationship between ethnicity and science participation. Fewer minority ethnic students continue with science in post-compulsory education, and little is known about the ways in which they participate and identify with science, particularly in the secondary school context. Drawing on an exploratory study of 46 interviews and 22h of classroom observations with British students (aged 1114) from Black Caribbean, Bangladeshi, Pakistani, Indian and Chinese ethnic backgrounds, this paper identified five types of science participation among minority ethnic students. The five types of science participation emerged from an analysis of students science achievement, science aspiration, science interest and science capital. The characteristics of the five types are as follows: Science adverse students have no aspirations towards science and lacked interest, achievement and capital in science. Science intrinsic students have high science aspirations, interest and capital but low science attainment. Students who are science intermediate have some aspirations, interest and capital in science, with average science grades. Science extrinsic students achieve highly in science, have some science capital but lacked science aspirations and/or interest. Science prominent students are high science achievers with science aspirations, high levels of interest and capital in science. The findings highlight that minority ethnic students participate in science in diverse ways. Policy implications are suggested for each type as this paper provides empirical evidence to counter against public (and even some academic) discourses of minority ethnic students as a homogeneous group.", "label": 0}
{"doc-1": "High-performance liquid chromatography is a promising alternative for determining the G+C content of bacterial deoxyribonucleic acid (DNA). The method which we evaluated involves enzymatic degradation of the DNA to nucleosides by P1 nuclease and bovine intestinal mucosa alkaline phosphatase, separation of the nucleosides by high-performance liquid chromatography, and calculation of the G+C content from the apparent ratios of deoxyguanosine and thymidine. Because the nucleosides are released from the DNA at different rates, incomplete degradation produces large errors in the apparent G+C content. For partially purified DNA, salts are a major source of interference in degradation. However, when the salts are carefully removed, the preparation and degradation of DNA contribute little error to the determination of G+C content. This method also requires careful selection of the chromatographic conditions to ensure separation of the major nucleosides from the nucleosides of modified bases and precise control of the flow rates. Both of these conditions are achievable with standard equipment and C18 reversed-phase columns. Then the method is precise, and the relative standard deviations of replicate measurements are close to 0.1%. It is also rapid, and a single measurement requires about 15 min. It requires small amounts of sample, and the G+C content can be determined from DNA isolated from a single bacterial colony. It is not affected by contamination with ribonucleic acid. Because this method yields a direct measurement, it may also be more accurate than indirect methods, such as the buoyant density and thermal denaturation methods. In addition, for highly purified DNA, the extent of modification can be determined.", "doc-2": "High quality single-crystalline wurtzite indium nitride (InN) thin film was first demonstrated to have a Young's modulus of 1495GPa along a-axis using atomic force microscopy microbending test since the revision of InN energy gap. These released InN cantilever beams were examined to have ignorable in-plane residual stress using micro-Raman spectroscopy, where the E2 (high) mode at 490cm1 exists zero shift because of the perfect lattice match (8:9 commensurate) between InN and underneath aluminum nitride buffer. The experimental value of Young's modulus agrees well with a number of theoretical estimations ranging from 146 to 159GPa.", "label": 0}
{"doc-1": "New updated! The latest book from a very famous author finally comes out. Book of pattern recognition with fuzzy objective function algorithms, as an amazing reference becomes what you need to get. What's for is this book? Are you still thinking for what the book is? Well, this is what you probably will get. You should have made proper choices for your better life. Book, as a source that may involve the facts, opinion, literature, religion, and many others are the great friends to join with.", "doc-2": "Personal photographs are being captured in digital form at an accelerating rate, and our computational tools for searching, browsing, and sharing these photos are struggling to keep pace. One promising approach is automatic face recognition, which would allow photos to be organized by the identities of the individuals they contain. However, achieving accurate recognition at the scale of the Web requires discriminating among hundreds of millions of individuals and would seem to be a daunting task. This paper argues that social network context may be the key for large-scale face recognition to succeed. Many personal photographs are shared on the Web through online social network sites, and we can leverage the resources and structure of such social networks to improve face recognition rates on the images shared. Drawing upon real photo collections from volunteers who are members of a popular online social network, we asses the availability of resources to improve face recognition and discuss techniques for applying these resources.", "label": 0}
{"doc-1": "The Cochrane Handbook for Systematic Reviews of Interventions is the official document that describes in detail the process of preparing and maintaining Cochrane systematic reviews on the effects of healthcare interventions.", "doc-2": "We report that -tocotrienol quinone (ATQ3) is a metabolite of -tocotrienol, and that ATQ3 is a potent cellular protectant against oxidative stress and aging. ATQ3 is orally bioavailable, crosses the blood-brain barrier, and has demonstrated clinical response in inherited mitochondrial disease in open label studies. ATQ3 activity is dependent upon reversible 2e-redox-cycling. ATQ3 may represent a broader class of unappreciated dietary-derived phytomolecular redox motifs that digitally encode biochemical data using redox state as a means to sense and transfer information essential for cellular function.", "label": 0}
{"doc-1": "1. Introduction.- 2. Early Research in Procedural Justice.- 3. Research Methods in Procedural Justice Research.- 4. Procedural Justice in Law I: Legal Attitudes and Behavior.- 5. Procedural Justice in Law II: Sources and Implications of Procedural Justice Judgments.- 6. The Generality of Procedural Justice.- 7. Procedural Justice in the Political Arena.- 8. Procedural Justice in Organizations.- 9. Conclusions and Hypotheses.- 10. Two Models of Procedural Justice.- References.- Author Index.", "doc-2": "Based on a research project looking at usersupplier interactions in the context of AMT, attempts to discuss an alternative to the measurement of success, based on a close scrutiny of usersupplier interaction processes. Closely examines a variety of factors which are both internal and external in nature. Presents some key factors which have been identified as facilitators or inhibitors for the implementation of AMT and also draws some comparisons with key findings from other studies and in similar areas of research.", "label": 0}
{"doc-1": "AbstractA general formula () of which a special case is the Kuder-Richardson coefficient of equivalence is shown to be the mean of all split-half coefficients resulting from different splittings of a test.  is therefore an estimate of the correlation between two random samples of items from a universe of items like those in the test.  is found to be an appropriate index of equivalence and, except for very short tests, of the first-factor concentration in the test. Tests divisible into distinct subtests should be so divided before using the formula. The index$$\\bar r_{ij} $$, derived from , is shown to be an index of inter-item homogeneity. Comparison is made to the Guttman and Loevinger approaches. Parallel split coefficients are shown to be unnecessary for tests of common types. In designing tests, maximum interpretability of scores is obtained by increasing the first-factor concentration in any separately-scored subtest and avoiding substantial group-factor clusters within a subtest. Scalability is not a requisite.", "doc-2": "This article argues that there are two lines of analysis in the high-performance work systems literature that are important for HR researchers and strategists. The first involves mapping the diversity that exists in work systems, and understanding which ones perform in which contexts and why. This line of analysis is most relevant where there are serious misfits between a firm's models of HRM and its strategic context. The second line of analysis can help to enhance performance in any firm. It involves analysing the chain of links inside the black box of HRM, asking how managers envisage HRM, how they interpret and enact it, how it affects the psychological and social climates inside the organization, and for whom it performs. Following these lines of analysis, and improving our research methods, will make our discipline more relevant to the larger debate around economic and employee well-being in our societies.", "label": 0}
{"doc-1": "Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.", "doc-2": "The Alexander biquandle of a virtual knot or link is a module over a 2-variable Laurent polynomial ring which is an invariant of virtual knots and links. The elementary ideals of this module are then invariants of virtual isotopy which determine both the generalized Alexander polynomial (also known as the Sawollek polynomial) for virtual knots and the classical Alexander polynomial for classical knots. For a fixed monomial ordering <, the Grobner bases for these ideals are computable, comparable invariants which fully determine the elementary ideals and which generalize and unify the classical and generalized Alexander polynomials. We provide examples to illustrate the usefulness of these invariants and propose questions for future work.", "label": 0}
{"doc-1": "genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/", "doc-2": "Highly dispersed Ni/support catalysts were prepared from toluene-solvated nickel atoms (solvated metal atom dispersed or SMAD). Catalysts were prepared on MgO, Al/sub 2/O/sub 3/, SiO/sub 2/, and carbon, and their activities were tested for hydrogenolysis of methylcyclopentane, hydrogenation of toluene, dehydrogenation of isopropyl alcohol, and methanation of carbon monoxide. Conventional catalysts were also studied and compared with the SMAD systems. The effect of the support on SMAD catalyst activities was minimal for hydrogenolysis of methylcyclopentane, hydrogenation of toluene, and dehydration of isopropyl alcohol. However, conventional catalysts showed a significant effect of support when these reactions were studied. This difference between SMAD and conventional catalysts is attributed to the presence of an insulating layer of carbonaceous species between Ni and the support in the SMAD systems. Conversely, catalyst activity for methanation of carbon monoxide was significantly affected by support, especially MgO. This phenomenon reflects a synergistic effect of MgO when Ni is present, where CO can be adsorbed readily on MgO which apparently aids in the initial CO reduction step. The SMAD method in combination with high surface area supports yields highly dispersed catalysts with very small particle sizes. Carbon, a support with a particularly high surface area, allows formation ofmore the smallest particle sizes, and this phenomenon is believed to indicate a direct dependency ofmetal particle size on the surface area of the support. The implications of this finding on the mechanism of particle formation are discussed, as well as the observation of optimum nickel particle size effects for the reactions studied. 5 figures, 4 tables.less", "label": 0}
{"doc-1": "Abstract The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions , is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.", "doc-2": "Metallothioneins (MTs) are a group of ubiquitous low-molecular-weight proteins essential for the protection of cells against heavy metal ion toxicity. The immunohistochemical expression of MT was studied by immunohistochemistry using a monoclonal antibody (E9) against a conserved epitope of I and II isoforms in a series of 89 endometrial carcinomas, 34 cases of hyperplasia, and 32 samples of normal endometrium. In secretory phase endometrium, extensive MT expression was detected in most cases (92.4%). In contrast, MT immunoreactivity was confined to small foci in 22.2% of proliferative phase cases. The MT values in normal endometrium were inversely correlated with oestrogen receptor (ER) content (p<0.0001), progesterone receptor (PgR) content and with PCNA (p<0.0001) and MIB1 (p=0.001) scores. In hyperplastic lesions, MT expression was detected only in 3.3% of cases, while in the group of carcinomas it was observed in 23.1%. A statistically significant difference of MT expression was observed between carcinomas and simple hyperplasias (p=0.03). In carcinomas, MT expression was positively correlated with grade (p=0.0065), MIB1 (p=0.022), and p53 (p=0.006) expression, and inversely with PgR (p=0.03). A trend of inverse correlation between MT and ER receptor was also detected (p=0.07). These data suggest that MT expression seems to be under hormonal control in normal endometrium; that it may modify p53 expression; and that it could be used as an additional biological marker indicating aggressive behaviour in endometrial lesions.", "label": 0}
{"doc-1": "Enterolignans (enterodiol and enterolactone) can potentially reduce the risk of certain cancers and cardiovascular diseases. Enterolignans are formed by the intestinal microflora after the consumption of plant lignans. Until recently, only secoisolariciresinol and matairesinol were considered enterolignan precursors, but now several new precursors have been identified, of which lariciresinol and pinoresinol have a high degree of conversion. Quantitative data on the contents in foods of these new enterolignan precursors are not available. Thus, the aim of this study was to compile a lignan database including all four major enterolignan precursors. Liquid chromatography-tandem mass spectrometry was used to quantify lariciresinol, pinoresinol, secoisolariciresinol and matairesinol in eighty-three solid foods and twenty-six beverages commonly consumed in The Netherlands. The richest source of lignans was flaxseed (301,129 microg/100 g), which contained mainly secoisolariciresinol. Also, lignan concentrations in sesame seeds (29,331 microg/100 g, mainly pinoresinol and lariciresinol) were relatively high. For grain products, which are known to be important sources of lignan, lignan concentrations ranged from 7 to 764 microg/100 g. However, many vegetables and fruits had similar concentrations, because of the contribution of lariciresinol and pinoresinol. Brassica vegetables contained unexpectedly high levels of lignans (185-2321 microg/100 g), mainly pinoresinol and lariciresinol. Lignan levels in beverages varied from 0 (cola) to 91 microg/100 ml (red wine). Only four of the 109 foods did not contain a measurable amount of lignans, and in most cases the amount of lariciresinol and pinoresinol was larger than that of secoisolariciresinol and matairesinol. Thus, available databases largely underestimate the amount of enterolignan precursors in foods.", "doc-2": "Endothelial cells can acquire a mesenchymal phenotype upon irritation [endothelial-to-mesenchymal transition (EndMT)]. Macrophages accumulate in the atherosclerotic plaque. This study addressed whether macrophages modulate EndMT and delineated a reciprocal effect of EndMT on macrophage functions in atherosclerosis. In atherosclerotic murine and human aortas, endothelial cells with mesenchymal markers were elevated by confocal microscopy and flow cytometric analysis. Increased EndMT master transcription factor Snai1 expression and extracellular matrix are consistent with enhanced EndMT in this condition. Hypoxia was detected in individual aortic EndMT cells in vivo and rapidly induced a similar EndMT phenotype in vitro. As a novel inducer of EndMT, macrophages, which are abundant in the atherosclerotic lesions, enhance mesothelial marker expression during coculture in vitro. In the reverse relationship, EndMT altered endothelial colony-stimulating factor expression. Functionally, EndMT cell-conditioned media attenuated macrophage proliferation, antigen-presenting cell marker expression, and TNF- production in response to oxidized LDL but increased oxidized LDL uptake and scavenger receptor expression. These experiments demonstrate that macrophages promote partial EndMT. In turn, EndMT cells modulate macrophage phenotype and lipid uptake. Our data suggest that EndMT shapes macrophage and endothelial cell phenotypes, thus affecting internal atherosclerotic plaque in addition to surface structure.-Helmke, A., Casper, J., Nordlohne, J., David, S., Haller, H., Zeisberg, E. M., von Vietinghoff, S. Endothelial-to-mesenchymal transition shapes the atherosclerotic plaque and modulates macrophage function.", "label": 0}
{"doc-1": "UNLABELLEDResearch over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.AVAILABILITYhttp://www.broad.mit.edu/mpg/haploview/CONTACTjcbarret@broad.mit.edu", "doc-2": "La lagune El Meleh est une lagune cotiere qui souvre sur le golfe de Tunis. Elle presente de nombreuses potentialites biologiques et ecologiques. Cependant les divers rejets lies aux activites anthropiques viennent sajouter a la fragilite naturelle de lecosysteme pour aggraver sa degradation. Ce travail a pour but didentifier les impacts anthropiques sur les eaux et les sediments et sur des compartiments non etudies jusqua present : les eaux interstitielles, les matieres en suspension et les argiles. Il a permis de confirmer par les etudes geochimiques et statistiques ce qui etait suspecte car tellement visible sur le terrain : Une contamination en elements metalliques de lensemble de la lagune et en particulier de la zone Sud Ouest. Les principales sources de la pollution sont les effluents de la station depuration, les effluents industriels draines par loued El Bey qui sont rejetes depuis des annees dans la lagune ainsi que les activites agricoles, pratiquees au Sud et a lEst de la lagune. Les sediments presentent une contamination par Ni et Zn. Letude de la contamination par le calcul du facteur denrichissement a permis de reveler dautres elements polluants tels que Cu ainsi que dautres sites contamines tels que la passe. Cu et Ni sont les plus enrichis au niveau des sediments carottes. Zn et Ni presentent les plus fortes teneurs dans la MES de la lagune El Meleh. Les eaux interstitielles presentent des teneurs elevees pour le Ni, Zn, Cu, Cr, et As par rapport aux eaux de surface. Letude de la mobilisation des metaux lourds a montre que lelement le plus contaminant est : As ; Cr et Zn viennent en second ordre, puis Ni et enfin Cu.", "label": 0}
{"doc-1": "CLUSTAL X is a new windows interface for the widely-used progressive multiple sequence alignment program CLUSTAL W. The new system is easy to use, providing an integrated system for performing multiple sequence and profile alignments and analysing the results. CLUSTAL X displays the sequence alignment in a window on the screen. A versatile sequence colouring scheme allows the user to highlight conserved features in the alignment. Pull-down menus provide all the options required for traditional multiple sequence and profile alignment. New features include: the ability to cut-and-paste sequences to change the order of the alignment, selection of a subset of the sequences to be realigned, and selection of a sub-range of the alignment to be realigned and inserted back into the original alignment. Alignment quality analysis can be performed and low-scoring segments or exceptional residues can be highlighted. Quality analysis and realignment of selected residue ranges provide the user with a powerful tool to improve and refine difficult alignments and to trap errors in input sequences. CLUSTAL X has been compiled on SUN Solaris, IRIX5.3 on Silicon Graphics, Digital UNIX on DECstations, Microsoft Windows (32 bit) for PCs, Linux ELF for x86 PCs, and Macintosh PowerMac.", "doc-2": "We propose a one-step nanopatterning method where liquid monomers are polymerized directly with an electron beam under an atmospheric pressure. The method allows precise positional control of an electron beam that induces electropolymerization based on an anodic oxidation only in the irradiated areas. Various versatile conjugated polymers, including polypyrrole, polyaniline and poly(3-hexylthiophene), have been directly polymerized from monomers without solvents and patterned by our one-step nanopatterning method. Vertically oriented arrays of nanorods several hundred nanometers in diameter with an aspect ratio (height to diameter) of around two were fabricated.", "label": 0}
{"doc-1": "AIMWe estimated the number of people worldwide with diabetes for the years 2010 and 2030.METHODSStudies from 91 countries were used to calculate age- and sex-specific diabetes prevalences, which were applied to national population estimates, to determine national diabetes prevalences for all 216 countries for 2010 and 2030. Studies were identified using Medline, and contact with all national and regional International Diabetes Federation offices. Studies were included if diabetes prevalence was assessed using a population-based methodology, and was based on World Health Organization or American Diabetes Association diagnostic criteria for at least three separate age-groups within the 20-79 year range. Self-report or registry data were used if blood glucose assessment was not available.RESULTSThe world prevalence of diabetes among adults (aged 20-79 years) will be 6.4%, affecting 285 million adults, in 2010, and will increase to 7.7%, and 439 million adults by 2030. Between 2010 and 2030, there will be a 69% increase in numbers of adults with diabetes in developing countries and a 20% increase in developed countries.CONCLUSIONThese predictions, based on a larger number of studies than previous estimates, indicate a growing burden of diabetes, particularly in developing countries.", "doc-2": "The growth of electronics technology is followed by increasing some kinds of frequency that circulating on the environment. The presence of those frequencies will decrease immunity and reliability of electronic equipments that should be improved by installation of filters. This paper is intended to look for a new filter topology, which is the most efficient from the various possible combinations. The filters installed before the equipments rectification system is called Electromagnetic Interference (EMI) filter. EMI filters are analyzed consists of harmonic filter and Low Pass Broadband Filter (LPBF). Single tone harmonic filter is used to dampen the additional grids frequency that appear ranging from 100 Hz to 2 kHz. LPBF will be combined to dampen the frequencies that higher than 2 kHz due to the effect of capacitance, induction or radiation of electromagnetic pulse from the events of Electrostatic Discharge (ESD), Electrical Fast Transient (EFT) and Surges. Some EMC standards for transient immunity and harmonic current as set out in the standard IEC 61000-4-2, IEC 61000-4-4, IEC 61000-4-5 and IEC 61000-3-2 were elaborated to determine the parameters of the filter. Analysis for the performance of the filter in the form of insertion loss (IL) uses the parameters of impedance, admittance and transmission in in two port network. The results of calculations based on the standard values of the source and load impedance, with a cut-off frequency for harmonic filter is 150 Hz and 6.37 kHz for LPBF shows that the parallel combination of the type a1 harmonic filter (series with the grid) with LPBF is the most efficient.", "label": 0}
{"doc-1": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data.", "doc-2": "Creativity is increasingly important in today's fast changing world. The use of group support systems has been shown to improve the quantity and quality of ideas produced by groups during idea generation. Similarly, creative techniques may be used to increase creativity. Therefore, the use of creative techniques together with a GSS may help groups think more creatively. Brainstorming is the most used and studied of the techniques. However, to further increase creativity, other types of creative techniques may be used. This paper presents a theory addressing structural aspects of both creative techniques and GSS, including testable hypotheses. A laboratory experiment is described that tests these hypotheses for three creative techniques (brainstorming, assumption reversals and analogies) implemented using a GSS. Results support the proposed theory. Analogies produced fewer but more creative ideas. Assumption reversals produced the most ideas, but these ideas were less creative than ideas produced by analogies and brainstorming.", "label": 0}
{"doc-1": "OBJECTIVETo evaluate the association between physical activity and all case mortality in postmenopausal women.DESIGNProspective cohort study with 7 years of follow-up through December 31, 1992.SETTING AND PARTICIPANTSSubjects were 40417 postmenopausal Iowa women, aged 55 to 69 years at baseline in 1986. Physical activity was assessed by mailed questionnaire.MAIN OUTCOME MEASUREAll-cause mortality (n=2260).RESULTSAfter adjustment for potential confounders and excluding women who reported having cancer or heart disease and those who died in the first 3 years of follow-up, women who reported regular physical activity were at significantly reduced risk of death during follow-up compared with women who did not (relative risk [RR], 0.77; 95% confidence interval [CI], 0.66-0.90). Increasing frequency of moderate physical activity was associated with reduced risk of death during follow-up (from rarely or never engaging in activity to activity at least 4 times per week, RRs, 1.0 [referent], 0.76, 0.70, and 0.62; P value for trend<.001). A similar pattern was seen for vigorous physical activity (corresponding RRs, 1.0, 0.89, 0.74, and 0.57; Pvalue for trend=.06). Reduced risks of death with increased physical activity were evident for cardiovascular diseases (n=729) and respiratory illnesses (n=147). Women who engaged only in moderate but not vigorous physical activity also benefited, with moderate activity as infrequently as once per week demonstrating a reduced mortality risk of 0.78 (95% CI, 0.64-0.96).CONCLUSIONSThese results demonstrate a graded, inverse association between physical activity and all-cause mortality in postmenopausal women. These findings strengthen the confidence that population recommendations to engage in regular physical activity are applicable to postmenopausal women.", "doc-2": "Abstract For the first time a mathematical modelling of the enzymatic glucose membraneless fuel cell with direct electron transfer has been reported. The niche of this mathematical modelling is the description of the new Homotopy perturbation method to solve the nonlinear differential equations that describes glucose concentration and hydrogen ions respectively. The analytical results of an enzymatic fuel cell should be used, while developing fuel cell, to estimate its various kinetic parameters to attain the highest power value. Our analytical results are compared with limiting case results and satisfactory agreement is noted. The influence of parameters on the concentrations are discussed.", "label": 0}
{"doc-1": "This paper analyzes the role of income distribution in macroeconomic analysis. The study demonstrates that the long-run equilibrium depends on the initial distribution of income. In accordance with empirical evidence concerning the correlation between income distribution and output, an economy that is characterized by a relatively equal distribution of wealth is likely to be wealthier in the long run. The study may, therefore, provide an additional explanation for the persistent differences in per-capita output across countries. Furthermore, the paper may shed light on cross-countries differences macroeconomic adjustment to aggregate shocks.", "doc-2": "Health Maintenance Organization (HMO) administrators have been accused of engaging in selective marketing. That is, through such strategies as tailoring the benefits package of the program or advertising in styles or in media that do not appeal to certain undesirable audiences, the administrator can minimize the percentage of persons in the HMO who are heavy users of health care services.By means of analyzing what insurance is (philosophically) and what it means for something to be a free market commodity, the author argues that, as long as American society chooses to regard health insurance as a commodity or service of the free market, the use of such strategies is within the moral rights of health administrators.The author concludes by noting some morally undesirable results of treating health insurance as a market commodity.", "label": 0}
{"doc-1": "BACKGROUNDAn improvement in overall survival among patients with metastatic melanoma has been an elusive goal. In this phase 3 study, ipilimumab--which blocks cytotoxic T-lymphocyte-associated antigen 4 to potentiate an antitumor T-cell response--administered with or without a glycoprotein 100 (gp100) peptide vaccine was compared with gp100 alone in patients with previously treated metastatic melanoma.METHODSA total of 676 HLA-A*0201-positive patients with unresectable stage III or IV melanoma, whose disease had progressed while they were receiving therapy for metastatic disease, were randomly assigned, in a 3:1:1 ratio, to receive ipilimumab plus gp100 (403 patients), ipilimumab alone (137), or gp100 alone (136). Ipilimumab, at a dose of 3 mg per kilogram of body weight, was administered with or without gp100 every 3 weeks for up to four treatments (induction). Eligible patients could receive reinduction therapy. The primary end point was overall survival.RESULTSThe median overall survival was 10.0 months among patients receiving ipilimumab plus gp100, as compared with 6.4 months among patients receiving gp100 alone (hazard ratio for death, 0.68; P<0.001). The median overall survival with ipilimumab alone was 10.1 months (hazard ratio for death in the comparison with gp100 alone, 0.66; P=0.003). No difference in overall survival was detected between the ipilimumab groups (hazard ratio with ipilimumab plus gp100, 1.04; P=0.76). Grade 3 or 4 immune-related adverse events occurred in 10 to 15% of patients treated with ipilimumab and in 3% treated with gp100 alone. There were 14 deaths related to the study drugs (2.1%), and 7 were associated with immune-related adverse events.CONCLUSIONSIpilimumab, with or without a gp100 peptide vaccine, as compared with gp100 alone, improved overall survival in patients with previously treated metastatic melanoma. Adverse events can be severe, long-lasting, or both, but most are reversible with appropriate treatment. (Funded by Medarex and Bristol-Myers Squibb; ClinicalTrials.gov number, NCT00094653.)", "doc-2": "ziness or vertigo, possibly involving vision impairment. A 1917 encyclopedia entry stated that English surgeon and former Beer student James Wardrop coined the term keratitis in an 1808 text. This claim has become conventional wisdom. In fact, Wardrop spoke simply of inflammation or ulcer of the cornea. We could not find the terms keratitis or ceratitis in Wardrops works (eReferences 3-18). To date, the first documented use of the term keratitis is by Weller and, in English, by Monteath. Monteaths English translation became his bestknown work and has left an important lexical legacy.", "label": 0}
{"doc-1": "Contents: Preface. J.R. Anderson, C. Lebiere, Introduction. J.R. Anderson, C. Lebiere, Knowledge Representation. J.R. Anderson, C. Lebiere, M. Lovett, Performance. J.R. Anderson, C. Lebiere, Learning. J.R. Anderson, M. Matessa, C. Lebiere, Visual Interface. M.D. Byrne, J.R. Anderson, Perception and Action. J.R. Anderson, D. Bothell, C. Lebiere, M. Matessa, List Memory. M. Lovett, Choice. C. Lebiere, J.R. Anderson, Cognitive Arithmetic. D.D. Salvucci, J.R. Anderson, Analogy. C.D. Schunn, J.R. Anderson, Scientific Discovery. J.R. Anderson, C. Lebiere, Reflections.", "doc-2": "Policies focusing on enforcing property code violations and the improvement of vacant properties are argued to be more efficacious than demolition policies to fight urban blight. This study applies parcel level data to a multi-year hybrid modeling structure. A fine-grained analysis is conducted on the dynamic patterns of abandonment and demolition for a unique period of four years before and after the City of Buffalos stepped-up demolition efforts. Results showed that proximity to vacant and abandoned properties, sustained over the years, had the greatest impact on the possibility of a property being abandoned. The second greatest positive impact on property abandonment was small lot front size. Results also showed that neighborhood vacancy density had the greatest negative impact on surrounding housing sales prices over the years. There was no significant impact of demolition on housing sales prices. These findings suggested that the City should aim to have more incentive programs that are tailored to control the number of vacant properties, rather than focusing primarily on demolition-oriented programs.", "label": 0}
{"doc-1": "\"The Seventh Report of the Joint National Committee on Prevention, Detection,Evaluation, and Treatment of High Blood Pressure\" provides a new guidelinefor hypertension prevention and management. The following are the key messages(1) In persons older than 50 years, systolic blood pressure (BP) ofmore than 140 mm Hg is a much more important cardiovascular disease(CVD) risk factor than diastolic BP; (2) The risk of CVD, beginning at 115/75mm Hg, doubles with each increment of 20/10 mm Hg; individuals who are normotensiveat 55 years of age have a 90% lifetime risk for developing hypertension; (3)Individuals with a systolic BP of 120 to 139 mm Hg or a diastolic BP of 80to 89 mm Hg should be considered as prehypertensive and require health-promotinglifestyle modifications to prevent CVD; (4) Thiazide-type diuretics shouldbe used in drug treatment for most patients with uncomplicated hypertension,either alone or combined with drugs from other classes. Certain high-riskconditions are compelling indications for the initial use of other antihypertensivedrug classes (angiotensin-converting enzyme inhibitors, angiotensin-receptorblockers, -blockers, calcium channel blockers); (5) Most patients withhypertension will require 2 or more antihypertensive medications to achievegoal BP (<140/90 mm Hg, or <130/80 mm Hg for patients with diabetesor chronic kidney disease); (6) If BP is more than 20/10 mm Hg above goalBP, consideration should be given to initiating therapy with 2 agents, 1 ofwhich usually should be a thiazide-type diuretic; and (7) The most effectivetherapy prescribed by the most careful clinician will control hypertensiononly if patients are motivated. Motivation improves when patients have positiveexperiences with and trust in the clinician. Empathy builds trust and is apotent motivator. Finally, in presenting these guidelines, the committee recognizesthat the responsible physician's judgment remains paramount.", "doc-2": "Abstract Considerable emphasis is placed on farm tourism as a tool of rural policy, in relieving the low-income problem of many small farms, and helping to ensure their viability. However, its importance is overstated. A critical review of sources and fieldwork in the County of Cumbria, UK, indicates that farm tourism is unlikely to make a significant contribution in easing the lot of either the poorer farmer or the other less privileged members of rural society. Returns are small; appeal for the smaller farmer is limited or absent; it is constrained by rigorous planning regulations; and has many harmful effects. As a result, farm tourism can be discounted as a significant means of tackling the serious problem of low farm incomes.", "label": 0}
{"doc-1": "This paper investigates the degrees of freedom of the interference channel in the presence of a dedicated MIMO relay. The relay is used to manage the interference at the receivers. We pose a fundamental question: What benefits are achieved by exploiting the direct links from the sources to the receivers and whether a two-hop strategy suffices considering the pre- log factor in the capacity formula? Using a number of hybrid encoding strategies and power allocation policies, we obtain non-asymptotic achievable sum-rates, subsequently leading to achievable degrees of freedom. The results are generalized from a two-user to a if-user network. Our main result is that only k/2 degrees of freedom are achievable in an interference channel with MIMO relay, assuming global channel knowledge at the relay but not at other nodes. Thus, appropriate signaling in a two-hop scenario captures the degrees of freedom gains without the need for the direct links. We also investigate the case where the relay (unlike other nodes) has access to abundant power, showing that when sources have power P and the relay is allowed power proportional to O(P2), the full degrees of freedom K are available to the network.", "doc-2": "The effects of elevated UV-B (280315nm) were assessed on nitrogen metabolism, carbohydrate pool, total phenolics, photosynthetic pigments, UV-B absorbing compounds, variables related to oxidative stress, biomass and yield of pea plants grown under various levels of NPK. The NPK levels assayed were: background NPK level (F0); recommended NPK (F1) and recommended NK+1.5recommended P (F2) and the UV-B levels were: control (C) and elevated (T). The responses of T plants varied with different combinations of NPK. Yield reduced under elevated UV-B at all NPK levels with maximum reduction in F0T and minimum reduction in F1T. Leghaemoglobin content was reduced under elevated UV-B at all NPK levels. Maximum increase in malondialdehyde content recorded in F0T plants corresponded with higher superoxide and hydrogen peroxide contents. Nitrite reductase activity decreased significantly under UV-B at all NPK levels, but nitrate reductase activity increased significantly in F1T and F2T. Maximum reduction in C:N ratio of leaves in F2T plants suggests competition between sucrose synthesis and nitrate reduction under additional P level. The study concludes that application of recommended level of NPK caused least changes in N metabolism leading to minimum yield losses due to elevated UV-B stress.", "label": 0}
{"doc-1": "Recent advances in high-throughput cDNA sequencing (RNA-seq) can reveal new genes and splice variants and quantify expression genome-wide in a single assay. The volume and complexity of data from RNA-seq experiments necessitate scalable, fast and mathematically principled analysis software. TopHat and Cufflinks are free, open-source software tools for gene discovery and comprehensive expression analysis of high-throughput mRNA sequencing (RNA-seq) data. Together, they allow biologists to identify new genes and new splice variants of known ones, as well as compare gene and transcript expression under two or more conditions. This protocol describes in detail how to use TopHat and Cufflinks to perform such analyses. It also covers several accessory tools and utilities that aid in managing data, including CummeRbund, a tool for visualizing RNA-seq analysis results. Although the procedure assumes basic informatics skills, these tools assume little to no background with RNA-seq analysis and are meant for novices and experts alike. The protocol begins with raw sequencing reads and produces a transcriptome assembly, lists of differentially expressed and regulated genes and transcripts, and publication-quality visualizations of analysis results. The protocol's execution time depends on the volume of transcriptome sequencing data and available computing resources but takes less than 1 d of computer time for typical experiments and 1 h of hands-on time.", "doc-2": "We present the case of a middle-aged gentleman who developed total bilateral irreversible peripheral facial palsy over a period of 10 years, starting with palsy of the marginal mandibular and buccal branches of the facial nerve and progressing to the zygomatic and temporal branches. The patient did not develop any other neurological symptoms, and all neurological and other tests have remained negative over the last 10 years. Dripping of saliva and inability to close the mouth necessitated reanimation of the perioral region with the help of a fascia lata graft fixed to the fascia of the masseter muscles. The increasing lagophthalmos and associated eye problems were alleviated with a temporal muscle transposition combined with a lengthening procedure using the temporal fascia, passed through the upper and lower eyelids and hooked around the medial canthal ligament. The fascia strips were sutured not to the canthal ligament itself, but to each other, thereby placing equal self-adjusted tension on the upper and lower eyelids. Both operations were successful and improved eating and eye closure functions, allowing resolution of the eye symptoms.", "label": 0}
{"doc-1": "The goals of this article are to (a) describe differences between moderator and mediator effects; (b) provide nontechnical descriptions of how to examine each type of effect, including study design, analysis, and interpretation of results; (c) demonstrate how to analyze each type of effect; and (d) provide suggestions for further reading. The authors focus on the use of multiple regression because it is an accessible data-analytic technique contained in major statistical packages. When appropriate, they also note limitations of using regression to detect moderator and mediator effects and describe alternative procedures, particularly structural equation modeling. Finally, to illustrate areas of confusion in counseling psychology research, they review research testing moderation and mediation that was published in the Journal of Counseling Psychology during 2001.", "doc-2": "A comparative analysis of the reactions between maleic anhydride and furan derivatives is presented in near and supercritical carbon dioxide and traditional organic solvents. Reaction kinetics were monitored by UV-vis absorbance spectroscopy in conjunction with an optimization technique which greatly simplified the experimental approach. In all of the reactions studied, supercritical carbon dioxide proved to facilitate a rate enhancement over conventional organic solvents. The reaction between maleic anhydride and furfuryl alcohol at 69 bar and 35 C was found to proceed 10 times faster in CO2 compared to reactions carried out in diethyl ether. All kinetic results were obtained from reactions undertaken in true homogeneous one phase fluid systems. The results achieved further indicate the potential of using carbon dioxide as a medium to carry out such chemical transformations through more environmentally acceptable processes.", "label": 0}
{"doc-1": "BACKGROUND & AIMSThe specificity of colonization by Helicobacter pylori and complex host-bacterium interactions cannot be readily examined in humans. The aim of this study was to perform such analyses in rhesus monkeys.METHODSFour animals that had been cured of natural H. pylori colonization were challenged with a mixture of 7 strains of human origin, and bacteria recovered during periodic videogastroscopy were DNA fingerprinted.RESULTSThree animals carried mixtures of several strains for 4 months, after which strain J166 predominated. In the fourth animal, only strain J238 was isolated from the earliest phase of colonization through 7 months, but strain J166 again became predominant by 10 months after the challenge. Gastritis scores and plasma gastrin and anti-H. pylori immunoglobulin G titers reached levels observed in naturally colonized animals by 4 months after the challenge; however, no plasma immunoglobulin A response was observed up to 10 months.CONCLUSIONSThese results show that (1) natural colonization does not elicit protective immunity against subsequent H. pylori challenge; (2) individuals differ in susceptibility to different H. pylori strains during initial stages of colonization; and (3) certain strains are better suited than others for long-term survival in different hosts. These observations show the complexity of H. pylori-host interactions.", "doc-2": "A large number of lead-free BaTiO 3 -based ceramics were prepared. Depending on the composition, some of them exhibit a relaxor behaviour whose characteristics were related to the type of ionic substitution and to the substitution rate. The relaxor effect is all the more favoured as the composition deviates more from BaTiO 3 and as the substitution is heterovalent in the 6-coordination number crystallographic site. Some of these materials could prove valuable (dielectrics for capacitors and actuators) because they are environment-friendly.", "label": 0}
{"doc-1": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \"autoencoder\" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.", "doc-2": "We evaluate the stock return performance of a modified version of the book-to-market strategy and its implications for market efficiency. If the previously documented superior stock return of the book-to-market strategy represents mispricing, its performance should be improved by excluding fairly valued firms with extreme book-to-market ratios. To attain this, we classify stocks as value or glamour on book-to-market ratios and accounting accruals jointly. This joint classification is likely to exclude stocks with extreme book-to-market ratios due to mismeasured accounting book values reflecting limitations underlying the accounting system. Using both 12-month buy-and-hold returns and earnings announcement returns, our results show that this joint classification generates substantially higher portfolio returns in the post-portfolio-formation year than the book-to-market classification alone with no evidence of increased risk. In addition, this superior stock return performance is more pronounced among firms held primarily by small (unsophisticated) investors and followed less closely by market participants (stock price <$10). Finally, and most importantly, financial analysts are overly optimistic (pessimistic) about earnings of glamour (value) stock, and for a subset of firms identified as overvalued by our strategy, the earnings announcement raw return, as well as abnormal return, is negative. These last results are particularly important because it is hard to envision a model consistent with rational investors holding risky stocks with predictable negative raw returns for a long period of time rather than holding fT-bills and with financial analysts systematically overestimating the earnings of these stocks while underestimating earnings of stocks that outperform the stock market.", "label": 0}
{"doc-1": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (semantic structure) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.", "doc-2": "Low-pressure plasma treatments in a 13.56 MHz RF glow discharge of Hydrogen (H2)/Oxygen (O2) gas mixture were used to introduce polar functional groups onto microporous polypropylene (PP) membrane surfaces to improve the hydrophilicity and surface modification. The change in hydrophilicity and surface free energy was monitored by static contact angle measurement. Significant increased surface energy of polypropylene membranes from the H2/O2 mixture gas plasma treatments was observed. The PP membrane surfaces became highly hydrophilic when exposed for only 5 s to the H2/O2 mixture gas plasma. Optical emission spectroscopy (OES) was used to examine the various chemical species of low pressure plasma processing. The chemical structure and surface morphological changes on the membrane surface were characterized by X-ray photoelectron spectroscopy (XPS) and confocal laser scanning microscopy (CLSM). XPS analysis showed significantly higher surface concentrations of oxygen functional groups for H2/O2 mixture gas plasma-modified PP membrane surfaces than the originally unmodified PP membrane surfaces. The experimental results revealed low pressure H2/O2 plasma processing is an effective method to improve the surface hydrophilicity of microporous PP membranes.  2011 Wiley Periodicals, Inc. J Appl Polym Sci, 2012", "label": 0}
{"doc-1": "In order to know the genetic diversity of Blastocystis hominis from a health district of Valencia (Spain) 51 clinical isolates from symptomatic patients,31 axenic and 20 monoxenic, were ribotyped by analysing the restriction fragment length polymorphism (RFLP) of amplicons obtained by polymerase chain reaction (PCR) of small-subunit of ribosomal DNA genes (SSU-rDNA). For this purpose, DNA was subjected to two independent PCR (RD3-RD5, F1-R1) and to three independent treatments with restrictases (AluI, HinfI and RsaI). The digested DNA was separated electrophoretically, the isolates were clustered into ribotypes (ribodemes, RD3-RD5; subgroups, F1-R1) according to their profiles and the results were translated into genetic subtypes (ST) proposed by a consensus terminology. The results show that the isolates studied are an heterogeneous population and that both PCR-RFLP SSU-rDNA protocols have a similar discriminative power, since it allowed the ribotyping of all isolates and their clustering into four demes: ribodemes 1, 3 and 3-r and 6, which include isolates belonging to subgroup III, IV, V and V-r, respectively; which were assigned to ST1 (2%), ST2 (3.9%) and ST4 (94.1%). The most common of which is a zoonotic subtype (Blastocystis ratti) which includes, according to recent studies, non-pathogenic and pathogenic variants.", "doc-2": "In the literature of feature selection, different criteria have been proposed to evaluate the goodness of features. In our investigation, we notice that a number of existing selection criteria implicitly select features that preserve sample similarity, and can be unified under a common framework. We further point out that any feature selection criteria covered by this framework cannot handle redundant features, a common drawback of these criteria. Motivated by these observations, we propose a new \"Similarity Preserving Feature Selection framework in an explicit and rigorous way. We show, through theoretical analysis, that the proposed framework not only encompasses many widely used feature selection criteria, but also naturally overcomes their common weakness in handling feature redundancy. In developing this new framework, we begin with a conventional combinatorial optimization formulation for similarity preserving feature selection, then extend it with a sparse multiple-output regression formulation to improve its efficiency and effectiveness. A set of three algorithms are devised to efficiently solve the proposed formulations, each of which has its own advantages in terms of computational complexity and selection performance. As exhibited by our extensive experimental study, the proposed framework achieves superior feature selection performance and attractive properties.", "label": 0}
{"doc-1": "Bacteria and archaea have evolved adaptive immune defenses, termed clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated (Cas) systems, that use short RNA to direct degradation of foreign nucleic acids. Here, we engineer the type II bacterial CRISPR system to function with custom guide RNA (gRNA) in human cells. For the endogenous AAVS1 locus, we obtained targeting rates of 10 to 25% in 293T cells, 13 to 8% in K562 cells, and 2 to 4% in induced pluripotent stem cells. We show that this process relies on CRISPR components; is sequence-specific; and, upon simultaneous introduction of multiple gRNAs, can effect multiplex editing of target loci. We also compute a genome-wide resource of ~190 K unique gRNAs targeting ~40.5% of human exons. Our results establish an RNA-guided editing tool for facile, robust, and multiplexable human genome engineering.", "doc-2": "Abstract Bi 2 WO 6 nanofibers and hierarchical microspheres were synthesized by an electrospinning process and a hydrothermal method. The phase, microstructure and photocatalytic performance of the obtained Bi 2 WO 6 photocatalysts were investigated. The X-ray powder diffraction and Fourier transform infrared spectroscopy suggest that Bi 2 WO 6 nanofibers and hierarchical microspheres have the single orthorhombic phase. The scanning electron microscope and transmission electron microscope images show that Bi 2 WO 6 nanofibers are composed of nanoparticles and Bi 2 WO 6 hierarchical microspheres consist of a large number of nanosheets. The BarrettEmmettTeller results, X-ray photoelectron spectroscopy, ultravioletvisible diffuse reflectance spectra, emission spectra, photocurrent and electrochemical impedance spectroscopy reveal that Bi 2 WO 6 hierarchical microspheres have a higher photocatalytic activity than that of Bi 2 WO 6 nanofibers. This is confirmed by the photo decomposition of Rhodamine B under light irradiation. The Bi 2 WO 6 hierarchical microspheres show a faster and higher efficiency decomposition of Rhodamine B under light irradiation. The higher photocatalytic activity of Bi 2 WO 6 hierarchical microspheres results from the larger specific surface area. The large specific surface area provides more surface active sits and makes an easier charge carrier transport.", "label": 0}
{"doc-1": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weightupdate Littlestone Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in R. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line. ] 1997 Academic Press", "doc-2": "One new multiresolution image fusion algorithm based on probabilistic model is developed. Suppose that there are multiple images obtained by different sensors to measure same object. First, to decompose each image into multiple subimages which buildup a multiresolution pyramid via wavelet packet transform, and to establish pixel-based subimage model on every level in the pyramid. Second, to identify parameters included in each subimage model based all measures from different sensors. Third, in each level local fusion estimate of the object subimage can be got by combining the model with a maximum posterior method. Finally, we may obtain global fusion estimate with the object image by applying orderly inverse wavelet packet transformation to every local fusion estimate from each level of the pyramid. This new approach has been effectively validated by fusing a visible image and an infrared image, which come entirely from same object.", "label": 0}
{"doc-1": "Breast cancer is the most common malignancy in United States women, accounting for >40,000 deaths each year. These breast tumors are comprised of phenotypically diverse populations of breast cancer cells. Using a model in which human breast cancer cells were grown in immunocompromised mice, we found that only a minority of breast cancer cells had the ability to form new tumors. We were able to distinguish the tumorigenic (tumor initiating) from the nontumorigenic cancer cells based on cell surface marker expression. We prospectively identified and isolated the tumorigenic cells as CD44(+)CD24(-/low)Lineage(-) in eight of nine patients. As few as 100 cells with this phenotype were able to form tumors in mice, whereas tens of thousands of cells with alternate phenotypes failed to form tumors. The tumorigenic subpopulation could be serially passaged: each time cells within this population generated new tumors containing additional CD44(+)CD24(-/low)Lineage(-) tumorigenic cells as well as the phenotypically diverse mixed populations of nontumorigenic cells present in the initial tumor. The ability to prospectively identify tumorigenic cancer cells will facilitate the elucidation of pathways that regulate their growth and survival. Furthermore, because these cells drive tumor development, strategies designed to target this population may lead to more effective therapies.", "doc-2": "BACKGROUNDThis investigation compares the results of contemporary percutaneous coronary intervention (PCI) with standard balloon angioplasty among patients with multivessel coronary disease. Patients having balloon angioplasty in the Bypass Angioplasty Revascularization Investigation (BARI) and those within the Dynamic Registry meeting BARI eligibility criteria were studied.METHODS AND RESULTSClinical features and in-hospital and 1-year outcomes of 857 BARI-eligible patients in the Dynamic Registry (contemporary PCI) were compared with the 904 randomized patients who underwent percutaneous transluminal coronary angioplasty in BARI. Compared with BARI patients, Registry patients had fewer lesions attempted (1.53 versus 2.56, P=0.001), more frequent single-vessel PCI (76% versus 33%, P<0.001), greater use of intracoronary stents (76% versus 1%, P<0.001), and GP IIb/IIIa receptor antagonist (24% versus 0%, P<0.001). Angiographic success was achieved more often among Registry patients (91% versus 72%, P<0.001), whereas abrupt closure (1.5% versus 9.5%, P<0.001) and in-hospital coronary artery bypass graft (CABG) (1.9% versus 10.2%, P<0.001) and myocardial infarction (0.8% versus 2.1%, P=0.025) were less common. No differences were observed in either in-hospital or 1-year death, but 1-year death/myocardial infarction was lower in the Registry. Registry patients had lower 1-year rates of subsequent CABG (8.6% versus 22.7%, P<0.001) and PCI (12.4% versus 22.5%, P<0.001). By multivariate analysis, contemporary PCI was independently associated with reduced risk for in-hospital CABG, 1-year CABG, and 1-year PCI.CONCLUSIONSAmong patients with multivessel disease, contemporary PCI resulted in safer and more durable revascularization. These results support the role of PCI for selected patients with multivessel coronary artery disease.", "label": 0}
{"doc-1": "SUMMARYThe program MODELTEST uses log likelihood scores to establish the model of DNA evolution that best fits the data.AVAILABILITYThe MODELTEST package, including the source code and some documentation is available at http://bioag.byu. edu/zoology/crandall_lab/modeltest.html.", "doc-2": "In these lectures, I present an introduction to the theory and phenomenology of dynamical electroweak symmetry breaking.", "label": 0}
{"doc-1": "From the Publisher: This is the first textbook on formal concept analysis. It gives a systematic presentation of the mathematical foundations and their relation to applications in computer science, especially in data analysis and knowledge processing. Above all, it presents graphical methods for representing conceptual systems that have proved themselves in communicating knowledge. Theory and graphical representation are thus closely coupled together. The mathematical foundations are treated thoroughly and illuminated by means of numerous examples.", "doc-2": "Interstitial cystitis (IC) is a chronic urinary tract disease that is characterized by unpleasant sensations, such as persistent pelvic pain, in the absence of infection or other identifiable causes. We previously performed comprehensive metabolomics profiling of urine samples from IC patients using nuclear magnetic resonance and gas-chromatography/mass spectrometry and found that urinary -oxoglutarate (-OG), was significantly elevated. -OG, a tricarboxylic acid (TCA) cycle intermediate, reportedly functions to suppress the proliferation of immortalized normal human bladder epithelial cells. Here, we identified AT-rich interactive domain 1A (ARID1A), a key chromatin remodeler, as being hypomethylated and upregulated by -OG treatment. This was done through EPIC DNA methylation profiling and subsequent biochemical approaches, including quantitative RT-PCR and western blot analyses. Furthermore, we found that -OG almost completely suppresses ten-eleven translocation (TET) activity, but does not affect DNA methyltransferase (DNMT) activity. Altogether, our studies reveal the potential role of -OG in epigenetic remodeling through its effects on ARID1A and TET expression in the bladder. This may provide a new possible therapeutic strategy in treating IC.", "label": 0}
{"doc-1": "Variations in neural circuitry, inherited or acquired, may underlie important individual differences in thought, feeling, and action patterns. Here, we used task-free connectivity analyses to isolate and characterize two distinct networks typically coactivated during functional MRI tasks. We identified a \"salience network,\" anchored by dorsal anterior cingulate (dACC) and orbital frontoinsular cortices with robust connectivity to subcortical and limbic structures, and an \"executive-control network\" that links dorsolateral frontal and parietal neocortices. These intrinsic connectivity networks showed dissociable correlations with functions measured outside the scanner. Prescan anxiety ratings correlated with intrinsic functional connectivity of the dACC node of the salience network, but with no region in the executive-control network, whereas executive task performance correlated with lateral parietal nodes of the executive-control network, but with no region in the salience network. Our findings suggest that task-free analysis of intrinsic connectivity networks may help elucidate the neural architectures that support fundamental aspects of human behavior.", "doc-2": "CD40 receptor is activated by ligand CD40L (CD154) which is synthesized in inflammation by NK cells, monocytes and lymphocytes B. TRAF proteins are activated in cells by CD40 stimulation and next they stimulate different enzymatic pathways. High concentrations of CD40L stimulate CD40, and consequently STAT enzyme system inhibits the expression ofnonstructural proteins ofHCV NS3 and NS5A and E2 core in infected human hepatocytes. PURPOSE. The aim of the study was to evaluate the concentration of soluble components of the complex: sCD40 and sCD40L in the serum of patients infected with HCV and HCV/HIV-1 co-infected. The effect ofHCV genotype, HIV and HCV viral load and rs12979860 polymorphism on serum sCD40 and sCD40L was established among the patients. The influence of the number of CD3+, CD4+ and CD8+ on the concentrations of sCD40 and sCD40L was evaluated in the HIV-1 infected group MATERIALS AND METHODS. Serum concentrations of sCD40 and sCD40L were determined using ELISA in 68 HCV infected patients including 39 HCV monoinfected and 29 HCV/HIV-1 co-infected. RESULTS. Serum concentration of sCD40 and sCD40L was significantly higher in HCV and HCV/HIV coinfected patients compared to healthy subjects (25.7 and 23.2 v. 8.5 pg/ml and 12.7 and 7.3 v. 0.79 ng/ml). The concentration of sCD40L in patients with genotype CC rs12979860 was significantly higher compared to patients with Non-CC genotypes (11.8 v. 7.6 ng/ml, p < 0.018). CONCLUSIONS. High levels of sCD40 and sCD40L were detected among patients with chronic HCV and HCV/ HIV-1 infection The high concentration of sCD40L correlates with CC rs12979860 genotype.", "label": 0}
{"doc-1": "SUMMARYThe program MODELTEST uses log likelihood scores to establish the model of DNA evolution that best fits the data.AVAILABILITYThe MODELTEST package, including the source code and some documentation is available at http://bioag.byu. edu/zoology/crandall_lab/modeltest.html.", "doc-2": "A cold trap system for the determination of selenium by hydride generation-atomic absorption spectrometry (HG-AAS) is described. For a 30-ml sample the limit of detection is <2 ng/l. and the precision is better than 4% at the 30 ng/l. level. A number of digestion procedures for the destruction of organic matter prior to the determination of total dissolved selenium in water has been tested and compared. Concordant results were obtained except for oxidation by peroxodisulphate in strongly acidic solutions with a high content of organic material. The selenium concentrations found were in agreement with those obtained by HG-AAS after preconcentration by evaporation and dry ashing with the magnesium nitrate-nitric acid-hydrochloric acid method.", "label": 0}
{"doc-1": "In this paper we draw on recent progress in the theory of (1) property rights, (2) agency, and (3) finance to develop a theory of ownership structure for the firm.1 In addition to tying together elements of the theory of each of these three areas, our analysis casts new light on and has implications for a variety of issues in the professional and popular literature, such as the definition of the firm, the separation of ownership and control, the social responsibility of business, the definition of a corporate objective function, the determination of an optimal capital structure, the specification of the content of credit agreements, the theory of organizations, and the supply side of the completeness-of-markets problem.", "doc-2": "aKey Laboratory of Urban Agriculture (North) of Ministry of Agriculture, Beijing University of Agriculture, Beijing 102206, China, Tel. +86-10-80795297; emails: zhuhong80@bua.edu.cn (H. Zhu), 271924269@qq.com (J. Liu), zhaojianzhuang@263.com (J.Z. Zhao) bTechnology Center for Heavy Metal Cleaner Production Engineerings, Chinese Research Academy of Environmental Sciences, Beijing 100012, China, Tel. +86 10 84916046; email: fuyuanxu@hotmail.com", "label": 0}
{"doc-1": "? Users may download and print one copy of any publication from the public portal for the purpose of private study or research. ? You may not further distribute the material or use it for any profit-making activity or commercial gain ? You may freely distribute the URL identifying the publication in the public portal ? Take down policy If you believe that this document breaches copyright please contact us at vbn@aub.aau.dk providing details, and we will remove access to the work immediately and investigate your claim.", "doc-2": "Osteoclasts generate a massive acid flux to mobilize bone calcium. Local extracellular acidification is carried out by vacuolar type H+-ATPase (V-ATPase) localized in the plasma membrane. We have shown that a3, one of the four subunit a isoforms (a1, a2, a3, and a4), is a component of the plasma membrane V-ATPase (Toyomura, T., Oka, T., Yamaguchi, C., Wada, Y., and Futai, M. (2000) J. Biol. Chem. 275, 8760-8765). To establish the unique localization of V-ATPase, we have used a murine macrophage cell line, RAW 264.7, that can differentiate into multinuclear osteoclast-like cells on stimulation with RANKL (receptor activator of nuclear factor kappaB ligand). The V-ATPase with the a3 isoform was localized to late endosomes and lysosomes, whereas those with the a1 and a2 isoforms were localized to organelles other than lysosomes. After stimulation, the V-ATPase with the a3 isoform was immunochemically colocalized with lysosome marker lamp2 and was detected in acidic organelles. These organelles were also colocalized with microtubules, and the signals of lamp2 and a3 were dispersed by nocodazole, a microtubule depolymerizer. In RAW-derived osteoclasts cultured on mouse skull pieces, the a3 isoform was transported to the plasma membrane facing the bone and accumulated inside podosome rings. These findings indicate that V-ATPases with the a3 isoform localized in late endosomes/lysosomes are transported to the cell periphery during differentiation and finally assembled into the plasma membrane of mature osteoclasts.", "label": 0}
{"doc-1": "In this study, we investigated a neglected form of extrarole behavior called taking charge and sought to understand factors that motivate employees to engage in this activity. Taking charge is disc...", "doc-2": "The rationale for melanoma specific dihydroxybenzene containing antitumor agents is based in part upon the ability of the enzyme tyrosinase to oxidize these pro drugs to toxic intermediates. In situ tyrosinase activity was demonstrated to be affected by both cell density and time from plating in pigmented melanoma cells. Phenylthiourea, which completely inhibited tyrosinase activity with minimal cytotoxicity was found to block the growth inhibitory activity of the antitumor dopamine analog 3,4-dihydroxybenzylamine (3,4-DHBA) (NSC 263475). The antioxidant dithioerythritol was also found to inhibit tyrosinase activity and to block the growth inhibitory effects of 3,4-DHBA in pigmented melanoma cell lines. Buthionine sulfoximine (BSO) was shown to be cytotoxic to melanoma cells and its growth inhibitory effects appears to correlate with tyrosinase levels. Furthermore, BSO was shown to potentiate the growth inhibitory effects of 3,4-DHBA on marginally pigmented human melanoma cell lines.", "label": 0}
{"doc-1": "BACKGROUNDPatients with advanced squamous-cell non-small-cell lung cancer (NSCLC) who have disease progression during or after first-line chemotherapy have limited treatment options. This randomized, open-label, international, phase 3 study evaluated the efficacy and safety of nivolumab, a fully human IgG4 programmed death 1 (PD-1) immune-checkpoint-inhibitor antibody, as compared with docetaxel in this patient population.METHODSWe randomly assigned 272 patients to receive nivolumab, at a dose of 3 mg per kilogram of body weight every 2 weeks, or docetaxel, at a dose of 75 mg per square meter of body-surface area every 3 weeks. The primary end point was overall survival.RESULTSThe median overall survival was 9.2 months (95% confidence interval [CI], 7.3 to 13.3) with nivolumab versus 6.0 months (95% CI, 5.1 to 7.3) with docetaxel. The risk of death was 41% lower with nivolumab than with docetaxel (hazard ratio, 0.59; 95% CI, 0.44 to 0.79; P<0.001). At 1 year, the overall survival rate was 42% (95% CI, 34 to 50) with nivolumab versus 24% (95% CI, 17 to 31) with docetaxel. The response rate was 20% with nivolumab versus 9% with docetaxel (P=0.008). The median progression-free survival was 3.5 months with nivolumab versus 2.8 months with docetaxel (hazard ratio for death or disease progression, 0.62; 95% CI, 0.47 to 0.81; P<0.001). The expression of the PD-1 ligand (PD-L1) was neither prognostic nor predictive of benefit. Treatment-related adverse events of grade 3 or 4 were reported in 7% of the patients in the nivolumab group as compared with 55% of those in the docetaxel group.CONCLUSIONSAmong patients with advanced, previously treated squamous-cell NSCLC, overall survival, response rate, and progression-free survival were significantly better with nivolumab than with docetaxel, regardless of PD-L1 expression level. (Funded by Bristol-Myers Squibb; CheckMate 017 ClinicalTrials.gov number, NCT01642004.).", "doc-2": "Wireless LAN networking is an indispensable technology in an All-IP network architecture to satisfy the ''anytime and anywhere'' communication requirement of end users. This investigation proposes feedback controllers designing based on dynamic quality-of-service requirement for wireless LAN multimedia services. During the controllers design process, the time-domain is replaced by the s-domain, simplifying the calculation. This work presents three controllers namely proportional integral (PI), proportional derivative (PD) and proportional integral derivative (PID). Experimental results show that systems that employ the proposed controllers can quickly achieve the required system performance. Additionally, the PID controller has the best performance, and can improve delay performance by a rate 11.44% that without the feedback controller. The PI controller is superior to the PD controller. The delay when using the PD is 6.2% less than that achieved without the feedback controller.", "label": 0}
{"doc-1": "Factors that affect the probability of genetic transformation of Escherichia coli by plasmids have been evaluated. A set of conditions is described under which about one in every 400 plasmid molecules produces a transformed cell. These conditions include cell growth in medium containing elevated levels of Mg2+, and incubation of the cells at 0 degrees C in a solution of Mn2+, Ca2+, Rb+ or K+, dimethyl sulfoxide, dithiothreitol, and hexamine cobalt (III). Transformation efficiency declines linearly with increasing plasmid size. Relaxed and supercoiled plasmids transform with similar probabilities. Non-transforming DNAs compete consistent with mass. No significant variation is observed between competing DNAs of different source, complexity, length or form. Competition with both transforming and non-transforming plasmids indicates that each cell is capable of taking up many DNA molecules, and that the establishment of a transformation event is neither helped nor hindered significantly by the presence of multiple plasmids.", "doc-2": "Neospora caninum is a parasite responsible for abortion in cows and neuromuscular disease in dogs. Serology is the most widely used technique to evaluate the prevalence of N. caninum in different host populations. A sandwich enzyme-linked immunosorbent assay (ELISA) based on the use of an anti-SRS2 monoclonal antibody was evaluated against the indirect fluorescent antibody test for 100 canine sera and against a well-characterized ELISA for 102 bovine sera. In cattle sera, the relative sensitivity and relative specificity were 100%. In dog sera, the relative specificity and relative sensitivity were 94% and 86%, respectively. The kappa value was 1 for bovine sera and 0.77 for canine sera. The seroprevalence was 3.9% in bovine sera and 21-23% in canine sera. The SRS2 sandwich ELISA was considered a valuable tool in both species.", "label": 0}
{"doc-1": "BACKGROUNDA phase 3 trial was conducted to evaluate the efficacy of a prophylactic quadrivalent vaccine in preventing anogenital diseases associated with human papillomavirus (HPV) types 6, 11, 16, and 18.METHODSIn this randomized, placebo-controlled, double-blind trial involving 5455 women between the ages of 16 and 24 years, we assigned 2723 women to receive vaccine and 2732 to receive placebo at day 1, month 2, and month 6. The coprimary composite end points were the incidence of genital warts, vulvar or vaginal intraepithelial neoplasia, or cancer and the incidence of cervical intraepithelial neoplasia, adenocarcinoma in situ, or cancer associated with HPV type 6, 11, 16, or 18. Data for the primary analysis were collected for a per-protocol susceptible population of women who had no virologic evidence of HPV type 6, 11, 16, or 18 through 1 month after administration of the third dose.RESULTSThe women were followed for an average of 3 years after administration of the first dose. In the per-protocol population, those followed for vulvar, vaginal, or perianal disease included 2261 women (83%) in the vaccine group and 2279 (83%) in the placebo group. Those followed for cervical disease included 2241 women (82%) in the vaccine group and 2258 (83%) in the placebo group. Vaccine efficacy was 100% for each of the coprimary end points. In an intention-to-treat analysis, including those with prevalent infection or disease caused by vaccine-type and non-vaccine-type HPV, vaccination reduced the rate of any vulvar or vaginal perianal lesions regardless of the causal HPV type by 34% (95% confidence interval [CI], 15 to 49), and the rate of cervical lesions regardless of the causal HPV type by 20% (95% CI, 8 to 31).CONCLUSIONSThe quadrivalent vaccine significantly reduced the incidence of HPV-associated anogenital diseases in young women. (ClinicalTrials.gov number, NCT00092521 [ClinicalTrials.gov].).", "doc-2": "In this paper we consider the allocation problem for multivariate stratified surveys. If the stratum variances for the different variates are not distributed in the same way Neyman allocation optimizing the measurement of one variate is of limited value. In our formulation we determine the allocation such that sample estimates meet stated levels of precision or tolerance at minimum cost. Solution of the allocation problem is shown to be a programming problem and an example is given to illustrate it. By obtaining the solution to one plan a sampler essentially obtains the solution to a whole series of plans. The problem of tolerance setting is then discussed. An emprical solution, based on practical rather than some over-riding theoretical consideration, to the problem is given. A set of coefficients which elucidate the cost implications of each of the tolerances are derived.", "label": 0}
{"doc-1": "The remarkable properties of graphene have renewed interest in inorganic, two-dimensional materials with unique electronic and optical attributes. Transition metal dichalcogenides (TMDCs) are layered materials with strong in-plane bonding and weak out-of-plane interactions enabling exfoliation into two-dimensional layers of single unit cell thickness. Although TMDCs have been studied for decades, recent advances in nanoscale materials characterization and device fabrication have opened up new opportunities for two-dimensional layers of thin TMDCs in nanoelectronics and optoelectronics. TMDCs such as MoS(2), MoSe(2), WS(2) and WSe(2) have sizable bandgaps that change from indirect to direct in single layers, allowing applications such as transistors, photodetectors and electroluminescent devices. We review the historical development of TMDCs, methods for preparing atomically thin layers, their electronic and optical properties, and prospects for future advances in electronics and optoelectronics.", "doc-2": "Distortion product otoacoustic emissions (DPOEs) were recorded in 8 normal hearing subjects (16 ears, mean age 37) in order to evaluate the sensitivity of the DPOE amplitudes as a function of pneumatic changes (-400 to +200 daPa) in the external ear canal. The responses were collected using time averaging and subsequent FFT-analysis of the collected data. Distortion products were measured at the following geometric mean frequencies: 1,000, 2,000, 4,000, 6,000 and 8,000 Hz. The results show that the amplitudes of the distortion products depend on an optimal transmission through the middle ear, and that measurements of DPOEs should always be preceded by determination of the middle ear pressure. The present findings are in good agreement with investigations based on evoked otoacoustic emissions published by other researchers.", "label": 0}
{"doc-1": "This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.", "doc-2": "Parallel imaging is one of the most promising developments in recent years for the acceleration of MR acquisitions. One area of practical importance where different parallel imaging methods perform differently is the manner in which they deal with aliasing in the full-FOV reconstructed image. It has been reported that sensitivity encoding (SENSE) reconstruction fails whenever the reconstructed FOV is smaller than the object being imaged. On the other hand, generalized autocalibrating partially parallel acquisition (GRAPPA) has been used successfully to reconstruct images with aliasing in the reconstructed FOV, as in conventional imaging. The disparate behavior of these methods can be easily demonstrated by a few simple illustrative examples. Additional in vivo examples using GRAPPA and modified SENSE (mSENSE) make this distinction clear. These experiments demonstrate that SENSE fails to reconstruct correct images when coil sensitivity maps are used that do not automatically account for the object size and therefore the aliasing in the reconstructed images. However, with the use of aliased high-resolution coil sensitivity maps, accurate SENSE reconstructions can be generated. On the other hand, GRAPPA produces images with an aliasing appearance that is exactly as would be expected from normal nonaccelerated acquisitions. An understanding of these effects could potentially lead to fewer operator-dependent errors, as well as a better understanding of the differences between the underlying reconstruction processes.", "label": 0}
{"doc-1": "We introduce a new class of problems called network information flow which is inspired by computer network applications. Consider a point-to-point communication network on which a number of information sources are to be multicast to certain sets of destinations. We assume that the information sources are mutually independent. The problem is to characterize the admissible coding rate region. This model subsumes all previously studied models along the same line. We study the problem with one information source, and we have obtained a simple characterization of the admissible coding rate region. Our result can be regarded as the max-flow min-cut theorem for network information flow. Contrary to one's intuition, our work reveals that it is in general not optimal to regard the information to be multicast as a \"fluid\" which can simply be routed or replicated. Rather, by employing coding at the nodes, which we refer to as network coding, bandwidth can in general be saved. This finding may have significant impact on future design of switching systems.", "doc-2": "OBJECTIVETo measure the upper-airway resistance in patients with tracheostomies and determine the value representing decannulation readiness.SUBJECTS AND METHODSFifty-six patients with tracheostomies resultant to laryngeal disease participated in this study. Forty patients met clinical criteria for decannulation; 16 did not. Subglottal pressure was measured with a tube connected to the tracheostomy tube, and airflow was monitored simultaneously using a facemask. Upper-airway resistance measurements were recorded during shallow and deep breathing.RESULTSDuring both shallow and deep breathing, the inspiratory and expiratory resistances were significantly higher for the group unsuitable for decannulation (P < .0001). The areas under the receiver operating characteristic curves were 0.938 or greater for the four curves, indicating a high sensitivity and specificity of resistance measures for diagnosis.CONCLUSIONSObjective measurement of upper-airway resistance during shallow and deep breathing may be a useful parameter in determining decannulation readiness of tracheostomized patients.", "label": 0}
{"doc-1": "The National Institute on Aging and the Alzheimer's Association charged a workgroup with the task of revising the 1984 criteria for Alzheimer's disease (AD) dementia. The workgroup sought to ensure that the revised criteria would be flexible enough to be used by both general healthcare providers without access to neuropsychological testing, advanced imaging, and cerebrospinal fluid measures, and specialized investigators involved in research or in clinical trial studies who would have these tools available. We present criteria for all-cause dementia and for AD dementia. We retained the general framework of probable AD dementia from the 1984 criteria. On the basis of the past 27 years of experience, we made several changes in the clinical criteria for the diagnosis. We also retained the term possible AD dementia, but redefined it in a manner more focused than before. Biomarker evidence was also integrated into the diagnostic formulations for probable and possible AD dementia for use in research settings. The core clinical criteria for AD dementia will continue to be the cornerstone of the diagnosis in clinical practice, but biomarker evidence is expected to enhance the pathophysiological specificity of the diagnosis of AD dementia. Much work lies ahead for validating the biomarker diagnosis of AD dementia.", "doc-2": "Com o objetivo de estabelecer o melhor tratamento para o condiloma plano viral, compararam-se os resultados terapeuticos da podofilina gel 2 por dento, podofilina 4 por dento, gel do acido metacresol-sulfonico e 5-fluorouracil-creme a 5 por cento, em estudo aleatorizado, cego, de 254 mulheres no periodo de janeiro/88 a marco/91. O grupo controlenao recebeu qualquer medicamento. No transcorrer do estudo, 110 pacientes foram excluidas por nao satisfazerem as exigencias do protocolo. Utilizaram-se os metodos colposcopico, citologico e histopatologico para o diagnostico da infeccao e controle de tratamento. O criterio cito-histopatologico adotado foi o proposto por Schneider et al. Os resultados obtidos foram submetidos a analise estatistica pelo teste do quiquadrado. Pelos resultados concluiu-se que: 31,3 por cento do grupo controle apresentou remissao espontnea; o uso do acido metacresol-sulfonico levou a resultados terapeuticos identicos aos do grupo controle; a podofilina a 2 por cento nao se mostrou eficaz; os melhores resultados foram encontrados com a utilizacao da posofilina a 4 por cento e 5-fluorouracil (p", "label": 0}
{"doc-1": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Dept. of Linguistics and Philosophy, 1987.", "doc-2": "PurposeThe purpose of this study is to test alternative models of job performance based on competing categorization criteria.Design/methodological/approachSurvey-based data were collected from individuals in two separate studies. In Study 1, proficiency ratings of job performance were collected from individuals (N=553) across multiple jobs in four organizations in three Latin America countries. Similar data (N=489) were collected as part of a second study in order to provide additional support for the results observed in the first study.FindingsModest support was obtained for performance models based on prior literature and a modified ten-factor solution. Follow-up analyses, on the basis of multidimensional scaling, suggested an alternative categorization that unveiled three underlying proficiency-dimensions. Emerging dimensions suggest that proficiency can be classified according to (a) the target of work behaviors (i.e., data, persons, and things), (b) the degree of influence behaviors convey (controlling others versus do-it-yourself), and (c) the degree of interaction involved (integration vs. working in isolation).ImplicationsThe modest fit of the data with performance models derived from the extant literature calls for further investigations of the structure emerging from the current studies.OriginalityThese studies contrasted existing methods to categorize employee proficiency and provided empirical evidence of the shortcomings of these methods. Results also provided alternative criteria to discriminate performance behaviors.", "label": 0}
{"doc-1": "Enterolignans (enterodiol and enterolactone) can potentially reduce the risk of certain cancers and cardiovascular diseases. Enterolignans are formed by the intestinal microflora after the consumption of plant lignans. Until recently, only secoisolariciresinol and matairesinol were considered enterolignan precursors, but now several new precursors have been identified, of which lariciresinol and pinoresinol have a high degree of conversion. Quantitative data on the contents in foods of these new enterolignan precursors are not available. Thus, the aim of this study was to compile a lignan database including all four major enterolignan precursors. Liquid chromatography-tandem mass spectrometry was used to quantify lariciresinol, pinoresinol, secoisolariciresinol and matairesinol in eighty-three solid foods and twenty-six beverages commonly consumed in The Netherlands. The richest source of lignans was flaxseed (301,129 microg/100 g), which contained mainly secoisolariciresinol. Also, lignan concentrations in sesame seeds (29,331 microg/100 g, mainly pinoresinol and lariciresinol) were relatively high. For grain products, which are known to be important sources of lignan, lignan concentrations ranged from 7 to 764 microg/100 g. However, many vegetables and fruits had similar concentrations, because of the contribution of lariciresinol and pinoresinol. Brassica vegetables contained unexpectedly high levels of lignans (185-2321 microg/100 g), mainly pinoresinol and lariciresinol. Lignan levels in beverages varied from 0 (cola) to 91 microg/100 ml (red wine). Only four of the 109 foods did not contain a measurable amount of lignans, and in most cases the amount of lariciresinol and pinoresinol was larger than that of secoisolariciresinol and matairesinol. Thus, available databases largely underestimate the amount of enterolignan precursors in foods.", "doc-2": "Aims To assess the relationship between self-reported suicidal ideation and alcohol and other substance use among 14-16-year-olds. Design, setting, participants A cross sectional school survey of 16 464 subjects aged 14-16 years in two Finnish regions. Findings Alcohol use frequency and any use of substances other than alcohol were significantly associated with suicidal ideation. Of girls (boys) who reported drinking weekly, 8% (7%) reported severe suicidal ideation compared with 1% (0.7%) of those not drinking. Of girls (boys) who reported use of substances other than alcohol five times or more, 13% (21%) reported severe suicidal ideation, compared with 1.3% (1.1%) of those who had no use of substances other than possibly alcohol. These associations persisted in multivariate analyses controlling for depressive symptoms and sociodemographic background. Conclusions Frequent alcohol use and use of substances other than alcohol independently indicate a risk for adolescent suicidal ideation and may thus repre...", "label": 0}
{"doc-1": "The basic organization of the catecholamine-containing neuronal systems and their axonal projections in the brain was initially worked out using classical histofluorescence techniques during the 1960s and 1970s. The introduction of more versatile immunohistochemical methods, along with a range of highly sensitive tract-tracing techniques, has provided a progressively more detailed picture, making the dopamine system one of the best known, and most completely mapped, neurotransmitter systems in the brain. The purpose of the present review is to summarize our current knowledge of the diversity and neurochemical features of the nine dopamine-containing neuronal cell groups in the mammalian brain, their distinctive cellular properties, and their ability to regulate their dopaminergic transmitter machinery in response to altered functional demands and aging.", "doc-2": "Partial left ventriculectomy (PLV) has been introduced as an option for patients with end-stage dilated cardiomyopathy. We report the result of a prospective trial of PLV in patients with idiopathic dilated cardiomyopathy, left ventricular end-diastolic diameter (LVEDD) > 7 cm, refractory New York Heart Association (NYHA) Class IV symptoms, and depressed exercise oxygen consumption studies. Sixteen patients underwent a PLV with a mean follow-up of 13 months. Fourteen patients were male. Mean age was 49.6  10.5 years (range 30 to 67 years). Left ventricular ejection fraction (LVEF) improved after surgery from 13.9  5.6 to 21.0  8.4, and this improvement persisted for up to 12 months after operation. LVEDD and NYHA Class also were significantly improved after surgery and for up to 12 months of follow-up. Operative mortality was 6.25%. Twelve-month survival was 86% by Kaplan-Meier analysis. Four (25%) of 16 patients that had initial improvement after PLV developed recurrent heart failure and were listed for transplantation. Freedom from need for listing for heart transplantation was 65% at 12 months. Freedom from death or the need for relisting at 12 months was 56%. PLV can be performed with acceptable early and 12-month mortality. Significant improvements in LVEF, LVEDD, and NYHA Class are seen at up to 12 months of follow-up. Some patients will develop recurrent heart failure and require relisting for heart transplantation.", "label": 0}
{"doc-1": "Bacteria and archaea have evolved adaptive immune defenses, termed clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated (Cas) systems, that use short RNA to direct degradation of foreign nucleic acids. Here, we engineer the type II bacterial CRISPR system to function with custom guide RNA (gRNA) in human cells. For the endogenous AAVS1 locus, we obtained targeting rates of 10 to 25% in 293T cells, 13 to 8% in K562 cells, and 2 to 4% in induced pluripotent stem cells. We show that this process relies on CRISPR components; is sequence-specific; and, upon simultaneous introduction of multiple gRNAs, can effect multiplex editing of target loci. We also compute a genome-wide resource of ~190 K unique gRNAs targeting ~40.5% of human exons. Our results establish an RNA-guided editing tool for facile, robust, and multiplexable human genome engineering.", "doc-2": "The results are reported of a laboratory testing program to determine the permeability ratio, rK, (ratio of coefficients of permeability for flow parallel to and perpendicular to the soil layers) of samples of New Liskeard varved soil. The maximum value of rK is less than 5, which is perhaps significantly smaller than values usually assumed for varved soils. To explain these results, tests were conducted to determine the permeability characteristics of the constituent soils of the varves. Information is given concerning the test methods, the determination of the influence on permeability of soil disturbance at the cut surfaces, and the finding that this soil behaved according to Darcy's law at small values of hydraulic gradient.", "label": 0}
{"doc-1": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.", "doc-2": "Human malaria infections resulting from Plasmodium falciparum have become increasingly difficult to treat due to the emergence of drug-resistant parasites. The P. falciparum purine salvage enzyme purine nucleoside phosphorylase (PfPNP) is a potential drug target. Previous studies, in which PfPNP was targeted by transition state analogue inhibitors, found that those inhibiting human PNP and PfPNPs killed P. falciparum in vitro. However, many drugs have off-target interactions, and genetic evidence is required to demonstrate single target action for this class of potential drugs. We used targeted gene disruption in P. falciparum strain 3D7 to ablate PNP expression, yielding transgenic 3D7 parasites (Deltapfpnp). Lysates of the Deltapfpnp parasites showed no PNP activity, but activity of another purine salvage enzyme, adenosine deaminase (PfADA), was normal. When compared with wild-type 3D7, the Deltapfpnp parasites showed a greater requirement for exogenous purines and a severe growth defect at physiological concentrations of hypoxanthine. Drug assays using immucillins, specific transition state inhibitors of PNP, were performed on wild-type and Deltapfpnp parasites. The Deltapfpnp parasites were more sensitive to PNP inhibitors that bound hPNP tighter and less sensitive to MT-ImmH, an inhibitor with 100-fold preference for PfPNP over hPNP. The results demonstrate the importance of purine salvage in P. falciparum and validate PfPNP as the target of immucillins.", "label": 0}
{"doc-1": "It has been more than 10 years since it was first proposed that the neurodegeneration in Alzheimer's disease (AD) may be caused by deposition of amyloid beta-peptide (Abeta) in plaques in brain tissue. According to the amyloid hypothesis, accumulation of Abeta in the brain is the primary influence driving AD pathogenesis. The rest of the disease process, including formation of neurofibrillary tangles containing tau protein, is proposed to result from an imbalance between Abeta production and Abeta clearance.", "doc-2": "The long-term durability and function of cardiac bioprostheses can be affected by both calcification and mechanical failure of the tissue. The mechanisms of failure and hydrodynamic function of 66 explanted bioprostheses have been studied. The majority of porcine valves were heavily calcified with leaflet tears adjacent to the calcification at the commissures. These tears caused prolapsed leaflets and regurgitation of between 30 and 70 per cent. Only three porcine valves had tissue failure in the absence of calcification. The majority of pericardial valves failed due to leaflet tears at the edge of the frame in the absence of macroscopic calcification. These tears also produced prolapsed leaflets and large regurgitation in hydrodynamic tests. Three pericardial valves were heavily calcified and stenotic without leaflet tears. Leaflet dynamics in the pericardial valves were affected by host tissue ingrowth which produced increased pressure drops across the valves, an asymmetrical open position and leaflet flutter. In the absence of calcification and leaflet tears, there was little change in the function of explanted porcine valves.", "label": 0}
{"doc-1": "This abridged version of the \"Anthropometric Standardisation Reference Manual\" contains the heart of the original manual - complete procedures for 45 anthropometric measurements. Its style enables it to be used as a supplemental text for courses in fitness assessment and exercise prescription, kinanthropometry, body composition, nutrition, and exercise physiology. It can also be used as a reference for exercise scientists. For each of the 45 measurements included in this abridged edition, readers will find complete information on the recommended technique for making the measurement, the purpose and uses for the measurement, the literature on which the measurement technique is based, and the reliability of the measurement.", "doc-2": "A recent paper in this journal argued that reported expression levels, kcat and Km for drug transporters could be used to estimate the likelihood that drug fluxes through Caco-2 cells could be accounted for solely by protein transporters. It was in fact concluded that if five such transporters contributed 'randomly' they could account for the flux of the most permeable drug tested (verapamil) 35% of the time. However, the values of permeability cited for verapamil were unusually high; this and other drugs have much lower permeabilities. Even for the claimed permeabilities, we found that a single 'random' transporter could account for the flux 42% of the time, and that two transporters can achieve 1010(-6)cms(-1) 90% of the time. Parameter optimisation methods show that even a single transporter can account for Caco-2 drug uptake of the most permeable drug. Overall, the proposal that 'phospholipid bilayer diffusion (of drugs) is negligible' is not disproved by the calculations of 'likely' transporter-based fluxes.", "label": 0}
{"doc-1": "In Risk, Uncertainty and Profit, Frank Knight explored the riddle of profitability in a competitive market profit should not be possible under competitive conditions, as the entry of new entrepreneurs would drive prices down and nullify margins, however evidence abounds of competitive yet profitable markets. To explain this seeming paradox, Knight uncovers the distinction between calculable risk and essentially unknowable uncertainty. Knight argued that risk stems from repeated events, which therefore allow probabilities to be calculated and factored into decisions, as for instance insurers do. Uncertainty however, stems from events that are unpredictable and as such cannot be prepared against. According to Knight, it is the interplay between risk and uncertainty on the one hand and competition between incumbent and new entrepreneurs that accounts for the enormous variation in profitability across firms and, for the same firms, over time. His insights on the sources of profit have been instrumental in shaping modern economic theory and to the development of a useful understanding of probability. This New Edition has been typeset with modern techniques and contains a newly compiled Index of important topics. It has been painstakingly proofread to ensure that it is free from errors and that the content is faithful to the original.", "doc-2": "The decomposition of CH3OH and C2H5OH in supercritical water was studied in a flow reactor tube (Ni /Mo/Cr/Fe alloy) in the temperature range 597  T/K  797 at a pressure of p = 315 bar for technical application of scH 2O for hazardous chemical waste destruction. The CH3OH and C2H5OH concentrations in the liquid as a function of the residence times were determined by a Raman spectrometer. The [CH3OH] and [C2H5OH] resp. decay followed first order kinetics and a rate constant k1(653 K) = 1.3  10 2 s 1 for CH3OH and k2(653 K) = 5.5  10 2 s 1 for C2H5OH was determined. The rate constant k1 was found to be independent of the initial CH3OH concentration in the mass fraction range 0.002  xm  0.04. The rate depended on the history of the reactor. Treatment with NH4OH, C2H5OH or with H2O2 at T = 653 K, did not change the rate. Treatment with HNO3/H2O2, however, at T = 838 K reduced the rate by about a factor of 1000. The Arrhenius-activation energy over the above temperature range was determined to be EA = 164 kJ/mol for methanol and EA = 145 kJ/mol for ethanol. The major products from methanol decomposition were CH4 ,H 2 ,a nd CO 2 as observed by gas chromatography and CH4 and CO2 by FTIR-spectrometry. No other products were found. The products were not effected by the pretreatment of the reactor wall. A non-radical mechanism, which explains the formation of only these products, will be discussed.", "label": 0}
{"doc-1": "Few theoretical methods and experimental data exist for the analysis of tunnelface stability in cohesionless soils. The present paper addresses a series of practical questions by using centrifugalmodel tests. The values of limit internalsupport pressures are given for various conditions (density of the sand, position of the tunnel with respect to the ground surface). These values are shown to be low as predicted by the latest limitcalculation models and collapse is shown to be sudden. The geometry of the failure zone is depicted for different embedment depths. The initial mechanism appears to be of a bulk shape with a limited extent in front of the face. The presence of a short unlined length of tunnel at the face is also investigated. Data are presented about its effect on the failure mechanism, on the limit pressure, and on stress transfer onto the tunnel lining at collapse. The results obtained in the model tests are in general agreement with present knowledge of fullscale situations.", "doc-2": "Theory of regression methods is based on the crispness of the observations and the parameters of interest. But there can be many different situations in which the above mentioned concepts are imprecise. On the other hand, the theory of fuzzy sets is a well established tool for formulation and analysis of imprecise and subjective concepts. In these times we must use the fuzzy regression. In this paper, at first we use a well-known signed distance, then with using this signed distance we estimate the crisp regression coefficients based on fuzzy data using least square method. Finally, we exhibit confidence interval and hypothesis testing for these coefficients based on bootstrap theory and numerical examples are also provided to illustrate the approach. In case of the confidence interval and hypothesis testing problem, bootstrap techniques (Efron and Tibshirani, [10]) have empirically been shown to be efficient and powerful.", "label": 0}
{"doc-1": "The transcription factors interferon regulatory factor 3 (IRF3) and NF-kappaB are required for the expression of many genes involved in the innate immune response. Viral infection, or the binding of double-stranded RNA to Toll-like receptor 3, results in the coordinate activation of IRF3 and NF-kappaB. Activation of IRF3 requires signal-dependent phosphorylation, but little is known about the signaling pathway or kinases involved. Here we report that the noncanonical IkappaB kinase homologs, IkappaB kinase-epsilon (IKKepsilon) and TANK-binding kinase-1 (TBK1), which were previously implicated in NF-kappaB activation, are also essential components of the IRF3 signaling pathway. Thus, IKKepsilon and TBK1 have a pivotal role in coordinating the activation of IRF3 and NF-kappaB in the innate immune response.", "doc-2": "This edited book contains a compilation of 14 advanced academic chapters dealing with the structure and function of membrane protein complexes. This rapidly advancing important field of study closely parallels those on soluble protein complexes, and viral protein and nucleoprotein complexes. Diverse topics are included in this book, ranging from membranebound enzymes to ion channels, proton pumps and photosystems. Data from X-ray crystallography, cryo-electron microscopy and other biophysical and biochemical techniques are presented throughout the book. There is extensive use of colour figures of protein structures. Throughout the book structure and function are closely correlated. The two editors, Egbert Boekema and J. Robin Harris, have worked on aspects of membrane and soluble proteins throughout their scientific careers and also have much publishing experience. The Subcellular Biochemistry series has expanded considerably in recent years, including several related volumes. The theme of protein complexes will be continued within several future volumes, thereby creating encyclopaedic coverage. The chapter topics within this book are particularly relevant to those involved in the biological and biomedical sciences. It is aimed at the advanced undergraduates, postgraduates and established researchers within this broad field. It is hoped that the book will be of interest and use to those involved with the study of cellular membranes and their associated proteins.", "label": 0}
{"doc-1": "The Agrobacterium vacuum infiltration method has made it possible to transform Arabidopsis thaliana without plant tissue culture or regeneration. In the present study, this method was evaluated and a substantially modified transformation method was developed. The labor-intensive vacuum infiltration process was eliminated in favor of simple dipping of developing floral tissues into a solution containing Agrobacterium tumefaciens, 5% sucrose and 500 microliters per litre of surfactant Silwet L-77. Sucrose and surfactant were critical to the success of the floral dip method. Plants inoculated when numerous immature floral buds and few siliques were present produced transformed progeny at the highest rate. Plant tissue culture media, the hormone benzylamino purine and pH adjustment were unnecessary, and Agrobacterium could be applied to plants at a range of cell densities. Repeated application of Agrobacterium improved transformation rates and overall yield of transformants approximately twofold. Covering plants for 1 day to retain humidity after inoculation also raised transformation rates twofold. Multiple ecotypes were transformable by this method. The modified method should facilitate high-throughput transformation of Arabidopsis for efforts such as T-DNA gene tagging, positional cloning, or attempts at targeted gene replacement.", "doc-2": "Abstract. The land surface provides a boundary condition to atmospheric forward and flux inversion models. These models require prior estimates of CO2 fluxes at relatively high temporal resolutions (e.g., 3-hourly) because of the high frequency of atmospheric mixing and wind heterogeneity. However, land surface model CO2 fluxes are often provided at monthly time steps, typically because the land surface modeling community focuses more on time steps associated with plant phenology (e.g., seasonal) than on sub-daily phenomena. Here, we describe a new dataset created from 15 global land surface models and 4 ensemble products in the Multi-scale Synthesis and Terrestrial Model Intercomparison Project (MsTMIP), temporally downscaled from monthly to 3-hourly output. We provide 3-hourly output for each individual model over 7years (20042010), as well as an ensemble mean, a weighted ensemble mean, and the multi-model standard deviation. Output is provided in three different spatial resolutions for user preferences: 0.50.5, 2.02.5, and 4.05.0 (latitudelongitude). These data are publicly available from doi:10.3334/ORNLDAAC/1315 .", "label": 0}
{"doc-1": "Model Notation, Covariances, and Path Analysis. Causality and Causal Models. Structural Equation Models with Observed Variables. The Consequences of Measurement Error. Measurement Models: The Relation Between Latent and Observed Variables. Confirmatory Factor Analysis. The General Model, Part I: Latent Variable and Measurement Models Combined. The General Model, Part II: Extensions. Appendices. Distribution Theory. References. Index.", "doc-2": "This paper highlights the relevance of the use of the Water Poverty Index as an effective water management tool in resources allocation and prioritization processes. Nevertheless, three conceptual weaknesses exist in the current index, including redundancy among variables, the decision of assigning weights to them, and the aggregation method. Based on a post process of readily available but sector relevant data, a revised method to construct the index has been developed through a case study in Kenya, at local scale. The paper discusses the results of this application. In particular, different approaches to exploit the index as a policy tool are presented, with the aim of enabling a more comprehensive understanding of the water sector constraints and challenges, and thus enhance related decision-making accordingly.", "label": 0}
{"doc-1": "The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSI-BLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.", "doc-2": "Seit geraumer Zeit steht den Unternehmen eine Klasse von Informationssystemen zur Verfugung, die speziell auf die Entscheidungsunterstutzung im Management abzielen. Fast evolutionar haben sich in den letzten 30 Jahren solche Systeme entwickelt und versucht, sich unter wechselnden Bezeichnungen auf dem IT Markt zu behaupten. Die Zielsetzung war und ist immer die gleiche: Entscheidungsrelevante Informationen zeitnah und problemadaquat in einer dem Management gerechten Weise aufzubereiten und gegebenenfalls angereichert durch Entscheidungsmodelle mit Losungsvorschlagen zur Verfugung zu stellen.", "label": 0}
{"doc-1": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.", "doc-2": "The entire encoding region for Aspergillus flavus uricase was cloned into pET-32a and expressed in Escherichia coli BL21 (DE3). The uricase was expressed in the E. coli cytoplasm in a completely soluble, biologically active form. A scalable process aimed to produce and purify multi-gram quantities of highly pure, recombinant urate oxidase (rUox) from E. coli was developed. The rUox protein was produced in a 30 L fermentor containing 25 L of 2x YT medium and purified to >99% purity using hydrophobic interaction, anion-exchange, and gel filtered chromatography. The final yield of purified rUox from fermentation resulted in approximately 27 g of highly pure, biologically active rUox per kg of cell paste (approximately 238 mg/8.8 g cell paste/L). The results presented here exhibit the ability to generate multi-gram quantities of rUox from E. coli that may be used for the development of pharmaceutics of reducing the hyperuricemia.", "label": 0}
{"doc-1": "Functional magnetic resonance imaging (fMRI) is widely used to study the operational organization of the human brain, but the exact relationship between the measured fMRI signal and the underlying neural activity is unclear. Here we present simultaneous intracortical recordings of neural signals and fMRI responses. We compared local field potentials (LFPs), single- and multi-unit spiking activity with highly spatio-temporally resolved blood-oxygen-level-dependent (BOLD) fMRI responses from the visual cortex of monkeys. The largest magnitude changes were observed in LFPs, which at recording sites characterized by transient responses were the only signal that significantly correlated with the haemodynamic response. Linear systems analysis on a trial-by-trial basis showed that the impulse response of the neurovascular system is both animal- and site-specific, and that LFPs yield a better estimate of BOLD responses than the multi-unit responses. These findings suggest that the BOLD contrast mechanism reflects the input and intracortical processing of a given area rather than its spiking output.", "doc-2": "Transformation acoustics opens a new avenue towards the design of acoustic metamaterials, which are materials engineered at the subwavelength scale in order to mimic the parameters in wave equations. The design of the acoustic cloaking is based on the property of equations being invariant under a coordinate transformation, i.e. a specific spatial compression is equivalent to a variation of the material parameters in the original space. In this paper, the sound invisibility performance is discussed for spherical cloaks. The original domain consists of alternating concentric layers made from piezoelectric ceramics and epoxy resin, following a triadic Cantor sequence. The spatial compression, obtained by applying the concave-down transformation, leads to an equivalent domain with an inhomogeneous and anisotropic distribution of the material parameters.", "label": 0}
{"doc-1": "A process for producing reagents useful in organic synthesis, for removing metal values from solutions thereof, for the capture of aldehydes, of the general formula wherein Z designates a recurring part (CH2-CH-CH2- of a polymeric backbone of a polymer like polystyrene, of a copolymer comprising polystyrene and divinylbenzene, and butadiene, or other copolymers comprising styrene moieties; or wherein Z is the aliphatic moiety of a long-chain aralkyl compound having a terminal aryl group; or wherein Z designates alkyl; corresponding compounds wherein instead of the optionally substituted phenyl group there is present an optionally substituted naphthyl group; wherein n is an integer of from 1 to 15, and wherein Q designates a group selected from: wherein R designates -H, lower alkyl, aryl, which may be substituted and wherein R'' designates -H, alkyl, aryl, halogen, nitro or carboxy, or wherein R is -H, lower alkyl, aryl (which may be substituted), R1 is -H, alkyl, aryl (which may be substituted), R2 is -H, alkyl, aryl or substituted aryl, and wherein Y is -H or a non-interfering substituent; which comprises chemically binding an activated chemical moiety to a group Z- -, or a corresponding naphthyl-containing group, wherein Z is as defined above, according to the reaction scheme: +TR wherein Q is as defined above, or a functional group which can be converted to such group after the chemical bonding; and X is -Cl or -Br.", "doc-2": "The worldwide emergence of multidrug-resistant pathogens is a serious medical concern nowadays. The need to discover new bioactive molecules active against these bacteria is crucial and is one of the main fields of research for modern microbiologists. Most natural antibiotics used in medicine are biosynthesised by Gram-positive bacteria. Recent advances in genomics and genome sequencing have shown that the potential of these organisms to produce molecules of pharmacological interest has been greatly underestimated. Full genome sequencing has revealed the three main groups according to their biosynthesis pathways: peptides manufactured by the conventional ribosomal assembly, NRPS metabolites (nonribosomal peptide synthetase) and polyketides (PKS  polyketide synthase). The genera Bacillus, Lactobacillus, Enterococcus, Streptococcus and Lactococcus are responsible for the production of the majority of ribosomal peptides (lantibiotics and bacteriocins) whereas NRPS and PKS metabolites  molecules synthesised by large enzymatic complexes  are mostly produced by bacteria of the Actinomycetales order (the Streptomyces genus produces two-thirds of natural antibiotics, antitumour agents and immunosuppressors used in medicine) and by Bacillus species.", "label": 0}
{"doc-1": "When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visualhaptic percept, for example when judging size, shape or position1,2,3, but in some circumstances the percept is clearly affected by haptics4,5,6,7. Here we propose that a general principle, which minimizes variance in the final estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation8,9,10,11,12,13,14,15 to combine the inputs. To investigate cue combination quantitatively, we first measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visualhaptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation.", "doc-2": "A trapping approach for semi-quantitative assessment of bioactivation potential has been established for new chemical entities by using [(35)S]cysteine and [(14)C]sodium cyanide as trapping reagents. Reactive metabolites were trapped as radioactive adducts with the trapping reagents to be analyzed by radio-LC(/MS). As a reference, hepatotoxic drugs (clozapine, diclofenac, R-(+)-pulegone and troglitazone) were tested in the [(35)S]cysteine trapping assay and the proposed structures of the cysteine adducts were consistent with glutathione adducts previously reported. The accuracy of this methodology to predict bioactivation potential of structurally diverse non-radiolabeled test compounds was evaluated by comparing the radiochromatographic peak area obtained in this assays with the extent of covalent binding to protein assessed by the conventional method using radiolabeled test compounds. The value obtained from the [(35)S]cysteine trapping assay in human liver microsomes predicted potential for covalent binding of the test compounds to proteins with reasonable accuracy. A combination of trapping reagents ([(35)S]cysteine and [(14)C]cyanide) improved the accuracy for prediction of bioactivation potential by simultaneously trapping both types of electrophilic reactive metabolites. This method is expected to be a useful to prioritize compounds for further development based on the bioactivation liability, especially at the lead optimization stage.", "label": 0}
{"doc-1": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \"autoencoder\" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.", "doc-2": "Human intrusion within areas of sea lion habitat is increasing worldwide, leading to concerns about disruption of distribution and daily activities of sea lions. Sea lion responses to disturbance can be quantified by recording changes in behavioral patterns, documenting numbers of animals on shore before, during, and after the disturbance, or by measuring physiological stress of individual animals. However, assessing recovery is not so straightforward, as highlighted by an example from a study of the short-term effects of disturbance on Steller sea lions. Recovery is generally recognized as a return to an original state or normal condition, but is often operationally defined as a percent-return to pre-disturbance numbers or behaviors. Simple interpretation of disturbance effects can be easily confounded by concurrent natural seasonal changes in behaviors or haul-out patterns, or by daily variability in numbers of animals present that can be attributed to weather, tidal cycle stage, and other factors. Overall, a range of recovery criteria needs to be simultaneously applied when assessing the effects of human disturbance on sea lion populations. Insights gained from research on the effects of disturbance on Steller sea lions may help guide the development of studies undertaken on other species of sea lions.", "label": 0}
{"doc-1": "MOTIVATIONThe Glimmer gene-finding software has been successfully used for finding genes in bacteria, archaea and viruses representing hundreds of species. We describe several major changes to the Glimmer system, including improved methods for identifying both coding regions and start codons. We also describe a new module of Glimmer that can distinguish host and endosymbiont DNA. This module was developed in response to the discovery that eukaryotic genome sequencing projects sometimes inadvertently capture the DNA of intracellular bacteria living in the host.RESULTSThe new methods dramatically reduce the rate of false-positive predictions, while maintaining Glimmer's 99% sensitivity rate at detecting genes in most species, and they find substantially more correct start sites, as measured by comparisons to known and well-curated genes. We show that our interpolated Markov model (IMM) DNA discriminator correctly separated 99% of the sequences in a recent genome project that produced a mixture of sequences from the bacterium Prochloron didemni and its sea squirt host, Lissoclinum patella.AVAILABILITYGlimmer is OSI Certified Open Source and available at http://cbcb.umd.edu/software/glimmer.", "doc-2": "We investigated the separation of nitrogen heterocyclic compound (NHC) contained in a model coal tar fraction comprising four kinds of NHC [indole (In), quinoline (Q), iso-quinoline (iQ), quinaldine (Qu)], three kinds of bicyclic aromatic compound (BAC) [1-methylnaphthalene (1MN), 2-methylnaphthalene (2MN), dimethylnaphthalene (DMN) mixture with ten structural isomers (DMNs; regarded as one component)], biphenyl (Bp) and phenyl ether (Pe) by liquid membrane permeation (LMP). A batch-stirred tank was used as the permeation unit. An aqueous solution of saponin and n-hexane were used as the liquid membrane and the outer oil phase, respectively. Yield and selectivity of individual NHC was much larger than that of BAC, Bp and Pe. Increasing the initial mass fraction of the saponin to the membrane solution () and the initial volume fraction of O/W emulsion to total liquid in a stirred tank () resulted in deteriorating the yield of individual NHC, but increasing the stirring speed (N) resulted in improving the yield of each NHC. With increasing , the selectivity of each NHC based on DMNs increased. Increasing and N resulted in decreasing the selectivity of individual NHC based on DMNs. At an experimental condition fixed, the sequence of the yield and selectivity in reference to DMNs for each NHC was Q > Qu = iQ > In. Furthermore, we compared LPM method with methanol extraction method in view of the separation efficiency (yield, selectivity) of NHC.", "label": 0}
{"doc-1": "EXAMINATION of the mental state is essential in evaluating psychiatric patients.1 Many investigators have added quantitative assessment of cognitive performance to the standard examination, and have documented reliability and validity of the several clinical tests of the sensorium.2*3 The available batteries are lengthy. For example, WITHERS and HINTONS test includes 33 questions and requires about 30 min to administer and score. The standard WAIS requires even more time. However, elderly patients, particularly those with delirium or dementia syndromes, cooperate well only for short periods.4 Therefore, we devised a simplified, scored form of the cognitive mental status examination, the Mini-Mental State (MMS) which includes eleven questions, requires only 5-10 min to administer, and is therefore practical to use serially and routinely. It is mini because it concentrates only on the cognitive aspects of mental functions, and excludes questions concerning mood, abnormal mental experiences and the form of thinking. But within the cognitive realm it is thorough. We have documented the validity and reliability of the MMS when given to 206 patients with dementia syndromes, affective disorder, affective disorder with cognitive impairment pseudodementia5T6), mania, schizophrenia, personality disorders, and in 63 normal subjects.", "doc-2": "OBJECTIVETo determine a correlation between conventional electronystagmography findings with results obtained from BalanceTrak 500 posturography assessment.STUDY DESIGNIndividuals with a variety of dizziness and balance disorder symptoms were tested with both electronystagmography (ocular motor studies, positional/positioning testing, caloric testing) and computer posturography using the BalanceTrak 500.SETTINGTertiary referral center.PATIENTSUrban/rural midwesterners referred for dizziness and balance dysfunction symptoms.INTERVENTIONResults of both testing modalities were sent to referring physicians.OUTCOME MEASURESElectronystagmography and posturography results.RESULTSWhen electronystagmography results were compared with BalanceTrak findings, a majority of patients whose electronystagmography findings indicated central and mixed causes, or peripheral lesions other than benign paroxysmal positional vertigo, had abnormal findings on posturography. Specifically, tests similar to the Balance Master Sensory Organization Tests 4 and 5 and a new test, Limits of Stability, presented the most difficulty for these individuals. Patients with normal electronystagmography findings and those with benign paroxysmal positional vertigo had mixed results on posturography. The results for specific individual electronystagmography tests were compared with those of posturography tests. No correlation was noted among any of the electronystagmography results and posturography findings. Furthermore, no correlation was observed between posturography and the causes of dizziness.CONCLUSIONFor many patients with dizziness and/or balance dysfunctions, posturography can provide additional information to that obtained with electronystagmography. This is especially apparent in individuals who have these symptoms but have normal or borderline normal electronystagmography findings.", "label": 0}
{"doc-1": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.", "doc-2": "The study of the Laplace operator and its corresponding eigenvalue problem is crucial to understand the foundations of 3D shape analysis. For that reason the most important mathematical properties of the Laplace operator in Euclidean spaces, its eigenvalues and eigenfunctions are summarized and explained in this report. The basic definitions and concepts of infinite dimensional function spaces, that are required are introduced beforehand. In order to motivate the study of the Laplace eigenvalue problem, the connection between the Laplace eigenvalues and the geometry of the domain, to which the operator is applied, is demonstrated by presenting Weyls law. Furthermore it is shown how the Fourier transform can be derived from the consequences of the spectral theorem and orthogonal basis functions of the L space. Finally some applications of the Laplace eigenfunctions in 3D shape analysis are demonstrated briefly.", "label": 0}
{"doc-1": "stargazer produces LaTeX code for well-formatted tables that hold regression analysis results from several models side-by-side, as well as summary statistics. It supports model objects from lm, glm, svyglm, gee, gam, polr, survreg, coxph, as well as from the implementation of these in zelig. It also supports the following zelig models for social network analysis: cloglog.net, gamma.net, and logit.net.", "doc-2": "We address a problem of increasing practical interest: control charting in the absence of an assumed normal distribution. We analyze the sampling uncertainties inherent in selecting control limits from the empirical distribution of a large sample of wha..", "label": 0}
{"doc-1": "Acute and chronic experimental ulcerative colitis models were produced in mice by providing them with drinking water containing synthetic dextran sulfate sodium. Mice that developed acute colitis showed signs of diarrhea, gross rectal bleeding, and weight loss within 6-10 days after ingesting 3%-10% dextran sulfate sodium. On postmortem examination, multiple erosions and inflammatory changes including crypt abscesses were found on the left side of the large intestine. Mice that developed chronic colitis showed signs of erosions, prominent regenerations of the colonic mucosa including dysplasia, shortening of the large intestine, and frequent formation of lymphoid follicles after 5 administration cycles, where each cycle was composed of 7 days' consumption of drinking water containing 5% dextran sulfate sodium followed by 10 days' consumption of distilled water. The population of intestinal microflora, Bacteroides distasonis and Clostridium spp., increased significantly in mice with acute and chronic ulcerative colitis. Further, morphological studies suggest that the administered dextran sulfate sodium was partially phagocytized by macrophages in the colonic mucosa.", "doc-2": "Few theoretical methods and experimental data exist for the analysis of tunnelface stability in cohesionless soils. The present paper addresses a series of practical questions by using centrifugalmodel tests. The values of limit internalsupport pressures are given for various conditions (density of the sand, position of the tunnel with respect to the ground surface). These values are shown to be low as predicted by the latest limitcalculation models and collapse is shown to be sudden. The geometry of the failure zone is depicted for different embedment depths. The initial mechanism appears to be of a bulk shape with a limited extent in front of the face. The presence of a short unlined length of tunnel at the face is also investigated. Data are presented about its effect on the failure mechanism, on the limit pressure, and on stress transfer onto the tunnel lining at collapse. The results obtained in the model tests are in general agreement with present knowledge of fullscale situations.", "label": 0}
{"doc-1": "UNLABELLEDResearch over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.AVAILABILITYhttp://www.broad.mit.edu/mpg/haploview/CONTACTjcbarret@broad.mit.edu", "doc-2": "SummaryA woman presented a complex chromosome rearrangement with translocation between chromosome 2 and 4 in addition to an insertion of the band 4q12q13 in the long arm of chromosome 18. The authors present a case study of the daughter who displayed the abnormal chromosome 18 and trisomy of band 4q12q13.", "label": 0}
{"doc-1": "The CES-D scale is a short self-report scale designed to measure depressive symptomatology in the general population. The items of the scale are symptoms associated with depression which have been used in previously validated longer scales. The new scale was tested in household interview surveys and in psychiatric settings. It was found to have very high internal consistency and adequate test- retest repeatability. Validity was established by pat terns of correlations with other self-report measures, by correlations with clinical ratings of depression, and by relationships with other variables which support its construct validity. Reliability, validity, and factor structure were similar across a wide variety of demographic characteristics in the general population samples tested. The scale should be a useful tool for epidemiologic studies of de pression.", "doc-2": "Dextran has been used in microsurgery to reduce the risk of free tissue transfer loss. A number of regimens which vary considerably in dosage and timing have been published in the literature. Using a postal questionnaire, a survey was conducted to delineate the current practise of UK plastic surgeons. Data were received from 161 plastic surgeons in 51 units (response rate of 61%). Forty-five percent of microsurgeons routinely use dextran post-operatively whilst 29% use alternative thromboprophylaxis. The indications, post-operative regimes and duration of administration of dextran vary significantly amongst surgeons and units. The reported success rates of free tissue transfer and digital replants were 97 and 85.1%, respectively, and was not significantly affected by the use of dextran. We conclude that there is considerable variation amongst UK plastic surgeons regarding thromboprophylaxis post microsurgery. Our data suggest that the use of dextrans does not affect free tissue transfer success rates.", "label": 0}
{"doc-1": "OBJECTIVEFunnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test of asymmetry of funnel plots predicts discordance of results when meta-analyses are compared to large trials, and we assessed the prevalence of bias in published meta-analyses.DESIGNMedline search to identify pairs consisting of a meta-analysis and a single large trial (concordance of results was assumed if effects were in the same direction and the meta-analytic estimate was within 30% of the trial); analysis of funnel plots from 37 meta-analyses identified from a hand search of four leading general medicine journals 1993-6 and 38 meta-analyses from the second 1996 issue of the Cochrane Database of Systematic Reviews.MAIN OUTCOME MEASUREDegree of funnel plot asymmetry as measured by the intercept from regression of standard normal deviates against precision.RESULTSIn the eight pairs of meta-analysis and large trial that were identified (five from cardiovascular medicine, one from diabetic medicine, one from geriatric medicine, one from perinatal medicine) there were four concordant and four discordant pairs. In all cases discordance was due to meta-analyses showing larger effects. Funnel plot asymmetry was present in three out of four discordant pairs but in none of concordant pairs. In 14 (38%) journal meta-analyses and 5 (13%) Cochrane reviews, funnel plot asymmetry indicated that there was bias.CONCLUSIONSA simple analysis of funnel plots provides a useful test for the likely presence of bias in meta-analyses, but as the capacity to detect bias will be limited when meta-analyses are based on a limited number of small trials the results from such analyses should be treated with considerable caution.", "doc-2": "Abstract We use the conformal bootstrap equations to study the non-perturbative gravitational scattering between infalling and outgoing particles in the vicinity of a black hole horizon in AdS. We focus on irrational 2D CFTs with large c and only Virasoro symmetry. The scattering process is described by the matrix element of two light operators (particles) between two heavy states (BTZ black holes). We find that the operator algebra in this regime is (i) universal and identical to that of Liouville CFT, and (ii) takes the form of an exchange algebra, specified by an R-matrix that exactly matches the scattering amplitude of 2 + 1 gravity. The R-matrix is given by a quantum 6 j -symbol and the scattering phase by the volume of a hyperbolic tetrahedron. We comment on the relevance of our results to scrambling and the holographic reconstruction of the bulk physics near black hole horizons.", "label": 0}
{"doc-1": "OBJECTIVETo assess the chromosomal aberrations in the abortus in recurrent miscarriage and the live birth rate after a euploid or aneuploid miscarriage.DESIGNRetrospective analysis.SETTINGTertiary referral unit in university hospital.PATIENT(S)One hundred sixty-seven patients with 3 to 16 miscarriages before 20 weeks.INTERVENTION(S)Material collected at curettage from 167 abortuses was analyzed by standard G-banding techniques.MAIN OUTCOME MEASURE(S)The incidence of aberrations and the outcome of the subsequent pregnancy were assessed according to the embryonic karyotype.RESULT(S)In this study 125 specimens were successfully karyotyped. Of these, 29% (36 of 125) had chromosome aberrations; 94% of the aberrations were aneuploidy, and 6% were structural. The most prevalent anomalies were chromosome 16, 18, and 21 trisomies, triploidy, and monosomy X. After an aneuploid miscarriage, there was a 68% subsequent live birth rate (13 of 19) compared to the 41% (16 of 39) rate after a euploid abortion.CONCLUSION(S)The low (29%) incidence of aberrations indicates that alternative mechanisms may be responsible for the majority of recurrent miscarriages. These figures provide a basis for assessing the efficacy of therapy for recurrent miscarriage. If further studies confirm that patients with karyotypically abnormal fetuses have a good prognosis, an informed decision can be made as to whether further investigations and treatment should be undertaken.", "doc-2": "Publisher Summary This chapter reviews the studies, suggesting that the orbitofrontal cortex (OFC) is involved in choosing responses and making decisions based on motivationally salient information. To do this effectively, the OFC must code current incentive value of external reinforcing cues and be able to respond rapidly to changes in contingencies and values. Motivationally salient information can be uncertain and unpredictable; therefore, the OFC must be able to process uncertainty and respond in anticipation of expected outcome, as well as be able to change response quickly in the face of unexpected negative outcomes. The social interactions and behaviors that are fundamental to everyday life depend on effectively and flexibly making decisions based on unpredictable and potentially changeable motivationally salient information, and therefore patients with OFC damage show impaired social behavior and decision making, although many cognitive components of complex behaviors may remain intact. The prefrontal cortex generally is considered to play a role in keeping relevant information in mind and in monitoring whether outcomes match expectations. The suggestion is that the OFC applies these functions of holding in mind and monitoring specifically to reinforcing and motivationally salient information.", "label": 0}
{"doc-1": "Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.", "doc-2": "Rapid increase in industrialization of world economy in the past century has resulted in significantly high emission of anthropogenic chemicals in the ecosystem. The organochlorine pesticides (OCPs) are a great risk to the global environment and endanger the human health due to their affinity for dispersion, transportation over long distances, and bioaccumulation in the food chain. Phytoremediation is a promising technology that aims to make use of plants and associated bacteria for the treatment of groundwater and soil polluted by these contaminants. Processes known to be involved in phytoremediation of OCPs include phytoaccumulation, rhizoremediation, and phytotransformation. Vegetation has been accounted to considerably amplify OCP elimination from soil, in contrast to non-planted soil, attributable to both, uptake within plant tissues and high microbial degradation of OCP within the root zone. Developing transgenic plants is a promising approach to enhance phytoremediation capabilities. Recent advances in the application of phytoremediation technique for OCPs, including uptake by plants and plant-microbe association in the rhizosphere for the enhanced degradation and mineralization of these pollutants, is presented in this review. Additionally, some attempts to improve this technique using transgenesis and role of certain enzymes are also discussed.", "label": 0}
{"doc-1": "Transposable elements (TEs) have a unique ability to mobilize to new genomic locations, and the major advance of second-generation DNA sequencing has provided insights into the dynamic relationship between TEs and their hosts. It now is clear that TEs have adopted diverse strategies  such as specific integration sites or patterns of activity  to thrive in host environments that are replete with mechanisms, such as small RNAs or epigenetic marks, that combat TE amplification. Emerging evidence suggests that TE mobilization might sometimes benefit host genomes by enhancing genetic diversity, although TEs are also implicated in diseases such as cancer. Here, we discuss recent findings about how, where and when TEs insert in diverse organisms.", "doc-2": "This article presents a fast solution to the volumesurface integral equation for electromagnetic scattering from three-dimensional (3D) targets comprising both conductors and dielectric materials by using the multilevel fast dipole method (MLFDM). This scheme is based on the concept of equivalent dipole-moment method (EDM) that views the RaoWiltonGlisson and the SchaubertWiltonGlisson basis functions as dipole models with equivalent dipole moments. In the MLFDM, a simple Taylor's series expansion of the terms R ( = 1, 1, 2, 3) and RR in the formulation of the EDM transforms the interaction between two equivalent dipoles into an aggregationtranslationdisaggregation form naturally. Furthermore, benefiting from the multilevel grouping scheme, the matrix-vector product can be accelerated and the memory cost is reduced remarkably. Simulation results are presented to demonstrate the efficiency and accuracy of this method.  2012 Wiley Periodicals, Inc. Int J RF and Microwave CAE, 2012.  2012 Wiley Periodicals, Inc.", "label": 0}
{"doc-1": "Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.", "doc-2": "ACKERMAN, BRIAN P. Developmental Differences in the Use of Conceptual Features in Retrieving Episodic Information from Memory. CHILD DEVELOPMENT, 1986, 57, 1109-1122. The use of defining, characteristic, category, and incidental semantic features of word concept information in cued recall was examined in 2 experiments. 7-8and 10-11-year-old children and college adults were shown word triplets in which the context words were Related (e.g., Rose-Tulip-Lily) or Unrelated (e.g., Wood-Brick-Lily) to the final target word. Recall was cued by Whole Context (e.g., Rose-Tulip) or Part Context (e.g., Rose) cues. The focal manipulation concerned the use of different feature orienting questions at acquisition in both experiments, and again at retrieval in Experiment 2. The results showed that cued recall was greatest for Defining Feature questions and least for Incidental Feature questions, especially for the children. The results suggest that meaning features differ in providing a medium for associative search at retrieval for children and adults, perhaps due to differences in feature salience in concept representations in memory. The results offer no support for the \"characteristic-to-defining\" feature developmental shift in concept representations hypothesized by Keil and Batterman.", "label": 0}
{"doc-1": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5years of the challenge, and propose future directions and improvements.", "doc-2": "We have designed, fabricated and tested a micromachined Coriolis flow sensor which can measure up to 50 g s-1 at a maximum pressure drop of 1 bar with a zero stability of 14ng s-1 an improvement by a factor 40 compared to current state of the art Coriolis flow sensors. This resolution opens up new fields of applications which could up to now not be measured with Coriolis flow sensors.", "label": 0}
{"doc-1": "Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.", "doc-2": "An equivalent martingale measure selection strategy for discrete time, continuous state, asset price evolution models is proposed. The minimal martingale law is shown to generally fail to produce a probability law in this context. The proposed strategy, termed the extended Girsanov principle, performs a multiplicative decomposition of asset price movements into a predictable and martingale component with the measure change identifying the discounted asset price process to the martingale component. However, unlike the minimal martingale law, the resulting martingale law of the extended Girsanov principle leads to weak form efficient price processes. It is shown that the proposed measure change is relevant for economies in which investors adopt hedging strategies that minimize the variance of a risk adjusted discounted cost of hedging that uses risk adjusted asset prices in calculating hedging returns. Risk adjusted prices deflate asset prices by the asset's excess return. The explicit form of the change of measure density leads to tractable econometric strategies for testing the validity of the extended Girsanov principle. A number of interesting applications of the extended Girsanov principle are also developed. Copyright Blackwell Publishers 1998.", "label": 0}
{"doc-1": "Human mesenchymal stem cells are thought to be multipotent cells, which are present in adult marrow, that can replicate as undifferentiated cells and that have the potential to differentiate to lineages of mesenchymal tissues, including bone, cartilage, fat, tendon, muscle, and marrow stroma. Cells that have the characteristics of human mesenchymal stem cells were isolated from marrow aspirates of volunteer donors. These cells displayed a stable phenotype and remained as a monolayer in vitro. These adult stem cells could be induced to differentiate exclusively into the adipocytic, chondrocytic, or osteocytic lineages. Individual stem cells were identified that, when expanded to colonies, retained their multilineage potential.", "doc-2": "BACKGROUNDHigh-dimensional biomedical data are frequently clustered to identify subgroup structures pointing at distinct disease subtypes. It is crucial that the used cluster algorithm works correctly. However, by imposing a predefined shape on the clusters, classical algorithms occasionally suggest a cluster structure in homogenously distributed data or assign data points to incorrect clusters. We analyzed whether this can be avoided by using emergent self-organizing feature maps (ESOM).METHODSData sets with different degrees of complexity were submitted to ESOM analysis with large numbers of neurons, using an interactive R-based bioinformatics tool. On top of the trained ESOM the distance structure in the high dimensional feature space was visualized in the form of a so-called U-matrix. Clustering results were compared with those provided by classical common cluster algorithms including single linkage, Ward and k-means.RESULTSWard clustering imposed cluster structures on cluster-less \"golf ball\", \"cuboid\" and \"S-shaped\" data sets that contained no structure at all (random data). Ward clustering also imposed structures on permuted real world data sets. By contrast, the ESOM/U-matrix approach correctly found that these data contain no cluster structure. However, ESOM/U-matrix was correct in identifying clusters in biomedical data truly containing subgroups. It was always correct in cluster structure identification in further canonical artificial data. Using intentionally simple data sets, it is shown that popular clustering algorithms typically used for biomedical data sets may fail to cluster data correctly, suggesting that they are also likely to perform erroneously on high dimensional biomedical data.CONCLUSIONSThe present analyses emphasized that generally established classical hierarchical clustering algorithms carry a considerable tendency to produce erroneous results. By contrast, unsupervised machine-learned analysis of cluster structures, applied using the ESOM/U-matrix method, is a viable, unbiased method to identify true clusters in the high-dimensional space of complex data.", "label": 0}
{"doc-1": "Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.", "doc-2": "Abstract Evisceration makes chicken carcasses susceptible to microbial contamination from gastrointestinal sources. A preventive action between spray washing and air chilling, a yogurt dip, may eliminate concerned contamination and enhance the bactericidal effect of nisin on Salmonella . This study was designed to determine whether synergism occurred with or without the application of an oilbeeswax coating. A 5 h yogurt dip then nisin with coating' and a 5 h yogurt dip then nisin, indicated significant inhibition of mesophilic aerobic bacteria and Salmonella with 2.11 and 1.97 log reductions, supported by pH, chromatographic and sensory findings ( p", "label": 0}
{"doc-1": "Multiple sequence alignments are fundamental to many sequence analysis methods. Most alignments are computed using the progressive alignment heuristic. These methods are starting to become a bottleneck in some analysis pipelines when faced with data sets of the size of many thousands of sequences. Some methods allow computation of larger data sets while sacrificing quality, and others produce high-quality alignments, but scale badly with the number of sequences. In this paper, we describe a new program called Clustal Omega, which can align virtually any number of protein sequences quickly and that delivers accurate alignments. The accuracy of the package on smaller test cases is similar to that of the high-quality aligners. On larger data sets, Clustal Omega outperforms other packages in terms of execution time and quality. Clustal Omega also has powerful features for adding sequences to and exploiting information in existing alignments, making use of the vast amount of precomputed information in public databases like Pfam.", "doc-2": "Given a smooth curve, the canonical representation of its automorphism group is the space of global holomorphic differential 1-forms as a representation of the automorphism group of the curve. In this paper, we study an explicit set of curves in positive characteristic with irreducible canonical representation whose genus is unbounded. Additionally, we study the implications this has for the de Rham hypercohomology as a representation of the automorphism group.", "label": 0}
{"doc-1": "Breast cancer is the most common malignancy in United States women, accounting for >40,000 deaths each year. These breast tumors are comprised of phenotypically diverse populations of breast cancer cells. Using a model in which human breast cancer cells were grown in immunocompromised mice, we found that only a minority of breast cancer cells had the ability to form new tumors. We were able to distinguish the tumorigenic (tumor initiating) from the nontumorigenic cancer cells based on cell surface marker expression. We prospectively identified and isolated the tumorigenic cells as CD44(+)CD24(-/low)Lineage(-) in eight of nine patients. As few as 100 cells with this phenotype were able to form tumors in mice, whereas tens of thousands of cells with alternate phenotypes failed to form tumors. The tumorigenic subpopulation could be serially passaged: each time cells within this population generated new tumors containing additional CD44(+)CD24(-/low)Lineage(-) tumorigenic cells as well as the phenotypically diverse mixed populations of nontumorigenic cells present in the initial tumor. The ability to prospectively identify tumorigenic cancer cells will facilitate the elucidation of pathways that regulate their growth and survival. Furthermore, because these cells drive tumor development, strategies designed to target this population may lead to more effective therapies.", "doc-2": "OBJECTIVESTo investigate the in-vitro antimicrobial activities of the extracts of Abrus precatorius on some clinical isolates as resistance to available and affordable antibiotics by these pathogens is on the increase.METHODIn this study the antimicrobial effects of the extracts of Abrus precatorius from leaves, stem and the seed oil were tested against Staphylococcus aureus ATCC 25923, three clinical S. aureus isolates from different sources, Staphylococcus epidermidis, Enterococcus faecalis, Streptococcus anginosus (S.milleri), Bacillus subtilis, Corynebacterium spp (toxigenic strain of the mitis biotype), Escherichia coli ATCC 25922, Klebsiella pneumoniae, Proteus mirabilis, Pseudomonas aeruginosa as well as Candida albicans using the agar well diffusion technique. Aqueous and methanolic extraction, using the soxhlet extractor was carried out on all plant parts used while petroleum ether was the solvent used to extract the seed oil. To measure the MIC values, various concentrations of the stock, 512, 256, 128, 64, 32, 16, 8 and 4 microg/ml were assayed against the test bacteria.RESULTAt the different concentrations of the extracts used (512 microg/ml - 4 microg/ml), Staphylococcus aureus was the most sensitive organism with an MIC of 8 ug/ml for the leaf extract. Extract from the stem and seed oil were potent against some of the gram-positive bacteria and Candida albicans but not against S anginosus, E. faecalis and gram-negative bacteria tested. The pH of the extracts ranged between pH5 and pH8. This study demonstrates that Abrus precatorius particularly the seed oil has a potent antimicrobial activity.CONCLUSIONThe results substantiate the ethno botanical use of different parts of Abrus precatorius for the treatment of various bacteria-related diseases. Topical application of Abrus precatorius extracts in ointments may be recommended especially for treating superficial infections caused by Staphylococcus aureus.", "label": 0}
{"doc-1": "This journal frequently contains papers that report values of F-statistics estimated from genetic data collected from several populations. These parameters, FST, FIT, and FIS, were introduced by Wright (1951), and offer a convenient means of summarizing population structure. While there is some disagreement about the interpretation of the quantities, there is considerably more disagreement on the method of evaluating them. Different authors make different assumptions about sample sizes or numbers of populations and handle the difficulties of multiple alleles and unequal sample sizes in different ways. Wright himself, for example, did not consider the effects of finite sample size. The purpose of this discussion is to offer some unity to various estimation formulae and to point out that correlations of genes in structured populations, with which F-statistics are concerned, are expressed very conveniently with a set of parameters treated by Cockerham (1 969, 1973). We start with the parameters and construct appropriate estimators for them, rather than beginning the discussion with various data functions. The extension of Cockerham's work to multiple alleles and loci will be made explicit, and the use of jackknife procedures for estimating variances will be advocated. All of this may be regarded as an extension of a recent treatment of estimating the coancestry coefficient to serve as a mea-", "doc-2": "Previous research finds that 20 Hz temporal frequency (TF) adaptation causes a compression of perceived visual event duration. We investigate if this temporal compression affects further time-dependent percepts, implying a further functional role for duration perception mechanisms. We measure the effect of 20 Hz flicker adaptation on Flash-Lag, an illusion whereby an observer perceives a moving object displaced further along its trajectory compared to a spatially localized briefly flashed object. The illusion scales with object speed; therefore, it has a fixed temporal component. By comparing adaptation at 5 Hz and 20 Hz we show that 20 Hz TF adaptation reduces perceived Flash-Lag magnitude significantly, with no effect at 5 Hz, whereas the opposite pattern of adaptation was seen on perceived speed. There is a significant effect of 20 Hz adaptation on the perceived duration of a moving bar. This suggests that 20 Hz TF adaptation has compressed the fixed temporal component of the Flash-Lag illusion, implying the mechanism underlying duration perception also has effects on judging spatial relationships in dynamic stimuli.", "label": 0}
{"doc-1": "The present article presents an integrative theoretical framework to explain and to predict psychological changes achieved by different modes of treatment. This theory states that psychological procedures, whatever their form, alter the level and strength of self-efficacy. It is hypothesized that expectations of personal efficacy determine whether coping behavior will be initiated, how much effort will be expended, and how long it will be sustained in the face of obstacles and aversive experiences. Persistence in activities that are subjectively threatening but in fact relatively safe produces, through experiences of mastery, further enhancement of self-efficacy and corresponding reductions in defensive behavior. In the proposed model, expectations of personal efficacy are derived from four principal sources of information: performance accomplishments, vicarious experience, verbal persuasion, and physiological states. The more dependable the experiential sources, the greater are the changes in perceived selfefficacy. A number of factors are identified as influencing the cognitive processing of efficacy information arising from enactive, vicarious, exhortative, and emotive sources. The differential power of diverse therapeutic procedures is analyzed in terms of the postulated cognitive mechanism of operation. Findings are reported from microanalyses of enactive, vicarious, and emotive modes of treatment that support the hypothesized relationship between perceived self-efficacy and behavioral changes. Possible directions for further research are discussed.", "doc-2": "We present a new matrix-logarithm model of the realized covariance matrix of stock returns. The model uses latent factors which are functions of both lagged volatility and returns. The model has several advantages: it is parsimonious; it does not require imposing parameter restrictions; and, it results in a positive-definite covariance matrix. We apply the model to the covariance matrix of size-sorted stock returns and find that two factors are sufficient to capture most of the dynamics. We also introduce a new method to track an index using our model of the realized volatility covariance matrix.", "label": 0}
{"doc-1": "The ability of killer T cells carrying the CD8 antigen to detect tumours or intracellular pathogens requires an extensive display of antigenic peptides by major histocompatibility complex (MHC) class I molecules on the surface of potential target cells1. These peptides are derived from almost all intracellular proteins and reveal the presence of foreign pathogens and mutations. How cells produce thousands of distinct peptides cleaved to the precise lengths required for binding different MHC class I molecules remains unknown2,3. The peptides are cleaved from endogenously synthesized proteins by the proteasome in the cytoplasm4,5 and then trimmed by an unknown aminopeptidase in the endoplasmic reticulum (ER)6,7,8. Here we identify ERAAP, the aminopeptidase associated with antigen processing in the ER. ERAAP has a broad substrate specificity, and its expression is strongly upregulated by interferon-. Reducing the expression of ERAAP through RNA interference prevents the trimming of peptides for MHC class I molecules in the ER and greatly reduces the expression of MHC class I molecules on the cell surface. Thus, ERAAP is the missing link between the products of cytosolic processing and the final peptides presented by MHC class I molecules on the cell surface.", "doc-2": "Abstract The reproductive cycle of Diopatra marocensis Paxton etal., 1995 has been studied in a population from Ria de Aveiro, Western Portugal with monthly samples, during a two-year period. This species presents a direct development with brooding in the parental tube and specimens with gametes inside the coelom and female tubes with eggs and/or larvae were observed in every sampling month. This suggested that the species reproduces during the whole year, with the main reproductive period from April to September. The male:female sex ratio ranged from 1:2 to 1:4, with females always dominating the population. A comparison with other Diopatra Audouin and Milne Edwards, 1833 (Onuphidae) showed that D.marocensis is the largest species with direct development and with the highest number of eggs and larvae inside the parental tube. With the exception of the colour, due to the presence of the gametes in the coelom cavity, no morphological differences between males and females were observed.", "label": 0}
{"doc-1": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.", "doc-2": "Pin-on-flat SEM tribometry was performed with polished, mostly C(100)-textured and acid-cleaned polycrystalline CVD diamond films heated to 950C then cooled to room temperature. Testing in~1.3310-3 Pa = 1 10-5 Torr vacuum was followed by similar experimentation in 13 to 40 Pa (0.1to 0.3 Torr) partial pressures of 99.999%-pure H2. In vacuum, all tests showed the characteristic step function-with-trough coefficient of friction (COF) signatures previously hypothesized as footprints of wear- and thermal desorption-induced generation, re(de)construction and passivation of the dangling bonds on the interacting surfaces. In hydrogen, all wear tracks exhibited stepfunction-like COF curves caused by adsorbate de(re)sorption on heating and cooling. A distinct re(de)construction COF trough obtained at the highest temperatures could be duplicated during repeated sliding in the same track on a large number (but not all) of the wear paths. The repeatable, incremental reduction in COF at the onset of heating and its substantial reduction on final cooling are attributed to tribocatalytically enhanced dissociative chemisorption of molecular hydrogen. The wear rates of the polished diamondon the pin tip, as controlled by the progressively reduced unit stresses caused by the enlargement of the wear scar, are between3.910-16 and 2.610-16m3/(N m) in PH2, in good agreement with previous data.", "label": 0}
{"doc-1": "The revised criteria for the classification of rheumatoid arthritis (RA) were formulated from a computerized analysis of 262 contemporary, consecutively studied patients with RA and 262 control subjects with rheumatic diseases other than RA (non-RA). The new criteria are as follows: 1) morning stiffness in and around joints lasting at least 1 hour before maximal improvement; 2) soft tissue swelling (arthritis) of 3 or more joint areas observed by a physician; 3) swelling (arthritis) of the proximal interphalangeal, metacarpophalangeal, or wrist joints; 4) symmetric swelling (arthritis); 5) rheumatoid nodules; 6) the presence of rheumatoid factor; and 7) radiographic erosions and/or periarticular osteopenia in hand and/or wrist joints. Criteria 1 through 4 must have been present for at least 6 weeks. Rheumatoid arthritis is defined by the presence of 4 or more criteria, and no further qualifications (classic, definite, or probable) or list of exclusions are required. In addition, a \"classification tree\" schema is presented which performs equally as well as the traditional (4 of 7) format. The new criteria demonstrated 91-94% sensitivity and 89% specificity for RA when compared with non-RA rheumatic disease control subjects.", "doc-2": "This paper discusses the conditions under which post-Soviet states succeed in fighting corruption. The method of paired comparison of most similar cases, Estonia and Latvia on the one hand and Georgia and Armenia on the other, is used to tease out the variables that vary within and across pairs and produce divergence. It is argued that young, and structurally and ideologically cohesive, groups in power that are antagonistically predisposed toward the former colonial patron and free from the influence of the old guard are more likely to reform while enduring political-economic networks undermine anti-corruption reform.", "label": 0}
{"doc-1": "Several issues relating to goodness of fit in structural equations are examined. The convergence and differentiation criteria, as applied by Bagozzi, are shown not to stand up under mathematical or...", "doc-2": "In addition to annulospiral sensory endings and fusimotor endings, multiaxonal nerve endings consisting of a bundle of naked axons were frequently found in the muscle spindles of the adult Chinese hamster. The multiaxonal endings were mainly distributed in the equatorial region of the nuclear bag fibers, adjacent to the annulospiral sensory endings. Terminal axons composing the endings were less than 1.5 microns in diameter and contained a significant number of clear synaptic vesicles and large granulated vesicles. Some axons formed synaptic contacts with each other and with the muscle cell surface. These structural features suggest that the multiaxonal endings are efferent in nature. They may possibly represent a temporal structure of fusimotor endings, or belong to the autonomic nerves.", "label": 0}
{"doc-1": "Emerging adulthood is proposed as a new conception of development for the period from the late teens through the twenties, with a focus on ages 18-25. A theoretical background is presented. Then evidence is provided to support the idea that emerging adulthood is a distinct period demographically, subjectively, and in terms of identity explorations. How emerging adulthood differs from adolescence and young adulthood is explained. Finally, a cultural context for the idea of emerging adulthood is outlined, and it is specified that emerging adulthood exists only in cultures that allow young people a prolonged period of independent role exploration during the late teens and twenties.", "doc-2": "We have fabricated heterojunction p + Si 1xy Ge x C y / p + Si diodes. The SiGeC layers were grown epitaxially on Si (100) substrates by the rapid thermal chemical vapor deposition (RTCVD) technique using methysilane gas as a carbon precursor. The germanium concentration is 20% in these SiGeC alloys and the carbon concentrations are in the range of 0% to 1%. By studying the current-voltage characteristics of these diodes as a function of temperature the valence band discontinuities between SiGeC and Si layers were obtained as a function of carbon concentrations. We have found that the valence band discontinuity of the SiGe/Si heterostructure decreases by II meV when 1% of carbon is incorporated. Photoluminescence (PL) results show that 1% carbon increases the bandgap of strained p + SiGe alloys by 25 meV. This would imply that the conduction band discontinuity of SiGe/Si will decrease by 14 meV when 1% carbon is incorporated.", "label": 0}
{"doc-1": "The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.", "doc-2": "This paper develops a class of exponential bounds for the probability that a martingale sequence crosses a time-dependent linear threshold. Our key insight is that it is both natural and fruitful to formulate exponential concentration inequalities in this way. We illustrate this point by presenting a single assumption and a single theorem that together strengthen many tail bounds for martingales, including classical inequalities (1960-80) by Bernstein, Bennett, Hoeffding, and Freedman; contemporary inequalities (1980-2000) by Shorack and Wellner, Pinelis, Blackwell, van de Geer, and de la Pena; and several modern inequalities (post-2000) by Khan, Tropp, Bercu and Touati, Delyon, and others. In each of these cases, we give the strongest and most general statements to date, quantifying the time-uniform concentration of scalar, matrix, and Banach-space-valued martingales, under a variety of nonparametric assumptions in discrete and continuous time. In doing so, we bridge the gap between existing line-crossing inequalities, the sequential probability ratio test, the Cramer-Chernoff method, self-normalized processes, and other parts of the literature.", "label": 0}
{"doc-1": "Contents: Prefaces. The Concepts of Power Analysis. The t-Test for Means. The Significance of a Product Moment rs (subscript s). Differences Between Correlation Coefficients. The Test That a Proportion is .50 and the Sign Test. Differences Between Proportions. Chi-Square Tests for Goodness of Fit and Contingency Tables. The Analysis of Variance and Covariance. Multiple Regression and Correlation Analysis. Set Correlation and Multivariate Methods. Some Issues in Power Analysis. Computational Procedures.", "doc-2": "We document latitudinal patterns of infestation of the bopyrid isopod parasite Pseudione tuberculata on southern king crab Lithodes santolla juveniles (20  50 mm carapace length) recruited to fishing grounds in the southern Chilean fjord system. A total of 750 individuals were collected by semiautonomous diving in 11 of 21 sampling locations in the study area along the western margin of the Magellan region between August and September 2013. The prevalence of P. tuberculata varied between 0 and ~22% and displayed a spatial pattern associated with three areas: i) northern Beagle Channel (10  ~22%; lengths between 37 and 47 mm), ii) northeastern Navarino Island without infestations (0%; 26  55 mm) and iii) Piazzi Island  Capitan Aracena Island (0  12%; 50  77 mm). Infestations were independent of host sex, while parasite prevalence decreased with host length. Thus no parasitization was observed on crabs longer than 55 mm. A comparison of slopes between linearized length-weight regressions suggests that parasitized individuals had lower weight growth than uninfested individuals. Both southern king crab juvenile density and P. tuberculata prevalence were higher to the southeast of fishing areas towards Beagle Channel where previous research reported lower average surface water temperatures ( 30 psu). The study area covers four zones relevant for the conservation and protection of subantarctic biodiversity and provides opportunities for large-scale geographic studies of the host-parasite relationship.", "label": 0}
{"doc-1": "5", "doc-2": "Fourteen diphenyl ether and diphenyl sulfide compounds were synthesized and a comparative study on their second-order nonlinear optical properties was carried out. The results showed that these two kinds of compounds all had fairly large molecular first-order nonlinear optical hyperpolarizabilities , but they have very different second harmonic generation (SHG). The diphenyl sulfide derivatives usually have strong SHG effects while almost all the diphenyl ether compounds have no SHG response, which can be attributed to their crystal structure. We found that the diphenyl sulfide compounds were easy to crystallize in a noncentrosymmetric style but the crystal structure of the diphenyl ether derivative was centrosymmetric, and therefore a zero (2) was produced. The atom O or S was the real origin of the difference in their crystal structures, and therefore of the SHG effect.", "label": 0}
{"doc-1": "The second edition of this book is unique in that it focuses on methods for making formal statistical inference from all the models in an a priori set (Multi-Model Inference). A philosophy is presented for model-based data analysis and a general strategy outlined for the analysis of empirical data. The book invites increased attention on a priori science hypotheses and modeling. Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected as an estimator of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These methods are relatively simple and easy to use in practice, but based on deep statistical theory. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems. The book presents several new ways to incorporate model selection uncertainty into parameter estimates and estimates of precision. An array of challenging examples is given to illustrate various technical issues. This is an applied book written primarily for biologists and statisticians wanting to make inferences from multiple models and is suitable as a graduate text or as a reference for professional analysts.", "doc-2": "New records of taxa from the Dry Gulch Creek Member of the Duchesne River Formation are: Copedelphys sp.; Lipotyphla (genera and species indeterminate); Mytonolagus sp.; Pareumys guensburgi; Griphomys sp.; Heliscomys sp.; Passaliscomys sp.; Metanoiamys lacus; Metanoiamys sp., cf. M. korthi; Protadjidaumo typus; Protadjidaumo sp., cf. P. typus; Paradjidaumo sp.; Adjidaumo sp., cf. A. craigi; Simiacritomys sp.; Microeutypomys sp.; Eutypomys sp.; and Poabromylus kayi. The mammalian assemblages from the Dry Gulch Creek and Lapoint members of the Duchesne River Formation are combined as the Halfway/Lapoint Fauna and regarded as the type fauna of the Duchesnean North American Land Mammal age. New correlations of the Uintan and Duchesnean faunas from the Sespe Formation of California to the Global Polarity Time Scale (GPTS) are based on taxonomic comparisons of the Sespe faunas to those from the Uinta Basin and radioisotopic data. Based these new correlations, the Uintan-Duchesnean boundary occurs within Chron C19n of the GPTS, or about 41.4 Ma.", "label": 0}
{"doc-1": "The purpose of this article is to determine whether the positive association between social support and well-being is attributable more to an overall beneficial effect of support (main- or direct-effect model) or to a process of support protecting persons from potentially adverse effects of stressful events (buffering model). The review of studies is organized according to (a) whether a measure assesses support structure or function, and (b) the degree of specificity (vs. globality) of the scale. By structure we mean simply the existence of relationships, and by function we mean the extent to which one's interpersonal relationships provide particular resources. Special attention is paid to methodologica l characteristic s that are requisite for a fair comparison of the models. The review concludes that there is evidence consistent with both models. Evidence for a buffering model is found when the social support measure assesses the perceived availability of interpersonal resources that are responsive to the needs elicited by stressful events. Evidence for a main effect model is found when the support measure assesses a person's degree of integration in a large social network. Both conceptualizations of social support are correct in some respects, but each represents a different process through which social support may affect well-being. Implications of these conclusions for theories of social support processes and for the design of preventive interventions are discussed.", "doc-2": "The purposes of this research were to examine the characteristics of those who look for physical activity-related information, where they find it, and to examine what types of physical activity-related advertisements are recalled (i.e., publicly funded or commercial). These purposes were tested using secondary data analyses from two population health surveys. Results from the first survey (n=1211) showed gender, age, education, and activity-level differences in who is more likely to search for physical activity-related information. Adding the goal of being active into the model made age and activity level no longer significant but gender and education remained significant factors. The Internet was the most often cited source of physical activity information. The second survey (n=1600) showed that adults 55 years of age or older and participants with the least amount of education were more than twice as likely to name commercial advertisements than were participants aged 18-54 years or those with more education. These results help further our understanding of how publicly funded promotional campaigns fare against commercial advertising and also highlight the need to understand physical activity information-seeking behavior on the Internet and its implications for health promotion.", "label": 0}
{"doc-1": "Five centrally acting sympathomimetic amines, d-amphetamine, d-methamphetamine, ephedrine, phenmetrazine, and methylphenidate, were studied in man. All of these agents increased blood pressure and respiratory rate, produced similar types of subiective changes, and increased the excretion of epinephrine. With regard to these parameters, there was a high concordance between estimates of their relative potencies. The concordance between the potency estimates for the different parameters suggests, but does not prove, that these five agents share a common mode of central action. Further, if the peripheral modes of action as elucidated by animal studies are true for man, this study suggests that it is unlikely that their central actions in man are a consequence of the release of norepinephrine in the brain.", "doc-2": "Probabilistic safety assessment (PSA) has had a significant role in quantitative decisionmaking by finding design and operational vulnerabilities and evaluating cost-benefit in improving such weak points. In particular, it has been widely used as the core methodology for risk-informed applications (RIAs). Even though the nature of PSA seeks realistic results, there are still conservative aspects. One of the sources for the conservatism is the assumptions of safety analysis and the estimation of failure frequency. Surveillance, diagnosis, and prognosis (SDP), utilizing massive databases and information technology, is worth highlighting in terms of its capability for alleviating the conservatism in conventional PSA. This article provides enabling techniques to solidify a method to provide timeand condition-dependent risks by integrating a conventional PSA model with condition monitoring and prognostics techniques. We will discuss how to integrate the results with frequency of initiating events (IEs) and probability of basic events (BEs). Two illustrative examples will be introduced: (1) how the failure probability of a passive system can be evaluated under different plant conditions and (2) how the IE frequency for a steam generator tube rupture (SGTR) can be updated in terms of operating time. We expect that the proposed model can take a role of annunciator to show the variation of core damage frequency (CDF) depending on operational conditions.", "label": 0}
{"doc-1": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ImageNet, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.", "doc-2": "PURPOSETo describe a quantitative ultrasonic spectroscopy technique for the noninvasive characterization of corneal biomechanical properties and to compare these measurements with established techniques in a porcine eye model.METHODSAn ultrasound system was constructed to accurately acquire acoustic reflections from corneas through a saline bath. Corneal properties (including thickness, density and aggregate modulus) were estimated from the measured reflection spectra based on wave propagation analysis. Twenty fresh porcine corneas were measured using the quantitative ultrasound method and other established techniques that can only be applied to dissected corneas.RESULTSThe ultrasonic measurements of corneal thickness and aggregate modulus were significantly correlated with the measurements of established techniques (Pearson's correlation = 0.99 and 0.61; P < 0.005), and good sample-to-sample consistency was achieved. The measurement of corneal density agreed well in terms of mean and range, but the correlation did not achieve statistical significance (Pearson's correlation = 0.41; P = 0.07).CONCLUSIONSThe ultrasonically measured corneal biomechanical properties agreed well with the measurements obtained by using established techniques, validating the accuracy of the ultrasound method. Quantitative ultrasound spectroscopy may provide a noninvasive approach for in vivo characterization of corneal biomechanical properties.", "label": 0}
{"doc-1": "Until the beginning of the 20th century, people in Africa depended to a significant extent on food which had its origins in Africa. A diverse range of originally wild African species was domesticated a long time ago and included rootcrops, cereals, legumes and many different vegetables. Popular food crops from outside the region were introduced into Africa and these exotic crops soon started to dominate the traditional crops. This trend was enforced with the arrival of European settlers and has resulted in most African vegetables becoming minor crops. However, most exotic crops are not successful in either dry or very humid regions and do not do well in the warmer parts of Africa; in these regions indigenous African crops are still important and indigenous vegetables are much in demand because many people no longer have enough money to buy the more expensive exotic crops. Consequently there is now a reversal in the trend away from exotics and towards traditional vegetables. This has generated a call for information, especially from students who wish to focus on such crops, and from extension staff who are under pressure from farmers to advise them. African Indigenous Vegetables, an Overview of the Cultivated Species describes over 100 African vegetable species and covers the 25 most common crops in detail. Where possible, information is provided on the origin of the species and on some botanical aspects. The main emphasis is on their agronomy, providing as much detail as is currently known about these crops. It is to be hoped that this book will contribute towards knowledge of African vegetables and their further advancement.", "doc-2": "Plasma and brain catecholamines were measured during immobilization in rats which had or had not received ethanol (0.5 g/kg i.p.). Plasma levels in unstressed animals were unaffected by ethanol. Immobilization markedly increased circulating norepinephrine and epinephrine concentrations. Ethanol administered 15 min before immobilization significantly reduced the stress-induced increases in both plasma catecholamines, although individual differences in response were noted. In the brain, immobilization affected catecholamine levels in several regions, including reduced norepinephrine levels in the telencephalon and hypothalamus. Interestingly, norepinephrine levels in the telencephalon and hypothalamus were reduced to a similar degree by ethanol alone. However, ethanol administration before immobilization tended to reverse some of the stress-induced changes in brain catecholamine levels. Our data indicate that the effects of ethanol vary among rats and with the state of the subject. In general, ethanol does reduce the stress response in rats. They support the tension reduction hypothesis in man, where reduction in distress has been implicated in the etiology of alcoholism.", "label": 0}
{"doc-1": "Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.", "doc-2": "What if Bach and Mozart heard richer, more dramatic chords than we hear in music today? What sonorities and moods have we lost in playing music in \"equal temperament\"-the equal division of the octave into twelve notes that has become our standard tuning method? Thanks to How Equal Temperament Ruined Harmony, \"we may soon be able to hear for ourselves what Beethoven really meant when he called B minor 'black'\" (Wall Street Journal).In this \"comprehensive plea for more variety in tuning methods\" (Kirkus Reviews), Ross W. Duffin presents \"a serious and well-argued case\" (Goldberg Magazine) that \"should make any contemporary musician think differently about tuning\" (Saturday Guardian).", "label": 0}
{"doc-1": "This article examines the adequacy of the rules of thumb conventional cutoff criteria and several new alternatives for various fit indexes used to evaluate model fit in practice. Using a 2index presentation strategy, which includes using the maximum likelihood (ML)based standardized root mean squared residual (SRMR) and supplementing it with either TuckerLewis Index (TLI), Bollen's (1989) Fit Index (BL89), Relative Noncentrality Index (RNI), Comparative Fit Index (CFI), Gamma Hat, McDonald's Centrality Index (Mc), or root mean squared error of approximation (RMSEA), various combinations of cutoff values from selected ranges of cutoff criteria for the MLbased SRMR and a given supplemental fit index were used to calculate rejection rates for various types of truepopulation and misspecified models; that is, models with misspecified factor covariance(s) and models with misspecified factor loading(s). The results suggest that, for the ML method, a cutoff value close to .95 for TLI, BL89, CFI, RNI, and G...", "doc-2": "For quite some time Europe has become the space for political action and reflection, on the identity and on the borders of Europe. tienne Balibar has been writing on these issues for a long time, combining a postnational option with a criticism of European policies, especially when denouncing the risk of a political apartheid, and proposing the project of Europe as a vanishing mediator. He has also stressed the importance of the struggles of migrants in Europe, whether referring to the complete isolation of the Algerians in France at the time of the 17 October 1961 massacre, or the visibility of the sans papiers movement in 1996. With the category of the national social state, he addresses the fact that the social and political system which was underpinning a certain idea of politics does not exist anymore.", "label": 0}
{"doc-1": "Starts with a brief review of the history and the application areas considered in the literature. The author then proceeds with introductory modeling examples, behavioral and structural properties, three methods of analysis, subclasses of Petri nets and their analysis. In particular, one section is devoted to marked graphs, the concurrent system model most amenable to analysis. Introductory discussions on stochastic nets with their application to performance modeling, and on high-level nets with their application to logic programming, are provided. Also included are recent results on reachability criteria. Suggestions are provided for further reading on many subject areas of Petri nets. >", "doc-2": "Salsola schweinfurthii is a perennial branched halophytic shrub that inhabits arid environments in and around the Arabian Peninsula. Its tolerance to extreme drought renders it suitable for urban arid landscaping. Germinability of intact and de-winged seeds (winged perianth removed) was determined under two photoperiods (0 and 12 hours light per day), three thermoperiods (daily low/high of 15/25, 20/30 and 25/35C) and five salinity levels (0, 100, 200, 400 and 600 mM NaCl). Germination was maximised (93%) by de-winging and incubation in 12 hours light at 25/35C. Intact and de-winged seeds both exhibited positive photoblastism. Germination of intact seeds was entirely prevented by the lowest level of salinity, and only slightly less prevented in de-winged seeds. Ability to germinate returned after saline solution was replaced with distilled water. The ability for S. schweinfurthii seeds to remain viable through a temporary period of salinity indicates an adaptation to unpredictable soil surface conditions in arid environments. Artificial propagation rates might be increased by removing perianths and sowing before or after mid-winter.", "label": 0}
{"doc-1": "Recent discoveries, notably of the hormones leptin and adiponectin, have revised the notion that adipocytes are simply a storage depot for body energy. Instead, adipocytes are also endocrine organs, with multiple metabolic roles in regulating whole-body physiology. Small adipocytes in lean individuals promote metabolic homeostasis; the enlarged adipocytes of obese individuals recruit macrophages and promote inflammation and the release of a range of factors that predispose toward insulin resistance. Exercise activates the AMP-activated protein kinase (AMPK) in muscle and other tissues, a pathway that increases fat oxidation and glucose transport. Importantly, the adipocyte hormones leptin and adiponectin also activate AMPK; remarkably, the same pathway is activated by certain antidiabetic agents such as thiazolidinediones. Increasingly, our understanding of the adipocyte as an endocrine organ is leading to new insights into obesity and health.", "doc-2": "Abstract Random regression models (RRM) have become common for the analysis of longitudinal data or repeated records on individuals over time. Applications in animal breeding research are emphasized while recognizing that RRM are used in many biological situations including human health. The best known application of RRM has been to genetic evaluation of dairy cattle using test day production records. The basic structure of a RRM is given. Other applications include growth traits in all species, genotype by environment interactions, and ad hoc proposals for the analysis of survival data and fertility data. RRM allow the researcher to study changes in genetic variability with time and allow selection of individuals to alter the general patterns of response over time.", "label": 0}
{"doc-1": "An adjusted rank correlation test is proposed as a technique for identifying publication bias in a meta-analysis, and its operating characteristics are evaluated via simulations. The test statistic is a direct statistical analogue of the popular \"funnel-graph.\" The number of component studies in the meta-analysis, the nature of the selection mechanism, the range of variances of the effect size estimates, and the true underlying effect size are all observed to be influential in determining the power of the test. The test is fairly powerful for large meta-analyses with 75 component studies, but has only moderate power for meta-analyses with 25 component studies. However, in many of the configurations in which there is low power, there is also relatively little bias in the summary effect size estimate. Nonetheless, the test must be interpreted with caution in small meta-analyses. In particular, bias cannot be ruled out if the test is not significant. The proposed technique has potential utility as an exploratory tool for meta-analysts, as a formal procedure to complement the funnel-graph.", "doc-2": "PURPOSEThe research study purpose was to describe the personal attitudes and beliefs of rural African American men related to prostate cancer and screening.PROCEDUREAudio taped interviews were conducted with nine (9) African American men living in rural communities of West Central Alabama.FINDINGSSix common themes were found among the rural African American men participants. The themes identified were: (1) Disparity; (2) Lack of understanding; (3) Tradition; (4) Mistrust in the system; (5) Fear; and (6) Threat to manhood.CONCLUSIONSThe results support the general significance of understanding the views of the target population and specifically its culture and offer opportunities for adapting health promotion to the population.", "label": 0}
{"doc-1": "This paper has always been one of my favorite children, combining as it does elements of the duality of linear programming and combinatorial tools from graph theory. It may be of some interest to tell the story of its origin.", "doc-2": "Reduced splanchnic blood flow and hyperthermia during exercise-heat stress can produce gastrointestinal barrier dysfunction and increased gastrointestinal permeability. This may allow endotoxin to enter the internal environment, causing local and systemic immune responses. These responses may be involved in the cause and outcome of exertional heatstroke. Countermeasures may reduce gastrointestinal permeability and possibly exertional heatstroke occurrence and outcome.", "label": 0}
{"doc-1": "When time is limited, researchers may be faced with the choice of using an extremely brief measure of the Big-Five personality dimensions or using no measure at all. To meet the need for a very brief measure, 5 and 10-item inventories were developed and evaluated. Although somewhat inferior to standard multi-item instruments, the instruments reached adequate levels in terms of: (a) convergence with widely used Big-Five measures in self, observer, and peer reports, (b) testretest reliability, (c) patterns of predicted external correlates, and (d) convergence between self and observer ratings. On the basis of these tests, a 10-item measure of the Big-Five dimensions is offered for situations where very short measures are needed, personality is not the primary topic of interest, or researchers can tolerate the somewhat diminished psychometric properties associated with very brief measures.", "doc-2": "Several approaches to alleviating the symptoms of premenstrual disorders are available to women and can be tailored according to individual needs and preferences. This article discusses methods that entail changes to lifestyle and diet and managing life stresses without relying on drug therapy, as well as a variety of medications that may be necessary in addition to or in place of recommended lifestyle modifications. New pharmacologic research is promising and is discussed along with the need to provide empathetic counseling for patients to determine the approach that will work best for each individual.", "label": 0}
{"doc-1": "The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.", "doc-2": "Patients with cystic fibrosis (CF) often suffer from gastrointestinal cramps and intestinal obstruction. The CF transmembrane conductance regulator (CFTR) channel has been shown to be expressed in vascular and airway smooth muscle (SM). We hypothesized that the absence of CFTR expression alters the gastrointestinal SM function and that these alterations may show strain-related differences in the mouse. The aim of this study was to measure the contractile properties of the ileal SM in two CF mouse models. CFTR(-/-) and CFTR(+/+) mice were studied on BALB/cJ and C57BL/6J backgrounds. Responsiveness of ileal strips to electrical field stimulation (EFS), methacholine (MCh), and isoproterenol was measured. The mass and the cell density of SM layers were measured morphometrically. Finally, the maximal velocity of shortening (Vmax) and the expression of the fast (+)insert myosin isoform were measured in the C57BL/6J ileum. Ileal hyperreactivity was observed in response to EFS and MCh in CFTR(-/-) compared with CFTR(+/+) mice in C57BL/6J background. This latter observation was not reproduced by acute inhibition of CFTR with CFTR(inh)172. BALB/cJ CFTR(-/-) mice exhibited a significant increase of SM mass with a lower density of cells compared with CFTR(+/+), whereas no difference was observed in the C57BL/6J background. In addition, in this latter strain, ileal strips from CFTR(-/-) exhibited a significant increase in Vmax compared with control and expressed a greater proportion of the fast (+)insert SM myosin isoform with respect to total myosin. BALB/cJ CFTR(-/-) ilium had a greater relaxation to isoproterenol than the CFTR(+/+) mice when precontracted with EFS, but no difference was observed in response to exogeneous MCh. In vivo, the lack of CFTR expression induces a different SM ileal phenotype in different mouse strains, supporting the importance of modifier genes in determining intestinal SM properties.", "label": 0}
{"doc-1": "Comparative protein modeling is increasingly gaining interest since it is of great assistance during the rational design of mutagenesis experiments. The availability of this method, and the resulting models, has however been restricted by the availability of expensive computer hardware and software. To overcome these limitations, we have developed an environment for comparative protein modeling that consists of SWISS-MODEL, a server for automated comparative protein modeling and of the SWISS-PdbViewer, a sequence to structure workbench. The Swiss-PdbViewer not only acts as a client for SWISS-MODEL, but also provides a large selection of structure analysis and display tools. In addition, we provide the SWISS-MODEL Repository, a database containing more than 3500 automatically generated protein models. By making such tools freely available to the scientific community, we hope to increase the use of protein structures and models in the process of experiment design.", "doc-2": "ATLAS is one of two general-purpose detectors at the next-generation protonproton collider, the LHC. The high rate of interactions and the large number of read-out channels make the trigger system for ATLAS a challenging task. The initial bunch-crossing rate of 40MHz has to be reduced to about 200 Hz while preserving the physics signals against a large background. ATLAS uses a three level trigger system, with the first level implemented in custom hardware, while the high level trigger systems are implemented in software on commodity hardware. This note describes the physics motivation, the various selection strategies for different channel and the physical implementation of the trigger system.PACS: 25.70.Ef  21.60.Gx  27.30.+t", "label": 0}
{"doc-1": "The Gene Ontology (GO) project (http://www. geneontology.org/) provides structured, controlled vocabularies and classications that cover several domains of molecular and cellular biology and are freely available for community use in the annotation of genes, gene products and sequences. Many model organism databases and genome annotation groups use the GO and contribute their annotation sets to the GO resource. The GO database integrates the vocabularies and contributed annotations and provides full access to this information in several formats. Members of the GO Consortium continually work collectively, involving outside experts as needed, to expand and update the GO vocabularies. The GO Web resource also provides access to extensive documentation about the GO project and links to applications that use GO data for functional", "doc-2": "PurposeThis study investigated the acoustic characteristics of spontaneous speech by talkers aged 9-14 years and their ability to adapt these characteristics to maintain effective communication when intelligibility was artificially degraded for their interlocutor.MethodRecordings were made for 96 children (50 female participants, 46 male participants) engaged in a problem-solving task with a same-sex friend; recordings for 20 adults were used as reference. The task was carried out in good listening conditions (normal transmission) and in degraded transmission conditions. Articulation rate, median fundamental frequency (f0), f0 range, and relative energy in the 1- to 3-kHz range were analyzed.ResultsWith increasing age, children significantly reduced their median f0 and f0 range, became faster talkers, and reduced their mid-frequency energy in spontaneous speech. Children produced similar clear speech adaptations (in degraded transmission conditions) as adults, but only children aged 11-14 years increased their f0 range, an unhelpful strategy not transmitted via the vocoder. Changes made by children were consistent with a general increase in vocal effort.ConclusionFurther developments in speech production take place during later childhood. Children use clear speech strategies to benefit an interlocutor facing intelligibility problems but may not be able to attune these strategies to the same degree as adults.", "label": 0}
{"doc-1": "Since 1922 when Wu proposed the use of the Folin phenol reagent for the measurement of proteins, a number of modified analytical procedures utilizing this reagent have been reported for the determination of proteins in serum, in antigen-antibody precipitates, and in insulin. Although the reagent would seem to be recommended by its great sensitivity and the simplicity of procedure possible with its use, it has not found great favor for general biochemical purposes. In the belief that this reagent, nevertheless, has considerable merit for certain application, but that its peculiarities and limitations need to be understood for its fullest exploitation, it has been studied with regard to effects of variations in pH, time of reaction, and concentration of reactants, permissible levels of reagents commonly used in handling proteins, and interfering substances. Procedures are described for measuring protein in solution or after precipitation with acids or other agents, and for the determination of as little as 0.2 gamma of protein.", "doc-2": "Abstract A CoSmCu ternary alloy was directionally solidified and quenched during growth. The solidification path was determined by electron probe microanalysis on a cross-section made along the quenched interface. The results are discussed with reference to the ternary phase diagram and to a simple theoretical analysis using the Sheil's equation. The good agreement found shows that the technique of the quenched interface, combined with a simple analysis, constitutes a powerful tool for the prediction of the microsegregation in complex alloys. It is also shown that, for the particular case of CoRECu type alloys for permanent magnets, extensive microsegregation can occur during solidification. This leads to the formation of Cu-rich zones which are detrimental to the magnetic properties and have to be eliminated by an homogenization heat treatment.", "label": 0}
{"doc-1": "1. Introduction Designing PCR and sequencing primers are essential activities for molecular biologists around the world. This chapter assumes acquaintance with the principles and practice of PCR, as outlined in, for example, refs. 14. Primer3 is a computer program that suggests PCR primers for a variety of applications, for example to create STSs (sequence tagged sites) for radiation hybrid mapping (5), or to amplify sequences for single nucleotide polymor-phism discovery (6). Primer3 can also select single primers for sequencing reactions and can design oligonucleotide hybridization probes. In selecting oligos for primers or hybridization probes, Primer3 can consider many factors. These include oligo melting temperature, length, GC content , 3 stability, estimated secondary structure, the likelihood of annealing to or amplifying undesirable sequences (for example interspersed repeats), the likelihood of primerdimer formation between two copies of the same primer, and the accuracy of the source sequence. In the design of primer pairs Primer3 can consider product size and melting temperature, the likelihood of primer dimer formation between the two primers in the pair, the difference between primer melting temperatures, and primer location relative to particular regions of interest or to be avoided.", "doc-2": "Etude des differents facteurs qui ont influence l'etat de developpement des vehicules maritimes avances. Introduction de ces vehicules de type nouveau dans la marine de guerre", "label": 0}
{"doc-1": "Dominant markers such as amplified fragment length polymorphisms (AFLPs) provide an economical way of surveying variation at many loci. However, the uncertainty about the underlying genotypes presents a problem for statistical analysis. Similarly, the presence of null alleles and the limitations of genotype calling in polyploids mean that many conventional analysis methods are invalid for many organisms. Here we present a simple approach for accounting for genotypic ambiguity in studies of population structure and apply it to AFLP data from whitefish. The approach is implemented in the program structure version 2.2, which is available from http://pritch.bsd.uchicago.edu/structure.html.", "doc-2": "AbstractAluminium alloy AA2219 is a high strength alloy widely used for aerospace application. One of the drawbacks of most of the high strength aluminium alloys is that they suffer from poor weldability. However, AA2219 is an exception due to the presence of more copper that helps in healing cracks by providing extra eutectics. Although AA2219 has excellent weldability, the strength of a welded joint is only 3545% of the base metal. The loss of strength is due to the dissolution of the strengthening precipitates during melting. Therefore, there is a need to improve the fusion zone strength of AA2219 welds. In this study, an attempt was made experimentally to use different gas tungsten arc welding (GTAW) techniques and modify the filler chemistry with addition of scandium (Sc) and zirconium (Zr) in order to improve the mechanical properties of the AA2219 weld joints. The application of the GTAW DCEN with Sc and Zr to the filler wire proved to be the most economical and perhaps the optimal choice for weld...", "label": 0}
{"doc-1": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \"autoencoder\" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.", "doc-2": "The Community context. Article 81(1). Article 81(3). Article 81: Common horizontal agreements. Joint ventures and similar collaborative arrangements. Mergers, acquisitions and other concentrations. Vertical agreements affecting distribution or supply. Intellectual property rights. Article 82. Enforcement of competition rules in member states. Notification and its effects. Enforcement and procedure. The role of the state in regulated industries. Telecommunications. Transport. Energy. Coal and steel. Agriculture. State aids.", "label": 0}
{"doc-1": "Multiple, complex molecular events characterize cancer development and progression. Deciphering the molecular networks that distinguish organ-confined disease from metastatic disease may lead to the identification of critical biomarkers for cancer invasion and disease aggressiveness. Although gene and protein expression have been extensively profiled in human tumours, little is known about the global metabolomic alterations that characterize neoplastic progression. Using a combination of high-throughput liquid-and-gas-chromatography-based mass spectrometry, we profiled more than 1,126 metabolites across 262 clinical samples related to prostate cancer (42 tissues and 110 each of urine and plasma). These unbiased metabolomic profiles were able to distinguish benign prostate, clinically localized prostate cancer and metastatic disease. Sarcosine, an N-methyl derivative of the amino acid glycine, was identified as a differential metabolite that was highly increased during prostate cancer progression to metastasis and can be detected non-invasively in urine. Sarcosine levels were also increased in invasive prostate cancer cell lines relative to benign prostate epithelial cells. Knockdown of glycine-N-methyl transferase, the enzyme that generates sarcosine from glycine, attenuated prostate cancer invasion. Addition of exogenous sarcosine or knockdown of the enzyme that leads to sarcosine degradation, sarcosine dehydrogenase, induced an invasive phenotype in benign prostate epithelial cells. Androgen receptor and the ERG gene fusion product coordinately regulate components of the sarcosine pathway. Here, by profiling the metabolomic alterations of prostate cancer progression, we reveal sarcosine as a potentially important metabolic intermediary of cancer cell invasion and aggressivity.", "doc-2": "We have previously identified the EphA2 receptor tyrosine kinase as a potentially important injury-responsive gene and a transcriptional target of Src kinase activity in renal ischemia-reperfusion injury (IRI). In the present study, we confirmed, using EphA2 gene trap mice that the endogenous EphA2 promoter is strongly activated following renal IRI. We also examined in more detail the mechanisms responsible for Src kinase-induced activation of the -2kb human EphA2 promoter and found that the minimal Src-responsive elements were contained in the -145 to +137 region of the human EphA2 gene. This region contains a canonical cAMP-responsive element (CRE) that we found to be critical for both basal and Src kinase-induced transcriptional activity. However, despite activation of the prototypical CRE-binding factor CREB by the Src kinase Fyn, siRNA-mediated knockdown of CREB had no significant impact on either basal or Fyn-induced EphA2 promoter activity. Similarly, activation of CREB by the adenylate cyclase agonist forskolin failed to induce EphA2 promoter activation. Thus, Src kinase-induced activation of the EphA2 promoter is CRE-dependent but CREB-independent.", "label": 0}
{"doc-1": "A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must, be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every", "doc-2": "This work introduces, for the first time worldwide, undeinked recycled old newsprint as a new resource of electrical purposes paper. Impregnation of undeinked recycled old newsprint paper with linseed oil enhances the breaking length of paper and remarkably improves its electrical properties, i.e., the dielectric constant increases greatly and the a.c. conductivity decreases significantly due to impregnation. It was found that the electrical properties of the undeinked old newsprint paper and its linseed oil impregnated counterpart are close to the electrical properties of paper made from the more expensive virgin wood pulps and their linseed oil impregnated counterparts. Using the undeinked pulp is more privileged than using the deinked pulp; because eliminating the deinking step saves money, time, and reagents. In addition, eliminating the deinking step improved the breaking length of paper. Electron dispersive X-ray elemental analysis (EDX) was used to investigate the undeinked and deinked pulps for residual elements originating from the printing materials. EDX was correlated to the slight differences in electrical properties of paper made from undeinked and deinked pulps. However, impregnation was able to overcome these slight differences. It was shown that improvement in electrical properties, due to impregnation, is sustained at elevated temperatures.", "label": 0}
{"doc-1": "Self-determination theory (SDT) maintains that an understanding of human motivation requires a consideration of innate psychological needs for competence, autonomy, and relatedness. We discuss the SDT concept of needs as it relates to previous need theories, emphasizing that needs specify the necessary conditions for psychological growth, integrity, and well-being. This concept of needs leads to the hypotheses that different regulatory processes underlying goal pursuits are differentially associated with effective functioning and well-being and also that different goal contents have different relations to the quality of behavior and mental health, specifically because different regulatory processes and different goal contents are associated with differing degrees of need satisfaction. Social contexts and individual differences that support satisfaction of the basic needs facilitate natural growth processes including intrinsically motivated behavior and integration of extrinsic motivations, whereas those that forestall autonomy, competence, or relatedness are associated with poorer motivation, performance, and well-being. We also discuss the relation of the psychological needs to cultural values, evolutionary processes, and other contemporary motivation theories.", "doc-2": "The effect of Cu content on the catalytic activity of CuxSiBEA zeolites in the selective catalytic reduction (SCR) of NO by ethanol is investigated. The CuxSiBEA zeolites (x=0.3, 1.5 and 3.3 Cuwt%) are prepared by a two-step postsynthesis method which allows to control the introduction of copper into BEA zeolite and thus to obtain catalysts with isolated tetrahedral Cu(II) species. The incorporation of Cu into the vacant T-sites of SiBEA framework is evidenced by XRD. The presence of isolated tetracoordinated Cu(II) as the main copper species is evidenced by DR UVvis and XPS investigations. Cu0.3SiBEA, Cu1.5SiBEA and Cu3.3SiBEA with isolated Cu(II) species are active in SCR of NO by ethanol with the maximum NO conversion of 33%, 45.5% and 50% and selectivity towards N2 of 90%, 97% and 75%, respectively. These results indicate that activity of CuxSiBEA in the SCR process increases with Cu content and the main reaction route is the reduction of NO toward N2. The decreases of selectivity toward N2 and increases toward NO2 with Cu content, is probably related to formation of small amount of octacoordinated Cu(II) as suggested by XPS data. A possible pathway for the formation of tetracoordinated Cu(II) in the framework of CuxSiBEA is proposed.", "label": 0}
{"doc-1": "A set of oligonucleotide primers capable of initiating enzymatic amplification (polymerase chain reaction) on a phylogenetically and taxonomically wide range of bacteria is described along with methods for their use and examples. One pair of primers is capable of amplifying nearly full-length 16S ribosomal DNA (rDNA) from many bacterial genera; the additional primers are useful for various exceptional sequences. Methods for purification of amplified material, direct sequencing, cloning, sequencing, and transcription are outlined. An obligate intracellular parasite of bovine erythrocytes, Anaplasma marginale, is used as an example; its 16S rDNA was amplified, cloned, sequenced, and phylogenetically placed. Anaplasmas are related to the genera Rickettsia and Ehrlichia. In addition, 16S rDNAs from several species were readily amplified from material found in lyophilized ampoules from the American Type Culture Collection. By use of this method, the phylogenetic study of extremely fastidious or highly pathogenic bacterial species can be carried out without the need to culture them. In theory, any gene segment for which polymerase chain reaction primer design is possible can be derived from a readily obtainable lyophilized bacterial culture.", "doc-2": "We evaluated the Lund-Manchester research criteria (LMRC) for frontotemporal dementia (FTD). With single-photon emission CT, we diagnosed 30 patients with FTD. These patients were compared with 30 with a research diagnosis of Alzheimer's disease (AD). We scored every patient on each LMRC item and compared the two groups. A discriminant function showed that loss of personal awareness, hyperorality, stereotyped and perseverative behavior, progressive reduction of speech, and preserved spatial orientation differentiated 100% of FTD and AD subjects. Items relating to affect and physical findings were not different in FTD versus AD. Loss of personal awareness, eating, perseverative behavior, and reduction of speech are the LMRC items that most clearly differentiate FTD from AD.", "label": 0}
{"doc-1": "We propose <i>B-MAC</i>, a carrier sense media access protocol for wireless sensor networks that provides a flexible interface to obtain ultra low power operation, effective collision avoidance, and high channel utilization. To achieve low power operation, <i>B-MAC</i> employs an adaptive preamble sampling scheme to reduce duty cycle and minimize idle listening. <i>B-MAC</i> supports on-the-fly reconfiguration and provides bidirectional interfaces for system services to optimize performance, whether it be for throughput, latency, or power conservation. We build an analytical model of a class of sensor network applications. We use the model to show the effect of changing <i>B-MAC</i>'s parameters and predict the behavior of sensor network applications. By comparing <i>B-MAC</i> to conventional 802.11-inspired protocols, specifically SMAC, we develop an experimental characterization of <i>B-MAC</i> over a wide range of network conditions. We show that <i>B-MAC</i>'s flexibility results in better packet delivery rates, throughput, latency, and energy consumption than S-MAC. By deploying a real world monitoring application with multihop networking, we validate our protocol design and model. Our results illustrate the need for flexible protocols to effectively realize energy efficient sensor network applications.", "doc-2": "BACKGROUNDSquamous cell carcinoma of the lung is a common cancer with 95% mortality at 5years. These cancers arise from preinvasive lesions, which have a natural history of development progressing through increasing severity of dysplasia to carcinoma in situ (CIS), and in some cases, ending in transformation to invasive carcinoma. Synchronous preinvasive lesions identified at autopsy have been previously shown to be clonally related.METHODSUsing autofluorescence bronchoscopy that allows visual observation of preinvasive lesions within the upper airways, together with molecular profiling of biopsies using gene sequencing and loss-of-heterozygosity analysis from both preinvasive lesions and from intervening normal tissue, we have monitored individual lesions longitudinally and documented their visual, histological and molecular relationship.RESULTSWe demonstrate that rather than forming a contiguous field of abnormal tissue, clonal CIS lesions can develop at multiple anatomically discrete sites over time. Further, we demonstrate that patients with CIS in the trachea have invariably had previous lesions that have migrated proximally, and in one case, into the other lung over a period of 12years.CONCLUSIONSMolecular information from these unique biopsies provides for the first time evidence that field cancerisation of the upper airways can occur through cell migration rather than via local contiguous cellular expansion as previously thought. Our findings urge a clinical strategy of ablating high-grade premalignant airway lesions with subsequent attentive surveillance for recurrence in the bronchial tree.", "label": 0}
{"doc-1": "This paper has always been one of my favorite children, combining as it does elements of the duality of linear programming and combinatorial tools from graph theory. It may be of some interest to tell the story of its origin.", "doc-2": "Nanocomposite materials, Na3V2(PO4)3/C and Na3V2(PO4)3/C/Ag, were synthesized by a modified Pechini method. Their properties were characterized with the use of the X-ray diffraction analysis, scanning electron microscopy, transmission electron microscopy, thermogravimetric analysis, elemental analysis, Raman spectroscopy, impedance spectroscopy, and charge-discharge tests as cathode materials for sodium-ion batteries. The discharge capacity of Na3V2(PO4)3/C obtained at 600C was 116.1 and 75 mAhg1 at a current density of 11 (0.1 C) and 110mAg1 (1 ) in the potential range of 2.73.8V. The high capacity values for fast charge/discharge were achieved as a result of heat treatment by two steps and incorporation of appropriate amount of silver particles into Na3V2(PO4)3/C nanocomposite. The discharge capacities of thus obtained Na3V2(PO4)3/C with 0.2wt% of Ag were 117.2, 112.5, and 83.5 mAhg1 at the current densities of 11, 110, and 880mAg1. This experimental evidence reveals the great potential of NVP/C/Ag synthesized by the modified Pechini method as cathode materials for the production of sodium-ion batteries.", "label": 0}
{"doc-1": "The adipose-derived hormone resistin is postulated to link obesity to insulin resistance and diabetes. Here, the infusion of either resistin or the resistin-like molecule-beta (RELMbeta) rapidly induced severe hepatic but not peripheral insulin resistance. In the presence of physiologic hyperinsulinemia, the infusion of purified recombinant resistin, increasing circulating resistin levels by approximately twofold to 15-fold, inhibited glucose metabolism such that lower rates of glucose infusion were required to maintain the plasma glucose concentration at basal levels. The effects of resistin and RELMbeta on in vivo insulin action were completely accounted for by a marked increase in the rate of glucose production. These results support the notion that a novel family of fat- and gut-derived circulating proteins modulates hepatic insulin action.", "doc-2": "This article is an exploration of possibilities and methodological considerations for using multiple theoretical perspectives in research that challenges inequitable power structures in student development theory. Specifically, I explore methodological considerations when partnering queer theory and constructivism in research on lesbian identity development. Considerations include the dilemma of partnering contradictory theoretical perspectives; the politics of representation; and the personal and professional implications for researchers who partner theoretical perspectives.", "label": 0}
{"doc-1": "MOTIVATIONAlthough many next-generation sequencing (NGS) read preprocessing tools already existed, we could not find any tool or combination of tools that met our requirements in terms of flexibility, correct handling of paired-end data and high performance. We have developed Trimmomatic as a more flexible and efficient preprocessing tool, which could correctly handle paired-end data.RESULTSThe value of NGS read preprocessing is demonstrated for both reference-based and reference-free tasks. Trimmomatic is shown to produce output that is at least competitive with, and in many cases superior to, that produced by other tools, in all scenarios tested.AVAILABILITY AND IMPLEMENTATIONTrimmomatic is licensed under GPL V3. It is cross-platform (Java 1.5+ required) and available at http://www.usadellab.org/cms/index.php?page=trimmomaticCONTACTusadel@bio1.rwth-aachen.deSUPPLEMENTARY INFORMATIONSupplementary data are available at Bioinformatics online.", "doc-2": "The evolution of powered flight is a major innovation that has facilitated the success of insects. Previously, studies of birds, bats, and insects have detected molecular signatures of differing selection regimes in energy-related genes associated with flight evolution and/or loss. Here, using DNA sequences from more than 1000 nuclear and mitochondrial protein-coding genes obtained from insect transcriptomes, we conduct a broader exploration of which gene categories display positive and relaxed selection at the origin of flight as well as with multiple independent losses of flight. We detected a number of categories of nuclear genes more often under positive selection in the lineage leading to the winged insects (Pterygota), related to catabolic processes such as proteases, as well as splicing-related genes. Flight loss was associated with relaxed selection signatures in splicing genes, mirroring the results for flight evolution. Similar to previous studies of flight loss in various animal taxa, we observed consistently higher nonsynonymous-to-synonymous substitution ratios in mitochondrial genes of flightless lineages, indicative of relaxed selection in energy-related genes. While oxidative phosphorylation genes were not detected as being under selection with the origin of flight specifically, they were most often detected as being under positive selection in holometabolous (complete metamorphosis) insects as compared with other insect lineages. This study supports some convergence in gene-specific selection pressures associated with flight ability, and the exploratory analysis provided some new insights into gene categories potentially associated with the gain and loss of flight in insects.", "label": 0}
{"doc-1": "The precision used in an algorithm affects the error and performance of individual computations, the memory usage, and the potential parallelism for a fixed hardware budget. This paper describes a new method to determine the minimum precision required to meet a given error specification for an algorithm consisting of the basic algebraic operations. Using this approach, it is possible to significantly reduce the computational word-length in comparison to existing methods, and this can lead to superior hardware designs. We demonstrate the proposed procedure on an iteration of the conjugate gradient algorithm, achieving proofs of bounds that can translate to global word-length savings ranging from a few bits to proving the existence of ranges that must otherwise be assumed to be unbounded when using competing approaches. We also achieve comparable bounds to recent literature in a small fraction of the execution time, with greater scalability.", "doc-2": "Grinding of tablets and opening of filled capsules are often requested as a part of dispensing. Current status of grinding of tablets was investigated on out-patient and in-patient prescriptions in Kumamoto University Hospital in April, 1990.It was shown that the frequency of prescriptions ordering grinding of tablets was about 2% of total prescriptions.Weight loss in tablet contents caused by grinding process was investigated with seven kinds of plain tablets, namely prednisolone, Halcion, Thyradine-S, Cortril, quinidine sulfate, Androcur, and Baktar.Two methods of grinding, one using a mortar and pestle and the other using a tablet grinding machine, were compared.In both methods the extent of loss in weight varied with numbers of tablets and with weight of each tablet employed.The increase in loss in weight was attended by the decrease in number of tablets and weight of each tablet.The loss in weight by the method using a tablet grinding machine was decreased by adding lactose (crystalline type).", "label": 0}
{"doc-1": "We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.", "doc-2": "As part of the U.S. FHWA-sponsored Detection Technology for IVHS program, ultrasonic, microwave radar, infrared laser radar, nonimaging passive infrared, video image processing with visible and infrared spectrum imagery, acoustic array, high sampling rate inductive loop, conventional inductive loop, microloop, and magnetometer detector technologies were evaluated at freeway and surface street arterial sites in Minnesota, Florida, and Arizona. These states were chosen because they exhibited a wide range of climatic conditions. The criteria for selecting the detector evaluation sites included searching for roadways with high traffic density and suitable structures for mounting the overhead detectors. Approximately 5.9 Gbytes of digital and analog vehicle detection and signature data and more than 300 video tapes of the corresponding traffic flow were recorded. The detector outputs were time tagged and recorded on 88 Mbyte magnetic cartridges by using a data logger specifically designed and built for this project. Detectors with serial RS-232 outputs required interface software to be written for each unique data structure. Data analysis software was also written to convert the raw data into an easily accessible Paradox database format compatible with a Windows personal computer operating system. Traffic volume ground truth data, obtained by counting vehicles from the recorded video imagery, were compared with the counts from the detector outputs. Speed ground truth data, obtained by driving probe vehicles through the field of view of the detectors and noting their speed as measured by the vehicle's speedometer, were compared with the speed measurement from the detectors. Several types of detectors were found to satisfy current traffic management requirements. However, improved accuracies and new types of information, such as queue length and vehicle turning or erratic movements, may be required from detectors for future traffic management applications.", "label": 0}
{"doc-1": "2008;133;113-122 Chest Holger J. Schnemann, Deborah Cook and Gordon Guyatt Guidelines (8th Edition) Physicians Evidence-Based Clinical Practice Development: American College of Chest Thrombolytic Therapy Guideline Methodology for Antithrombotic and http://chestjournal.org/cgi/content/abstract/133/6_suppl/113S and services can be found online on the World Wide Web at: The online version of this article, along with updated information ). ISSN: 0012-3692. http://www.chestjournal.org/misc/reprints.shtml ( of the copyright holder may be reproduced or distributed without the prior written permission Northbrook IL 60062. All rights reserved. No part of this article or PDF by the American College of Chest Physicians, 3300 Dundee Road, 2007 Physicians. It has been published monthly since 1935. Copyright CHEST is the official journal of the American College of Chest", "doc-2": "A nonconfocal laser resonator that has output-coupling apertures has been analyzed using the matrix eigenvalue technique. Numerical calculations of eigenvalues and eigenfunctions are performed for the interesting resonator consisting of one plane mirror with a coupling aperture and one spherical mirror. The effects of the coupling aperture are also discussed for several kinds of modes when both the mirror and coupling- aperture Fresnel numbers vary. It is found that the power loss of the TEM(00) mode becomes nearly constant in a finite range of the mirror Fresnel number. In such a range, the major source of a resonator loss is the power coupling through an aperture, and the coupling loss can be estimated independently of the loss caused by the spillover at mirror edges.", "label": 0}
{"doc-1": "The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.", "doc-2": "Background and PurposeThe aim of this study is to estimate the risk of ischemic stroke during a 3-year follow-up period after a tuberculosis diagnosis using a nationwide, population-based study and a retrospective cohort design. MethodThe study cohort comprised 2283 patients who had received treatment for tuberculosis, except tuberculosis of the meninges and central nervous system, between 2000 and 2003; 6849 randomly selected subjects comprised the comparison cohort. Cox proportional hazard regressions were performed as a means of comparing the 3-year ischemic stroke-free survival rate between these 2 cohorts. ResultsOf the 9132 sampled patients, 392 (4.3%) experienced ischemic stroke during the 3-year follow-up period, including 136 (6.0% of the tuberculosis patients) from the study cohort and 256 (3.7%) from the comparison cohort. After adjusting for patient age, gender, hypertension, diabetes, coronary heart disease, hyperlipidemia, malignancy, monthly income, and the geographical region and urbani...", "label": 0}
{"doc-1": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed.", "doc-2": "BACKGROUNDSupernumerary teeth are often observed in patients suffering from cleidocranial dysplasia due to a mutation in Runx2 that results in haploinsufficiency. However, the underlying molecular mechanisms are poorly defined. In this study, we assessed the roles of Runx2 and its functional antagonist Twist1 in regulating fibroblast growth factor (FGF) signaling using in vitro biochemical approaches.RESULTSWe showed that Twist1 stimulated Fgfr2 and Fgf10 expression in a mesenchymal cell line and that it formed heterodimers with ubiquitously expressed E12 (together with E47 encoded by E2A gene) and upregulated Fgfr2 and Fgf10 promoter activities in a dental mesenchyme-derived cell line. We further demonstrated that the bHLH domain of Twist1 was essential for its synergistic activation of Fgfr2 promoter with E12 and that the binding of E12 stabilized Twist1 by preventing it from undergoing lysosomal degradation. Although Runx2 had no apparent effects on Fgfr2 and Fgf10 promoter activities, it inhibited the stimulatory activity of Twist1 on Fgfr2 promoter.CONCLUSIONSThese findings suggest that Runx2 haploinsufficiency might result in excessive unbound Twist1 that can freely bind to E12 and enhance FGF signaling, thereby promoting the formation of extra teeth.", "label": 0}
{"doc-1": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.", "doc-2": "There is increasingly strong observational evidence that slow magnetoacoustic modes arise in the solar atmosphere, either as propagating or standing waves. Sunspots, coronal plumes and coronal loops all appear to support slow modes. Here we examine theoretically how the slow mode may be extracted from the magnetohydrodynamic equations, considering the special case of a vertical magnetic field in a stratified medium: the slow mode is described by the Klein-Gordon equation. We consider its application to recent observations of slow waves in coronal loops.", "label": 0}
{"doc-1": "This study evaluated the sensitivity of maximum likelihood (ML)-, generalized least squares (GLS)-, and asymptotic distribution-free (ADF)-based fit indices to model misspecification, under conditions that varied sample size and distribution. The effect of violating assumptions of asymptotic robustness theory also was examined. Standardized root-mean-square residual (SRMR) was the most sensitive index to models with misspecified factor covariance(s), and Tucker-Lewis Index (1973; TLI), Bollen's fit index (1989; BL89), relative noncentrality index (RNI), comparative fit index (CFI), and the MLand GLS-based gamma hat, McDonald's centrality index (1989; Me), and root-mean-square error of approximation (RMSEA) were the most sensitive indices to models with misspecified factor loadings. With ML and GLS methods, we recommend the use of SRMR, supplemented by TLI, BL89, RNI, CFI, gamma hat, Me, or RMSEA (TLI, Me, and RMSEA are less preferable at small sample sizes). With the ADF method, we recommend the use of SRMR, supplemented by TLI, BL89, RNI, or CFI. Finally, most of the ML-based fit indices outperformed those obtained from GLS and ADF and are preferable for evaluating model fit.", "doc-2": "A layered mineral, like muscovite, is a good model of heterogeneous solid because it presents two types of crystalline surfaces: basal and lateral surfaces. A convenient method for changing its degree of surface heterogeneity is to submit muscovite to a grinding process, creating new surfaces: either basal surfaces if the delamination of the crystal is the dominant process or lateral surfaces if comminution is prevalent. The aim of the present work is to demonstrate how inverse gas chromatography, combined with an original method of calculation ofthe adsorption energy distribution functions, is a very sensitive method to monitor the evolution ofthe surface heterogeneity of muscovite ground in the presence of different grinding additives such as glutaric acid (0.5% in aqueous solution) or potassium chloride (1 M in aqueous solution). It is shown that the latter favors the delamination of the muscovite crystal whereas the former induces the comminution of the crystal leading to an increase of lateral surfaces.", "label": 0}
{"doc-1": "A new method called the neighbor-joining method is proposed for reconstructing phylogenetic trees from evolutionary distance data. The principle of this method is to find pairs of operational taxonomic units (OTUs [= neighbors]) that minimize the total branch length at each stage of clustering of OTUs starting with a starlike tree. The branch lengths as well as the topology of a parsimonious tree can quickly be obtained by using this method. Using computer simulation, we studied the efficiency of this method in obtaining the correct unrooted tree in comparison with that of five other tree-making methods: the unweighted pair group method of analysis, Farris's method, Sattath and Tversky's method, Li's method, and Tateno et al.'s modified Farris method. The new, neighbor-joining method and Sattath and Tversky's method are shown to be generally better than the other methods.", "doc-2": "Cognitive products use cognitive functions to work autonomously and reduce the amount of interaction necessary from the user. However, to date no method exists to support the integration of cognitive functions in common products. This paper presents a method that supports designers when exploring ideas for new cognitive products. The method is based on functions/actions that humans perform while using a product, as well as functions/actions performed by the product itself, all of which can be consistently modelled in an activity diagram. Initially, the system boundary of the product is drawn around the functions/actions performed by the product. Cognitive functions are then identified that are currently performed by the user, and can possibly be integrated into a new cognitive concept. The resulting concept is specified systematically by interpreting the system boundary of the product to include cognitive functions. This method has been verified via design projects performed by interdisciplinary student design teams, and an example of this work is presented.", "label": 0}
{"doc-1": "Since 1922 when Wu proposed the use of the Folin phenol reagent for the measurement of proteins, a number of modified analytical procedures utilizing this reagent have been reported for the determination of proteins in serum, in antigen-antibody precipitates, and in insulin. Although the reagent would seem to be recommended by its great sensitivity and the simplicity of procedure possible with its use, it has not found great favor for general biochemical purposes. In the belief that this reagent, nevertheless, has considerable merit for certain application, but that its peculiarities and limitations need to be understood for its fullest exploitation, it has been studied with regard to effects of variations in pH, time of reaction, and concentration of reactants, permissible levels of reagents commonly used in handling proteins, and interfering substances. Procedures are described for measuring protein in solution or after precipitation with acids or other agents, and for the determination of as little as 0.2 gamma of protein.", "doc-2": "OBJECTIVETo identify occupations with a high risk of disability retirement as a result of hip osteoarthritis (OA), and to examine the effect of physical workload factors on the occupational differences in disability retirement.METHODSA total of 1,135,654 (49.4% women) Finns aged 30-60 years in gainful employment were followed from 2005 to 2013 for full disability retirement as a result of hip OA. Information on pensions, occupation, and education were obtained from national registers. Physical workload was assessed by a sex-specific job exposure matrix. We calculated age-adjusted incidence rates and examined the associations of occupation, education, and physical workload factors with disability retirement using a competing risk regression model.RESULTSAge-adjusted incidence rate was 25 and 22 per 100,000 person-years in men and women, respectively. Both men and women working in lower-level nonmanual and manual occupations had an elevated age-adjusted risk of disability retirement as a result of hip OA. A very high risk of disability retirement was found among male construction workers, electricians, and plumbers (HR 12.7, 95% CI 8.4-19.7), and female professional drivers (HR 15.2, 95% CI 7.5-30.8) as compared with professionals. After adjustment for age and education, the observed occupational differences in disability retirement were largely explained by physical workload factors among men and to a smaller extent, among women.CONCLUSIONOur results suggest that education and physical workload factors appear to be the major reasons for excess disability retirement as a result of hip OA in manual occupations, particularly among men.", "label": 0}
{"doc-1": "OBJECTIVETo evaluate the association between physical activity and all case mortality in postmenopausal women.DESIGNProspective cohort study with 7 years of follow-up through December 31, 1992.SETTING AND PARTICIPANTSSubjects were 40417 postmenopausal Iowa women, aged 55 to 69 years at baseline in 1986. Physical activity was assessed by mailed questionnaire.MAIN OUTCOME MEASUREAll-cause mortality (n=2260).RESULTSAfter adjustment for potential confounders and excluding women who reported having cancer or heart disease and those who died in the first 3 years of follow-up, women who reported regular physical activity were at significantly reduced risk of death during follow-up compared with women who did not (relative risk [RR], 0.77; 95% confidence interval [CI], 0.66-0.90). Increasing frequency of moderate physical activity was associated with reduced risk of death during follow-up (from rarely or never engaging in activity to activity at least 4 times per week, RRs, 1.0 [referent], 0.76, 0.70, and 0.62; P value for trend<.001). A similar pattern was seen for vigorous physical activity (corresponding RRs, 1.0, 0.89, 0.74, and 0.57; Pvalue for trend=.06). Reduced risks of death with increased physical activity were evident for cardiovascular diseases (n=729) and respiratory illnesses (n=147). Women who engaged only in moderate but not vigorous physical activity also benefited, with moderate activity as infrequently as once per week demonstrating a reduced mortality risk of 0.78 (95% CI, 0.64-0.96).CONCLUSIONSThese results demonstrate a graded, inverse association between physical activity and all-cause mortality in postmenopausal women. These findings strengthen the confidence that population recommendations to engage in regular physical activity are applicable to postmenopausal women.", "doc-2": "SUMMARY BACKGROUND DATAThe value of laparoscopy in appendicitis is not established. Studies suffer from multiple limitations. Our aim is to compare the safety and benefits of laparoscopic versus open appendectomy in a prospective randomized double blind study.METHODSTwo hundred forty-seven patients were analyzed following either laparoscopic or open appendectomy. A standardized wound dressing was applied blinding both patients and independent data collectors. Surgical technique was standardized among 4 surgeons. The main outcome measures were postoperative complications. Secondary outcome measures included evaluation of pain and activity scores at base line preoperatively and on every postoperative day, as well as resumption of diet and length of stay. Activity scores and quality of life were assessed on short-term follow-up.RESULTSThere was no mortality. The overall complication rate was similar in both groups (18.5% versus 17% in the laparoscopic and open groups respectively), but some early complications in the laparoscopic group required a reoperation. Operating time was significantly longer in the laparoscopic group (80 minutes versus 60 minutes; P = 0.000) while there was no difference in the pain scores and medications, resumption of diet, length of stay, or activity scores. At 2 weeks, there was no difference in the activity or pain scores, but physical health and general scores on the short-form 36 (SF36) quality of life assessment forms were significantly better in the laparoscopic group. Appendectomy for acute or complicated (perforated and gangrenous) appendicitis had similar complication rates, regardless of the technique (P = 0.181).CONCLUSIONSUnlike other minimally invasive procedures, laparoscopic appendectomy did not offer a significant advantage over open appendectomy in all studied parameters except quality of life scores at 2 weeks. It also took longer to perform. The choice of the procedure should be based on surgeon or patient preference.", "label": 0}
{"doc-1": "In this paper we report exploratory analyses of high-density oligonucleotide array data from the Affymetrix GeneChip system with the objective of improving upon currently used measures of gene expression. Our analyses make use of three data sets: a small experimental study consisting of five MGU74A mouse GeneChip arrays, part of the data from an extensive spike-in study conducted by Gene Logic and Wyeth's Genetics Institute involving 95 HG-U95A human GeneChip arrays; and part of a dilution study conducted by Gene Logic involving 75 HG-U95A GeneChip arrays. We display some familiar features of the perfect match and mismatch probe (PM and MM) values of these data, and examine the variance-mean relationship with probe-level data from probes believed to be defective, and so delivering noise only. We explain why we need to normalize the arrays to one another using probe level intensities. We then examine the behavior of the PM and MM using spike-in data and assess three commonly used summary measures: Affymetrix's (i) average difference (AvDiff) and (ii) MAS 5.0 signal, and (iii) the Li and Wong multiplicative model-based expression index (MBEI). The exploratory data analyses of the probe level data motivate a new summary measure that is a robust multi-array average (RMA) of background-adjusted, normalized, and log-transformed PM values. We evaluate the four expression summary measures using the dilution study data, assessing their behavior in terms of bias, variance and (for MBEI and RMA) model fit. Finally, we evaluate the algorithms in terms of their ability to detect known levels of differential expression using the spike-in data. We conclude that there is no obvious downside to using RMA and attaching a standard error (SE) to this quantity using a linear model which removes probe-specific affinities.", "doc-2": "A simple dynamical model for studying the charging of substrates irradiated by particle beams is developed. The charging potential for positive ion beams can be as large as the beam voltage. For negative ion beams, the charging potential is significantly lower and is governed by the secondary electrons. A closed form expression derived for the charging voltage in the case of negative ion beams agrees well with our numerical work. The results are consistent with observations on charging of isolated substrates during ion implantation with positive and negative ion beams.", "label": 0}
{"doc-1": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.", "doc-2": "BACKGROUNDWe used virtual histology-intravascular ultrasound (VH-IVUS) to evaluate the relationship between circulating endothelial progenitor cells (EPC) and thin-cap fibroatheroma (TCFA).METHODSThis study included 52 patients with unstable angina who underwent coronary angiography and IVUS examination. Patients were divided into a TCFA group (n = 21) or a non-TCFA group (n = 31) based on VH-IVUS performance. Before angiography, peripheral blood levels of EPC were measured by flow cytometry. TCFA was defined as a necrotic core (NC)  10% of the plaque area without overlying fibrous tissue in the presence of  40% plaque burden.RESULTSLevels of circulating EPCs were 72.45  31.73 (count/105) in the TCFA group and 23.93  11.87 (count/ 105) (p < 0.01). Mean levels of CRP were 0.38  0.21 mg/L in the TCFA group and 0.23  0.17 mg/L (p < 0.01). Levels of EPCs correlated positively with necrotic core volume(r = 0.421, p = 0.005), CRP (r = 0.405, p = 0.011) and negatively with fibrous tissue volume(r = -0.411, p = 0.009). In multivariate logistic regression analysis, level of EPC (OR: 1.815, 95% CI: 1.12 - 2.798, p = 0.016), plaque burden (OR: 1.26, 95% CI: 1.07 - 1.86, p = 0.027), and CRP (OR; 1.14, 95% CI: 0.74 - 1.56, p = 0.029) were independent predictors of TCFA.CONCLUSIONSCirculating EPCs were increased in patients with TCFA, level of EPCs could predict the presence of TCFA.", "label": 0}
{"doc-1": "A submitted manuscript is the author's version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "BACKGROUNDOur objective was to employ a novel genetic methodology - whereby functional variants of the dopamine pathway were aggregated to reflect a polygenic liability - in the study of food addiction. We anticipated that the composite index of elevated dopamine signaling (a multilocus genetic profile score [MLGP]) would distinguish those with a designation of food addiction (according to the Yale Food Addiction Scale [YFAS] criteria), and age and weight equivalent controls. Our second aim was to assess whether this index was positively associated with eating-related sub-phenotypes of food addiction (e.g. binge eating and food cravings).METHODSAdults (n=120) recruited from the community were solicited for an overeating/overweight study. Eating-behavior questionnaires were completed and a blood sample was taken for genotyping.RESULTS AND CONCLUSIONSThe YFAS identified 21 participants with food addiction. As predicted, the MLGP score was higher in those with YFAS-diagnosed food addiction, and it correlated positively with binge eating, food cravings, and emotional overeating. We then tested a multiple-mediation model proposing that reward-driven overeating facilitates the relationship between the MLGP score and food addiction. The model was statistically significant, supporting the view that the relationship between a composite genetic index of dopamine signaling and food addiction is mediated by certain aspects of reward-responsive overeating.", "label": 0}
{"doc-1": "A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code Author(s): M. D. Mckay, R. J. Beckman, W. J. Conover Source: Technometrics, Vol. 42, No. 1, Special 40th Anniversary Issue (Feb., 2000), pp. 55-61 Published by: American Statistical Association and American Society for Quality Stable URL: http://www.jstor.org/stable/1271432 Accessed: 29/06/2010 10:02", "doc-2": "Introduction: American literary realism 1. Literary precursors, literary contexts 2. The 'look of agony' and everyday middle-class life: three transitional works 3. Creating the 'odor' of the real: techniques of realism 4. Conflicting manners: high realism and social competition 5. 'Democracy in literature'? Literary regionalism 6. 'The blab of the pave': realism and the city 7. Crisis of agency: literary naturalism, the changing economy, and 'masculinity' 8. 'Certain facts of life': realism and feminism 9. 'The unjust spirit of caste': race and realism 10. New Americans write realism Conclusion: realisms after realism Further reading Index.", "label": 0}
{"doc-1": "We introduce a new class of problems called network information flow which is inspired by computer network applications. Consider a point-to-point communication network on which a number of information sources are to be multicast to certain sets of destinations. We assume that the information sources are mutually independent. The problem is to characterize the admissible coding rate region. This model subsumes all previously studied models along the same line. We study the problem with one information source, and we have obtained a simple characterization of the admissible coding rate region. Our result can be regarded as the max-flow min-cut theorem for network information flow. Contrary to one's intuition, our work reveals that it is in general not optimal to regard the information to be multicast as a \"fluid\" which can simply be routed or replicated. Rather, by employing coding at the nodes, which we refer to as network coding, bandwidth can in general be saved. This finding may have significant impact on future design of switching systems.", "doc-2": "As part of a program to determine the stellar population of novae, we have conducted a multiepoch H survey of the galaxies M51, M87, and M101. A total of nine and 12 novae were detected in the spiral galaxies M51 and M101, respectively, during four epochs of observation, and two epochs of observation yielded a total of nine novae in the giant elliptical galaxy M87. After correcting for the effective survey time and for the fraction of luminosity sampled, we find global nova rates of 18  7, 91  34, and 12  4 novae per year for M51, M87, and M101, respectively. After normalizing to the total K-band luminosity of each galaxy, we estimate luminosity-specific nova rates for M51, M87, and M101 of 1.09  0.47, 2.30  0.99, and 0.97  0.38 novae per year per 1010 solar luminosities in K. When we compare these data with measured values for the luminosity-specific nova rates of other galaxies, we find no compelling evidence for a significant variation with Hubble type. Possible ramifications of this result are discussed within the context of current theoretical models for nova production in galaxies.", "label": 0}
{"doc-1": "A grand challenge in the post-genomic era is a complete computer representation of the cell and the organism, which will enable computational prediction of higher-level complexity of cellular processes and organism behavior from genomic information. Toward this end we have been developing a knowledge-based approach for network prediction, which is to predict, given a complete set of genes in the genome, the protein interaction networks that are responsible for various cellular processes. KEGG at http://www.genome.ad.jp/kegg/ is the reference knowledge base that integrates current knowledge on molecular interaction networks such as pathways and complexes (PATHWAY database), information about genes and proteins generated by genome projects (GENES/SSDB/KO databases) and information about biochemical compounds and reactions (COMPOUND/GLYCAN/REACTION databases). These three types of database actually represent three graph objects, called the protein network, the gene universe and the chemical universe. New efforts are being made to abstract knowledge, both computationally and manually, about ortholog clusters in the KO (KEGG Orthology) database, and to collect and analyze carbohydrate structures in the GLYCAN database.", "doc-2": "As software reuse becomes more prominent and accepted in industry, systems and tools for software reuse become a key aspect in achieving successful reuse of software artifacts. A major problem with such tools is the retrieval and classification of the software modules. To search for and retrieve the conceptually closest software component from a library of software modules, components need to be classified in some manner. We address this problem by showing how the software library can be organized using a clustering scheme. We also show graphically using a simplified example, how our scheme clusters software components containing descriptions of software modules. We contend that this organization easily supports a retrieval method for software components to be reused. Our scheme is automatic and classifies components that have been represented using a knowledge representation-based language.", "label": 0}
{"doc-1": "+ Abstract: Statistical parametric maps are spatially extended statistical processes that are used to test hypotheses about regionally specific effects in neuroimaging data. The most established sorts of statistical parametric maps (e.g., Friston et al. (1991): J Cereb Blood Flow Metab 11:690-699; Worsley et al. 119921: J Cereb Blood Flow Metab 12:YOO-918) are based on linear models, for example ANCOVA, correlation coefficients and t tests. In the sense that these examples are all special cases of the general linear model it should be possible to implement them (and many others) within a unified framework. We present here a general approach that accommodates most forms of experimental layout and ensuing analysis (designed experiments with fixed effects for factors, covariates and interaction of factors). This approach brings together two well established bodies of theory (the general linear model and the theory of Gaussian fields) to provide a complete and simple framework for the analysis of imaging data. The importance of this framework is twofold: (i) Conceptual and mathematical simplicity, in that the same small number of operational equations is used irrespective of the complexity of the experiment or nature of the statistical model and (ii) the generality of the framework provides for great latitude in experimental design and analysis.", "doc-2": "Grapevine leaf has three unique sinuses. This study examined the relationship between the formation of the upper lateral sinus and the expression of VvNAC21/22-like , a member of grape NAC transcription factor family. VvNAC21/22-like expression was not upregulated in young leaves of all the cultivars tested and in mature leaves of cultivars having shallow sinuses but was abundant in mature leaves of cultivars having deep sinuses. Simple linear regression analysis demonstrated that in mature leaves, VvNAC21/22-like expression, but not VvNAC1 , VvCUC2 , and VvCUC3 expression, showed strong positive correlation with the depth of upper lateral sinus, suggesting that the increase in VvNAC21/22-like expression at the late stage of leaf maturation was related to the formation of deep upper lateral sinus in grapevine leaves. VvNAC21/22-like mRNAs were distributed in the upper and lower lateral sinuses of grapevine leaves. From these results, we hypothesize that VvNAC21/22-like plays a role in the formation of the upper lateral sinus in grapevine leaves. The findings indicate that sinuses in grapevine leaves may serve as a breeding target to enhance adaptation to environmental conditions.", "label": 0}
{"doc-1": "Introduction to the Logistic Regression Model Multiple Logistic Regression Interpretation of the Fitted Logistic Regression Model Model-Building Strategies and Methods for Logistic Regression Assessing the Fit of the Model Application of Logistic Regression with Different Sampling Models Logistic Regression for Matched Case-Control Studies Special Topics References Index.", "doc-2": "The circuit in this paper is an effective solution to interference and noise of input signal during data acquisition and the circuit designed is based on an active low pass circuit with output frequency from 0~100Hz. The low pass circuit consisted mainly of an OPAMP TL084. Chaos theory is applied in this active nonlinear filter.The designed circuit is analysed by Matlab simulation software and the simulation results show the method can effectively improve effects of the filtering circuit.", "label": 0}
{"doc-1": "1. Introduction. 2. Partitioning Around Medoids (Program PAM). 3. Clustering large Applications (Program CLARA). 4. Fuzzy Analysis. 5. Agglomerative Nesting (Program AGNES). 6. Divisive Analysis (Program DIANA). 7. Monothetic Analysis (Program MONA). Appendix 1. Implementation and Structure of the Programs. Appendix 2. Running the Programs. Appendix 3. Adapting the Programs to Your Needs. Appendix 4. The Program CLUSPLOT. References. Author Index. Subject Index.", "doc-2": "The Fully Bayesian Significance Test (FBST) is a coherent Bayesian significance test for sharp hypotheses. This paper proposes the FBST as a model selection tool for general mixture models, and compares its performance with Mclust, a modelbased clustering software. The FBST robust performance strongly encourages further developments and investigations.", "label": 0}
{"doc-1": "BACKGROUNDSubjects with a mild cognitive impairment (MCI) have a memory impairment beyond that expected for age and education yet are not demented. These subjects are becoming the focus of many prediction studies and early intervention trials.OBJECTIVETo characterize clinically subjects with MCI cross-sectionally and longitudinally.DESIGNA prospective, longitudinal inception cohort.SETTINGGeneral community clinic.PARTICIPANTSA sample of 76 consecutively evaluated subjects with MCI were compared with 234 healthy control subjects and 106 patients with mild Alzheimer disease (AD), all from a community setting as part of the Mayo Clinic Alzheimer's Disease Center/Alzheimer's Disease Patient Registry, Rochester, Minn.MAIN OUTCOME MEASURESThe 3 groups of individuals were compared on demographic factors and measures of cognitive function including the Mini-Mental State Examination, Wechsler Adult Intelligence Scale-Revised, Wechsler Memory Scale-Revised, Dementia Rating Scale, Free and Cued Selective Reminding Test, and Auditory Verbal Learning Test. Clinical classifications of dementia and AD were determined according to the Diagnostic and Statistical Manual of Mental Disorders, Revised Third Edition and the National Institute of Neurological and Communicative Disorders and Stroke-Alzheimer's Disease and Related Disorders Association criteria, respectively.RESULTSThe primary distinction between control subjects and subjects with MCI was in the area of memory, while other cognitive functions were comparable. However, when the subjects with MCI were compared with the patients with very mild AD, memory performance was similar, but patients with AD were more impaired in other cognitive domains as well. Longitudinal performance demonstrated that the subjects with MCI declined at a rate greater than that of the controls but less rapidly than the patients with mild AD.CONCLUSIONSPatients who meet the criteria for MCI can be differentiated from healthy control subjects and those with very mild AD. They appear to constitute a clinical entity that can be characterized for treatment interventions.", "doc-2": "We report a case of dust mite carriage in a 56-year-old gentleman. Dust mites eggs and larvae were found in a stool sample which was taken for a routine clinical examination. He was completely asymptomatic with no history of rash, airway disease or other allergic manifestations associated with dust mites. We noticed that the oval structure of mite eggs resembled helminth eggs and therefore may be misidentified during routine clinical analysis. As the patient was otherwise healthy, it was concluded that no rigorous antiparasitic therapy was necessary to eliminate dust mites from his system.", "label": 0}
{"doc-1": "Newborn mice homozygous for a targeted disruption of insulin-like growth factor gene (Igf-1) exhibit a growth deficiency similar in severity to that previously observed in viable Igf-2 null mutants (60% of normal birthweight). Depending on genetic background, some of the Igf-1(-/-) dwarfs die shortly after birth, while others survive and reach adulthood. In contrast, null mutants for the Igf1r gene die invariably at birth of respiratory failure and exhibit a more severe growth deficiency (45% normal size). In addition to generalized organ hypoplasia in Igf1r(-/-) embryos, including the muscles, and developmental delays in ossification, deviations from normalcy were observed in the central nervous system and epidermis. Igf-1(-/-)/Igf1r(-/-) double mutants did not differ in phenotype from Igf1r(-/-) single mutants, while in Igf-2(-)/Igf1r(-/-) and Igf-1(-/-)/Igf-2(-) double mutants, which are phenotypically identical, the dwarfism was further exacerbated (30% normal size). The roles of the IGFs in mouse embryonic development, as revealed from the phenotypic differences between these mutants, are discussed.", "doc-2": "AIMSThe objectives of this study were to assess the genetic relationships between toxigenic and atoxigenic isolates of Aspergillus flavus collected from peanut fields in China, and to analyse deletions within the aflatoxin biosynthetic gene cluster for the atoxigenic isolates.METHODS AND RESULTSAnalysis of random-amplified polymorphic DNA and microsatellite-primed PCR data showed that the toxigenic and atoxigenic isolates of A. flavus were not clustered based on their regions and their ability of aflatoxin and sclerotial production. These results were further supported by DNA sequence of ITS, pksA and omtA genes. PCR assays showed that 24 of 35 isolates containing no detectable aflatoxins had the entire aflatoxin gene cluster. Eleven atoxigenic isolates had five different deletion patterns in the cluster.CONCLUSIONSToxigenic and atoxigenic isolates of A. flavus are genetically similar, but some atoxigenic isolates having deletions within the aflatoxin gene cluster can be identified readily by PCR assays.SIGNIFICANCE AND IMPACT OF THE STUDYBecause the extensive deletions within the aflatoxin gene cluster are not rare in the atoxigenic isolates, analysis of deletion within the cluster would be an effective method for the rapid screening of atoxigenic isolates for developing biocontrol agents.", "label": 0}
{"doc-1": "In spite of the extensive empirical evidence supporting Porter's (1980) typology of generic strategies, many researchers have criticized it for its conceptual limitations. To address these criticisms, Mintzberg (1988) proposed an alternative typology of generic strategies. Our findings, based on a survey of executives in manufacturing firms, provide support for Mintzberg's typology and fail to support Porter's typology. Given the findings, we call for further empirical validation of competing typologies to revitalize research on generic strategies.", "doc-2": "Recently, M. Daws introduced a notion of co-representation of abelian Hopf--von Neumann algebras on general reflexive Banach spaces. In this note, we show that this notion cannot be extended beyond subhomogeneous Hopf--von Neumann algebras. The key is our observation that, for a von Neumann algebra $\\M$ and a reflexive operator space $E$, the normal spatial tensor product $\\M \\bar{\\tensor} \\CB(E)$ is a Banach algebra if and only if $\\M$ is subhomogeneous or $E$ is completely isomorphic to column Hilbert space.", "label": 0}
{"doc-1": "A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of \"no free lunch\" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori \"head-to-head\" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.", "doc-2": "Recuerdo muy graficamente una extrana emision televisiva de hace unos anos. En uno de los primeros dias de la invasion estadounidense de Iraq, en 2003, un experimentado corresponsal de la CNN iba subido en un vehiculo blindado. Se le veia exultante porque estaba realizando una emision en directo con la camara de un telefono movil colocado fuera de la ventana. Decia a voz en grito que nunca antes se habia visto una emision de ese tipo. Y realmente era asi. Porque era dificil ver algo en aquellas imagenes. Debido a la baja resolucion, lo unico que se veia eran unas manchas verdes y marrones moviendose lentamente sobre la pantalla. En realidad, la imagen era como el camuflaje de los uniformes de combate; una version militar de expresionismo abstracto. ?Que nos dice este tipo de documentalismo abstracto sobre el documentalismo como tal? Apunta hacia una caracteristica mas profunda de muchas imagenes documentales contemporaneas: cuanto mas rapido se transforman, menos hay que ver en ellas. Cuanto mas cerca de la realidad estamos, menos inteligible es. Lo llamaremos el principio de incertidumbre del documentalismo moderno.", "label": 0}
{"doc-1": "Discusses the notion that the ability to exploit external knowledge is crucial to a firm's innovative capabilities. In addition, it is argued that the ability to evaluate and use outside knowledge is largely a function of the level of prior related knowledge--i.e., absorptive capacity. Prior research has shown that firms that conduct their own research and development (R&D) are better able to use information from external sources. Therefore, it is possible that the absorptive capacity of a firm is created as a byproduct of the firm's R&D investment. A simple model of firm R&D intensity is constructed in a broader context of what applied economists call the three classes of industry-level determinants of R&D intensity: demand, appropriability, and technological opportunity conditions. Several predictions are made, including the notions that absorptive capacity does have a direct effect on R&D spending and spillovers will provide a positive incentive to conduct R&D. All hypotheses are tested using cross-sectional survey data on technological opportunity and appropriability conditions--collected over the period 1975 to 1977 for 1,719 business units--in the American manufacturing sector from Levin et al. (1983, 1987) and the Federal Trade Commission's Line of Business Program data on business unit sales, transfers, and R&D expenditures. Results confirm that firms are sensitive to the characteristics of the learning environment in which they operate and that absorptive capacity does appear to be a part of a firm's decisions regarding resource allocation for innovative activity. Results also suggest that, although the analysis showing a positive effect of spillovers in two industry groups do not represent a direct test of the model, positive absorption incentive associated with spillovers may be sufficiently strong in some cases to more than offset the negative appropribility incentive. (SFL)", "doc-2": "OBJECTIVESThis article examines social and economic differences in the prevalence of needs and unmet needs for health-related personal assistance among the household population aged 65 and older and the sources from which they received support.DATA SOURCEThe data are from the 1991 Health and Activity Limitation Survey (HALS).ANALYTICAL TECHNIQUESAll calculations were based on weighted data. Age-standardized percentages of people with needs and unmet needs for personal assistance were calculated by sex, marital status, living arrangements, education, and household income.MAIN RESULTSIn 1991, 30% of seniors living in private households had some need for health-related personal assistance. Three-quarters of them required help only with instrumental activities of daily living (IADL); the remainder needed help with basic activities of daily living (ADL). The prevalence of need and unmet need was higher among women than men, was inversely related to household income and education, and was relatively high among formerly married seniors and those living alone. Household seniors were more likely to receive personal assistance from informal than formal sources, although this varied depending on their socioeconomic characteristics and the type of assistance they received.", "label": 0}
{"doc-1": "In area F5 of the monkey premotor cortex there are neurons that discharge both when the monkey performs an action and when he observes a similar action made by another monkey or by the experimenter. We report here some of the properties of these 'mirror' neurons and we propose that their activity 'represents' the observed action. We posit, then, that this motor representation is at the basis of the understanding of motor events. Finally, on the basis of some recent data showing that, in man, the observation of motor actions activate the posterior part of inferior frontal gyrus, we suggest that the development of the lateral verbal communication system in man derives from a more ancient communication system based on recognition of hand and face gestures.", "doc-2": "Extracellular matrices (ECM) triggered cellular signaling processes often begin with the clustering of the cellular receptors such as integrin and FcRI. The sizes of these initial protein complexes or clusters are tens to 100 nm in dimension; therefore, engineered nanostructures could provide effective mimics of ECM for investigation and control of the initial and downstream specific signaling processes. This current topic discusses recent advances in nanotechnology in the context of design and production of matching chemical functionality and geometry for control of specific cellular signaling processes. Two investigations are reported to demonstrate this concept: (a) how the presentation of antigen at the nanometer scale would influence the aggregation of FcRI, which would impact the formation of activation complexes, leading to the rearrangement of actin in cytoskeleton and degranulation or activation of mast cells; (b) how the engineered nanostructure could guide the initial integrin clustering, which would impact the formation of focal adhesion and downstream cell signaling cascades, leading to polarization, migration, and morphological changes. Complementary to engineered ECMs using synthetic ligands or peptides, or topographic control at the micrometer scale, nanostructures of designed geometry and chemical functionality provide new and effective biochemical cues for regulation of cellular signaling processes and downstream behaviors.", "label": 0}
{"doc-1": "Platelet-derived growth factor (PDGF) exerts its stimulatory effects on cell growth and motility by binding to two related protein tyrosine kinase receptors. Ligand binding induces receptor dimerization and autophosphorylation, allowing binding and activation of cytoplasmic SH2-domain containing signal transduction molecules. Thereby, a number of different signaling pathways are initiated leading to cell growth, actin reorganization migration and differentiation. Recent observations suggest that extensive cross-talk occurs between different signaling pathways, and that stimulatory signals are modulated by inhibitory signals arising in parallel.", "doc-2": "UNLABELLEDThe Cynara scolymus (artichoke) is widely consumed as tea or food and shows important therapeutic properties. However, few studies have assessed the possible toxic effects of artichoke extracts. This study evaluates genotoxic and mutagenic activities of artichoke leaf aqueous extract in mice using the comet assay and the micronucleus test. Leaf extracts were given by gavage (500 mg/kg, 1000 mg/kg, and 2000 mg/kg) for 3 consecutive days. Extract composition was investigated using phytochemical screening and high-performance liquid chromatography (HPLC). In addition, antioxidant capacity was analyzed through the diphenyl-picrylhydrazyl (DPPH) and xanthine oxidase assay. Phytochemical screening detected the presence of phenolic compounds, flavonoids, and saponins. HPLC analyses indicated the presence of chlorogenic acid, caffeic acid, isoquercetrin, and rutin. Extracts showed a dose-dependent free radical scavenging effect of DPPH and an inhibitory effect of xanthine oxidase. The genotoxic results showed that leaf extracts did not increase micronuclei in peripheral blood cells. Compared to the control group, a significant increase in comet assay values was observed only in bone marrow of group treated with 2000 mg/kg, the highest dose tested, indicating that artichoke tea should be consumed with moderation.PRACTICAL APPLICATIONThis is the first report of in vivo mutagenic and genotoxic evaluation with C. scolymus. The present study revealed leaf aqueous extract from artichoke shows lack of mutagenicity in vivo, and low genotoxicity and antioxidant activity; indicating that artichoke tea should be consumed with moderation.", "label": 0}
{"doc-1": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.", "doc-2": "In this paper, we present platform independent model (PIM) concepts of IISCase tool for information system (IS) modeling and design. IISCase is a model driven software tool that provides generation of executable application prototypes. The concepts are described by Meta Object Facility (MOF) specification, one of the commonly sed approaches for describing meta-models. One of the main reasons for having IISCase PIM concepts specified through the meta-model, is to provide software documentation in a formal way, as well as a domain analysis purposed to create a domain specific langage to support IS design. Using the meta-model of PIM concepts, we can generate test cases that may assist in software tool verification.", "label": 0}
{"doc-1": "A set of related medical disorders that lack a proper classification system and diagnostic criteria is like a society without laws. The result is incoherence at best, chaos at worst. For this reason, the International Classification of Headache Disorders (ICHD) is arguably the single most important breakthrough in headache medicine over the last 50 years. The ICHD identifies and categorizes more than a hundred different kinds of headache in a logical, hierarchal system. Even more important, it has provided explicit diagnostic criteria for all of the headache disorders listed. The ICHD quickly became universally accepted, and criticism of the classification has been minor relative to that directed at other disease classification systems. Over the 20 years following publication of the first edition of the ICHD, headache research has rapidly accelerated despite sparse allocation of resources to that effort. In summary, the ICHD has attained widespread acceptance at the international level and has substantially facilitated both clinical research and clinical care in the field of headache medicine.", "doc-2": "5002Background: AA added to medical castration augments cytoreduction in LHRPC though wide range of persistent cancer is observed. To build on these findings we conducted a study examining AA+ LHRH...", "label": 0}
{"doc-1": "A new family of highly fluorescent indicators has been synthesized for biochemical studies of the physiological role of cytosolic free Ca2+. The compounds combine an 8-coordinate tetracarboxylate chelating site with stilbene chromophores. Incorporation of the ethylenic linkage of the stilbene into a heterocyclic ring enhances the quantum efficiency and photochemical stability of the fluorophore. Compared to their widely used predecessor, \"quin2\", the new dyes offer up to 30-fold brighter fluorescence, major changes in wavelength not just intensity upon Ca2+ binding, slightly lower affinities for Ca2+, slightly longer wavelengths of excitation, and considerably improved selectivity for Ca2+ over other divalent cations. These properties, particularly the wavelength sensitivity to Ca2+, should make these dyes the preferred fluorescent indicators for many intracellular applications, especially in single cells, adherent cell layers, or bulk tissues.", "doc-2": "Engineering of microorganisms to directly utilize plant biomass as a feedstock for the biosynthesis of value-added products such as bioplastics is the aim of consolidated bioprocessing. In previous research we successfully engineered E. coli LS5218 to produce polyhydroxyalkanoates (PHAs) from xylan. In this study we report further genetic modifications to Escherichia coli LS5218 in order to increase the lactic acid (LA) fraction in poly(lactic acid-co-3-hydroxyalkanoate) P(LA-co-HA) copolymers. Deletion of the pflA gene resulted in increased content of LA repeating units in the copolymers by over 3-fold compared with the wild type; however, this increase was offset by reduced yields in cell mass. Additionally, when acetate was used as a feedstock LA monomer incorporation reached 18.5 (mol%), which suggests that acetate can be used as a feedstock for the production of P(LA-co-HA) copolymers by E. coli.", "label": 0}
{"doc-1": "A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.", "doc-2": "ABSTRACT Ultra high performance concrete (UHPC) has been developed to overcome the low strengths and brittleness of conventional concrete. Considering that UHPC, owing to its composition and the use of steel fibers, develops a compressive stre ngth of 180 MPa as well as high stiffness, the top flange of the steel girder may be superfluous in the composite beam combining a slab made of UHPC and the steel girder. In such composite beam, the steel girder takes the form of an inverted-T shaped structure wi thout top flange in which the studs needed for the composition of the steel girder with the UHPC slab are disposed in the web of the steel girder. This study investigates experimentally and analytically the flexural behavior of this new type of composite beam to propose details like stud spacing and slab thickness for further design recommendations. To that goal, eight composite beams with varying stud spacing and slab thickness were fabricated and tested. The test results indicated that stud spacing running from 100 mm to 2 to 3 times the slab thickness can be recommended. In view of the relative characteristic slip limit of Eurocode-4, the results showed that the composite beam developed ductile behavior. Moreover, except for the members with thin slab and large stud spacing, most of the specimens exhibited results different to those predicted by AASHTO LRFD and Eurocode-4 because of the high performance developed by UHPC.", "label": 0}
{"doc-1": "SUMMARYIt is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data.AVAILABILITYThe package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org).", "doc-2": "Abstract In last decades, rubber-toughened polymer blends have been the object of considerable interest by many investigators, owing to their attractive mechanical as well as physical properties. Polypropylene (PP) is a type of polyolefin which can be toughened using rubber particles. In another paper [J. Appl. Polym. Sci., submitted for publication], the role of ethylenepropylene (EPR) particles on the deformation mechanism during tensile tests and the fracture mechanism under quasi-static loading tests has been investigated. This paper is instead focused on the role of EPR particles on the fracture mechanism under dynamic loading (impact properties) of EPR/PP blends. Blends with different weight percent of elastomer phase were produced. Impact tests at different temperatures, and microscopy techniques were used in this study. The results show that impact strength rises with both EPR content and test temperature, showing a brittle-to-ductile transition temperature (BDTT). In particular, increasing rubber content shifts BDTT to lower temperatures. For clarifying the fracture behaviour, impact tests were also simulated by slow bending tests. The results illustrate that the dominant fracture mechanism is due to the formation of craze-like structures that appear to be highly localised dilatational bands. This type of deformation pattern is discussed in relation to the interparticle distance effect observed previously in some rubber toughened polymers, and supports a model previously proposed by Lazzeri [A. Lazzeri, The Kinetics of Dilatational Bands and the Interparticle Distance Effect in Rubber Toughened Polymers, 10th International Conference on Deformation, Yield and Fracture of Polymers, April 710, 1997, Cambridge, UK, p. 75] to explain the interparticle distance effect on the basis of the stability of dilatational band propagation.", "label": 0}
{"doc-1": "Problems demanding globally optimal solutions are ubiquitous, yet many are intractable when they involve constrained functions having many local optima and interacting, mixed-type variables.The differential evolution (DE) algorithm is a practical approach to global numerical optimization which is easy to understand, simple to implement, reliable, and fast. Packed with illustrations, computer code, new insights, and practical advice, this volume explores DE in both principle and practice. It is a valuable resource for professionals needing a proven optimizer and for students wanting an evolutionary perspective on global numerical optimization.", "doc-2": "Abstract The denaturation of DNA, brought about through the gradual withdrawal of electrolytes by dialysis of conc. solutions in the cold against distilled water for periods up to 216 h, was studied. In most experiments calf thymus DNA was employed; a few experiments were performed with Escherichia coli DNA. The principal criteria of the loss of secondary structure were the hyperchromicity, which amounted to an increase of 40 % over the initial e(P), and the precipitability with metal salts. The effects of denaturation could be abolished nearly completely or partially, depending upon the duration of dialysis, by the addition of NaCl, as shown by the behavior of the reconstituted products upon subsequent thermal denaturation. The differences between the denaturation of mammalian DNA by heat and by dialysis are underlined by the observation that when maximum hyperchromicity is reached, after a dialysis of 24 h, the addition of salt yields preparations exhibiting normal profiles of thermal denaturation. Though extended dialysis produces additional changes, not all reversible by salt, the renatured product, even after a dialysis of 216 h, exhibits, on being heated, a hyperchromic rise of which more than half occurs at the normal transition temperature (87). The view that the dialyzed preparations, even at their maximum hyperchromicity, do not exist as entirely segregated single strands is borne out by the finding that the fractional precipitation of denatured DNA by a variety of cations invariably yields preparations exhibiting full base-pairing and the unchanged dissymmetry ratios of the initial DNA.", "label": 0}
{"doc-1": "We quantified the biomass allocation patterns to leaves, stems and roots in vegetative plants, and how this is influenced by the growth environment, plant size, evolutionary history and competition. Dose-response curves of allocation were constructed by means of a meta-analysis from a wide array of experimental data. They show that the fraction of whole-plant mass represented by leaves (LMF) increases most strongly with nutrients and decreases most strongly with light. Correction for size-induced allocation patterns diminishes the LMF-response to light, but makes the effect of temperature on LMF more apparent. There is a clear phylogenetic effect on allocation, as eudicots invest relatively more than monocots in leaves, as do gymnosperms compared with woody angiosperms. Plants grown at high densities show a clear increase in the stem fraction. However, in most comparisons across species groups or environmental factors, the variation in LMF is smaller than the variation in one of the other components of the growth analysis equation: the leaf area : leaf mass ratio (SLA). In competitive situations, the stem mass fraction increases to a smaller extent than the specific stem length (stem length : stem mass). Thus, we conclude that plants generally are less able to adjust allocation than to alter organ morphology.", "doc-2": "We discuss experiments on dense packing of granular beads that are cyclically sheared quasi-statically between parallel walls under constant pressure boundary conditions. The particle positions inside the shear cell are tracked over several cycles in three dimensions using particle index-matching imaging technique. The total volume fraction of the particles  in the cell is observed to increase slowly over thousands of cycles from   0.59 to   0.63, while even slower growth in volume fraction is observed in the bulk away from boundaries. We illustrate with internal images that the difference arises due to inhomogeneity of packing with ordered regions developing progressively from the boundaries. We then focus in the bulk where the packing is uniformly disordered, and find that a linear bulk strain is observed within the first half of a cycle, which is reversed in the second half of the cycle. We present analysis of the trajectories of the particles within a shear cycle as well as over several cycles. We find anisotropic fluctuations relative to shear gradient within a cycle. However, homogeneous growth of mean square displacement when fluctuations are examined average over a cycle. The rate of growth is significantly lower leading us to hypothesize that granular matter under cyclic shear show reversible as well as irreversible or plastic response for small enough strain amplitude.", "label": 0}
{"doc-1": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].", "doc-2": "Psoriatic skin differs distinctly from normal skin by its thickened epidermis. Most gene expression comparisons utilize full-thickness biopsies, with substantial amount of dermis. We assayed the transcriptomes of normal, lesional, and non-lesional psoriatic epidermis, sampled as split-thickness skin grafts, with 5'-end RNA sequencing. We found that psoriatic epidermis contains more mRNA per total RNA than controls, and took this into account in the bioinformatic analysis. The approach highlighted innate immunity-related pathways in psoriasis, including NOD-like receptor (NLR) signaling and inflammasome activation. We demonstrated that the NLR signaling genes NOD2, PYCARD, CARD6, and IFI16 are upregulated in psoriatic epidermis, and strengthened these findings by protein expression. Interestingly, PYCARD, the key component of the inflammasome, showed an altered expression pattern in the lesional epidermis. The profiling of non-lesional skin highlighted PSORS4 and mitochondrially encoded transcripts, suggesting that their gene expression is altered already before the development of lesions. Our data suggest that all components needed for the active inflammasome are present in the keratinocytes of psoriatic skin. The characterization of inflammasome pathways provides further opportunities for therapy. Complementing previous transcriptome studies, our approach gives deeper insight into the gene regulation in psoriatic epidermis.", "label": 0}
{"doc-1": "A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known--a collaboration network and a food web--and find that it detects significant and informative community divisions in both cases.", "doc-2": "Increased exposure to nickel compounds and alloys due to industrial development has resulted in nickel pollution and many pathological effects on human health. However, there is very limited information about nickel response, transport, and tolerance in eukaryotes. To investigate nickel resistance in the model eukaryote Saccharomyces cerevisiae, evolutionary engineering by batch selection under gradually increasing nickel stress levels was performed. Nickel hyper-resistant mutants that could resist up to 5.3 mM NiCl2 , a lethal level for the reference strain, were selected. The mutants were also cross-resistant against iron, cobalt, zinc, and manganese stresses and accumulated more than twofold higher nickel than the reference strain. Global transcriptomic analysis revealed that 640 upregulated genes were related to iron homeostasis, stress response, and oxidative damage, implying that nickel resistance may share common mechanisms with iron and cobalt resistance, general stress response, and oxidative damage.", "label": 0}
{"doc-1": "An adaptationist programme has dominated evolutionary thought in England and the United States during the past 40 years. It is based on faith in the power of natural selection as an optimizing agent. It proceeds by breaking an oragnism into unitary 'traits' and proposing an adaptive story for each considered separately. Trade-offs among competing selective demands exert the only brake upon perfection; non-optimality is thereby rendered as a result of adaptation as well. We criticize this approach and attempt to reassert a competing notion (long popular in continental Europe) that organisms must be analysed as integrated wholes, with Bauplne so constrained by phyletic heritage, pathways of development and general architecture that the constraints themselves become more interesting and more important in delimiting pathways of change than the selective force that may mediate change when it occurs. We fault the adaptationist programme for its failure to distinguish current utility from reasons for origin (male tyrannosaurs may have used their diminutive front legs to titillate female partners, but this will not explain why they got so small); for its unwillingness to consider alternatives to adaptive stories; for its reliance upon plausibility alone as a criterion for accepting speculative tales; and for its failure to consider adequately such competing themes as random fixation of alleles, production of non-adaptive structures by developmental correlation with selected features (allometry, pleiotropy, material compensation, mechanically forced correlation), the separability of adaptation and selection, multiple adaptive peaks, and current utility as an epiphenomenon of non-adaptive structures. We support Darwin's own pluralistic approach to identifying the agents of evolutionary change.", "doc-2": "Background Measures for estimating costs associated with the provision of disability services in Australia have not previously been available. Because such instruments are scarce worldwide, decisions about funding services have relied more on historical precedent and less on individual need. Recognising the necessity for an objective measure, Gould (1998) developed the Service Need Assessment Profile (SNAP), a scale for estimating the support needs and associated costs for people with disabilities.Method This study examined the technical properties of SNAP using assessment data from 318 adults (190 males and 128 females), mean age 43 years, with a range of disability types and levels of severity, residing in supported accommodation around metropolitan Adelaide, South Australia.Results Results suggest that SNAP's reliability varies across different subgroups and across domains.Conclusion Using SNAP assessments as a method for allocating funds/resources across the disability sector should be approached cau...", "label": 0}
{"doc-1": "A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website.  The final author version and the galley proof are versions of the publication after peer review.  The final published version features the final layout of the paper including the volume, issue and page numbers.", "doc-2": "N-methyl-d-aspartate (NMDA) receptors and c-Jun N-terminal kinase (JNK) have been shown to be involved in morphine antinociceptive tolerance. However, whether chronic morphine-induced activation of the spinal JNK is NMDA receptor-dependent is unknown. The present study investigated the link between the spinal NMDA receptor NR2B subunit and the JNK activation during morphine antinociceptive tolerance in rats. Our results showed that chronic morphine treatment induced upregulation of the NR2B expression and activation of JNK in the spinal cord. Moreover, the increased NR2B-immunoreactivity (IR) and phosphorylated JNK-IR were observed mainly at the superficial dorsal horn laminae of the spinal cord; the spinal p-JNK was mainly expressed in astrocytes and NR2B in neurons. SP600125, a selective inhibitor of JNK, significantly attenuated morphine tolerance. MK-801, a noncompetitive NMDA receptor antagonist, not only suppressed morphine antinociceptive tolerance and the increase in NR2B, but also reduced the spinal JNK activation induced by chronic morphine treatment. These findings demonstrated for the first time that NMDA receptor-dependent activation of the spinal JNK contributes to morphine antinociceptive tolerance and that MK-801 attenuates morphine tolerance partly due to its inhibition on the spinal JNK activation.", "label": 0}
{"doc-1": "Functional magnetic resonance imaging (fMRI) is widely used to study the operational organization of the human brain, but the exact relationship between the measured fMRI signal and the underlying neural activity is unclear. Here we present simultaneous intracortical recordings of neural signals and fMRI responses. We compared local field potentials (LFPs), single- and multi-unit spiking activity with highly spatio-temporally resolved blood-oxygen-level-dependent (BOLD) fMRI responses from the visual cortex of monkeys. The largest magnitude changes were observed in LFPs, which at recording sites characterized by transient responses were the only signal that significantly correlated with the haemodynamic response. Linear systems analysis on a trial-by-trial basis showed that the impulse response of the neurovascular system is both animal- and site-specific, and that LFPs yield a better estimate of BOLD responses than the multi-unit responses. These findings suggest that the BOLD contrast mechanism reflects the input and intracortical processing of a given area rather than its spiking output.", "doc-2": "To shorten the development process of embedded vehicle navigation system,improve the maintenance of system and capability of upgrade,the characteristics of Android platform and the performance requirement of vehicle navigation system are researched.Based on Android operating system and GPS and GPRS technology,the software of vehicle navigation system is constructed.The platform of system and main modules are analyzed in detail.The result shows that the common structure of Android is used for developers to design application software of vehicle navigation,is easy to port and upgrade in different platforms.The system is proved to be designed fairy,and will be widely used in the future.", "label": 0}
{"doc-1": "We provide an updated version of the Compendium of Physical Activities, a coding scheme that classifies specific physical activity (PA) by rate of energy expenditure. It was developed to enhance the comparability of results across studies using self-reports of PA. The Compendium coding scheme links a five-digit code that describes physical activities by major headings (e.g., occupation, transportation, etc.) and specific activities within each major heading with its intensity, defined as the ratio of work metabolic rate to a standard resting metabolic rate (MET). Energy expenditure in MET-minutes, MET-hours, kcal, or kcal per kilogram body weight can be estimated for specific activities by type or MET intensity. Additions to the Compendium were obtained from studies describing daily PA patterns of adults and studies measuring the energy cost of specific physical activities in field settings. The updated version includes two new major headings of volunteer and religious activities, extends the number of specific activities from 477 to 605, and provides updated MET intensity levels for selected activities.", "doc-2": "This document evaluates candidate protocols against the NVO3requirements. Gaps are identified and further work recommended.", "label": 0}
{"doc-1": "Abstract Electronically available data on the Web is exploding at an ever increasing pace. Much of this data is unstructured, which makes searching hard and traditional database querying impossible. Many Web documents, however, contain an abundance of recognizable constants that together describe the essence of a document's content. For these kinds of data-rich, multiple-record documents (e.g., advertisements, movie reviews, weather reports, travel information, sports summaries, financial statements, obituaries, and many others) we can apply a conceptual-modeling approach to extract and structure data automatically. The approach is based on an ontology  a conceptual model instance  that describes the data of interest, including relationships, lexical appearance, and context keywords. By parsing the ontology, we can automatically produce a database scheme and recognizers for constants and keywords, and then invoke routines to recognize and extract data from unstructured documents and structure it according to the generated database scheme. Experiments show that it is possible to achieve good recall and precision ratios for documents that are rich in recognizable constants and narrow in ontological breadth. Our approach is less labor-intensive than other approaches that manually or semiautomatically generate wrappers, and it is generally insensitive to changes in Web-page format.", "doc-2": "Stories of conflict between saints and dragons flourished between the eighth and fourteenth centuries at the disputed boundary zone between folktale and hagiography. The presence of dragons at wells was an accepted image in vernacular culture, independently adopted by successive writers of saints' Lives to enliven stories about the spiritual power of their heroes and the pastoral and missionary work they performed. In the transition of hagiography from its Middle Eastern origins the dragon, originally a plausible desert snake, took on mythical status and became identified with social evils from paganism to corruption. Christian imagery of baptism involved a symbolic contrast of lethal and healing waters, given visual expression in the sculptural motif of a dragon encircling the font. But the story of the dragon-fight could carry multiple meanings. Earlier texts reflect a world in which clerical culture had to make headway against lay power, and the dragon is something to be banished, like the aggressive c...", "label": 0}
{"doc-1": "Since 1922 when Wu proposed the use of the Folin phenol reagent for the measurement of proteins, a number of modified analytical procedures utilizing this reagent have been reported for the determination of proteins in serum, in antigen-antibody precipitates, and in insulin. Although the reagent would seem to be recommended by its great sensitivity and the simplicity of procedure possible with its use, it has not found great favor for general biochemical purposes. In the belief that this reagent, nevertheless, has considerable merit for certain application, but that its peculiarities and limitations need to be understood for its fullest exploitation, it has been studied with regard to effects of variations in pH, time of reaction, and concentration of reactants, permissible levels of reagents commonly used in handling proteins, and interfering substances. Procedures are described for measuring protein in solution or after precipitation with acids or other agents, and for the determination of as little as 0.2 gamma of protein.", "doc-2": "Abstract It has been shown that the properties of charcoal with respect to adsorption may be modified by pretreatment with a saturator in order to achieve satisfactory chromatographic resolution of the substances to be analysed. The bulk of the more strongly adsorbed material can be separated from other components by sectional displacement and/or rechromatography on more highly saturated columns. The concentration of the saturator must be fixed close to the critical saturation point , which is the concentration of the saturator above which the highly adsorbed component begins to appear in the eluate. By this procedure, elution and displacement analyses of insulin have been performed, whereby it was demonstrated that the hormone exhibits chromatographic homogeneity. Adrenocorticotropic peptides have also been investigated, and it has been found that a 5-fold purification from a starting material having a potency of approximately 50 U.S.P. units per mg can be achieved by the new procedures herein described.", "label": 0}
{"doc-1": "Molecular analysis of blood samples is pivotal to clinical diagnosis and has been intensively investigated since the rise of systems biology. Recent developments have opened new opportunities to utilize transcriptomics and metabolomics for personalized and precision medicine. Efforts from human immunology have infused into this area exquisite characterizations of subpopulations of blood cells. It is now possible to infer from blood transcriptomics, with fine accuracy, the contribution of immune activation and of cell subpopulations. In parallel, high-resolution mass spectrometry has brought revolutionary analytical capability, detecting >10,000 metabolites, together with environmental exposure, dietary intake, microbial activity, and pharmaceutical drugs. Thus, the re-examination of blood chemicals by metabolomics is in order. Transcriptomics and metabolomics can be integrated to provide a more comprehensive understanding of the human biological states. We will review these new data and methods and discuss how they can contribute to personalized medicine.", "doc-2": "The modified differential ground fault protection system is discussed for the purpose of illustrating that: such systems are suitable for application on service equipment having multiple sources of electrical power, each of which may have multiple grounds; such systems may be applied using conventional equipment that is currently available from several suppliers; such systems can meet requirements for generator grounding without the use of four-pole transfer switches and switched neutrals; and such systems may be analyzed for effectiveness using conventional circuit analysis techniques.<<ETX>>", "label": 0}
{"doc-1": "The comparison of two treatments generally falls into one of the following two categories: (a) we may have a number of replications for each of the two treatments, which are unpaired, or (b) we may have a number of paired comparisons leading to a series of differences, some of which may be positive and some negative. The appropriate methods for testing the significance of the differences of the means in these two cases are described in most of the textbooks on statistical methods.", "doc-2": "The authors compared the composition and density of the on-site vegetation, seed bank, and seed rain of three geomorphic and successional surfaces along third- and fifth- order streams on the western slope of the Cascade Range in Oregon. The on-site vegetation generally was dominated by tree species, the seed bank by herb species, and the seed rain by tree and herb species. Seed rain density generally correspond to the successional stage of the geomorphic surface and frequency of site disturbance, with the youngest and least vegetatively stable geomorphic surfaces having the highest density of trapped viable seeds. The highest density and greatest species richness of seed germinants were found on the intermediate-aged geomorphic surfaces, which had moderate levels of disturbance.", "label": 0}
{"doc-1": "Introduction Conclusions References", "doc-2": "BACKGROUND AND OBJECTIVESThe Italian Society of Hematology (SIE) and the two affiliated Societies (SIES and GITMO) commissioned a project to develop guidelines for the therapy of essential thrombocythemia (ET) using evidence-based knowledge and consensus formation techniques.DESIGN AND METHODSKey questions on the optimal management of ET patients were formulated by an Advisory Council (AC) and approved by an Expert Panel (EP) composed of 7 senior hematologists. The AC systematically reviewed the published literature from 1980 to August 2002, and articles were graded according to their internal validity and quality. Using the Delphi technique, the EP was asked to answer the key questions according to the available evidence. From September 2002 to March 2003, four Consensus Conferences were held in accordance with the Nominal Group Technique with the goal of solving residual disagreement on recommendations.RESULTSThe EP provided recommendations on when to start platelet-lowering therapy, the most appropriate platelet-lowering agent, the use of anti-platelet therapy, and the management of women in childbearing age and of pregnant women.INTERPRETATION AND CONCLUSIONSBy using evidence and consensus, recommendations for the treatment of key problems in ET have been issued. Statements are graded according to the strength of the supporting evidence and uncertainty is explicitly declared.", "label": 0}
{"doc-1": "1. Introduction to probabilities, graphs, and causal models 2. A theory of inferred causation 3. Causal diagrams and the identification of causal effects 4. Actions, plans, and direct effects 5. Causality and structural models in the social sciences 6. Simpson's paradox, confounding, and collapsibility 7. Structural and counterfactual models 8. Imperfect experiments: bounds and counterfactuals 9. Probability of causation: interpretation and identification Epilogue: the art and science of cause and effect.", "doc-2": "Wireless Mesh Network (WMN) provides a cheaper option for backhauls that can be leveraged to provide low-cost access services. Compared to conventional wireless LANs, the benefits of a WMN include greater range because of packet relaying, and higher throughput because of shorter hops. Typical WMN applications include intelligent transportation, public safety, sensing backbone, and community access [1]. For example, as of the end of 2006, there were over 300 cities and counties in the US with municipal wireless networks up and running, or in the deployment or planning phase (Figure 1).", "label": 0}
{"doc-1": "Model Notation, Covariances, and Path Analysis. Causality and Causal Models. Structural Equation Models with Observed Variables. The Consequences of Measurement Error. Measurement Models: The Relation Between Latent and Observed Variables. Confirmatory Factor Analysis. The General Model, Part I: Latent Variable and Measurement Models Combined. The General Model, Part II: Extensions. Appendices. Distribution Theory. References. Index.", "doc-2": "The characteristics of a H2O2 producing dielectric barrier discharge (DBD) at atmospheric pressure and room temperature is studied. The DBD operates at 30 to 60 kHz AC voltages and at powers up to 2 W. The volume of the plasma is small (0.35 cm). Humid helium and a mixture of helium with 2% H2 and 2% O2 are used. The focus of this study is on the efficiency of the process. H2O2 production is measured in the liquid phase using a spectrophotometric method which uses the reaction of H2O2 with ammonium metavanadate. Powers are calculated using Lissajous figures from the voltage V (t) plotted versus the charge C(t) in the DBD. The gas temperature was firstly obtained by acquiring the rotational temperature of N2 by fitting the N2(C-B)(0-0) rotational band and secondly by obtaining a Boltzmann plot of resolved rotational OH(A-X) lines. A temperature of 350  50 K is found. Any fluctuations of the temperature remained within the experimental accuracy therefore no temperature dependency of the efficiency is determined. Using humid helium it is shown that the production increases with power and water content. The efficiency shows a peak around 1 watt and saturation at higher powers. Agains expectations using pulsed power decreases the production and efficiency. Using the H2O2 mixture it is shown that the production is not dependent on the power. With a pulsed power applied the production increases, in contrary to the humid helium. The results indicate that a minimum residence time is needed for an efficient H2O2 production. Comparison with literature confirms this result. This work is part of a 10 weeks long internship for the concluding project of the bachelor Applied Physics. The research is done in the framework of a STW project and a PhD thesis on the production of hydrogen peroxide.", "label": 0}
{"doc-1": "The literature indicates that dysfunctional individual and organizational consequences result from the existence of role conflict and role ambiguity in complex organizations. Yet, systematic measurement and empirical testing of these role constructs is lacking. This study describes the development and testing of questionnaire measures of role conflict and ambiguity. Analyses of responses of managers show these two constructs to be factorially identifiable and independent. Derived measures of role conflict and ambiguity tend to correlate in two samples in expected directions with measures of organizational and managerial practices and leader behavior, and with member satisfaction, anxiety, and propensity to leave the organization.", "doc-2": "The legal profession was hit particularly hard by the recent recession. Law firms laid off lawyers in record numbers, and law school graduates found few if any employment opportunities. Clients also started rethinking the terms of the lawyer-client relationship, at least in the larger law firm context. Some commentators suggest that these changes are indicative of things to come; that the legal profession is undergoing a long-overdue paradigm shift that will permanently change the nature of the legal profession. This Essay examines these developments through the lens of Larry Ribsteins The Death of Big Law and Richard Susskinds The End of Lawyers?: Rethinking the Nature of Legal Services. It compares and contrasts Ribsteins and Susskinds analyses of the profession and assesses potential lessons for lawyers, clients, and legal educators. This Essay concludes by encouraging professionals to remain open to changes that improve efficiency and client service. It also stresses the value of preserving and promoting the hallmark of being a lawyer - that is, thinking like a lawyer.", "label": 0}
{"doc-1": "Computational evolutionary biology, statistical phylogenetics and coalescent-based population genetics are becoming increasingly central to the analysis and understanding of molecular sequence data. We present the Bayesian Evolutionary Analysis by Sampling Trees (BEAST) software package version 1.7, which implements a family of Markov chain Monte Carlo (MCMC) algorithms for Bayesian phylogenetic inference, divergence time dating, coalescent analysis, phylogeography and related molecular evolutionary analyses. This package includes an enhanced graphical user interface program called Bayesian Evolutionary Analysis Utility (BEAUti) that enables access to advanced models for molecular sequence and phenotypic trait evolution that were previously available to developers only. The package also provides new tools for visualizing and summarizing multispecies coalescent and phylogeographic analyses. BEAUti and BEAST 1.7 are open source under the GNU lesser general public license and available at http://beast-mcmc.googlecode.com and http://beast.bio.ed.ac.uk.", "doc-2": "Lymph was collected from renal capsular lymphatics in anesthetized dogs before, during and after periods of raised venous pressure produced by partial occlusion of the inferior vena cava. Renal lymph flow increased about five times during the period of elevated pressure. Electrolytes and protein flows changed proportionately except at high venous pressure (3035 cm H2O) when disproportionately high levels of protein were found in renal lymph. Urine flow and sodium excretion decreased during the periods of elevated venous pressure. With increased venous pressure, lymph flow in one lymphatic may equal or exceed urine flow from the ureter of the same kidney. The results are interpreted as supporting the countercurrent hypothesis of urine formation and as indicating a possible role of the renal lymphatics in renal diseases and in the retention of sodium and water found in congestive heart failure.", "label": 0}
{"doc-1": "SummaryA new statistical method for estimating divergence dates of species from DNA sequence data by a molecular clock approach is developed. This method takes into account effectively the information contained in a set of DNA sequence data. The molecular clock of mitochondrial DNA (mtDNA) was calibrated by setting the date of divergence between primates and ungulates at the Cretaceous-Tertiary boundary (65 million years ago), when the extinction of dinosaurs occurred. A generalized leastsquares method was applied in fitting a model to mtDNA sequence data, and the clock gave dates of 92.311.7, 13.31.5, 10.91.2, 3.70.6, and 2.70.6 million years ago (where the second of each pair of numbers is the standard deviation) for the separation of mouse, gibbon, orangutan, gorilla, and chimpanzee, respectively, from the line leading to humans. Although there is some uncertainty in the clock, this dating may pose a problem for the widely believed hypothesis that the bipedal creatureAustralopithecus afarensis, which lived some 3.7 million years ago at Laetoli in Tanzania and at Hadar in Ethiopia, was ancestral to man and evolved after the human-ape splitting. Another likelier possibility is that mtDNA was transferred through hybridization between a proto-human and a protochimpanzee after the former had developed bipedalism.", "doc-2": "Objective and designYKL-40 is involved in inflammation and endothelial dysfunction, and is increased in patients with type 1 diabetes, with an independent association between increasing YKL-40 levels and increasing levels of albuminuria. YKL-40 is associated with atherosclerosis and an increased cardiovascular mortality in the general population. In the present study YKL-40 levels were examined in patients with type 2 diabetes (T2D) with increasing levels of albuminuria, known to be associated with an increased risk of cardiovascular disease.Materials and methodsOne-hundred-five patients with T2D were examined: 49 with normoalbuminuria (N, U-albumin/creatinine < 2.5 mg/mmol), 35 with persistent microalbuminuria (MA, 2.5-25 mg/mmol) and 21 with persistent macroalbuminuria/diabetic nephropathy (DN, > 25 mg/mmol). The control group consisted of 20 healthy individuals (C). Groups were matched according to age, gender and known duration of diabetes.ResultsMedian levels (interquartile range) of serum YKL-40 were significantly higher in N and MA vs. C (86 (55-137) ng/ml and 84 (71-147) ng/ml, respectively vs. 41 (33-55) ng/ml, p < 0.01) and even higher in patients with DN (120 (83-220) ng/ml, p < 0.001 for all comparisons). YKL-40 levels correlated with urinary albumin/creatinine-ratio in the total group of participants (r = 0.41, p < 0.001). Significant intercorrelations of YKL-40 were found with age, duration of diabetes, systolic blood pressure, lipid levels, HbA1c and HOMA-IR. After adjustment for significant covariates, albuminuria was significantly associated with YKL-40 levels (r = 0.32, p = 0.006).ConclusionsYKL-40 levels are elevated in patients with T2D with an independent association between increasing YKL-40 levels and increasing levels of albuminuria. The study suggests a role of YKL-40 in the progressing vascular complications in patients with T2D.", "label": 0}
{"doc-1": "Modern embedded computing systems tend to be heterogeneous in the sense of being composed of subsystems with very different characteristics, which communicate and interact in a variety of ways-synchronous or asynchronous, buffered or unbuffered, etc. Obviously, when designing such systems, a modeling language needs to reflect this heterogeneity. Today's modeling environments usually offer a variant of what we call amorphous heterogeneity to address this problem. This paper argues that modeling systems in this manner leads to unexpected and hard-to-analyze interactions between the communication mechanisms and proposes a more structured approach to heterogeneity, called hierarchical heterogeneity, to solve this problem. It proposes a model structure and semantic framework that support this form of heterogeneity, and discusses the issues arising from heterogeneous component interaction and the desire for component reuse. It introduces the notion of domain polymorphism as a way to address these issues.", "doc-2": "Abstract Coulter counters (a.k.a. resistive pulse sensors) were widely used to measure the size of biological cells and colloidal particles. One of the important parameters of Coulter counters is its size discriminative capability. This work reports a multiple pore-based microfluidic Coulter counter for improved size differentiation in a mixed sample. When a single particle translocated across an array of sensing pores, multiple time-related resistive pulse signals were generated. Due to the time correlation of these resistive pulse signals, we found a multiple cross-correlation analysis (MCCA) could enhance the sizing signal-to-noise ( SNR ) ratio by a factor of n 1/2 , where n is the pore numbers in series. This proof-of-concept is experimentally validated with polystyrene beads as well as human red blood cells. We anticipate this method would be highly beneficial for applications where improved size differentiation is required.", "label": 0}
{"doc-1": "Tumor necrosis factor-alpha (TNF-alpha) has been shown to have certain catabolic effects on fat cells and whole animals. An induction of TNF-alpha messenger RNA expression was observed in adipose tissue from four different rodent models of obesity and diabetes. TNF-alpha protein was also elevated locally and systemically. Neutralization of TNF-alpha in obese fa/fa rats caused a significant increase in the peripheral uptake of glucose in response to insulin. These results indicate a role for TNF-alpha in obesity and particularly in the insulin resistance and diabetes that often accompany obesity.", "doc-2": "Preliminary sizing of the members of high-rise buildings for adaptation in Nigeria and other countries with similar earth tremor data is carried out in this work using the linear static (lateral force) method. The studied building model comprises a regular, symmetric 50 storey Steel Dual-Concentric (chevron) Brace Frame, SD-CBF. European wide flange beam section of HE220M, column section HE260M and brace section HE180B were realised as initial design sections which are structurally safe. Results indicate that the aforementioned sections, though structurally safe can be made more robust for greater safety by applying a factor of safety ranging from 1.25 to 1.5 depending on available investment and seismicity of the environment. This is to justify safety of lives and properties. Keywords : High-rise, Earth-tremor, Linear Static Method and SD-CBF.", "label": 0}
{"doc-1": "Psychophysical and physiological evidence indicates that the visual system of primates and humans has evolved a specialized processing focus moving across the visual scene. This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention. Specifically, we propose the following: (1) A number of elementary features, such as color, orientation, direction of movement, disparity etc. are represented in parallel in different topographical maps, called the early representation. (2) There exists a selective mapping from the early topographic representation into a more central non-topographic representation, such that at any instant the central representation contains the properties of only a single location in the visual scene, the selected location. We suggest that this mapping is the principal expression of early selective visual attention. One function of selective attention is to fuse information from different maps into one coherent whole. (3) Certain selection rules determine which locations will be mapped into the central representation. The major rule, using the conspicuity of locations in the early representation, is implemented using a so-called Winner-Take-All network. Inhibiting the selected location in this network causes an automatic shift towards the next most conspicious location. Additional rules are proximity and similarity preferences. We discuss how these rules can be implemented in neuron-like networks and suggest a possible role for the extensive back-projection from the visual cortex to the LGN.", "doc-2": "Abstract This objective of this paper is to demonstrate that NMP is a viable pollution prevention alternative to methylene chloride. Marine Corps Logistics Base (MCLB), Albany, GA, USA was the host site for the demonstration. MCLB's primary function is maintenance of military ground support vehicles, electronic equipment, and small arms. These maintenance processes require the use of methylene chloride to depaint or strip metal parts. A full scale demonstration of NMP was performed at the host site, which included equipment retrofits and material substitution. A cost analysis, using standard US EPA costing methods, was performed and emissions were estimated based on material usage. Results show that, based on the success measures and criteria established by MCLB, NMP is a satisfactory pollution prevention alternative to methylene chloride.", "label": 0}
{"doc-1": "On the basis of computational studies it has been proposed that the central nervous system internally simulates the dynamic behavior of the motor system in planning, control, and learning; the existence and use of such an internal model is still under debate. A sensorimotor integration task was investigated in which participants estimated the location of one of their hands at the end of movements made in the dark and under externally imposed forces. The temporal propagation of errors in this task was analyzed within the theoretical framework of optimal state estimation. These results provide direct support for the existence of an internal model.", "doc-2": "Spiroperidol binding in the substantia nigra and QNB anda-bungarotoxin (a-Btx) binding in the neostriatum were measured in rats with lesions designed to produce selective alterations in pre- and postsynaptic neuronal processes. The objective was to determine whether presynaptic receptor sites may exist for dendritically released transmitters. Spiroperidol was used to measure dopaminergic receptor sites while QNB anda-Btx were used to measure muscarinic and nicotinic cholinergic receptor sites, respectively. The binding results were correlated with measurements on the individual striata of tyrosine hydroxylase (as an index of the integrity of nigrostriatal dopaminergic neurons) and of glutamic acid decarylase (as an index of the integrity of striatal interneurons and descending striatonigral pathways). The results indicate that muscarinic receptor sites in the striatum are on neuronal perikarya or dendrites but nicotinic receptor sites are on afferent dopaminergic and corticostriatal neurons; in the substantia nigra spiroperidol binding is on afferent striatonigral neurons. The results, together with available biochemical and morphological data, are used to support the hypothesis that communication at many CNS synapses may involve a neurotransmitter dialog rather than a monolog. If true, this will affect interpretations of many pharmacological, behavioral and physiological experiments.", "label": 0}
{"doc-1": "Human alteration of Earth is substantial and growing. Between one-third and one-half of the land surface has been transformed by human action; the carbon dioxide concentration in the atmosphere has increased by nearly 30 percent since the beginning of the Industrial Revolution; more atmospheric nitrogen is fixed by humanity than by all natural terrestrial sources combined; more than half of all accessible surface fresh water is put to use by humanity; and about one-quarter of the bird species on Earth have been driven to extinction. By these and other standards, it is clear that we live on a human-dominated planet.", "doc-2": "Xavier Lafon, La voie littorale Sperlonga, Gaeta, Formia, p. 399-429. ; ; La voie littorale Sperlonga-Gaeta appelee communement Via Flacca est connue depuis longtemps en raison des restes importants encore conserves. Cette etude a donc pour but d'essayer de comprendre quand et pourquoi cette route a ete construite, en etudiant les structures encore visibles, son trace dans le cadre a la fois geographique et historique de cette zone du Latium meridional, et de confronter ces donnees a celles fournies par les textes, en particulier Tite-Live. ; Ainsi se trouve precise le cadre dans lequel ont pu commencer a se developper a partir du IIe siecle av. J.-C. les nombreuses villae qui jalonnent son parcours.", "label": 0}
{"doc-1": "Valid measurement scales for predicting user acceptance of computers are in short supply. Most subjective measures used in practice are unvalidated, and their relationship to system usage is unknown. The present research develops and validates new scales for two specific variables, perceived usefulness and perceived ease of use, which are hypothesized to be fundamental determinants of user acceptance. Definitions of these two variables were used to develop scale items that were pretested for content validity and then tested for reliability and construct validity in two studies involving a total of 152 users and four application programs. The measures were refined and streamlined, resulting in two six-item scales with reliabilities of .98 for usefulness and .94 for ease of use. The scales exhibited hgih convergent, discriminant, and factorial validity. Perceived usefulness was significnatly correlated with both self-reported current usage r = .63, Study 1) and self-predicted future usage r = .85, Study 2). Perceived ease of use was also significantly correlated with current usage r = .45, Study 1) and future usage r = .59, Study 2). In both studies, usefulness had a signficnatly greater correaltion with usage behavior than did ease of use. Regression analyses suggest that perceived ease of use may actually be a causal antecdent to perceived usefulness, as opposed to a parallel, direct determinant of system usage. Implications are drawn for future research on user acceptance.", "doc-2": "Background: Thyroid autoimmunity can cause several forms of thyroid disorders i.e. Graves disease, Hashimotos thyroiditis, atrophic autoimmune thyroiditis, post-partum thyroidits etc. Cytological diagnosis may be sometimes difficult is some cases. In such conditions, cytology along with serological tests aid at reaching a correct diagnosis.Hence, this study was undertaken to evaluate the serum level of anti-TPO antibody with respect to serum concentrations of thyroid hormones and its importance in diagnosing autoimmune thyroiditis. Material and Methods: This study was carried out in the department of pathology from June 2013-May 2014. Patients coming to the department of pathology TUTH, Maharajgunj for FNA of thyroid were included. TFT level was noted and anti TPO antibody level was evaluated by CLIA. Results: Ninety-five thyroid FNAC was included in the study, which comprises of 16.8 % males and 83.2% females with a M: F 1: 4.9. Maximum number of cases was seen in the age range 21-30 years (25.3%), mean age being 40.4years. The cytological diagnosis comprised colloid goiter(43.2%), lymphocytic thyroiditis (25.3%), Hashimoto thyroiditis(18.9%). Out of 42 cases of autoimmune thyroiditis diagnosed cytologically, 16 (38%) were hypothyroid, 4 (9.5%) hyperthyroid, 8 (19%) sub-clinical hypothyroid and 14 (33.5%) were euthyroid. The sensitivity and specificity of positive anti TPO in correctly identifying autoimmune thyroiditis was 85.7% and 79.2% respectively. The positive and negative predictive value for the test was 76.5% and 87.5% respectively. Conclusion: Nodular goitre can harbour a certain per cent of autoimmune thyroiditis and in such cases anti TPO antibody level along with cytodiagnosis appears to be helpful.", "label": 0}
{"doc-1": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed.", "doc-2": "Abstract Microspectrophotometric analysis of Feulgen-stained nuclei of the terminal follicle cells in the cockroach Leucophaea maderae showed that during maturation the follicle cells became polyploid. In virgin females, the follicle cell nuclei were diploid. After mating, and during vitellogenesis, the ploidy of the follicle cells increased from 2 C to 32 C with a small percentage of 64 C nuclei. There was no further increase in the ploidy levels during the chorionic stage of development. Injections of juvenile hormone III into decapitated virgin females elevated the ploidy levels in the follicle cells. The DNA content of these nuclei at 96120 h after injection of juvenile hormone III increased from 2 C to 4 C. Such polyploidization of nuclei was dose-dependent with the highest DNA content occurring in response to 2550 g juvenile hormone III. The juvenile hormone-induced increase in DNA content correlated with an increase in the rate of [ 3 H]thymidine incorporation into DNA. Our data suggest that the role of juvenile hormone in follicle cell development during the vitellogenic period, whether direct or indirect, is to promote selectively a large increase in the DNA content of the cells. This may facilitate the next stage of follicle cell development, choriogenesis.", "label": 0}
